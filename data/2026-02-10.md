<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 205]
- [cs.CL](#cs.CL) [Total: 96]
- [cs.AI](#cs.AI) [Total: 113]
- [cs.SE](#cs.SE) [Total: 19]
- [cs.NI](#cs.NI) [Total: 15]
- [cs.SI](#cs.SI) [Total: 6]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Scalable spatial point process models for forensic footwear analysis](https://arxiv.org/abs/2602.07006)
*Alokesh Manna,Neil Spencer,Dipak K. Dey*

Main category: cs.CV

TL;DR: 提出了一种用于量化鞋印偶然特征稀有性的分层贝叶斯模型，通过潜在高斯模型和空间变化系数改进法医鞋印分析的准确性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 在法医调查中，鞋印证据至关重要，但仅匹配鞋子的品牌和型号不足以确定嫌疑人的鞋子，因为同一型号可能生产数千双。需要分析鞋底上的"偶然特征"（如划痕、磨损等）的稀有性来量化证据强度。

Method: 开发了分层贝叶斯模型，采用潜在高斯模型框架，通过集成嵌套拉普拉斯近似实现大规模标注鞋印数据的高效推理，并引入空间变化系数来建模鞋底花纹图案与偶然特征位置之间的关系。

Result: 在保留数据上表现出优越性能，提高了法医鞋印分析的准确性和可靠性。

Conclusion: 该分层贝叶斯模型通过先进的统计方法改进了现有技术，能够更准确地量化鞋印偶然特征的稀有性，从而增强法医证据的强度评估。

Abstract: Shoe print evidence recovered from crime scenes plays a key role in forensic investigations. By examining shoe prints, investigators can determine details of the footwear worn by suspects. However, establishing that a suspect's shoes match the make and model of a crime scene print may not be sufficient. Typically, thousands of shoes of the same size, make, and model are manufactured, any of which could be responsible for the print. Accordingly, a popular approach used by investigators is to examine the print for signs of ``accidentals,'' i.e., cuts, scrapes, and other features that accumulate on shoe soles after purchase due to wear. While some patterns of accidentals are common on certain types of shoes, others are highly distinctive, potentially distinguishing the suspect's shoe from all others. Quantifying the rarity of a pattern is thus essential to accurately measuring the strength of forensic evidence. In this study, we address this task by developing a hierarchical Bayesian model. Our improvement over existing methods primarily stems from two advancements. First, we frame our approach in terms of a latent Gaussian model, thus enabling inference to be efficiently scaled to large collections of annotated shoe prints via integrated nested Laplace approximations. Second, we incorporate spatially varying coefficients to model the relationship between shoes' tread patterns and accidental locations. We demonstrate these improvements through superior performance on held-out data, which enhances accuracy and reliability in forensic shoe print analysis.

</details>


### [2] [Where Not to Learn: Prior-Aligned Training with Subset-based Attribution Constraints for Reliable Decision-Making](https://arxiv.org/abs/2602.07008)
*Ruoyu Chen,Shangquan Sun,Xiaoqing Guo,Sanyi Zhang,Kangwei Liu,Shiming Liu,Zhangcheng Wang,Qunli Zhang,Hua Zhang,Xiaochun Cao*

Main category: cs.CV

TL;DR: 提出基于归因的人类先验对齐方法，通过惩罚偏离人类先验区域的模型决策证据，提高模型决策的可靠性和准确性


<details>
  <summary>Details</summary>
Motivation: 传统监督学习仅提供类别标签，模型可能通过捷径相关性而非预期证据实现高准确率。人类先验可以帮助约束这种行为，但模型学习到的表示往往与人类感知存在偏差，对齐模型与人类先验仍然具有挑战性。

Method: 提出基于归因的人类先验对齐方法：将人类先验编码为模型预期依赖的输入区域（如边界框），利用高保真度的基于子集选择的归因方法在训练中暴露模型的决策证据。当归因区域显著偏离先验区域时，惩罚对非先验证据的依赖，促使模型将归因转向预期区域，通过训练目标施加人类先验诱导的归因约束。

Result: 在基于MLLM的GUI代理模型的图像分类和点击决策任务上验证了该方法。在传统分类和自回归生成设置中，人类先验对齐一致提高了任务准确性，同时增强了模型决策的合理性。

Conclusion: 基于归因的人类先验对齐方法能够有效约束模型依赖预期证据进行决策，提高模型可靠性和决策合理性，在多种任务设置中均表现出良好效果。

Abstract: Reliable models should not only predict correctly, but also justify decisions with acceptable evidence. Yet conventional supervised learning typically provides only class-level labels, allowing models to achieve high accuracy through shortcut correlations rather than the intended evidence. Human priors can help constrain such behavior, but aligning models to these priors remains challenging because learned representations often diverge from human perception. To address this challenge, we propose an attribution-based human prior alignment method. We encode human priors as input regions that the model is expected to rely on (e.g., bounding boxes), and leverage a highly faithful subset-selection-based attribution approach to expose the model's decision evidence during training. When the attribution region deviates substantially from the prior regions, we penalize reliance on off-prior evidence, encouraging the model to shift its attribution toward the intended regions. This is achieved through a training objective that imposes attribution constraints induced by the human prior. We validate our method on both image classification and click decision tasks in MLLM-based GUI agent models. Across conventional classification and autoregressive generation settings, human prior alignment consistently improves task accuracy while also enhancing the model's decision reasonability.

</details>


### [3] [MAU-GPT: Enhancing Multi-type Industrial Anomaly Understanding via Anomaly-aware and Generalist Experts Adaptation](https://arxiv.org/abs/2602.07011)
*Zhuonan Wang,Zhenxuan Fan,Siwen Tan,Yu Zhong,Yuqian Yuan,Haoyuan Li,Hao Jiang,Wenqiao Zhang,Feifei Shao,Hongwei Wang,Jun Xiao*

Main category: cs.CV

TL;DR: 提出了MAU-Set数据集和MAU-GPT模型，用于解决工业异常检测中数据集覆盖不足和模型泛化能力差的问题，通过多领域数据集和新型适应机制显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 随着工业制造规模扩大，自动化细粒度产品图像分析对质量控制变得至关重要。现有方法受限于数据集覆盖不足和模型对多样化复杂异常模式的泛化能力差。

Method: 1) 引入MAU-Set数据集，涵盖多个工业领域，具有从二元分类到复杂推理的分层任务结构；2) 建立严格的评估协议；3) 提出MAU-GPT模型，采用新颖的AMoE-LoRA机制，统一异常感知和通用专家适应，增强对不同缺陷类的理解和推理能力。

Result: 大量实验表明，MAU-GPT在所有领域都持续优于先前的最先进方法，展示了在可扩展自动化工业检测方面的强大潜力。

Conclusion: MAU-Set数据集和MAU-GPT模型有效解决了工业异常检测中的关键挑战，通过全面的数据集和创新的适应机制显著提升了模型性能，为工业自动化检测提供了有力工具。

Abstract: As industrial manufacturing scales, automating fine-grained product image analysis has become critical for quality control. However, existing approaches are hindered by limited dataset coverage and poor model generalization across diverse and complex anomaly patterns. To address these challenges, we introduce MAU-Set, a comprehensive dataset for Multi-type industrial Anomaly Understanding. It spans multiple industrial domains and features a hierarchical task structure, ranging from binary classification to complex reasoning. Alongside this dataset, we establish a rigorous evaluation protocol to facilitate fair and comprehensive model assessment. Building upon this foundation, we further present MAU-GPT, a domain-adapted multimodal large model specifically designed for industrial anomaly understanding. It incorporates a novel AMoE-LoRA mechanism that unifies anomaly-aware and generalist experts adaptation, enhancing both understanding and reasoning across diverse defect classes. Extensive experiments show that MAU-GPT consistently outperforms prior state-of-the-art methods across all domains, demonstrating strong potential for scalable and automated industrial inspection.

</details>


### [4] [A General Model for Retinal Segmentation and Quantification](https://arxiv.org/abs/2602.07012)
*Zhonghua Wang,Lie Ju,Sijia Li,Wei Feng,Sijin Zhou,Ming Hu,Jianhao Xiong,Xiaoying Tang,Yifan Peng,Mingquan Lin,Yaodong Ding,Yong Zeng,Wenbin Wei,Li Dong,Zongyuan Ge*

Main category: cs.CV

TL;DR: RetSAM是一个通用的视网膜分割和量化框架，通过深度学习在超过20万张眼底图像上训练，能够分割多种解剖结构和病变，并提取30多种标准化生物标志物，显著提升了分割性能。


<details>
  <summary>Details</summary>
Motivation: 视网膜成像快速、无创且广泛可用，为眼科和全身健康评估提供了可量化的结构和血管信号。然而，由于公共多标签数据集的有限性和缺乏统一的分割到量化流程，大规模分析仍然困难。

Method: 提出RetSAM框架，采用多阶段训练策略，结合私有和公共眼底数据，支持三类任务：分割五种解剖结构、四种视网膜表型模式和20多种不同病变类型，并将分割结果转化为30多种标准化生物标志物。

Result: 在17个公共数据集上实现了优越的分割性能，平均DSC比先前最佳方法提高3.9个百分点，在具有挑战性的多任务基准上提升高达15个百分点，在不同人群、成像设备和临床环境中具有良好的泛化能力。

Conclusion: RetSAM将眼底图像转化为标准化、可解释的定量表型，支持大规模眼科研究和转化，特别是对糖尿病视网膜病变、年龄相关性黄斑变性、青光眼和病理性近视等主要眼科疾病的系统性相关性分析。

Abstract: Retinal imaging is fast, non-invasive, and widely available, offering quantifiable structural and vascular signals for ophthalmic and systemic health assessment. This accessibility creates an opportunity to study how quantitative retinal phenotypes relate to ocular and systemic diseases. However, such analyses remain difficult at scale due to the limited availability of public multi-label datasets and the lack of a unified segmentation-to-quantification pipeline. We present RetSAM, a general retinal segmentation and quantification framework for fundus imaging. It delivers robust multi-target segmentation and standardized biomarker extraction, supporting downstream ophthalmologic studies and oculomics correlation analyses. Trained on over 200,000 fundus images, RetSAM supports three task categories and segments five anatomical structures, four retinal phenotypic patterns, and more than 20 distinct lesion types. It converts these segmentation results into over 30 standardized biomarkers that capture structural morphology, vascular geometry, and degenerative changes. Trained with a multi-stage strategy using both private and public fundus data, RetSAM achieves superior segmentation performance on 17 public datasets. It improves on prior best methods by 3.9 percentage points in DSC on average, with up to 15 percentage points on challenging multi-task benchmarks, and generalizes well across diverse populations, imaging devices, and clinical settings. The resulting biomarkers enable systematic correlation analyses across major ophthalmic diseases, including diabetic retinopathy, age-related macular degeneration, glaucoma, and pathologic myopia. Together, RetSAM transforms fundus images into standardized, interpretable quantitative phenotypes, enabling large-scale ophthalmic research and translation.

</details>


### [5] [Steering to Say No: Configurable Refusal via Activation Steering in Vision Language Models](https://arxiv.org/abs/2602.07013)
*Jiaxi Yang,Shicheng Liu,Yuchen Yang,Dongwon Lee*

Main category: cs.CV

TL;DR: CR-VLM提出了一种基于激活引导的可配置拒绝方法，通过教师强制机制提取可配置拒绝向量、门控机制防止过度拒绝，以及反事实视觉增强模块对齐视觉表示，实现更灵活、高效和鲁棒的视觉语言模型拒绝机制。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型（VLMs）的拒绝机制通常是"一刀切"的，无法适应不同用户需求和上下文约束，导致要么拒绝不足要么过度拒绝。需要一种可配置的拒绝方法来实现更灵活和负责任的安全对齐。

Method: CR-VLM包含三个核心组件：1）通过教师强制机制提取可配置拒绝向量以增强拒绝信号；2）引入门控机制保护范围内查询的接受性，防止过度拒绝；3）设计反事实视觉增强模块，将视觉表示与拒绝要求对齐。

Result: 在多个数据集和各种VLMs上的综合实验表明，CR-VLM实现了有效、高效和鲁棒的可配置拒绝，为VLMs中用户自适应的安全对齐提供了可扩展的路径。

Conclusion: CR-VLM通过激活引导方法实现了可配置的拒绝机制，解决了现有拒绝策略的局限性，为视觉语言模型提供了更灵活、用户自适应的安全对齐解决方案。

Abstract: With the rapid advancement of Vision Language Models (VLMs), refusal mechanisms have become a critical component for ensuring responsible and safe model behavior. However, existing refusal strategies are largely \textit{one-size-fits-all} and fail to adapt to diverse user needs and contextual constraints, leading to either under-refusal or over-refusal. In this work, we firstly explore the challenges mentioned above and develop \textbf{C}onfigurable \textbf{R}efusal in \textbf{VLM}s (\textbf{CR-VLM}), a robust and efficient approach for {\em configurable} refusal based on activation steering. CR-VLM consists of three integrated components: (1) extracting a configurable refusal vector via a teacher-forced mechanism to amplify the refusal signal; (2) introducing a gating mechanism that mitigates over-refusal by preserving acceptance for in-scope queries; and (3) designing a counterfactual vision enhancement module that aligns visual representations with refusal requirements. Comprehensive experiments across multiple datasets and various VLMs demonstrate that CR-VLM achieves effective, efficient, and robust configurable refusals, offering a scalable path toward user-adaptive safety alignment in VLMs.

</details>


### [6] [Vectra: A New Metric, Dataset, and Model for Visual Quality Assessment in E-Commerce In-Image Machine Translation](https://arxiv.org/abs/2602.07014)
*Qingyu Wu,Yuxuan Han,Haijun Li,Zhao Xu,Jianshan Zhao,Xu Jin,Longyue Wang,Weihua Luo*

Main category: cs.CV

TL;DR: Vectra是首个基于MLLM的无参考视觉质量评估框架，专门针对电商图像内机器翻译场景，通过14维可解释指标、大规模数据集和4B参数模型解决现有方法缺乏可解释性和细粒度奖励信号的问题。


<details>
  <summary>Details</summary>
Motivation: 现有电商图像内机器翻译研究主要关注机器翻译质量评估，而视觉渲染质量对用户参与度至关重要。当前基于参考的方法（如SSIM、FID）缺乏可解释性，而模型作为评判者的方法缺乏领域基础和细粒度奖励信号，特别是在面对上下文密集的产品图像和多模态缺陷时。

Method: Vectra框架包含三个核心组件：1) Vectra Score - 14维可解释质量度量系统，通过空间感知的缺陷面积比量化减少标注歧义；2) Vectra Dataset - 从110万真实产品图像构建的数据集，包含2K基准测试集、30K推理标注和3.5K专家偏好标注；3) Vectra Model - 40亿参数的多模态大语言模型，能生成定量分数和诊断推理。

Result: 实验表明Vectra在人类排名相关性方面达到最先进水平，其模型在评分性能上超越了包括GPT-5和Gemini-3在内的领先MLLMs。

Conclusion: Vectra填补了电商图像内机器翻译视觉质量评估的空白，提供了首个无参考、MLLM驱动的评估框架，通过可解释的维度分解、大规模数据集和强大的模型实现了优越的性能，数据集和模型将在论文接受后发布。

Abstract: In-Image Machine Translation (IIMT) powers cross-border e-commerce product listings; existing research focuses on machine translation evaluation, while visual rendering quality is critical for user engagement. When facing context-dense product imagery and multimodal defects, current reference-based methods (e.g., SSIM, FID) lack explainability, while model-as-judge approaches lack domain-grounded, fine-grained reward signals. To bridge this gap, we introduce Vectra, to the best of our knowledge, the first reference-free, MLLM-driven visual quality assessment framework for e-commerce IIMT. Vectra comprises three components: (1) Vectra Score, a multidimensional quality metric system that decomposes visual quality into 14 interpretable dimensions, with spatially-aware Defect Area Ratio (DAR) quantification to reduce annotation ambiguity; (2) Vectra Dataset, constructed from 1.1M real-world product images via diversity-aware sampling, comprising a 2K benchmark for system evaluation, 30K reasoning-based annotations for instruction tuning, and 3.5K expert-labeled preferences for alignment and evaluation; and (3) Vectra Model, a 4B-parameter MLLM that generates both quantitative scores and diagnostic reasoning. Experiments demonstrate that Vectra achieves state-of-the-art correlation with human rankings, and our model outperforms leading MLLMs, including GPT-5 and Gemini-3, in scoring performance. The dataset and model will be released upon acceptance.

</details>


### [7] [Robust and Real-Time Bangladeshi Currency Recognition: A Dual-Stream MobileNet and EfficientNet Approach](https://arxiv.org/abs/2602.07015)
*Subreena,Mohammad Amzad Hossain,Mirza Raquib,Saydul Akbar Murad,Farida Siddiqi Prity,Muhammad Hanif,Nick Rahimi*

Main category: cs.CV

TL;DR: 提出一种用于孟加拉国纸币识别的混合CNN架构，结合MobileNetV3-Large和EfficientNetB0进行特征提取，配合MLP分类器，在资源受限设备上实现高精度识别。


<details>
  <summary>Details</summary>
Motivation: 为视障人士提供准确的纸币识别技术，减少他们对他人依赖带来的欺诈风险。当前识别模型存在局限性，需要更鲁棒和高效的解决方案。

Method: 1) 构建新的孟加拉国纸币数据集（包含控制环境和真实场景）；2) 整合四个额外数据集增强鲁棒性；3) 提出混合CNN架构（MobileNetV3-Large + EfficientNetB0）进行特征提取；4) 使用多层感知机分类器；5) 采用五折交叉验证和七种评估指标；6) 集成LIME和SHAP增强可解释性。

Result: 模型在控制数据集上达到97.95%准确率，复杂背景上92.84%，所有数据集综合94.98%。通过五折交叉验证和多种评估指标验证性能，并利用可解释AI方法提供透明度。

Conclusion: 提出的混合CNN架构在孟加拉国纸币识别任务中表现出色，兼顾高精度和计算效率，适合资源受限设备，为视障人士提供可靠的辅助技术解决方案。

Abstract: Accurate currency recognition is essential for assistive technologies, particularly for visually impaired individuals who rely on others to identify banknotes. This dependency puts them at risk of fraud and exploitation. To address these challenges, we first build a new Bangladeshi banknote dataset that includes both controlled and real-world scenarios, ensuring a more comprehensive and diverse representation. Next, to enhance the dataset's robustness, we incorporate four additional datasets, including public benchmarks, to cover various complexities and improve the model's generalization. To overcome the limitations of current recognition models, we propose a novel hybrid CNN architecture that combines MobileNetV3-Large and EfficientNetB0 for efficient feature extraction. This is followed by an effective multilayer perceptron (MLP) classifier to improve performance while keeping computational costs low, making the system suitable for resource-constrained devices. The experimental results show that the proposed model achieves 97.95% accuracy on controlled datasets, 92.84% on complex backgrounds, and 94.98% accuracy when combining all datasets. The model's performance is thoroughly evaluated using five-fold cross-validation and seven metrics: accuracy, precision, recall, F1-score, Cohen's Kappa, MCC, and AUC. Additionally, explainable AI methods like LIME and SHAP are incorporated to enhance transparency and interpretability.

</details>


### [8] [Gaussian-Constrained LeJEPA Representations for Unsupervised Scene Discovery and Pose Consistency](https://arxiv.org/abs/2602.07016)
*Mohsen Mostafa*

Main category: cs.CV

TL;DR: 该论文提出了一种基于LeJEPA启发的各向同性高斯约束嵌入方法，用于解决无监督3D场景重建中的场景发现和相机姿态估计问题，在IMC2025挑战中验证了该方法在视觉模糊场景下的有效性。


<details>
  <summary>Details</summary>
Motivation: 从非结构化图像集合中进行无监督3D场景重建是计算机视觉中的基础挑战，特别是当图像来自多个不相关场景且包含显著视觉模糊性时。IMC2025挑战突出了这些困难，需要在包含异常值和混合内容的真实世界条件下同时进行场景发现和相机姿态估计。

Method: 提出了三种逐步改进的流程，最终采用LeJEPA启发的各向同性高斯约束嵌入方法。该方法在学习的图像嵌入上强制执行各向同性高斯约束，而不是引入新的理论保证，而是实证评估这些约束如何影响聚类一致性和姿态估计鲁棒性。

Result: 在IMC2025上的实验结果表明，与启发式基线相比，高斯约束嵌入可以改善场景分离和姿态合理性，特别是在视觉模糊设置中。这些约束有助于提高场景发现和姿态估计的准确性。

Conclusion: 理论驱动的表示约束为桥接自监督学习原理和实际运动结构重建流程提供了有前景的方向。高斯约束嵌入在实践中的有效性表明，将理论动机与实证评估相结合可以改善无监督3D重建系统的性能。

Abstract: Unsupervised 3D scene reconstruction from unstructured image collections remains a fundamental challenge in computer vision, particularly when images originate from multiple unrelated scenes and contain significant visual ambiguity. The Image Matching Challenge 2025 (IMC2025) highlights these difficulties by requiring both scene discovery and camera pose estimation under real-world conditions, including outliers and mixed content. This paper investigates the application of Gaussian-constrained representations inspired by LeJEPA (Joint Embedding Predictive Architecture) to address these challenges. We present three progressively refined pipelines, culminating in a LeJEPA-inspired approach that enforces isotropic Gaussian constraints on learned image embeddings. Rather than introducing new theoretical guarantees, our work empirically evaluates how these constraints influence clustering consistency and pose estimation robustness in practice. Experimental results on IMC2025 demonstrate that Gaussian-constrained embeddings can improve scene separation and pose plausibility compared to heuristic-driven baselines, particularly in visually ambiguous settings. These findings suggest that theoretically motivated representation constraints offer a promising direction for bridging self-supervised learning principles and practical structure-from-motion pipelines.

</details>


### [9] [XAI-CLIP: ROI-Guided Perturbation Framework for Explainable Medical Image Segmentation in Multimodal Vision-Language Models](https://arxiv.org/abs/2602.07017)
*Thuraya Alzubaidi,Sana Ammar,Maryam Alsharqi,Islem Rekik,Muzammil Behzad*

Main category: cs.CV

TL;DR: XAI-CLIP：一种基于多模态视觉语言模型的ROI引导扰动框架，用于生成更清晰、边界感知的显著性图，显著提高医学图像分割的可解释性和计算效率。


<details>
  <summary>Details</summary>
Motivation: 尽管基于Transformer的医学图像分割模型性能优越，但其有限的可解释性阻碍了临床信任和部署。现有XAI技术计算成本高、需要多次前向传播，且常产生噪声大或解剖学不相关的解释。

Method: 提出XAI-CLIP框架，利用多模态视觉语言模型嵌入定位临床相关的解剖区域，通过语言引导的区域定位与医学图像分割结合，应用目标明确的区域感知扰动来生成解释。

Result: 在FLARE22和CHAOS数据集上，XAI-CLIP相比传统扰动方法：运行时减少60%，Dice分数提高44.6%，基于遮挡的解释IoU提高96.7%。定性结果显示更干净、解剖学一致的归因图。

Conclusion: 将多模态视觉语言表示整合到基于扰动的XAI框架中，显著提升了医学图像分割系统的可解释性和效率，为实现透明且可临床部署的系统提供了有效途径。

Abstract: Medical image segmentation is a critical component of clinical workflows, enabling accurate diagnosis, treatment planning, and disease monitoring. However, despite the superior performance of transformer-based models over convolutional architectures, their limited interpretability remains a major obstacle to clinical trust and deployment. Existing explainable artificial intelligence (XAI) techniques, including gradient-based saliency methods and perturbation-based approaches, are often computationally expensive, require numerous forward passes, and frequently produce noisy or anatomically irrelevant explanations. To address these limitations, we propose XAI-CLIP, an ROI-guided perturbation framework that leverages multimodal vision-language model embeddings to localize clinically meaningful anatomical regions and guide the explanation process. By integrating language-informed region localization with medical image segmentation and applying targeted, region-aware perturbations, the proposed method generates clearer, boundary-aware saliency maps while substantially reducing computational overhead. Experiments conducted on the FLARE22 and CHAOS datasets demonstrate that XAI-CLIP achieves up to a 60\% reduction in runtime, a 44.6\% improvement in dice score, and a 96.7\% increase in Intersection-over-Union for occlusion-based explanations compared to conventional perturbation methods. Qualitative results further confirm cleaner and more anatomically consistent attribution maps with fewer artifacts, highlighting that the incorporation of multimodal vision-language representations into perturbation-based XAI frameworks significantly enhances both interpretability and efficiency, thereby enabling transparent and clinically deployable medical image segmentation systems.

</details>


### [10] [Deep Learning Based Multi-Level Classification for Aviation Safety](https://arxiv.org/abs/2602.07019)
*Elaheh Sabziyan Varnousfaderani,Syed A. M. Shihab,Jonathan King*

Main category: cs.CV

TL;DR: 提出基于卷积神经网络的图像鸟类分类框架，用于识别鸟种、群体形态和规模，以改进航空鸟击预防系统


<details>
  <summary>Details</summary>
Motivation: 鸟击对航空安全构成重大威胁，现有雷达系统无法识别鸟种，而不同鸟种的飞行行为和高度偏好不同，这是预测飞行路径的关键信息

Method: 使用卷积神经网络设计图像分类框架，与相机系统配合实现自主视觉检测，包括鸟种识别、群体形态分类和群体规模估计

Result: CNN框架能够识别鸟种并提供关键输入给物种特异性预测模型，同时群体形态和规模信息为航空安全提供有价值的补充信息

Conclusion: 提出的图像分类框架解决了现有雷达系统的局限性，通过识别鸟种和群体特征，为更准确的飞行路径预测和风险评估提供了重要信息

Abstract: Bird strikes pose a significant threat to aviation safety, often resulting in loss of life, severe aircraft damage, and substantial financial costs. Existing bird strike prevention strategies primarily rely on avian radar systems that detect and track birds in real time. A major limitation of these systems is their inability to identify bird species, an essential factor, as different species exhibit distinct flight behaviors, and altitudinal preference. To address this challenge, we propose an image-based bird classification framework using Convolutional Neural Networks (CNNs), designed to work with camera systems for autonomous visual detection. The CNN is designed to identify bird species and provide critical input to species-specific predictive models for accurate flight path prediction. In addition to species identification, we implemented dedicated CNN classifiers to estimate flock formation type and flock size. These characteristics provide valuable supplementary information for aviation safety. Specifically, flock type and size offer insights into collective flight behavior, and trajectory dispersion . Flock size directly relates to the potential impact severity, as the overall damage risk increases with the combined kinetic energy of multiple birds.

</details>


### [11] [The Geometry of Representational Failures in Vision Language Models](https://arxiv.org/abs/2602.07025)
*Daniele Savietto,Declan Campbell,André Panisson,Marco Nurisso,Giovanni Petri,Jonathan D. Cohen,Alan Perotti*

Main category: cs.CV

TL;DR: 该论文通过分析开放权重视觉语言模型（VLMs）的表示几何，提出概念向量方法来解释模型在多物体视觉任务中的失败模式，如幻觉和识别错误。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型在多物体视觉任务中表现出令人困惑的失败模式，如幻觉不存在的元素或无法在干扰物中识别最相似的物体。这些错误类似于人类的"绑定问题"认知约束，但人工系统中的内部机制仍不清楚。

Method: 分析开放权重VLMs（Qwen、InternVL、Gemma）的表示几何，比较蒸馏"概念向量"的方法论——这些是编码视觉概念的潜在方向。通过转向干预验证概念向量，在简化和自然视觉任务中可靠地操纵模型行为。

Result: 观察到这些概念向量之间的几何重叠与特定错误模式强相关，为理解内部表示如何塑造模型行为和驱动视觉失败提供了基于量化的框架。

Conclusion: 概念向量的几何分析为理解VLMs在多物体视觉任务中的失败机制提供了机械性洞察，建立了内部表示与行为错误之间的量化联系。

Abstract: Vision-Language Models (VLMs) exhibit puzzling failures in multi-object visual tasks, such as hallucinating non-existent elements or failing to identify the most similar objects among distractions. While these errors mirror human cognitive constraints, such as the "Binding Problem", the internal mechanisms driving them in artificial systems remain poorly understood. Here, we propose a mechanistic insight by analyzing the representational geometry of open-weight VLMs (Qwen, InternVL, Gemma), comparing methodologies to distill "concept vectors" - latent directions encoding visual concepts. We validate our concept vectors via steering interventions that reliably manipulate model behavior in both simplified and naturalistic vision tasks (e.g., forcing the model to perceive a red flower as blue). We observe that the geometric overlap between these vectors strongly correlates with specific error patterns, offering a grounded quantitative framework to understand how internal representations shape model behavior and drive visual failures.

</details>


### [12] [Modality Gap-Driven Subspace Alignment Training Paradigm For Multimodal Large Language Models](https://arxiv.org/abs/2602.07026)
*Xiaomin Yu,Yi Xin,Wenjie Zhang,Chonghan Liu,Hanzhen Zhao,Xiaoxing Hu,Xinlei Yu,Ziyue Qiao,Hao Tang,Xue Yang,Xiaobin Hu,Chengwei Qin,Hui Xiong,Yu Qiao,Shuicheng Yan*

Main category: cs.CV

TL;DR: 提出ReVision框架，通过ReAlign方法利用非配对数据解决模态间隙问题，实现多模态大语言模型的高效扩展


<details>
  <summary>Details</summary>
Motivation: 尽管多模态对比学习在视觉和语言表示对齐方面取得了成功，但模态间隙问题仍然存在：表达相同语义的不同模态嵌入占据系统偏移的区域。现有方法受限于过度简化的各向同性假设，难以应用于大规模场景。

Method: 1. 提出固定框架模态间隙理论，将模态间隙分解为稳定偏差和各向异性残差；2. 提出ReAlign训练自由模态对齐策略，通过Anchor、Trace和Centroid Alignment三步将文本表示对齐到图像表示分布；3. 提出ReVision可扩展训练范式，将ReAlign集成到预训练阶段，使模型能在视觉指令调优前从未配对的文本中学习视觉表示分布。

Result: 该框架表明，统计对齐的非配对数据可以有效替代昂贵的图像-文本对，为多模态大语言模型的高效扩展提供了稳健路径。

Conclusion: 通过精确建模模态间隙的几何形状并利用大规模非配对数据，实现了多模态表示的高效对齐和模型扩展，为解决模态间隙问题提供了新的理论框架和实践方法。

Abstract: Despite the success of multimodal contrastive learning in aligning visual and linguistic representations, a persistent geometric anomaly, the Modality Gap, remains: embeddings of distinct modalities expressing identical semantics occupy systematically offset regions. Prior approaches to bridge this gap are largely limited by oversimplified isotropic assumptions, hindering their application in large-scale scenarios. In this paper, we address these limitations by precisely characterizing the geometric shape of the modality gap and leveraging it for efficient model scaling. First, we propose the Fixed-frame Modality Gap Theory, which decomposes the modality gap within a frozen reference frame into stable biases and anisotropic residuals. Guided by this precise modeling, we introduce ReAlign, a training-free modality alignment strategy. Utilizing statistics from massive unpaired data, ReAlign aligns text representation into the image representation distribution via a three-step process comprising Anchor, Trace, and Centroid Alignment, thereby explicitly rectifying geometric misalignment. Building on ReAlign, we propose ReVision, a scalable training paradigm for Multimodal Large Language Models (MLLMs). ReVision integrates ReAlign into the pretraining stage, enabling the model to learn the distribution of visual representations from unpaired text before visual instruction tuning, without the need for large-scale, high-quality image-text pairs. Our framework demonstrates that statistically aligned unpaired data can effectively substitute for expensive image-text pairs, offering a robust path for the efficient scaling of MLLMs.

</details>


### [13] [Fair Context Learning for Evidence-Balanced Test-Time Adaptation in Vision-Language Models](https://arxiv.org/abs/2602.07027)
*Sanggeon Yun,Ryozo Masukawa,SungHeon Jeong,Wenjun Huang,Hanning Chen,Mohsen Imani*

Main category: cs.CV

TL;DR: FCL提出了一种公平上下文学习的测试时适应框架，通过解耦增强探索和公平驱动校准来缓解共享证据偏差，避免熵最小化带来的虚假相关性问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于提示的测试时适应方法依赖熵最小化，但这种方法会放大虚假相关性，在类别共享视觉特征时导致过度自信的错误。需要一种能明确处理共享证据偏差的方法。

Method: FCL采用分阶段的测试时适应框架：1）基于增强的探索识别可能的类别候选；2）公平驱动校准，通过调整文本上下文使对共同视觉证据的敏感性相等化，缓解部分特征痴迷问题。

Result: FCL在多种域偏移和细粒度基准测试中取得了与最先进测试时适应方法相竞争的适应性能，并通过实验验证了理论动机。

Conclusion: 通过避免熵最小化并采用公平约束来校准文本嵌入，FCL能够有效缓解共享证据偏差，提高视觉语言模型在分布偏移下的鲁棒性。

Abstract: Vision-Language Models (VLMs) such as CLIP enable strong zero-shot recognition but suffer substantial degradation under distribution shifts. Test-Time Adaptation (TTA) aims to improve robustness using only unlabeled test samples, yet most prompt-based TTA methods rely on entropy minimization -- an approach that can amplify spurious correlations and induce overconfident errors when classes share visual features. We propose Fair Context Learning (FCL), an episodic TTA framework that avoids entropy minimization by explicitly addressing shared-evidence bias. Motivated by our additive evidence decomposition assumption, FCL decouples adaptation into (i) augmentation-based exploration to identify plausible class candidates, and (ii) fairness-driven calibration that adapts text contexts to equalize sensitivity to common visual evidence. This fairness constraint mitigates partial feature obsession and enables effective calibration of text embeddings without relying on entropy reduction. Through extensive evaluation, we empirically validate our theoretical motivation and show that FCL achieves competitive adaptation performance relative to state-of-the-art TTA methods across diverse domain-shift and fine-grained benchmarks.

</details>


### [14] [A Comparative Study of Adversarial Robustness in CNN and CNN-ANFIS Architectures](https://arxiv.org/abs/2602.07028)
*Kaaustaaub Shankar,Bharadwaj Dogga,Kelly Cohen*

Main category: cs.CV

TL;DR: ANFIS增强的CNN在对抗攻击下的鲁棒性表现不一致：ResNet18-ANFIS有所改善，而VGG-ANFIS通常不如基线模型。


<details>
  <summary>Details</summary>
Motivation: CNN在图像分类中表现出色但缺乏可解释性且易受对抗攻击。神经模糊混合模型如DCNFIS通过ANFIS替换全连接层来提高可解释性，但其鲁棒性尚未充分研究。

Method: 比较标准CNN（ConvNet、VGG、ResNet18）与其ANFIS增强版本在MNIST、Fashion-MNIST、CIFAR-10和CIFAR-100数据集上的表现，使用基于梯度的PGD攻击和无梯度的Square攻击进行评估。

Result: ANFIS集成并未一致提高干净准确率，且对鲁棒性的影响与架构相关：ResNet18-ANFIS表现出更好的对抗鲁棒性，而VGG-ANFIS通常表现不如其基线模型。

Conclusion: 神经模糊增强可以在特定架构中提高鲁棒性，但并非普遍有益，需要针对具体架构进行考虑。

Abstract: Convolutional Neural Networks (CNNs) achieve strong image classification performance but lack interpretability and are vulnerable to adversarial attacks. Neuro-fuzzy hybrids such as DCNFIS replace fully connected CNN classifiers with Adaptive Neuro-Fuzzy Inference Systems (ANFIS) to improve interpretability, yet their robustness remains underexplored. This work compares standard CNNs (ConvNet, VGG, ResNet18) with their ANFIS-augmented counterparts on MNIST, Fashion-MNIST, CIFAR-10, and CIFAR-100 under gradient-based (PGD) and gradient-free (Square) attacks. Results show that ANFIS integration does not consistently improve clean accuracy and has architecture-dependent effects on robustness: ResNet18-ANFIS exhibits improved adversarial robustness, while VGG-ANFIS often underperforms its baseline. These findings suggest that neuro-fuzzy augmentation can enhance robustness in specific architectures but is not universally beneficial.

</details>


### [15] [UNIKIE-BENCH: Benchmarking Large Multimodal Models for Key Information Extraction in Visual Documents](https://arxiv.org/abs/2602.07038)
*Yifan Ji,Zhipeng Xu,Zhenghao Liu,Zulong Chen,Qian Zhang,Zhibo Yang,Junyang Lin,Yu Gu,Ge Yu,Maosong Sun*

Main category: cs.CV

TL;DR: UNIKIE-BENCH是一个用于评估大型多模态模型在文档关键信息抽取能力上的统一基准，包含约束类别和开放类别两个赛道，揭示了现有模型在多样化模式定义、长尾关键字段和复杂布局下的性能挑战。


<details>
  <summary>Details</summary>
Motivation: 现实世界文档的关键信息抽取面临布局结构、视觉质量和任务特定需求的巨大差异，而现有评估不够全面系统。需要建立一个统一的基准来全面评估大型多模态模型在各种实际应用场景中的KIE能力。

Method: 提出UNIKIE-BENCH基准，包含两个互补赛道：1) 约束类别KIE赛道：基于场景预定义模式，反映实际应用需求；2) 开放类别KIE赛道：提取文档中明确存在的任何关键信息。对15个最先进的大型多模态模型进行实验评估。

Result: 实验发现：1) 在不同模式定义下模型性能显著下降；2) 长尾关键字段和复杂布局带来挑战；3) 不同文档类型和场景间存在明显性能差异；4) 模型在基础准确性和布局感知推理方面存在持续挑战。

Conclusion: UNIKIE-BENCH为大型多模态模型的KIE能力提供了全面评估框架，揭示了当前模型在实际应用中的局限性，特别是在基础准确性和布局感知推理方面仍需改进。所有代码和数据集已开源。

Abstract: Key Information Extraction (KIE) from real-world documents remains challenging due to substantial variations in layout structures, visual quality, and task-specific information requirements. Recent Large Multimodal Models (LMMs) have shown promising potential for performing end-to-end KIE directly from document images. To enable a comprehensive and systematic evaluation across realistic and diverse application scenarios, we introduce UNIKIE-BENCH, a unified benchmark designed to rigorously evaluate the KIE capabilities of LMMs. UNIKIE-BENCH consists of two complementary tracks: a constrained-category KIE track with scenario-predefined schemas that reflect practical application needs, and an open-category KIE track that extracts any key information that is explicitly present in the document. Experiments on 15 state-of-the-art LMMs reveal substantial performance degradation under diverse schema definitions, long-tail key fields, and complex layouts, along with pronounced performance disparities across different document types and scenarios. These findings underscore persistent challenges in grounding accuracy and layout-aware reasoning for LMM-based KIE. All codes and datasets are available at https://github.com/NEUIR/UNIKIE-BENCH.

</details>


### [16] [OMNI-Dent: Towards an Accessible and Explainable AI Framework for Automated Dental Diagnosis](https://arxiv.org/abs/2602.07041)
*Leeje Jang,Yao-Yi Chiang,Angela M. Hastings,Patimaporn Pungchanchaikul,Martha B. Lucas,Emily C. Schultz,Jeffrey P. Louie,Mohamed Estai,Wen-Chen Wang,Ryan H. L. Ip,Boyen Huang*

Main category: cs.CV

TL;DR: OMNI-Dent是一个数据高效、可解释的牙科诊断框架，利用视觉语言模型处理智能手机多视角照片，嵌入牙科专家的诊断启发式方法，无需特定微调即可进行牙齿级评估。


<details>
  <summary>Details</summary>
Motivation: 当前AI牙科诊断方法主要将诊断视为视觉模式识别任务，未能反映牙科专业人员的结构化临床推理，且需要大量专家标注数据，难以在多样化现实成像条件下泛化。许多人也缺乏及时的专业评估机会。

Method: 将临床推理原则整合到视觉语言模型管道中，利用多视角智能手机照片，嵌入牙科专家的诊断启发式方法，引导通用VLM进行牙齿级评估，无需对VLM进行牙科特定微调。

Result: OMNI-Dent旨在支持在缺乏临床影像数据的场景中进行诊断评估，作为早期辅助工具帮助用户识别潜在异常并确定何时需要专业评估，为缺乏现场护理的个人提供实用选择。

Conclusion: OMNI-Dent通过结合临床推理原则和通用VLM能力，提供了一种数据高效、可解释的牙科诊断方法，特别适用于资源有限的环境，有助于改善口腔医疗可及性。

Abstract: Accurate dental diagnosis is essential for oral healthcare, yet many individuals lack access to timely professional evaluation. Existing AI-based methods primarily treat diagnosis as a visual pattern recognition task and do not reflect the structured clinical reasoning used by dental professionals. These approaches also require large amounts of expert-annotated data and often struggle to generalize across diverse real-world imaging conditions. To address these limitations, we present OMNI-Dent, a data-efficient and explainable diagnostic framework that incorporates clinical reasoning principles into a Vision-Language Model (VLM)-based pipeline. The framework operates on multi-view smartphone photographs,embeds diagnostic heuristics from dental experts, and guides a general-purpose VLM to perform tooth-level evaluation without dental-specific fine-tuning of the VLM. By utilizing the VLM's existing visual-linguistic capabilities, OMNI-Dent aims to support diagnostic assessment in settings where curated clinical imaging is unavailable. Designed as an early-stage assistive tool, OMNI-Dent helps users identify potential abnormalities and determine when professional evaluation may be needed, offering a practical option for individuals with limited access to in-person care.

</details>


### [17] [COMBOOD: A Semiparametric Approach for Detecting Out-of-distribution Data for Image Classification](https://arxiv.org/abs/2602.07042)
*Magesh Rajasekaran,Md Saiful Islam Sajol,Frej Berglind,Supratik Mukhopadhyay,Kamalika Das*

Main category: cs.CV

TL;DR: COMBOOD是一个用于图像识别中OOD检测的无监督半参数框架，结合最近邻和马氏距离两种度量信号，在近OOD和远OOD场景下都能提供准确的置信度评分。


<details>
  <summary>Details</summary>
Motivation: 在推理时识别OOD数据对许多机器学习应用至关重要，特别是自动化应用。现有方法在近OOD场景（实际应用中常见）中表现不佳，需要一种能在近OOD和远OOD场景下都有效的方法。

Method: 提出COMBOOD框架，结合最近邻（非参数方法）和马氏距离（参数方法）两种距离度量信号。最近邻方法提供非参数OOD检测，马氏距离在远OOD场景中有效但在近OOD场景中表现不佳。COMBOOD在半参数设置中结合这两种信号，生成适用于两种场景的置信度评分。

Result: 在OpenOOD（v1和v1.5）基准数据集和文档数据集上，COMBOOD在准确率方面优于最先进的OOD检测方法（包括远OOD和近OOD）。在大多数基准数据集上，COMBOOD带来的准确率提升具有统计显著性。框架计算复杂度与嵌入空间大小呈线性关系，适合实际应用。

Conclusion: COMBOOD是一个有效且可扩展的OOD检测框架，通过结合两种距离度量信号，在近OOD和远OOD场景下都能提供准确的检测性能，适合实际应用部署。

Abstract: Identifying out-of-distribution (OOD) data at inference time is crucial for many machine learning applications, especially for automation. We present a novel unsupervised semi-parametric framework COMBOOD for OOD detection with respect to image recognition. Our framework combines signals from two distance metrics, nearest-neighbor and Mahalanobis, to derive a confidence score for an inference point to be out-of-distribution. The former provides a non-parametric approach to OOD detection. The latter provides a parametric, simple, yet effective method for detecting OOD data points, especially, in the far OOD scenario, where the inference point is far apart from the training data set in the embedding space. However, its performance is not satisfactory in the near OOD scenarios that arise in practical situations. Our COMBOOD framework combines the two signals in a semi-parametric setting to provide a confidence score that is accurate both for the near-OOD and far-OOD scenarios. We show experimental results with the COMBOOD framework for different types of feature extraction strategies. We demonstrate experimentally that COMBOOD outperforms state-of-the-art OOD detection methods on the OpenOOD (both version 1 and most recent version 1.5) benchmark datasets (for both far-OOD and near-OOD) as well as on the documents dataset in terms of accuracy. On a majority of the benchmark datasets, the improvements in accuracy resulting from the COMBOOD framework are statistically significant. COMBOOD scales linearly with the size of the embedding space, making it ideal for many real-life applications.

</details>


### [18] [PipeMFL-240K: A Large-scale Dataset and Benchmark for Object Detection in Pipeline Magnetic Flux Leakage Imaging](https://arxiv.org/abs/2602.07044)
*Tianyi Qu,Songxiao Yang,Haolin Wang,Huadong Song,Xiaoting Guo,Wenguang Hu,Guanlin Liu,Honghe Chen,Yafei Ou*

Main category: cs.CV

TL;DR: PipeMFL-240K：首个大规模公开的管道漏磁检测数据集与基准，包含24万张图像和19万标注，用于解决管道缺陷检测中的长尾分布、微小目标和类内变异等挑战。


<details>
  <summary>Details</summary>
Motivation: 管道完整性对工业安全和环境保护至关重要，漏磁检测是主要无损检测技术。尽管深度学习在自动化漏磁解释方面有前景，但由于缺乏大规模公开数据集和基准，可靠模型的进展受到限制，难以进行公平比较和可重复评估。

Method: 构建了PipeMFL-240K数据集，包含240,320张图像和191,530个高质量边界框标注，来自11条总长约1,480公里的管道。数据集反映了真实检测复杂性，包含12个类别的极端长尾分布、大量微小目标（仅几个像素）和显著的类内变异。

Result: 通过最先进的目标检测器进行广泛实验建立基准。结果显示，现代检测器仍难以处理漏磁数据的内在特性，表明有相当大的改进空间。PipeMFL-240K为未来研究提供了可靠且具有挑战性的测试平台。

Conclusion: PipeMFL-240K是首个公开的、规模和范围如此之大的管道漏磁检测数据集和基准，为高效管道诊断和维护规划提供了关键基础，有望加速基于漏磁的管道完整性评估的算法创新和可重复研究。

Abstract: Pipeline integrity is critical to industrial safety and environmental protection, with Magnetic Flux Leakage (MFL) detection being a primary non-destructive testing technology. Despite the promise of deep learning for automating MFL interpretation, progress toward reliable models has been constrained by the absence of a large-scale public dataset and benchmark, making fair comparison and reproducible evaluation difficult. We introduce \textbf{PipeMFL-240K}, a large-scale, meticulously annotated dataset and benchmark for complex object detection in pipeline MFL pseudo-color images. PipeMFL-240K reflects real-world inspection complexity and poses several unique challenges: (i) an extremely long-tailed distribution over \textbf{12} categories, (ii) a high prevalence of tiny objects that often comprise only a handful of pixels, and (iii) substantial intra-class variability. The dataset contains \textbf{240,320} images and \textbf{191,530} high-quality bounding-box annotations, collected from 11 pipelines spanning approximately \textbf{1,480} km. Extensive experiments are conducted with state-of-the-art object detectors to establish baselines. Results show that modern detectors still struggle with the intrinsic properties of MFL data, highlighting considerable headroom for improvement, while PipeMFL-240K provides a reliable and challenging testbed to drive future research. As the first public dataset and the first benchmark of this scale and scope for pipeline MFL inspection, it provides a critical foundation for efficient pipeline diagnostics as well as maintenance planning and is expected to accelerate algorithmic innovation and reproducible research in MFL-based pipeline integrity assessment.

</details>


### [19] [VLRS-Bench: A Vision-Language Reasoning Benchmark for Remote Sensing](https://arxiv.org/abs/2602.07045)
*Zhiming Luo,Di Wang,Haonan Guo,Jing Zhang,Bo Du*

Main category: cs.CV

TL;DR: VLRS-Bench是首个专门针对遥感复杂推理任务的基准测试，包含2000个问答对，涵盖认知、决策和预测三个维度，旨在推动遥感领域多模态大语言模型的发展。


<details>
  <summary>Details</summary>
Motivation: 现有遥感基准测试主要偏向感知任务（如目标识别和场景分类），这限制了多模态大语言模型在认知要求高的遥感应用中的发展，因此需要专门的复杂推理基准。

Method: 通过专门构建的流程创建VLRS-Bench，该流程整合了遥感特定先验知识和专家知识，确保地理空间真实性和推理复杂性。基准包含2000个问答对，平均长度71词，涵盖14个任务和最多八个时间阶段。

Result: 实验结果显示现有最先进的多模态大语言模型在VLRS-Bench上存在显著瓶颈，为遥感社区推进多模态推理提供了关键见解。

Conclusion: VLRS-Bench填补了遥感领域复杂推理基准的空白，揭示了当前模型的局限性，为未来遥感多模态大语言模型的发展提供了重要指导。

Abstract: Recent advancements in Multimodal Large Language Models (MLLMs) have enabled complex reasoning. However, existing remote sensing (RS) benchmarks remain heavily biased toward perception tasks, such as object recognition and scene classification. This limitation hinders the development of MLLMs for cognitively demanding RS applications. To address this, , we propose a Vision Language ReaSoning Benchmark (VLRS-Bench), which is the first benchmark exclusively dedicated to complex RS reasoning. Structured across the three core dimensions of Cognition, Decision, and Prediction, VLRS-Bench comprises 2,000 question-answer pairs with an average length of 71 words, spanning 14 tasks and up to eight temporal phases. VLRS-Bench is constructed via a specialized pipeline that integrates RS-specific priors and expert knowledge to ensure geospatial realism and reasoning complexity. Experimental results reveal significant bottlenecks in existing state-of-the-art MLLMs, providing critical insights for advancing multimodal reasoning within the remote sensing community.

</details>


### [20] [ShapBPT: Image Feature Attributions Using Data-Aware Binary Partition Trees](https://arxiv.org/abs/2602.07047)
*Muhammad Rashid,Elvio G. Amparore,Enrico Ferrari,Damiano Verda*

Main category: cs.CV

TL;DR: ShapBPT：一种基于数据感知层次Shapley公式的新型XCV方法，利用图像的多尺度结构（BPT）提供更高效、语义更丰富的像素级特征归因。


<details>
  <summary>Details</summary>
Motivation: 现有层次Shapley方法未能利用图像数据的多尺度结构，导致收敛慢且与真实形态特征对齐差；缺乏针对计算机视觉任务的数据感知层次方法，存在模型可解释性空白。

Method: 提出ShapBPT方法，将Shapley系数分配给为图像定制的多尺度层次结构——二叉划分树（BPT），通过数据感知的层次划分确保特征归因与内在图像形态对齐。

Result: 实验证明ShapBPT有效性：与图像结构对齐更优、计算效率更高；20人用户研究确认人类更偏好ShapBPT的解释。

Conclusion: ShapBPT将层次Shapley方法与图像数据连接，为视觉可解释性提供了更高效、语义更丰富的方法，填补了结构化视觉数据模型解释的空白。

Abstract: Pixel-level feature attributions are an important tool in eXplainable AI for Computer Vision (XCV), providing visual insights into how image features influence model predictions. The Owen formula for hierarchical Shapley values has been widely used to interpret machine learning (ML) models and their learned representations. However, existing hierarchical Shapley approaches do not exploit the multiscale structure of image data, leading to slow convergence and weak alignment with the actual morphological features. Moreover, no prior Shapley method has leveraged data-aware hierarchies for Computer Vision tasks, leaving a gap in model interpretability of structured visual data. To address this, this paper introduces ShapBPT, a novel data-aware XCV method based on the hierarchical Shapley formula. ShapBPT assigns Shapley coefficients to a multiscale hierarchical structure tailored for images, the Binary Partition Tree (BPT). By using this data-aware hierarchical partitioning, ShapBPT ensures that feature attributions align with intrinsic image morphology, effectively prioritizing relevant regions while reducing computational overhead. This advancement connects hierarchical Shapley methods with image data, providing a more efficient and semantically meaningful approach to visual interpretability. Experimental results confirm ShapBPT's effectiveness, demonstrating superior alignment with image structures and improved efficiency over existing XCV methods, and a 20-subject user study confirming that ShapBPT explanations are preferred by humans.

</details>


### [21] [Enhancing IMU-Based Online Handwriting Recognition via Contrastive Learning with Zero Inference Overhead](https://arxiv.org/abs/2602.07049)
*Jindong Li,Dario Zanca,Vincent Christlein,Tim Hamann,Jens Barth,Peter Kämpf,Björn Eskofier*

Main category: cs.CV

TL;DR: 提出ECHWR训练框架，通过辅助分支和双重对比目标提升在线手写识别性能，训练后丢弃辅助分支保持推理效率，在OnHW-Words500数据集上显著降低错误率。


<details>
  <summary>Details</summary>
Motivation: 在线手写识别使用IMU传感器实现纸上书写作为数字设备输入，在边缘硬件上运行可提高隐私性和降低延迟，但面临内存限制。需要在不增加推理成本的情况下提升识别精度。

Method: 提出ECHWR训练框架，包含临时辅助分支将传感器信号与语义文本嵌入对齐，采用双重对比目标：批内对比损失用于模态对齐，新颖的基于错误的对比损失区分正确信号和合成困难负样本。训练后丢弃辅助分支，保持原始高效架构。

Result: 在OnHW-Words500数据集上显著优于最先进基线，在writer-independent分割上字符错误率降低7.4%，在writer-dependent分割上降低10.4%。消融研究表明基于错误的对比损失对处理未见书写风格有效。

Conclusion: ECHWR框架通过训练时增强特征表示提升识别精度，同时保持推理效率，特别适合边缘设备部署。基于错误的对比损失是处理未见书写风格的有效方法。

Abstract: Online handwriting recognition using inertial measurement units opens up handwriting on paper as input for digital devices. Doing it on edge hardware improves privacy and lowers latency, but entails memory constraints. To address this, we propose Error-enhanced Contrastive Handwriting Recognition (ECHWR), a training framework designed to improve feature representation and recognition accuracy without increasing inference costs. ECHWR utilizes a temporary auxiliary branch that aligns sensor signals with semantic text embeddings during the training phase. This alignment is maintained through a dual contrastive objective: an in-batch contrastive loss for general modality alignment and a novel error-based contrastive loss that distinguishes between correct signals and synthetic hard negatives. The auxiliary branch is discarded after training, which allows the deployed model to keep its original, efficient architecture. Evaluations on the OnHW-Words500 dataset show that ECHWR significantly outperforms state-of-the-art baselines, reducing character error rates by up to 7.4% on the writer-independent split and 10.4% on the writer-dependent split. Finally, although our ablation studies indicate that solving specific challenges require specific architectural and objective configurations, error-based contrastive loss shows its effectiveness for handling unseen writing styles.

</details>


### [22] [Interpreting Physics in Video World Models](https://arxiv.org/abs/2602.07050)
*Sonia Joseph,Quentin Garrido,Randall Balestriero,Matthew Kowal,Thomas Fel,Shahab Bakhtiari,Blake Richards,Mike Rabbat*

Main category: cs.CV

TL;DR: 视频编码器中的物理表示研究：发现物理变量在中间层突然变得可访问（物理涌现区），但并非采用经典物理引擎的分解表示，而是使用分布式表示。


<details>
  <summary>Details</summary>
Motivation: 研究视频模型是否需要依赖物理变量的分解表示来做出准确的物理预测，还是能以任务特定的分布式方式隐式表示这些变量。现代视频世界模型在直觉物理基准上表现良好，但其内部实现哪种表示机制尚不清楚。

Method: 使用分层探测、子空间几何、补丁级解码和针对性注意力消融等方法，分析大规模视频编码器内部的物理表示。研究物理信息在何处变得可访问以及如何在编码器中组织。

Result: 发现跨架构存在一个尖锐的中间深度过渡（物理涌现区），物理变量在此变得可访问。物理相关表示在此后达到峰值，然后向输出层退化。标量（速度、加速度）从早期层就可访问，而运动方向仅在物理涌现区变得可访问，且通过具有圆形几何结构的高维群体结构编码。

Conclusion: 现代视频模型不使用像经典物理引擎那样的物理变量分解表示，而是使用分布式表示，但这种表示足以进行物理预测。

Abstract: A long-standing question in physical reasoning is whether video-based models need to rely on factorized representations of physical variables in order to make physically accurate predictions, or whether they can implicitly represent such variables in a task-specific, distributed manner. While modern video world models achieve strong performance on intuitive physics benchmarks, it remains unclear which of these representational regimes they implement internally. Here, we present the first interpretability study to directly examine physical representations inside large-scale video encoders. Using layerwise probing, subspace geometry, patch-level decoding, and targeted attention ablations, we characterize where physical information becomes accessible and how it is organized within encoder-based video transformers.
  Across architectures, we identify a sharp intermediate-depth transition -- which we call the Physics Emergence Zone -- at which physical variables become accessible. Physics-related representations peak shortly after this transition and degrade toward the output layers. Decomposing motion into explicit variables, we find that scalar quantities such as speed and acceleration are available from early layers onwards, whereas motion direction becomes accessible only at the Physics Emergence Zone. Notably, we find that direction is encoded through a high-dimensional population structure with circular geometry, requiring coordinated multi-feature intervention to control. These findings suggest that modern video models do not use factorized representations of physical variables like a classical physics engine. Instead, they use a distributed representation that is nonetheless sufficient for making physical predictions.

</details>


### [23] [Neural Sentinel: Unified Vision Language Model (VLM) for License Plate Recognition with Human-in-the-Loop Continual Learning](https://arxiv.org/abs/2602.07051)
*Karthik Sivakoti*

Main category: cs.CV

TL;DR: 提出Neural Sentinel，一個基於視覺語言模型的統一車牌識別系統，使用微調的PaliGemma 3B模型，在單次前向傳播中同時完成車牌識別、狀態分類和車輛屬性提取，準確率達92.3%，比傳統方法提升顯著。


<details>
  <summary>Details</summary>
Motivation: 傳統ALPR系統採用多階段管道（物體檢測+OCR模塊），存在錯誤累積、延遲增加和架構複雜的問題。需要更統一、高效且能處理多任務的解決方案。

Method: 使用PaliGemma 3B視覺語言模型，通過LoRA進行微調，實現單次前向傳播的多任務處理。引入人機協同持續學習框架，以70:30比例混合原始訓練數據和修正樣本，防止災難性遺忘。

Result: 車牌識別準確率達92.3%，比EasyOCR提升14.1%，比PaddleOCR提升9.9%。平均推理延遲152ms，預期校準誤差0.048。零樣本泛化能力：車輛顏色檢測89%、安全帶檢測82%、乘員計數78%。

Conclusion: 統一視覺語言方法代表ALPR系統的範式轉移，提供更高的準確性、更低的架構複雜度，以及傳統管道方法無法實現的新興多任務能力。

Abstract: Traditional Automatic License Plate Recognition (ALPR) systems employ multi-stage pipelines consisting of object detection networks followed by separate Optical Character Recognition (OCR) modules, introducing compounding errors, increased latency, and architectural complexity. This research presents Neural Sentinel, a novel unified approach that leverages Vision Language Models (VLMs) to perform license plate recognition, state classification, and vehicle attribute extraction through a single forward pass. Our primary contribution lies in demonstrating that a fine-tuned PaliGemma 3B model, adapted via Low-Rank Adaptation (LoRA), can simultaneously answer multiple visual questions about vehicle images, achieving 92.3% plate recognition accuracy, which is a 14.1% improvement over EasyOCR and 9.9% improvement over PaddleOCR baselines. We introduce a Human-in-the-Loop (HITL) continual learning framework that incorporates user corrections while preventing catastrophic forgetting through experience replay, maintaining a 70:30 ratio of original training data to correction samples. The system achieves a mean inference latency of 152ms with an Expected Calibration Error (ECE) of 0.048, indicating well calibrated confidence estimates. Additionally, the VLM first architecture enables zero-shot generalization to auxiliary tasks including vehicle color detection (89%), seatbelt detection (82%), and occupancy counting (78%) without task specific training. Through extensive experimentation on real world toll plaza imagery, we demonstrate that unified vision language approaches represent a paradigm shift in ALPR systems, offering superior accuracy, reduced architectural complexity, and emergent multi-task capabilities that traditional pipeline approaches cannot achieve.

</details>


### [24] [Toward Accurate and Accessible Markerless Neuronavigation](https://arxiv.org/abs/2602.07052)
*Ziye Xie,Oded Schlesinger,Raj Kundu,Jessica Y. Choi,Pablo Iturralde,Dennis A. Turner,Stefan M. Goetz,Guillermo Sapiro,Angel V. Peterchev,J. Matias Di Martino*

Main category: cs.CV

TL;DR: 提出并评估了无需标记物的神经导航方法，使用低成本可见光和红外光相机结合面部几何建模，相比传统标记系统在50名受试者中实现了2.32mm和2.01°的中位跟踪误差，适用于经颅磁刺激等应用。


<details>
  <summary>Details</summary>
Motivation: 传统神经导航系统依赖主体安装的标记物，需要手动配准，可能在手术过程中移位，并引起不适。需要开发更舒适、低成本且无需标记物的替代方案。

Method: 使用低成本可见光和红外光相机，结合立体视觉和深度感知技术，通过算法对面部几何进行建模，实现无需标记物的神经导航。

Result: 在50名人类受试者验证中，最佳无标记算法的中位跟踪误差仅为2.32mm和2.01°，相比传统标记系统具有足够精度，且显著优于先前无标记方法结果。

Conclusion: 提出的无标记神经导航方法可以降低设置成本和复杂性，提高患者舒适度，并扩大神经导航在临床和研究环境中的可及性。多传感器数据融合可进一步提高整体精度。

Abstract: Neuronavigation is widely used in biomedical research and interventions to guide the precise placement of instruments around the head to support procedures such as transcranial magnetic stimulation. Traditional systems, however, rely on subject-mounted markers that require manual registration, may shift during procedures, and can cause discomfort. We introduce and evaluate markerless approaches that replace expensive hardware and physical markers with low-cost visible and infrared light cameras incorporating stereo and depth sensing combined with algorithmic modeling of the facial geometry. Validation with $50$ human subjects yielded a median tracking discrepancy of only $2.32$ mm and $2.01°$ for the best markerless algorithms compared to a conventional marker-based system, which indicates sufficient accuracy for transcranial magnetic stimulation and a substantial improvement over prior markerless results. The results suggest that integration of the data from the various camera sensors can improve the overall accuracy further. The proposed markerless neuronavigation methods can reduce setup cost and complexity, improve patient comfort, and expand access to neuronavigation in clinical and research settings.

</details>


### [25] [RECITYGEN -- Interactive and Generative Participatory Urban Design Tool with Latent Diffusion and Segment Anything](https://arxiv.org/abs/2602.07057)
*Di Mo,Mingyang Sun,Chengxiu Yin,Runjia Tian,Yanhong Wu,Liyan Xu*

Main category: cs.CV

TL;DR: RECITYGEN是一个结合潜在扩散模型和交互式语义分割的工具，允许用户通过文本提示交互式生成城市街景的变体图像，用于参与式城市设计。


<details>
  <summary>Details</summary>
Motivation: 传统自上而下的城市设计方法往往忽视公众意见，导致设计愿景与现实之间存在差距。虽然数字工具如城市信息建模和增强现实已经促进了更多利益相关者参与，但仍需进一步降低设计生成的门槛。

Method: 结合最先进的潜在扩散模型与交互式语义分割技术，开发了RECITYGEN工具，用户可以通过文本提示交互式创建城市环境的变体街景图像。

Result: 在北京的试点项目中，用户使用RECITYGEN为正在进行中的城市更新项目提出改进建议。尽管存在一些限制，但该工具在符合公众偏好方面显示出显著潜力。

Conclusion: RECITYGEN代表了向更动态、包容的城市规划方法的转变，通过降低设计生成门槛，使更多利益相关者能够参与城市设计过程。

Abstract: Urban design profoundly impacts public spaces and community engagement. Traditional top-down methods often overlook public input, creating a gap in design aspirations and reality. Recent advancements in digital tools, like City Information Modelling and augmented reality, have enabled a more participatory process involving more stakeholders in urban design. Further, deep learning and latent diffusion models have lowered barriers for design generation, providing even more opportunities for participatory urban design. Combining state-of-the-art latent diffusion models with interactive semantic segmentation, we propose RECITYGEN, a novel tool that allows users to interactively create variational street view images of urban environments using text prompts. In a pilot project in Beijing, users employed RECITYGEN to suggest improvements for an ongoing Urban Regeneration project. Despite some limitations, RECITYGEN has shown significant potential in aligning with public preferences, indicating a shift towards more dynamic and inclusive urban planning methods. The source code for the project can be found at RECITYGEN GitHub.

</details>


### [26] [FADE: Selective Forgetting via Sparse LoRA and Self-Distillation](https://arxiv.org/abs/2602.07058)
*Carolina R. Kelsch,Leonardo S. B. Pereira,Natnael Mola,Luis H. Arribas,Juan C. S. M. Avedillo*

Main category: cs.CV

TL;DR: FADE是一种用于文本到图像扩散模型的两阶段遗忘学习方法，通过参数定位和自蒸馏实现高效的概念擦除，在保持模型整体性能的同时实现特定数据的遗忘。


<details>
  <summary>Details</summary>
Motivation: 随着数据保护法规和负责任AI实践的要求增加，需要从训练模型中移除特定数据或概念的影响，同时保持整体性能。当前文本到图像扩散模型的遗忘学习面临计算成本高、遗忘与保留难以平衡的挑战。

Method: FADE采用两阶段方法：1) 使用基于梯度的显著性分析识别与遗忘集最相关的参数，通过稀疏LoRA适配器进行约束更新；2) 应用自蒸馏目标，用用户定义的替代概念覆盖遗忘概念，同时保留在保留数据上的行为。

Result: 在UnlearnCanvas基准测试和多个数据集（Imagenette、Labeled Faces in the Wild、AtharvaTaras Dog Breeds Dataset、SUN Attributes）上的评估表明，FADE实现了最先进的遗忘性能，在遗忘-保留权衡方面具有细粒度控制。

Conclusion: FADE通过轻量级、可逆的适配器实现了强大的概念擦除和高保留性，适合在基于扩散的图像生成模型中进行选择性遗忘学习，为生产系统提供了灵活的部署方案。

Abstract: Machine Unlearning aims to remove the influence of specific data or concepts from trained models while preserving overall performance, a capability increasingly required by data protection regulations and responsible AI practices. Despite recent progress, unlearning in text-to-image diffusion models remains challenging due to high computational costs and the difficulty of balancing effective forgetting with retention of unrelated concepts. We introduce FADE (Fast Adapter for Data Erasure), a two-stage unlearning method for image generation that combines parameter localization with self-distillation. FADE first identifies parameters most responsible for the forget set using gradient-based saliency and constrains updates through sparse LoRA adapters, ensuring lightweight, localized modifications. In a second stage, FADE applies a self-distillation objective that overwrites the forgotten concept with a user-defined surrogate while preserving behavior on retained data. The resulting adapters are memory-efficient, reversible, and can be merged or removed at runtime, enabling flexible deployment in production systems. We evaluated FADE on the UnlearnCanvas benchmark and conducted ablation studies on Imagenette, Labeled Faces in the Wild, AtharvaTaras Dog Breeds Dataset, and SUN Attributes datasets, demonstrating State-of-the-Art unlearning performance with fine-grained control over the forgetting-retention trade-off. Our results demonstrate that FADE achieves strong concept erasure and high retainability across various domains, making it a suitable solution for selective unlearning in diffusion-based image generation models.

</details>


### [27] [From Images to Decisions: Assistive Computer Vision for Non-Metallic Content Estimation in Scrap Metal](https://arxiv.org/abs/2602.07062)
*Daniil Storonkin,Ilia Dziub,Maksim Golyadkin,Ilya Makarov*

Main category: cs.CV

TL;DR: 开发计算机视觉系统，通过多实例学习和多任务学习从铁路车厢图像中自动评估废钢污染程度和分类废钢类型，减少主观判断并提高安全性


<details>
  <summary>Details</summary>
Motivation: 当前废钢质量评估依赖人工目视检查，存在主观性强、危险性高（粉尘和移动机械）的问题，需要自动化解决方案来减少主观差异并提高安全性

Method: 将污染评估构建为回归任务，采用多实例学习（MIL）处理序列数据，结合多任务学习（MTL）同时进行污染估计和废钢分类；系统包括磁铁/车厢检测、版本化推理服务、操作员审查和主动学习循环

Result: MIL方法达到MAE 0.27和R² 0.83；MTL设置达到MAE 0.36，废钢分类F1分数0.79；系统已集成到验收工作流中，实现近实时处理

Conclusion: 该计算机视觉管道减少了主观变异性，提高了人员安全性，并能集成到验收和熔炼计划工作流中，通过主动学习实现持续改进

Abstract: Scrap quality directly affects energy use, emissions, and safety in steelmaking. Today, the share of non-metallic inclusions (contamination) is judged visually by inspectors - an approach that is subjective and hazardous due to dust and moving machinery. We present an assistive computer vision pipeline that estimates contamination (per percent) from images captured during railcar unloading and also classifies scrap type. The method formulates contamination assessment as a regression task at the railcar level and leverages sequential data through multi-instance learning (MIL) and multi-task learning (MTL). Best results include MAE 0.27 and R2 0.83 by MIL; and an MTL setup reaches MAE 0.36 with F1 0.79 for scrap class. Also we present the system in near real time within the acceptance workflow: magnet/railcar detection segments temporal layers, a versioned inference service produces railcar-level estimates with confidence scores, and results are reviewed by operators with structured overrides; corrections and uncertain cases feed an active-learning loop for continual improvement. The pipeline reduces subjective variability, improves human safety, and enables integration into acceptance and melt-planning workflows.

</details>


### [28] [Exploring Physical Intelligence Emergence via Omni-Modal Architecture and Physical Data Engine](https://arxiv.org/abs/2602.07064)
*Minghao Han,Dingkang Yang,Yue Jiang,Yizhou Liu,Lihua Zhang*

Main category: cs.CV

TL;DR: OmniFysics是一个紧凑的全模态模型，通过物理数据引擎注入显式物理知识，统一理解图像、音频、视频和文本，并集成语音和图像生成。


<details>
  <summary>Details</summary>
Motivation: 现有全模态模型在物理理解方面存在脆弱性，因为关键物理属性在视觉上具有歧义性，且在网络规模数据中稀疏表示，需要注入显式物理知识来增强物理理解能力。

Method: 构建物理数据引擎FysicsAny（通过层次检索和物理定律验证生成物理基础的指令-图像监督）和FysicsOmniCap（通过音频-视觉一致性过滤蒸馏网络视频生成高质量视频-指令对）；采用分阶段多模态对齐和指令调优训练；使用潜在空间流匹配进行文本到图像生成；通过意图路由器仅在需要时激活生成功能。

Result: 在标准多模态基准测试中表现具有竞争力，在物理导向评估中取得改进结果。

Conclusion: OmniFysics通过显式物理知识注入，有效增强了全模态模型的物理理解能力，在保持标准任务性能的同时，显著提升了物理相关任务的性能。

Abstract: Physical understanding remains brittle in omni-modal models because key physical attributes are visually ambiguous and sparsely represented in web-scale data. We present OmniFysics, a compact omni-modal model that unifies understanding across images, audio, video, and text, with integrated speech and image generation. To inject explicit physical knowledge, we build a physical data engine with two components. FysicsAny produces physics-grounded instruction--image supervision by mapping salient objects to verified physical attributes through hierarchical retrieval over a curated prototype database, followed by physics-law--constrained verification and caption rewriting. FysicsOmniCap distills web videos via audio--visual consistency filtering to generate high-fidelity video--instruction pairs emphasizing cross-modal physical cues. We train OmniFysics with staged multimodal alignment and instruction tuning, adopt latent-space flow matching for text-to-image generation, and use an intent router to activate generation only when needed. Experiments show competitive performance on standard multimodal benchmarks and improved results on physics-oriented evaluations.

</details>


### [29] [Contactless estimation of continuum displacement and mechanical compressibility from image series using a deep learning based framework](https://arxiv.org/abs/2602.07065)
*A. N. Maria Antony,T. Richter,E. Gladilin*

Main category: cs.CV

TL;DR: 提出基于深度学习的端到端方法，从图像序列直接估计连续位移和材料压缩性，相比传统方法在效率和精度上都有优势


<details>
  <summary>Details</summary>
Motivation: 传统基于非刚性图像配准和有限元/有限差分等数值方法的材料力学特性估计方法计算耗时，不适合高通量数据处理，需要更高效的非接触式材料特性估计方法

Method: 使用两个深度神经网络分别进行图像配准和材料压缩性估计的端到端框架，能够直接从图像序列估计连续位移和材料压缩性

Result: 深度学习模型在效率和精度上优于传统方法，即使在图像配准预测的映射与参考位移场存在显著局部偏差时，仍能准确确定材料压缩性

Conclusion: 深度学习端到端模型的优异精度源于其能够评估高阶认知特征（如矢量场的涡度），而不仅仅是传统的局部图像位移特征

Abstract: Contactless and non-invasive estimation of mechanical properties of physical media from optical observations is of interest for manifold engineering and biomedical applications, where direct physical measurements are not possible. Conventional approaches to the assessment of image displacement and non-contact material probing typically rely on time-consuming iterative algorithms for non-rigid image registration and constitutive modelling using discretization and iterative numerical solving techniques, such as Finite Element Method (FEM) and Finite Difference Method (FDM), which are not suitable for high-throughput data processing. Here, we present an efficient deep learning based end-to-end approach for the estimation of continuum displacement and material compressibility directly from the image series. Based on two deep neural networks for image registration and material compressibility estimation, this framework outperforms conventional approaches in terms of efficiency and accuracy. In particular, our experimental results show that the deep learning model trained on a set of reference data can accurately determine the material compressibility even in the presence of substantial local deviations of the mapping predicted by image registration from the reference displacement field. Our findings suggest that the remarkable accuracy of the deep learning end-to-end model originates from its ability to assess higher-order cognitive features, such as the vorticity of the vector field, rather than conventional local features of the image displacement.

</details>


### [30] [Bidirectional Reward-Guided Diffusion for Real-World Image Super-Resolution](https://arxiv.org/abs/2602.07069)
*Zihao Fan,Xin Lu,Yidi Liu,Jie Huang,Dong Li,Xueyang Fu,Zheng-Jun Zha*

Main category: cs.CV

TL;DR: Bird-SR：基于双向奖励引导的扩散框架，通过轨迹级偏好优化实现真实世界超分辨率，平衡结构保真度和感知质量


<details>
  <summary>Details</summary>
Motivation: 基于扩散的超分辨率方法能合成丰富细节，但在合成数据上训练的模型对真实世界低分辨率图像存在分布偏移问题。需要同时利用合成LR-HR对和真实世界LR图像，解决结构保真度和感知质量的平衡问题。

Method: 1. 采用双向奖励引导扩散框架，通过奖励反馈学习进行轨迹级偏好优化；2. 早期扩散步骤直接在合成对上优化以保持结构保真度；3. 后期采样步骤对合成和真实图像应用质量引导奖励；4. 为防止奖励黑客，合成结果奖励在相对优势空间中计算，真实世界优化通过语义对齐约束正则化；5. 采用动态保真度-感知权重策略，早期强调结构保持，后期逐步转向感知优化。

Result: 在真实世界超分辨率基准测试中，Bird-SR在保持结构一致性的同时，在感知质量方面始终优于最先进的方法。

Conclusion: Bird-SR通过双向奖励引导扩散框架有效解决了真实世界超分辨率中的分布偏移问题，成功平衡了结构保真度和感知质量，为真实世界图像超分辨率提供了有效解决方案。

Abstract: Diffusion-based super-resolution can synthesize rich details, but models trained on synthetic paired data often fail on real-world LR images due to distribution shifts. We propose Bird-SR, a bidirectional reward-guided diffusion framework that formulates super-resolution as trajectory-level preference optimization via reward feedback learning (ReFL), jointly leveraging synthetic LR-HR pairs and real-world LR images. For structural fidelity easily affected in ReFL, the model is directly optimized on synthetic pairs at early diffusion steps, which also facilitates structure preservation for real-world inputs under smaller distribution gap in structure levels. For perceptual enhancement, quality-guided rewards are applied at later sampling steps to both synthetic and real LR images. To mitigate reward hacking, the rewards for synthetic results are formulated in a relative advantage space bounded by their clean counterparts, while real-world optimization is regularized via a semantic alignment constraint. Furthermore, to balance structural and perceptual learning, we adopt a dynamic fidelity-perception weighting strategy that emphasizes structure preservation at early stages and progressively shifts focus toward perceptual optimization at later diffusion steps. Extensive experiments on real-world SR benchmarks demonstrate that Bird-SR consistently outperforms state-of-the-art methods in perceptual quality while preserving structural consistency, validating its effectiveness for real-world super-resolution.

</details>


### [31] [MosaicThinker: On-Device Visual Spatial Reasoning for Embodied AI via Iterative Construction of Space Representation](https://arxiv.org/abs/2602.07082)
*Haoming Wang,Qiyao Xue,Weichen Liu,Wei Gao*

Main category: cs.CV

TL;DR: MosaicThinker：一种用于设备端具身AI的推理时计算技术，通过将多帧空间信息整合到统一的全局语义地图中，增强小型VLM的跨帧空间推理能力


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型在空间推理方面能力较弱，特别是涉及多帧复杂空间关系的任务，而具身AI需要从视频输入中感知物体空间关系以指导设备动作

Method: 提出MosaicThinker技术，将多帧碎片化空间信息整合到统一的全局语义地图表示中，并通过视觉提示引导VLM在语义地图上进行空间推理

Result: 实验结果表明，该技术能显著提高资源受限具身AI设备在跨帧空间推理任务上的准确性，适用于多种类型和复杂度的推理任务

Conclusion: MosaicThinker通过整合多帧空间信息到全局语义地图并利用视觉提示，有效增强了设备端小型VLM的跨帧空间推理能力

Abstract: When embodied AI is expanding from traditional object detection and recognition to more advanced tasks of robot manipulation and actuation planning, visual spatial reasoning from the video inputs is necessary to perceive the spatial relationships of objects and guide device actions. However, existing visual language models (VLMs) have very weak capabilities in spatial reasoning due to the lack of knowledge about 3D spatial information, especially when the reasoning task involve complex spatial relations across multiple video frames. In this paper, we present a new inference-time computing technique for on-device embodied AI, namely \emph{MosaicThinker}, which enhances the on-device small VLM's spatial reasoning capabilities on difficult cross-frame reasoning tasks. Our basic idea is to integrate fragmented spatial information from multiple frames into a unified space representation of global semantic map, and further guide the VLM's spatial reasoning over the semantic map via a visual prompt. Experiment results show that our technique can greatly enhance the accuracy of cross-frame spatial reasoning on resource-constrained embodied AI devices, over reasoning tasks with diverse types and complexities.

</details>


### [32] [WorldEdit: Towards Open-World Image Editing with a Knowledge-Informed Benchmark](https://arxiv.org/abs/2602.07095)
*Wang Lin,Feng Wang,Majun Zhang,Wentao Hu,Tao Jin,Zhou Zhao,Fei Wu,Jingyuan Chen,Alan Yuille,Sucheng Ren*

Main category: cs.CV

TL;DR: WorldEdit数据集专注于隐式编辑指令的图像编辑，通过两阶段训练框架提升模型在因果推理编辑任务上的表现


<details>
  <summary>Details</summary>
Motivation: 现有图像编辑模型在处理隐式编辑指令时面临挑战，这些指令描述视觉变化的原因而非具体结果，需要复杂的世界知识和推理能力

Method: 提出WorldEdit数据集，包含高质量编辑样本和符合现实世界因果逻辑的转述指令；采用两阶段训练框架微调模型，整合因果验证奖励机制

Result: 显著缩小了与GPT-4o和Nano-Banana的差距，在指令遵循和知识合理性方面表现出竞争力

Conclusion: WorldEdit数据集和方法有效解决了隐式编辑指令的挑战，提升了模型在因果推理编辑任务上的性能

Abstract: Recent advances in image editing models have demonstrated remarkable capabilities in executing explicit instructions, such as attribute manipulation, style transfer, and pose synthesis. However, these models often face challenges when dealing with implicit editing instructions, which describe the cause of a visual change without explicitly detailing the resulting outcome. These limitations arise because existing models rely on uniform editing strategies that are not equipped to handle the complex world knowledge and reasoning required for implicit instructions. To address this gap, we introduce \textbf{WorldEdit}, a dataset specifically designed to enable world-driven image editing. WorldEdit consists of high-quality editing samples, guided by paraphrased instructions that align with real-world causal logic. Furthermore, we provide \textbf{WorldEdit-Test} for evaluating the existing model's performance on causal editing scenarios. With WorldEdit, we use a two-stage training framework for fine-tuning models like Bagel, integrating with a causal verification reward. Our results show that the proposed dataset and methods significantly narrow the gap with GPT-4o and Nano-Banana, demonstrating competitive performance not only in instruction following but also in knowledge plausibility, where many open-source systems typically struggle.

</details>


### [33] [TLC-Plan: A Two-Level Codebook Based Network for End-to-End Vector Floorplan Generation](https://arxiv.org/abs/2602.07100)
*Biao Xiong,Zhen Peng,Ping Wang,Qiegen Liu,Xian Zhong*

Main category: cs.CV

TL;DR: TLC-Plan：一种直接从输入边界生成矢量平面图的分层生成模型，通过两级VQ-VAE编码全局布局和局部几何，使用CodeTree表示和自回归Transformer生成多样且拓扑有效的设计。


<details>
  <summary>Details</summary>
Motivation: 现有方法在栅格空间中操作并依赖后处理矢量化，导致结构不一致并阻碍端到端学习。受组合空间推理启发，希望开发与人类基于模块化和可重用模式的建筑工作流程对齐的矢量平面图生成方法。

Method: 提出TLC-Plan分层生成模型：1）使用两级VQ-VAE编码全局布局（语义标记的房间边界框）和局部几何（多边形级编码）；2）统一为CodeTree表示；3）使用自回归Transformer根据边界条件采样编码，无需显式房间拓扑或维度先验。

Result: 在RPLAN数据集上达到最先进性能（FID = 1.84，MSE = 2.06），在LIFULL数据集上取得领先结果。框架支持约束感知和可扩展的矢量平面图生成。

Conclusion: TLC-Plan通过直接合成矢量平面图，解决了现有方法的矢量化问题，实现了与人类建筑工作流程对齐的端到端学习，为实际建筑应用提供了先进的约束感知和可扩展生成框架。

Abstract: Automated floorplan generation aims to improve design quality, architectural efficiency, and sustainability by jointly modeling global spatial organization and precise geometric detail. However, existing approaches operate in raster space and rely on post hoc vectorization, which introduces structural inconsistencies and hinders end-to-end learning. Motivated by compositional spatial reasoning, we propose TLC-Plan, a hierarchical generative model that directly synthesizes vector floorplans from input boundaries, aligning with human architectural workflows based on modular and reusable patterns. TLC-Plan employs a two-level VQ-VAE to encode global layouts as semantically labeled room bounding boxes and to refine local geometries using polygon-level codes. This hierarchy is unified in a CodeTree representation, while an autoregressive transformer samples codes conditioned on the boundary to generate diverse and topologically valid designs, without requiring explicit room topology or dimensional priors. Extensive experiments show state-of-the-art performance on RPLAN dataset (FID = 1.84, MSE = 2.06) and leading results on LIFULL dataset. The proposed framework advances constraint-aware and scalable vector floorplan generation for real-world architectural applications. Source code and trained models are released at https://github.com/rosolose/TLC-PLAN.

</details>


### [34] [Zero-Shot UAV Navigation in Forests via Relightable 3D Gaussian Splatting](https://arxiv.org/abs/2602.07101)
*Zinan Lv,Yeqian Qian,Chen Sang,Hao Liu,Danping Zou,Ming Yang*

Main category: cs.CV

TL;DR: 提出Relightable 3D Gaussian Splatting和强化学习框架，实现无人机在复杂森林环境中无需微调的零样本导航，速度达10m/s，对光照变化具有强鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 无人机在非结构化室外环境中的单目视觉导航面临仿真与现实的视觉域差距问题。现有3D高斯泼溅方法将静态光照与几何耦合，限制了策略在动态真实光照下的泛化能力。

Method: 提出可重光照3D高斯泼溅，分解场景组件以在神经表示中实现物理基础的光照编辑。在基于真实数据的高保真仿真中，训练策略将原始单目RGB观测直接映射到连续控制命令，并通过多样化的合成光照条件增强训练。

Result: 轻量级四旋翼无人机在复杂森林环境中实现鲁棒、无碰撞导航，速度达10m/s，对剧烈光照变化表现出显著适应能力，无需微调。

Conclusion: 该方法通过可重光照神经表示和光照增强训练，有效解决了仿真与现实的光照域差距问题，实现了无人机在非结构化室外环境的零样本鲁棒导航。

Abstract: UAV navigation in unstructured outdoor environments using passive monocular vision is hindered by the substantial visual domain gap between simulation and reality. While 3D Gaussian Splatting enables photorealistic scene reconstruction from real-world data, existing methods inherently couple static lighting with geometry, severely limiting policy generalization to dynamic real-world illumination. In this paper, we propose a novel end-to-end reinforcement learning framework designed for effective zero-shot transfer to unstructured outdoors. Within a high-fidelity simulation grounded in real-world data, our policy is trained to map raw monocular RGB observations directly to continuous control commands. To overcome photometric limitations, we introduce Relightable 3D Gaussian Splatting, which decomposes scene components to enable explicit, physically grounded editing of environmental lighting within the neural representation. By augmenting training with diverse synthesized lighting conditions ranging from strong directional sunlight to diffuse overcast skies, we compel the policy to learn robust, illumination-invariant visual features. Extensive real-world experiments demonstrate that a lightweight quadrotor achieves robust, collision-free navigation in complex forest environments at speeds up to 10 m/s, exhibiting significant resilience to drastic lighting variations without fine-tuning.

</details>


### [35] [Extended to Reality: Prompt Injection in 3D Environments](https://arxiv.org/abs/2602.07104)
*Zhuoheng Li,Ying Chen*

Main category: cs.CV

TL;DR: PI3D是一种针对3D环境中多模态大语言模型的提示注入攻击，通过放置带有文本的物理物体来覆盖模型的预期任务，而非数字图像编辑。


<details>
  <summary>Details</summary>
Motivation: 随着MLLMs在3D环境中的广泛应用（如机器人、对话代理），当模型通过摄像头观察物理世界时，攻击者可以通过放置带有文本的物理物体来创建新的攻击面。现有研究主要关注文本域和数字编辑的2D图像攻击，但3D物理环境中的攻击效果尚不清楚。

Method: PI3D通过放置带有注入文本的物理物体实现攻击，核心是识别有效的3D物体姿态（位置和方向）。攻击者目标是诱导MLLM执行注入任务，同时确保物体放置的物理合理性。该方法解决了在3D环境中确定有效物体姿态的问题。

Result: 实验表明PI3D对多种MLLM在不同摄像头轨迹下都是有效的攻击。现有防御措施评估显示它们不足以防御PI3D攻击。

Conclusion: PI3D揭示了3D物理环境中MLLM的新安全漏洞，通过物理物体放置实现的提示注入攻击具有实际威胁。现有防御措施需要改进以应对这种新型攻击。

Abstract: Multimodal large language models (MLLMs) have advanced the capabilities to interpret and act on visual input in 3D environments, empowering diverse applications such as robotics and situated conversational agents. When MLLMs reason over camera-captured views of the physical world, a new attack surface emerges: an attacker can place text-bearing physical objects in the environment to override MLLMs' intended task. While prior work has studied prompt injection in the text domain and through digitally edited 2D images, it remains unclear how these attacks function in 3D physical environments. To bridge the gap, we introduce PI3D, a prompt injection attack against MLLMs in 3D environments, realized through text-bearing physical object placement rather than digital image edits. We formulate and solve the problem of identifying an effective 3D object pose (position and orientation) with injected text, where the attacker's goal is to induce the MLLM to perform the injected task while ensuring that the object placement remains physically plausible. Experiments demonstrate that PI3D is an effective attack against multiple MLLMs under diverse camera trajectories. We further evaluate existing defenses and show that they are insufficient to defend against PI3D.

</details>


### [36] [Ex-Omni: Enabling 3D Facial Animation Generation for Omni-modal Large Language Models](https://arxiv.org/abs/2602.07106)
*Haoyu Zhang,Zhipeng Li,Yiwen Guo,Tianshu Yu*

Main category: cs.CV

TL;DR: Ex-Omni是一个开源的全模态框架，通过解耦语义推理与时间生成，利用语音单元作为时间支架，实现语音伴随的3D面部动画生成。


<details>
  <summary>Details</summary>
Motivation: 现有的全模态大语言模型（OLLMs）主要关注多模态理解与生成，但将语音与3D面部动画结合的研究仍然不足，这对于自然交互至关重要。主要挑战在于LLMs的离散、token级语义推理与3D面部运动所需的密集、细粒度时间动态之间存在表示不匹配。

Method: 提出Ex-Omni框架，通过解耦语义推理与时间生成来降低学习难度：1) 使用语音单元作为时间支架；2) 采用统一的token-as-query门控融合（TQGF）机制进行受控语义注入；3) 引入InstructEx数据集来支持训练。

Result: 实验表明，Ex-Omni在性能上与现有开源OLLMs竞争，同时能够稳定生成对齐的语音和面部动画。

Conclusion: Ex-Omni成功解决了将语音与3D面部动画集成到OLLMs中的挑战，通过解耦策略和TQGF机制实现了稳定、对齐的多模态生成，为自然交互系统提供了有效解决方案。

Abstract: Omni-modal large language models (OLLMs) aim to unify multimodal understanding and generation, yet incorporating speech with 3D facial animation remains largely unexplored despite its importance for natural interaction. A key challenge arises from the representation mismatch between discrete, token-level semantic reasoning in LLMs and the dense, fine-grained temporal dynamics required for 3D facial motion, which makes direct modeling difficult to optimize under limited data. We propose Expressive Omni (Ex-Omni), an open-source omni-modal framework that augments OLLMs with speech-accompanied 3D facial animation. Ex-Omni reduces learning difficulty by decoupling semantic reasoning from temporal generation, leveraging speech units as temporal scaffolding and a unified token-as-query gated fusion (TQGF) mechanism for controlled semantic injection. We further introduce InstructEx, a dataset aims to facilitate augment OLLMs with speech-accompanied 3D facial animation. Extensive experiments demonstrate that Ex-Omni performs competitively against existing open-source OLLMs while enabling stable aligned speech and facial animation generation.

</details>


### [37] [Privacy in Image Datasets: A Case Study on Pregnancy Ultrasounds](https://arxiv.org/abs/2602.07149)
*Rawisara Lohanimit,Yankun Wu,Amelia Katirai,Yuta Nakashima,Noa Garcia*

Main category: cs.CV

TL;DR: 研究发现LAION-400M数据集中包含大量敏感的个人怀孕超声图像，这些图像带有可识别身份的信息，存在隐私泄露风险


<details>
  <summary>Details</summary>
Motivation: 随着生成模型的发展，大规模网络数据集的使用日益普遍，但缺乏数据筛选可能导致敏感隐私信息被包含在内。本研究关注怀孕超声图像这类包含高度敏感个人信息的内容，探讨其在公开数据集中的存在情况

Method: 通过系统性地检查LAION-400M数据集，使用CLIP嵌入相似性检索包含怀孕超声的图像，并检测其中的私人信息实体（如姓名、位置等）

Result: 研究发现数千个包含私人信息的实体，多个图像具有高风险信息，可能使个人被重新识别或冒充

Conclusion: 建议改进数据集筛选实践，加强数据隐私保护，并制定公开图像数据集的伦理使用指南

Abstract: The rise of generative models has led to increased use of large-scale datasets collected from the internet, often with minimal or no data curation. This raises concerns about the inclusion of sensitive or private information. In this work, we explore the presence of pregnancy ultrasound images, which contain sensitive personal information and are often shared online. Through a systematic examination of LAION-400M dataset using CLIP embedding similarity, we retrieve images containing pregnancy ultrasound and detect thousands of entities of private information such as names and locations. Our findings reveal that multiple images have high-risk information that could enable re-identification or impersonation. We conclude with recommended practices for dataset curation, data privacy, and ethical use of public image datasets.

</details>


### [38] [DuMeta++: Spatiotemporal Dual Meta-Learning for Generalizable Few-Shot Brain Tissue Segmentation Across Diverse Ages](https://arxiv.org/abs/2602.07174)
*Yongheng Sun,Jun Shu,Jianhua Ma,Fan Wang*

Main category: cs.CV

TL;DR: DuMeta++：一种无需配对纵向数据的双元学习框架，用于跨年龄脑组织MRI分割，通过元特征学习和元初始化学习实现更好的泛化性能。


<details>
  <summary>Details</summary>
Motivation: 脑MRI组织分割在神经科学和临床应用中至关重要，但由于大脑随年龄变化的动态外观和形态变化，实现跨生命周期的稳定性能具有挑战性。现有方法通常需要配对的纵向数据进行自监督正则化，但这类数据在实践中往往难以获取。

Method: 提出DuMeta++双元学习框架：1）元特征学习提取年龄无关的时空演化脑结构语义表示；2）元初始化学习实现数据高效的分割模型适应；3）基于记忆库的类别感知正则化策略，无需显式纵向监督即可强制纵向一致性。理论证明了算法的收敛性。

Result: 在iSeg-2019、IBIS、OASIS、ADNI等多个数据集上的少样本设置实验中，DuMeta++在跨年龄泛化方面优于现有方法。

Conclusion: DuMeta++成功解决了无需配对纵向数据的跨年龄脑组织分割问题，通过双元学习框架实现了更好的泛化性能，为实际临床应用提供了可行方案。

Abstract: Accurate segmentation of brain tissues from MRI scans is critical for neuroscience and clinical applications, but achieving consistent performance across the human lifespan remains challenging due to dynamic, age-related changes in brain appearance and morphology. While prior work has sought to mitigate these shifts by using self-supervised regularization with paired longitudinal data, such data are often unavailable in practice. To address this, we propose \emph{DuMeta++}, a dual meta-learning framework that operates without paired longitudinal data. Our approach integrates: (1) meta-feature learning to extract age-agnostic semantic representations of spatiotemporally evolving brain structures, and (2) meta-initialization learning to enable data-efficient adaptation of the segmentation model. Furthermore, we propose a memory-bank-based class-aware regularization strategy to enforce longitudinal consistency without explicit longitudinal supervision. We theoretically prove the convergence of our DuMeta++, ensuring stability. Experiments on diverse datasets (iSeg-2019, IBIS, OASIS, ADNI) under few-shot settings demonstrate that DuMeta++ outperforms existing methods in cross-age generalization. Code will be available at https://github.com/ladderlab-xjtu/DuMeta++.

</details>


### [39] [Condition Matters in Full-head 3D GANs](https://arxiv.org/abs/2602.07198)
*Heyuan Li,Huimin Zhang,Yuda Qiu,Zhengwentai Sun,Keru Zheng,Lingteng Qiu,Peihao Li,Qi Zuo,Ce Chen,Yujian Zheng,Yuming Gu,Zilong Dong,Xiaoguang Han*

Main category: cs.CV

TL;DR: 提出使用视角不变语义特征作为条件输入，解决传统3D头部GAN中视角条件导致的生成偏差问题，提升全局一致性和多样性


<details>
  <summary>Details</summary>
Motivation: 传统3D头部GAN使用视角角度作为条件输入会导致学习到的3D空间沿条件视角方向产生偏差，造成条件视角与非条件视角之间生成质量和多样性的显著差异，导致不同头部区域的全局不一致性

Method: 使用视角不变语义特征作为条件输入，通过FLUX.1 Kontext扩展现有高质量正面人脸数据集到多视角，提取正面视角的图像clip特征作为所有视角的共享语义条件，确保语义对齐并消除方向偏差

Result: 在完整头部合成和单视角GAN反演实验中，该方法实现了显著更高的保真度、多样性和泛化能力

Conclusion: 通过视角不变语义条件，成功解耦了3D头部生成能力与视角方向的依赖，解决了传统方法中的视角偏差问题，提升了生成的全局一致性和多样性

Abstract: Conditioning is crucial for stable training of full-head 3D GANs. Without any conditioning signal, the model suffers from severe mode collapse, making it impractical to training. However, a series of previous full-head 3D GANs conventionally choose the view angle as the conditioning input, which leads to a bias in the learned 3D full-head space along the conditional view direction. This is evident in the significant differences in generation quality and diversity between the conditional view and non-conditional views of the generated 3D heads, resulting in global incoherence across different head regions. In this work, we propose to use view-invariant semantic feature as the conditioning input, thereby decoupling the generative capability of 3D heads from the viewing direction. To construct a view-invariant semantic condition for each training image, we create a novel synthesized head image dataset. We leverage FLUX.1 Kontext to extend existing high-quality frontal face datasets to a wide range of view angles. The image clip feature extracted from the frontal view is then used as a shared semantic condition across all views in the extended images, ensuring semantic alignment while eliminating directional bias. This also allows supervision from different views of the same subject to be consolidated under a shared semantic condition, which accelerates training and enhances the global coherence of the generated 3D heads. Moreover, as GANs often experience slower improvements in diversity once the generator learns a few modes that successfully fool the discriminator, our semantic conditioning encourages the generator to follow the true semantic distribution, thereby promoting continuous learning and diverse generation. Extensive experiments on full-head synthesis and single-view GAN inversion demonstrate that our method achieves significantly higher fidelity, diversity, and generalizability.

</details>


### [40] [Understanding Real-World Traffic Safety through RoadSafe365 Benchmark](https://arxiv.org/abs/2602.07212)
*Xinyu Liu,Darryl C. Jacob,Yuxin Liu,Xinsong Du,Muchao Ye,Bolei Zhou,Pan He*

Main category: cs.CV

TL;DR: RoadSafe365是一个大规模视觉语言基准，用于细粒度交通安全性分析，包含36,196个标注视频片段和864K候选选项，填补了现有基准缺乏官方安全标准系统评估的空白。


<details>
  <summary>Details</summary>
Motivation: 现有交通基准缺乏与官方安全标准对齐的系统性评估，且主要关注粗略的事故识别，无法支持细粒度的交通安全性分析。

Method: 构建大规模视觉语言基准RoadSafe365，使用分层分类法系统组织，扩展碰撞、事件和违规的基础定义，包含丰富的属性标注（事件类型、环境上下文、交互场景），提供多项选择题-答案集和详细场景描述。

Result: 包含36,196个标注视频片段（来自行车记录仪和监控摄像头），864K候选选项，8.4K唯一答案，36K详细场景描述。微调实验显示一致性能提升，跨域实验验证其有效性。

Conclusion: RoadSafe365为大规模训练和标准化评估提供了全面基准，可推进现实世界交通安全性分析的可重复研究。

Abstract: Although recent traffic benchmarks have advanced multimodal data analysis, they generally lack systematic evaluation aligned with official safety standards. To fill this gap, we introduce RoadSafe365, a large-scale vision-language benchmark that supports fine-grained analysis of traffic safety from extensive and diverse real-world video data collections. Unlike prior works that focus primarily on coarse accident identification, RoadSafe365 is independently curated and systematically organized using a hierarchical taxonomy that refines and extends foundational definitions of crash, incident, and violation to bridge official traffic safety standards with data-driven traffic understanding systems. RoadSafe365 provides rich attribute annotations across diverse traffic event types, environmental contexts, and interaction scenarios, yielding 36,196 annotated clips from both dashcam and surveillance cameras. Each clip is paired with multiple-choice question-answer sets, comprising 864K candidate options, 8.4K unique answers, and 36K detailed scene descriptions collectively designed for vision-language understanding and reasoning. We establish strong baselines and observe consistent gains when fine-tuning on RoadSafe365. Cross-domain experiments on both real and synthetic datasets further validate its effectiveness. Designed for large-scale training and standardized evaluation, RoadSafe365 provides a comprehensive benchmark to advance reproducible research in real-world traffic safety analysis.

</details>


### [41] [The Double-Edged Sword of Data-Driven Super-Resolution: Adversarial Super-Resolution Models](https://arxiv.org/abs/2602.07251)
*Haley Duba-Sullivan,Steven R. Young,Emma J. Reid*

Main category: cs.CV

TL;DR: AdvSR：一种在超分辨率模型训练时嵌入对抗行为的新攻击框架，无需推理时输入访问，能在保持图像质量的同时诱导下游分类器误判


<details>
  <summary>Details</summary>
Motivation: 数据驱动的超分辨率模型常作为预处理步骤集成到成像管道中，但这些模型引入了一个未被探索的攻击面。现有攻击通常扰动输入或依赖后门触发器，而本文探索在模型层面直接嵌入对抗行为的可能性。

Method: 提出AdvSR框架，在训练超分辨率模型时联合优化重建质量和目标对抗结果。通过直接修改模型权重，使模型在标准图像质量指标下表现正常，但能诱导下游分类器产生特定误分类。

Result: 在三种超分辨率架构（SRCNN、EDSR、SwinIR）与YOLOv11分类器配对评估中，AdvSR模型能以最小质量退化实现高攻击成功率，证明模型层面的威胁真实存在。

Conclusion: AdvSR揭示了一种新的模型级威胁，对成像管道安全具有重要影响，特别是在安全关键应用中，需要重新考虑如何获取和验证模型。

Abstract: Data-driven super-resolution (SR) methods are often integrated into imaging pipelines as preprocessing steps to improve downstream tasks such as classification and detection. However, these SR models introduce a previously unexplored attack surface into imaging pipelines. In this paper, we present AdvSR, a framework demonstrating that adversarial behavior can be embedded directly into SR model weights during training, requiring no access to inputs at inference time. Unlike prior attacks that perturb inputs or rely on backdoor triggers, AdvSR operates entirely at the model level. By jointly optimizing for reconstruction quality and targeted adversarial outcomes, AdvSR produces models that appear benign under standard image quality metrics while inducing downstream misclassification. We evaluate AdvSR on three SR architectures (SRCNN, EDSR, SwinIR) paired with a YOLOv11 classifier and demonstrate that AdvSR models can achieve high attack success rates with minimal quality degradation. These findings highlight a new model-level threat for imaging pipelines, with implications for how practitioners source and validate models in safety-critical applications.

</details>


### [42] [3D Transport-based Morphometry (3D-TBM) for medical image analysis](https://arxiv.org/abs/2602.07260)
*Hongyu Kan,Kristofor Pas,Ivan Medri,Naqib Sad Pathan,Natasha Ironside,Shinjini Kundu,Jingjia He,Gustavo Kunde Rohde*

Main category: cs.CV

TL;DR: 3D-TBM是一个基于传输的形态测量工具，用于3D医学图像分析，通过可逆变换将图像嵌入传输域，支持分类、回归等任务，并能将结果投影回原始图像空间进行空间解释。


<details>
  <summary>Details</summary>
Motivation: 促进传输式形态测量（TBM）在临床影像研究中的更广泛应用，为研究人员提供一个完整的3D医学图像形态分析工具。

Method: 开发3D-TBM工具，包括数据预处理、最优传输嵌入计算、主要传输方向可视化、判别方向识别等分析方法，并提供完整文档和教程。

Result: 提出了3D-TBM框架，通过PyTransKit公开源代码，为医学影像研究提供了一个实用的传输式形态测量工具。

Conclusion: 3D-TBM是一个促进传输式形态测量在临床影像研究中应用的实用工具，通过可逆变换实现图像分析与空间解释的结合。

Abstract: Transport-Based Morphometry (TBM) has emerged as a new framework for 3D medical image analysis. By embedding images into a transport domain via invertible transformations, TBM facilitates effective classification, regression, and other tasks using transport-domain features. Crucially, the inverse mapping enables the projection of analytic results back into the original image space, allowing researchers to directly interpret clinical features associated with model outputs in a spatially meaningful way. To facilitate broader adoption of TBM in clinical imaging research, we present 3D-TBM, a tool designed for morphological analysis of 3D medical images. The framework includes data preprocessing, computation of optimal transport embeddings, and analytical methods such as visualization of main transport directions, together with techniques for discerning discriminating directions and related analysis methods. We also provide comprehensive documentation and practical tutorials to support researchers interested in applying 3D-TBM in their own medical imaging studies. The source code is publicly available through PyTransKit.

</details>


### [43] [TwistNet-2D: Learning Second-Order Channel Interactions via Spiral Twisting for Texture Recognition](https://arxiv.org/abs/2602.07262)
*Junbo Jacob Lian,Feng Xiong,Yujun Sun,Kaichen Ouyang,Mingyang Yu,Shengwei Fu,Zhong Rui,Zhang Yujun,Huiling Chen*

Main category: cs.CV

TL;DR: TwistNet-2D是一个轻量级模块，通过局部成对通道乘积在方向性空间位移下计算，联合编码特征共现位置和交互方式，显著提升纹理识别性能。


<details>
  <summary>Details</summary>
Motivation: 二阶特征统计对纹理识别至关重要，但现有方法存在根本矛盾：双线性池化和Gram矩阵捕获全局通道相关性但破坏空间结构，而自注意力通过加权聚合建模空间上下文而非显式的成对特征交互。

Method: 引入TwistNet-2D模块，核心是螺旋扭曲通道交互(STCI)：将特征图沿规定方向移位后进行逐元素通道乘法，捕获结构化周期性纹理的跨位置共现模式。通过四个方向头聚合，学习通道重加权，并通过sigmoid门控残差路径注入。

Result: TwistNet仅增加3.5%参数和2%FLOPs，但在四个纹理和细粒度识别基准上，持续超越参数匹配和更大基线（包括ConvNeXt、Swin Transformer和混合CNN-Transformer架构）。

Conclusion: TwistNet-2D通过局部成对通道交互有效解决了二阶特征统计中的空间结构保留问题，以极低计算成本显著提升纹理识别性能。

Abstract: Second-order feature statistics are central to texture recognition, yet current methods face a fundamental tension: bilinear pooling and Gram matrices capture global channel correlations but collapse spatial structure, while self-attention models spatial context through weighted aggregation rather than explicit pairwise feature interactions. We introduce TwistNet-2D, a lightweight module that computes \emph{local} pairwise channel products under directional spatial displacement, jointly encoding where features co-occur and how they interact. The core component, Spiral-Twisted Channel Interaction (STCI), shifts one feature map along a prescribed direction before element-wise channel multiplication, thereby capturing the cross-position co-occurrence patterns characteristic of structured and periodic textures. Aggregating four directional heads with learned channel reweighting and injecting the result through a sigmoid-gated residual path, \TwistNet incurs only 3.5% additional parameters and 2% additional FLOPs over ResNet-18, yet consistently surpasses both parameter-matched and substantially larger baselines -- including ConvNeXt, Swin Transformer, and hybrid CNN--Transformer architectures -- across four texture and fine-grained recognition benchmarks.

</details>


### [44] [VideoNeuMat: Neural Material Extraction from Generative Video Models](https://arxiv.org/abs/2602.07272)
*Bowen Xue,Saeed Hadadan,Zheng Zeng,Fabrice Rousselle,Zahra Montazeri,Milos Hasan*

Main category: cs.CV

TL;DR: VideoNeuMat从视频扩散模型中提取可重用的神经材质资产，通过两阶段流程：1) 微调大视频模型生成受控相机和光照轨迹下的材质样本视频；2) 从视频重建紧凑的神经材质，实现单次推理预测可泛化到新视角和光照条件的材质参数。


<details>
  <summary>Details</summary>
Motivation: 为3D渲染创建逼真材质需要高超的艺术技能，而现有生成模型受限于高质量训练数据的缺乏。虽然视频生成模型能轻松产生逼真的材质外观，但这些知识仍与几何和光照纠缠在一起，无法直接重用。

Method: 两阶段流程：第一阶段微调大视频模型(Wan 2.1 14B)生成受控相机和光照轨迹下的材质样本视频，创建"虚拟测角反射计"；第二阶段通过从较小视频骨干微调的大型重建模型(LRM)，从17个生成视频帧中单次推理预测神经材质参数。

Result: 生成的材质在真实感和多样性上远超有限的合成训练数据，成功将互联网规模视频模型中的材质知识转移到独立的、可重用的神经3D资产中，能够泛化到新的视角和光照条件。

Conclusion: 材质知识可以从互联网规模的视频模型中成功提取并转化为独立的、可重用的神经3D资产，为3D渲染提供了高质量的材质生成解决方案。

Abstract: Creating photorealistic materials for 3D rendering requires exceptional artistic skill. Generative models for materials could help, but are currently limited by the lack of high-quality training data. While recent video generative models effortlessly produce realistic material appearances, this knowledge remains entangled with geometry and lighting. We present VideoNeuMat, a two-stage pipeline that extracts reusable neural material assets from video diffusion models. First, we finetune a large video model (Wan 2.1 14B) to generate material sample videos under controlled camera and lighting trajectories, effectively creating a "virtual gonioreflectometer" that preserves the model's material realism while learning a structured measurement pattern. Second, we reconstruct compact neural materials from these videos through a Large Reconstruction Model (LRM) finetuned from a smaller Wan 1.3B video backbone. From 17 generated video frames, our LRM performs single-pass inference to predict neural material parameters that generalize to novel viewing and lighting conditions. The resulting materials exhibit realism and diversity far exceeding the limited synthetic training data, demonstrating that material knowledge can be successfully transferred from internet-scale video models into standalone, reusable neural 3D assets.

</details>


### [45] [Cross-View World Models](https://arxiv.org/abs/2602.07277)
*Rishabh Sharma,Gijs Hogervorst,Wayne E. Mackey,David J. Heeger,Stefano Martiniani*

Main category: cs.CV

TL;DR: XVWM通过跨视角预测目标训练世界模型，使智能体能够在不同视角下规划，利用多视角一致性作为几何正则化学习环境3D结构


<details>
  <summary>Details</summary>
Motivation: 现有世界模型通常只从单一视角（通常是自我中心视角）操作，即使其他视角可能使规划更容易。例如，导航任务从鸟瞰视角会受益。需要能够跨视角预测的世界模型来支持更灵活的规划

Method: 提出跨视角世界模型（XVWM），通过跨视角预测目标训练：给定一个视角的帧序列，预测采取行动后相同或不同视角的未来状态。使用Aimlabs平台的多视角游戏数据训练，该数据提供精确对齐的多摄像头录制和高频动作标签

Result: 模型为智能体提供跨视角的并行想象流，能够在最适合任务的参考框架中规划，同时从自我中心视角执行。多视角一致性为空间基础表示提供了强大的学习信号

Conclusion: 跨视角世界模型通过几何正则化学习环境3D结构，支持灵活视角规划。从他人视角预测行动后果可能为多智能体环境中的视角采择提供基础

Abstract: World models enable agents to plan by imagining future states, but existing approaches operate from a single viewpoint, typically egocentric, even when other perspectives would make planning easier; navigation, for instance, benefits from a bird's-eye view. We introduce Cross-View World Models (XVWM), trained with a cross-view prediction objective: given a sequence of frames from one viewpoint, predict the future state from the same or a different viewpoint after an action is taken. Enforcing cross-view consistency acts as geometric regularization: because the input and output views may share little or no visual overlap, to predict across viewpoints, the model must learn view-invariant representations of the environment's 3D structure. We train on synchronized multi-view gameplay data from Aimlabs, an aim-training platform providing precisely aligned multi-camera recordings with high-frequency action labels. The resulting model gives agents parallel imagination streams across viewpoints, enabling planning in whichever frame of reference best suits the task while executing from the egocentric view. Our results show that multi-view consistency provides a strong learning signal for spatially grounded representations. Finally, predicting the consequences of one's actions from another viewpoint may offer a foundation for perspective-taking in multi-agent settings.

</details>


### [46] [Diabetic Retinopathy Lesion Segmentation through Attention Mechanisms](https://arxiv.org/abs/2602.07301)
*Aruna Jithesh,Chinmayi Karumuri,Venkata Kiran Reddy Kotha,Meghana Doddapuneni,Taehee Jeong*

Main category: cs.CV

TL;DR: 本文提出了一种基于注意力机制的DeepLab-V3+模型，用于糖尿病视网膜病变相关病变的像素级分割，在DDR数据集上实现了性能提升。


<details>
  <summary>Details</summary>
Motivation: 糖尿病视网膜病变（DR）是导致视力丧失和失明的眼病，早期筛查至关重要。虽然已有许多基于深度学习的自动筛查算法，但在病变分割方面的临床应用仍有限。本文旨在提供像素级病变标注，辅助眼科医生进行DR筛查。

Method: 在DeepLab-V3+模型中集成注意力机制，用于分割四种DR相关病变：微动脉瘤、软性渗出物、硬性渗出物和出血。使用DDR数据集的757张图像进行训练和评估。

Result: Attention-DeepLab模型相比基线模型，平均精度（mAP）从0.3010提升至0.3326，平均交并比（IoU）从0.1791提升至0.1928。微动脉瘤检测从0.0205提升至0.0763，这是临床上的显著改进。

Conclusion: 集成注意力机制的DeepLab-V3+模型在DR病变分割方面表现出更好的性能，特别是对微动脉瘤的检测有显著提升，这对早期DR筛查具有重要临床意义。

Abstract: Diabetic Retinopathy (DR) is an eye disease which arises due to diabetes mellitus. It might cause vision loss and blindness. To prevent irreversible vision loss, early detection through systematic screening is crucial. Although researchers have developed numerous automated deep learning-based algorithms for DR screening, their clinical applicability remains limited, particularly in lesion segmentation. Our method provides pixel-level annotations for lesions, which practically supports Ophthalmologist to screen DR from fundus images. In this work, we segmented four types of DR-related lesions: microaneurysms, soft exudates, hard exudates, and hemorrhages on 757 images from DDR dataset. To enhance lesion segmentation, an attention mechanism was integrated with DeepLab-V3+. Compared to the baseline model, the Attention-DeepLab model increases mean average precision (mAP) from 0.3010 to 0.3326 and the mean Intersection over Union (IoU) from 0.1791 to 0.1928. The model also increased microaneurysm detection from 0.0205 to 0.0763, a clinically significant improvement. The detection of microaneurysms is the earliest visible symptom of DR.

</details>


### [47] [Optimization of Precipitate Segmentation Through Linear Genetic Programming of Image Processing](https://arxiv.org/abs/2602.07310)
*Kyle Williams,Andrew Seltzman*

Main category: cs.CV

TL;DR: 开发基于线性遗传编程的图像处理算法，自动检测增材制造铌铜合金显微图像中的析出物，替代人工标注，加速合金开发迭代


<details>
  <summary>Details</summary>
Motivation: 当前增材制造铌基铜合金分析依赖人工标注显微图像，但由于图像对比度变化、噪声和伪影等问题，标注过程缓慢，严重拖慢了合金开发迭代速度

Method: 使用线性遗传编程优化图像过滤和分割算法，通过特定领域语言构建图像处理流程，生成可解释的MATLAB代码，自动检测FIB截面显微图像中的析出物

Result: 在理想条件下（种群规模60，最大程序长度5个块），系统找到接近人工精度的解决方案，平均评估误差1.8%，处理360万像素图像仅需约2秒

Conclusion: 自动化算法显著加速了材料成分和工艺空间的探索，为增材制造聚变反应堆部件开发高强度、低活化、沉淀硬化铜合金提供了高效工具

Abstract: Current analysis of additive manufactured niobium-based copper alloys relies on hand annotation due to varying contrast, noise, and image artifacts present in micrographs, slowing iteration speed in alloy development. We present a filtering and segmentation algorithm for detecting precipitates in FIB cross-section micrographs, optimized using linear genetic programming (LGP), which accounts for the various artifacts. To this end, the optimization environment uses a domain-specific language for image processing to iterate on solutions. Programs in this language are a list of image-filtering blocks with tunable parameters that sequentially process an input image, allowing for reliable generation and mutation by a genetic algorithm. Our environment produces optimized human-interpretable MATLAB code representing an image filtering pipeline. Under ideal conditions--a population size of 60 and a maximum program length of 5 blocks--our system was able to find a near-human accuracy solution with an average evaluation error of 1.8% when comparing segmentations pixel-by-pixel to a human baseline using an XOR error evaluation. Our automation work enabled faster iteration cycles and furthered exploration of the material composition and processing space: our optimized pipeline algorithm processes a 3.6 megapixel image in about 2 seconds on average. This ultimately enables convergence on strong, low-activation, precipitation hardened copper alloys for additive manufactured fusion reactor parts.

</details>


### [48] [LUCID-SAE: Learning Unified Vision-Language Sparse Codes for Interpretable Concept Discovery](https://arxiv.org/abs/2602.07311)
*Difei Gu,Yunhe Gao,Gerasimos Chatzoudis,Zihan Dong,Guoning Zhang,Bangwei Guo,Yang Zhou,Mu Zhou,Dimitris Metaxas*

Main category: cs.CV

TL;DR: LUCID是一个统一的视觉-语言稀疏自编码器，学习图像补丁和文本标记表示的共享潜在字典，通过最优传输匹配实现特征对齐，产生可解释的共享特征并支持跨模态概念发现。


<details>
  <summary>Details</summary>
Motivation: 当前稀疏自编码器按模态单独训练，产生的特征字典不可直接理解且解释无法跨域迁移。需要一种统一的方法来学习可解释的跨模态表示。

Method: 提出LUCID框架：1) 学习图像补丁和文本标记的共享潜在字典，同时保留模态特定细节的私有容量；2) 通过最优传输匹配目标耦合共享代码实现特征对齐，无需标签；3) 开发基于术语聚类的自动字典解释流程。

Result: LUCID产生可解释的共享特征，支持补丁级定位、建立跨模态神经元对应关系，增强相似性评估中对概念聚类问题的鲁棒性。共享特征捕获超越对象的多样化语义类别，包括动作、属性和抽象概念。

Conclusion: LUCID通过统一的视觉-语言稀疏自编码器实现了可解释的跨模态概念发现，为理解多模态表示提供了一种全面的方法，展示了共享特征在捕捉丰富语义内容方面的潜力。

Abstract: Sparse autoencoders (SAEs) offer a natural path toward comparable explanations across different representation spaces. However, current SAEs are trained per modality, producing dictionaries whose features are not directly understandable and whose explanations do not transfer across domains. In this study, we introduce LUCID (Learning Unified vision-language sparse Codes for Interpretable concept Discovery), a unified vision-language sparse autoencoder that learns a shared latent dictionary for image patch and text token representations, while reserving private capacity for modality-specific details. We achieve feature alignment by coupling the shared codes with a learned optimal transport matching objective without the need of labeling. LUCID yields interpretable shared features that support patch-level grounding, establish cross-modal neuron correspondence, and enhance robustness against the concept clustering problem in similarity-based evaluation. Leveraging the alignment properties, we develop an automated dictionary interpretation pipeline based on term clustering without manual observations. Our analysis reveals that LUCID's shared features capture diverse semantic categories beyond objects, including actions, attributes, and abstract concepts, demonstrating a comprehensive approach to interpretable multimodal representations.

</details>


### [49] [Seeing Roads Through Words: A Language-Guided Framework for RGB-T Driving Scene Segmentation](https://arxiv.org/abs/2602.07343)
*Ruturaj Reddy,Hrishav Bakul Barua,Junn Yong Loo,Thanh Thi Nguyen,Ganesh Krishnasamy*

Main category: cs.CV

TL;DR: CLARITY提出了一种动态RGB-热融合策略，通过视觉语言模型先验自适应调整模态贡献，在恶劣光照条件下实现鲁棒的道路场景语义分割。


<details>
  <summary>Details</summary>
Motivation: 现有RGB-热融合方法采用静态融合策略，无法适应不同光照条件，导致模态特定噪声在网络中传播，影响自动驾驶在恶劣光照下的语义分割性能。

Method: 1) 基于视觉语言模型先验动态调整融合策略；2) 保留暗物体语义的有效信息；3) 引入分层解码器增强多尺度结构一致性；4) 利用物体嵌入而非固定融合策略进行分割。

Result: 在MFNet数据集上达到62.3% mIoU和77.5% mAcc，建立了新的最先进性能。

Conclusion: CLARITY通过动态融合策略和结构一致性机制，显著提升了恶劣光照条件下道路场景语义分割的鲁棒性和准确性。

Abstract: Robust semantic segmentation of road scenes under adverse illumination, lighting, and shadow conditions remain a core challenge for autonomous driving applications. RGB-Thermal fusion is a standard approach, yet existing methods apply static fusion strategies uniformly across all conditions, allowing modality-specific noise to propagate throughout the network. Hence, we propose CLARITY that dynamically adapts its fusion strategy to the detected scene condition. Guided by vision-language model (VLM) priors, the network learns to modulate each modality's contribution based on the illumination state while leveraging object embeddings for segmentation, rather than applying a fixed fusion policy. We further introduce two mechanisms, i.e., one which preserves valid dark-object semantics that prior noise-suppression methods incorrectly discard, and a hierarchical decoder that enforces structural consistency across scales to sharpen boundaries on thin objects. Experiments on the MFNet dataset demonstrate that CLARITY establishes a new state-of-the-art (SOTA), achieving 62.3% mIoU and 77.5% mAcc.

</details>


### [50] [Optimizing Few-Step Generation with Adaptive Matching Distillation](https://arxiv.org/abs/2602.07345)
*Lichen Bai,Zikai Zhou,Shitong Shao,Wenliang Zhong,Shuo Yang,Shuo Chen,Bojun Chen,Zeke Xie*

Main category: cs.CV

TL;DR: 本文提出自适应匹配蒸馏（AMD），通过显式检测和逃离"禁区"来增强分布匹配蒸馏的稳定性，在图像和视频生成任务中显著提升样本保真度和训练鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统分布匹配蒸馏（DMD）在"禁区"区域稳定性差，因为真实教师提供不可靠指导而虚假教师排斥力不足，需要解决这一优化问题。

Method: 提出自适应匹配蒸馏（AMD）：1）使用奖励代理显式检测和逃离禁区；2）通过结构信号分解动态优先校正梯度；3）引入排斥景观锐化来强制陡峭的能量壁垒防止失败模式崩溃。

Result: 在图像和视频生成任务（SDXL、Wan2.1）和基准测试（VBench、GenEval）中，AMD显著提升样本保真度和训练鲁棒性，如将SDXL的HPSv2分数从30.64提高到31.25，优于现有方法。

Conclusion: 显式修正禁区内的优化轨迹对于提升少步生成模型的性能上限至关重要，AMD通过自校正机制有效解决了DMD的稳定性问题。

Abstract: Distribution Matching Distillation (DMD) is a powerful acceleration paradigm, yet its stability is often compromised in Forbidden Zone, regions where the real teacher provides unreliable guidance while the fake teacher exerts insufficient repulsive force. In this work, we propose a unified optimization framework that reinterprets prior art as implicit strategies to avoid these corrupted regions. Based on this insight, we introduce Adaptive Matching Distillation (AMD), a self-correcting mechanism that utilizes reward proxies to explicitly detect and escape Forbidden Zones. AMD dynamically prioritizes corrective gradients via structural signal decomposition and introduces Repulsive Landscape Sharpening to enforce steep energy barriers against failure mode collapse. Extensive experiments across image and video generation tasks (e.g., SDXL, Wan2.1) and rigorous benchmarks (e.g., VBench, GenEval) demonstrate that AMD significantly enhances sample fidelity and training robustness. For instance, AMD improves the HPSv2 score on SDXL from 30.64 to 31.25, outperforming state-of-the-art baselines. These findings validate that explicitly rectifying optimization trajectories within Forbidden Zones is essential for pushing the performance ceiling of few-step generative models.

</details>


### [51] [Row-Column Separated Attention Based Low-Light Image/Video Enhancement](https://arxiv.org/abs/2602.07428)
*Chengqi Dong,Zhiyuan Cao,Tuoshi Qi,Kexin Wu,Yixing Gao,Fan Tang*

Main category: cs.CV

TL;DR: 提出基于改进U-Net和行列分离注意力模块的低光图像/视频增强方法，通过全局信息指导局部信息，减少参数同时保持时间一致性。


<details>
  <summary>Details</summary>
Motivation: 现有U-Net结构在低光增强中缺乏全局信息指导，导致局部噪声大和细节丢失；注意力机制能更好利用全局信息但参数和计算量大。

Method: 1) 改进U-Net结构；2) 提出行列分离注意力模块(RCSA)，利用特征图行列的均值和最大值，以较少参数实现全局信息指导局部信息；3) 提出两种时间损失函数用于视频增强的时间一致性。

Result: 在LOL、MIT Adobe FiveK图像数据集和SDSD视频数据集上的大量实验证明了方法的有效性。

Conclusion: 提出的URCSA方法通过RCSA模块有效利用全局信息指导低光增强，减少参数同时保持时间一致性，代码已开源。

Abstract: U-Net structure is widely used for low-light image/video enhancement. The enhanced images result in areas with large local noise and loss of more details without proper guidance for global information. Attention mechanisms can better focus on and use global information. However, attention to images could significantly increase the number of parameters and computations. We propose a Row-Column Separated Attention module (RCSA) inserted after an improved U-Net. The RCSA module's input is the mean and maximum of the row and column of the feature map, which utilizes global information to guide local information with fewer parameters. We propose two temporal loss functions to apply the method to low-light video enhancement and maintain temporal consistency. Extensive experiments on the LOL, MIT Adobe FiveK image, and SDSD video datasets demonstrate the effectiveness of our approach. The code is publicly available at https://github.com/cq-dong/URCSA.

</details>


### [52] [Perspective-aware fusion of incomplete depth maps and surface normals for accurate 3D reconstruction](https://arxiv.org/abs/2602.07444)
*Ondrej Hlinka,Georg Kaniak,Christian Kapeller*

Main category: cs.CV

TL;DR: 提出一种透视感知的对数深度融合方法，从单视角相机获取的深度和法线图重建3D表面，处理缺失深度测量并实现度量精确的重建。


<details>
  <summary>Details</summary>
Motivation: 现有基于正交投影的梯度深度-法线融合方法在处理透视投影数据时存在精度问题，需要一种能够显式考虑透视投影的方法来实现度量精确的3D重建。

Method: 提出透视感知的对数深度融合方法，扩展现有正交梯度深度-法线融合技术，显式考虑透视投影，并利用表面法线信息填补深度测量缺失区域。

Result: 在DiLiGenT-MV数据集上的实验证明了方法的有效性，并突出了透视感知深度-法线融合的重要性。

Conclusion: 该方法能够从单视角相机获取的深度和法线图实现度量精确的3D重建，有效处理缺失深度测量，为基于深度-法线融合的3D重建提供了透视感知的解决方案。

Abstract: We address the problem of reconstructing 3D surfaces from depth and surface normal maps acquired by a sensor system based on a single perspective camera. Depth and normal maps can be obtained through techniques such as structured-light scanning and photometric stereo, respectively. We propose a perspective-aware log-depth fusion approach that extends existing orthographic gradient-based depth-normals fusion methods by explicitly accounting for perspective projection, leading to metrically accurate 3D reconstructions. Additionally, the method handles missing depth measurements by leveraging available surface normal information to inpaint gaps. Experiments on the DiLiGenT-MV data set demonstrate the effectiveness of our approach and highlight the importance of perspective-aware depth-normals fusion.

</details>


### [53] [PTB-XL-Image-17K: A Large-Scale Synthetic ECG Image Dataset with Comprehensive Ground Truth for Deep Learning-Based Digitization](https://arxiv.org/abs/2602.07446)
*Naqcho Ali Mehdi*

Main category: cs.CV

TL;DR: PTB-XL-Image-17K是一个包含17,271个高质量12导联心电图图像的合成数据集，为心电图数字化研究提供完整的基准数据，包括图像、分割掩码、时间序列信号、边界框标注和元数据。


<details>
  <summary>Details</summary>
Motivation: 心电图数字化（将纸质或扫描的心电图图像转换回时间序列信号）对于利用数十年的临床数据至关重要，但缺乏大规模同时包含图像和真实信号标注的数据集阻碍了研究进展。

Method: 基于PTB-XL信号数据库，开发了一个开源Python框架，生成包含五种互补数据类型的合成心电图图像：真实心电图图像、像素级分割掩码、时间序列信号、YOLO格式边界框标注和元数据，支持可自定义参数。

Result: 成功生成了17,271个样本，生成成功率100%，平均处理时间1.35秒/样本，提供了第一个支持完整心电图数字化流程（导联检测、波形分割、信号提取）的大规模资源。

Conclusion: PTB-XL-Image-17K填补了心电图数字化研究的关键空白，为严格的算法评估提供了首个大规模基准数据集，数据集、生成框架和文档均已公开。

Abstract: Electrocardiogram (ECG) digitization-converting paper-based or scanned ECG images back into time-series signals-is critical for leveraging decades of legacy clinical data in modern deep learning applications. However, progress has been hindered by the lack of large-scale datasets providing both ECG images and their corresponding ground truth signals with comprehensive annotations. We introduce PTB-XL-Image-17K, a complete synthetic ECG image dataset comprising 17,271 high-quality 12-lead ECG images generated from the PTB-XL signal database. Our dataset uniquely provides five complementary data types per sample: (1) realistic ECG images with authentic grid patterns and annotations (50% with visible grid, 50% without), (2) pixel-level segmentation masks, (3) ground truth time-series signals, (4) bounding box annotations in YOLO format for both lead regions and lead name labels, and (5) comprehensive metadata including visual parameters and patient information. We present an open-source Python framework enabling customizable dataset generation with controllable parameters including paper speed (25/50 mm/s), voltage scale (5/10 mm/mV), sampling rate (500 Hz), grid appearance (4 colors), and waveform characteristics. The dataset achieves 100% generation success rate with an average processing time of 1.35 seconds per sample. PTB-XL-Image-17K addresses critical gaps in ECG digitization research by providing the first large-scale resource supporting the complete pipeline: lead detection, waveform segmentation, and signal extraction with full ground truth for rigorous evaluation. The dataset, generation framework, and documentation are publicly available at https://github.com/naqchoalimehdi/PTB-XL-Image-17K and https://doi.org/10.5281/zenodo.18197519.

</details>


### [54] [SoulX-FlashHead: Oracle-guided Generation of Infinite Real-time Streaming Talking Heads](https://arxiv.org/abs/2602.07449)
*Tan Yu,Qian Qiao,Le Shen,Ke Zhou,Jincheng Hu,Dian Sheng,Bo Hu,Haoming Qin,Jun Gao,Changhai Zhou,Shunshun Yin,Siyuan Liu*

Main category: cs.CV

TL;DR: SoulX-FlashHead是一个1.3B参数的实时音频驱动肖像生成框架，通过流式时空预训练和双向蒸馏技术，在保持高保真视觉质量的同时实现低延迟流式生成。


<details>
  <summary>Details</summary>
Motivation: 现有音频驱动肖像生成模型面临两难：大规模模型计算成本过高，轻量级模型则牺牲了面部表示完整性和时间稳定性。需要平衡高保真视觉质量和低延迟流式生成。

Method: 1) 提出1.3B参数统一框架；2) 引入流式感知时空预训练，配备时序音频上下文缓存机制；3) 提出Oracle引导双向蒸馏，利用真实运动先验提供物理指导；4) 构建VividHead数据集（782小时对齐视频）。

Result: 在HDTF和VFHQ基准测试中达到SOTA性能。Lite变体在单张RTX 4090上实现96 FPS推理速度，支持超快速交互而不牺牲视觉连贯性。

Conclusion: SoulX-FlashHead成功解决了音频驱动肖像生成中高保真与低延迟的矛盾，通过创新的流式预训练和蒸馏技术，实现了实时、无限长度的高质量流式视频生成。

Abstract: Achieving a balance between high-fidelity visual quality and low-latency streaming remains a formidable challenge in audio-driven portrait generation. Existing large-scale models often suffer from prohibitive computational costs, while lightweight alternatives typically compromise on holistic facial representations and temporal stability. In this paper, we propose SoulX-FlashHead, a unified 1.3B-parameter framework designed for real-time, infinite-length, and high-fidelity streaming video generation. To address the instability of audio features in streaming scenarios, we introduce Streaming-Aware Spatiotemporal Pre-training equipped with a Temporal Audio Context Cache mechanism, which ensures robust feature extraction from short audio fragments. Furthermore, to mitigate the error accumulation and identity drift inherent in long-sequence autoregressive generation, we propose Oracle-Guided Bidirectional Distillation, leveraging ground-truth motion priors to provide precise physical guidance. We also present VividHead, a large-scale, high-quality dataset containing 782 hours of strictly aligned footage to support robust training. Extensive experiments demonstrate that SoulX-FlashHead achieves state-of-the-art performance on HDTF and VFHQ benchmarks. Notably, our Lite variant achieves an inference speed of 96 FPS on a single NVIDIA RTX 4090, facilitating ultra-fast interaction without sacrificing visual coherence.

</details>


### [55] [SpatialReward: Bridging the Perception Gap in Online RL for Image Editing via Explicit Spatial Reasoning](https://arxiv.org/abs/2602.07458)
*Yancheng Long,Yankai Yang,Hongyang Wei,Wei Chen,Tianke Zhang,Haonan fan,Changyi Liu,Kaiyu Jiang,Jiankang Chen,Kaiyu Tang,Bin Wen,Fan Yang,Tingting Gao,Han Li,Shuo Yang*

Main category: cs.CV

TL;DR: SpatialReward提出了一种基于空间推理的奖励模型，通过像素级证据进行精确验证，解决了在线强化学习图像编辑中奖励信号不足和注意力崩溃问题，在多个基准测试中达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 当前在线强化学习图像编辑面临可靠细粒度奖励信号稀缺的问题，现有评估器存在"注意力崩溃"现象，即模型忽视跨图像比较和细粒度细节，导致感知不准确和分数校准错误。

Method: 提出SpatialReward奖励模型，通过显式空间推理进行精确验证，将推理锚定到预测的编辑区域，使语义判断基于像素级证据。在精心策划的26万空间感知数据集上进行训练。

Result: 在MMRB2和EditReward-Bench上达到最先进性能，在提出的MultiEditReward-Bench上优于专有评估器。作为在线RL信号，将OmniGen2在GEdit-Bench上提升+0.90，超越领先判别模型，是GPT-4.1增益的两倍。

Conclusion: 空间推理对于实现图像编辑中的有效对齐至关重要，SpatialReward通过像素级证据的精确验证显著提升了评估准确性，为在线强化学习图像编辑提供了可靠的奖励信号。

Abstract: Online Reinforcement Learning (RL) offers a promising avenue for complex image editing but is currently constrained by the scarcity of reliable and fine-grained reward signals. Existing evaluators frequently struggle with a critical perception gap we term "Attention Collapse," where models neglect cross-image comparisons and fail to capture fine-grained details, resulting in inaccurate perception and miscalibrated scores. To address these limitations, we propose SpatialReward, a reward model that enforces precise verification via explicit spatial reasoning. By anchoring reasoning to predicted edit regions, SpatialReward grounds semantic judgments in pixel-level evidence, significantly enhancing evaluative accuracy. Trained on a curated 260k spatial-aware dataset, our model achieves state-of-the-art performance on MMRB2 and EditReward-Bench, and outperforms proprietary evaluators on our proposed MultiEditReward-Bench. Furthermore, SpatialReward serves as a robust signal in online RL, boosting OmniGen2 by +0.90 on GEdit-Bench--surpassing the leading discriminative model and doubling the gain of GPT-4.1 (+0.45). These results demonstrate that spatial reasoning is essential for unlocking effective alignment in image editing.

</details>


### [56] [GlobalWasteData: A Large-Scale, Integrated Dataset for Robust Waste Classification and Environmental Monitoring](https://arxiv.org/abs/2602.07463)
*Misbah Ijaz,Saif Ur Rehman Khan,Abd Ur Rehman,Tayyaba Asif,Sebastian Vollmer,Andreas Dengel,Muhammad Nabeel Asim*

Main category: cs.CV

TL;DR: 研究者创建了GlobalWasteData (GWD)数据集，整合了多个公开的垃圾分类数据集，包含89,807张图像、14个主类别和68个子类，旨在解决现有数据集碎片化、不一致和偏置问题。


<details>
  <summary>Details</summary>
Motivation: 现有垃圾分类数据集存在碎片化、不一致、偏置特定环境等问题，类别名称、标注格式、图像条件和类别分布差异大，难以组合或训练出泛化能力强的模型，阻碍了自动化垃圾分类系统的发展。

Method: 通过合并多个公开数据集创建统一的GWD数据集，进行质量过滤、重复去除和元数据生成等预处理，确保一致的标注、改进的领域多样性和更平衡的类别表示。

Result: 成功构建了包含89,807张图像、14个主类别和68个子类的GWD数据集，提供了更一致、多样且平衡的垃圾分类数据资源，为开发鲁棒且可泛化的垃圾识别模型奠定了基础。

Conclusion: GWD数据集解决了现有垃圾分类数据集的局限性，为环境监测、回收自动化和垃圾识别等机器学习应用提供了可靠基础，公开可用以促进未来研究和可重复性。

Abstract: The growing amount of waste is a problem for the environment that requires efficient sorting techniques for various kinds of waste. An automated waste classification system is used for this purpose. The effectiveness of these Artificial Intelligence (AI) models depends on the quality and accessibility of publicly available datasets, which provide the basis for training and analyzing classification algorithms. Although several public waste classification datasets exist, they remain fragmented, inconsistent, and biased toward specific environments. Differences in class names, annotation formats, image conditions, and class distributions make it difficult to combine these datasets or train models that generalize well to real world scenarios. To address these issues, we introduce the GlobalWasteData (GWD) archive, a large scale dataset of 89,807 images across 14 main categories, annotated with 68 distinct subclasses. We compile this novel integrated GWD archive by merging multiple publicly available datasets into a single, unified resource. This GWD archive offers consistent labeling, improved domain diversity, and more balanced class representation, enabling the development of robust and generalizable waste recognition models. Additional preprocessing steps such as quality filtering, duplicate removal, and metadata generation further improve dataset reliability. Overall, this dataset offers a strong foundation for Machine Learning (ML) applications in environmental monitoring, recycling automation, and waste identification, and is publicly available to promote future research and reproducibility.

</details>


### [57] [Thermal odometry and dense mapping using learned ddometry and Gaussian splatting](https://arxiv.org/abs/2602.07493)
*Tianhao Zhou,Yujia Chen,Zhihao Zhan,Yuhang Ming,Jianzhu Huai*

Main category: cs.CV

TL;DR: TOM-GS：首个基于高斯溅射的热红外相机SLAM系统，结合学习里程计与密集建图，在恶劣条件下实现鲁棒的运动估计和高质量重建


<details>
  <summary>Details</summary>
Motivation: 热红外传感器能在黑暗、灰尘和烟雾条件下稳定成像，但现有热里程计和建图方法主要是几何方法，在不同数据集上表现不稳定且无法生成密集地图。受高斯溅射技术高效高质量重建能力的启发，需要开发专门针对热相机的SLAM系统。

Method: 提出TOM-GS方法，整合学习型里程计与基于高斯溅射的密集建图。系统包含专门的热图像增强模块和单目深度集成模块，是首个针对热相机的高斯溅射SLAM系统。

Result: 在运动估计和新视角渲染方面的广泛实验表明，TOM-GS优于现有的学习方法，验证了学习型流程在鲁棒热里程计和密集重建方面的优势。

Conclusion: TOM-GS成功将高斯溅射技术应用于热红外SLAM，实现了在恶劣条件下的鲁棒运动估计和高质量密集重建，为热相机在机器人环境感知中的应用提供了有效解决方案。

Abstract: Thermal infrared sensors, with wavelengths longer than smoke particles, can capture imagery independent of darkness, dust, and smoke. This robustness has made them increasingly valuable for motion estimation and environmental perception in robotics, particularly in adverse conditions. Existing thermal odometry and mapping approaches, however, are predominantly geometric and often fail across diverse datasets while lacking the ability to produce dense maps. Motivated by the efficiency and high-quality reconstruction ability of recent Gaussian Splatting (GS) techniques, we propose TOM-GS, a thermal odometry and mapping method that integrates learning-based odometry with GS-based dense mapping. TOM-GS is among the first GS-based SLAM systems tailored for thermal cameras, featuring dedicated thermal image enhancement and monocular depth integration. Extensive experiments on motion estimation and novel-view rendering demonstrate that TOM-GS outperforms existing learning-based methods, confirming the benefits of learning-based pipelines for robust thermal odometry and dense reconstruction.

</details>


### [58] [Learning Brain Representation with Hierarchical Visual Embeddings](https://arxiv.org/abs/2602.07495)
*Jiawen Zheng,Haonan Jia,Ming Li,Yuhui Zheng,Yufeng Zeng,Yang Gao,Chen Liang*

Main category: cs.CV

TL;DR: 提出一种利用多预训练视觉编码器和对比学习的大脑-图像对齐策略，结合融合先验增强跨模态一致性，在视觉解码中实现检索精度与重建保真度的良好平衡。


<details>
  <summary>Details</summary>
Motivation: 当前视觉解码方法大多关注高层语义特征而忽略像素级细节，限制了我们对人类视觉系统的理解。需要探索更有效的大脑-图像对齐策略来解码大脑信号中的视觉信息。

Method: 1) 利用多个具有不同归纳偏置的预训练视觉编码器捕获分层多尺度视觉表示；2) 采用对比学习目标实现大脑信号与视觉嵌入的有效对齐；3) 引入融合先验，在大规模视觉数据上学习稳定映射，然后将大脑特征匹配到这个预训练先验，增强跨模态分布一致性。

Result: 广泛的定量和定性实验表明，该方法在检索精度和重建保真度之间实现了良好的平衡，优于现有方法。

Conclusion: 提出的多编码器对齐策略和融合先验方法能够有效解码大脑信号中的视觉信息，为理解人类视觉系统提供了新视角。

Abstract: Decoding visual representations from brain signals has attracted significant attention in both neuroscience and artificial intelligence. However, the degree to which brain signals truly encode visual information remains unclear. Current visual decoding approaches explore various brain-image alignment strategies, yet most emphasize high-level semantic features while neglecting pixel-level details, thereby limiting our understanding of the human visual system. In this paper, we propose a brain-image alignment strategy that leverages multiple pre-trained visual encoders with distinct inductive biases to capture hierarchical and multi-scale visual representations, while employing a contrastive learning objective to achieve effective alignment between brain signals and visual embeddings. Furthermore, we introduce a Fusion Prior, which learns a stable mapping on large-scale visual data and subsequently matches brain features to this pre-trained prior, thereby enhancing distributional consistency across modalities. Extensive quantitative and qualitative experiments demonstrate that our method achieves a favorable balance between retrieval accuracy and reconstruction fidelity.

</details>


### [59] [IM-Animation: An Implicit Motion Representation for Identity-decoupled Character Animation](https://arxiv.org/abs/2602.07498)
*Zhufeng Xu,Xuan Gao,Feng-Lin Liu,Haoxian Zhang,Zhixue Fang,Yu-Kun Lai,Xiaoqiang Liu,Pengfei Wan,Lin Gao*

Main category: cs.CV

TL;DR: 提出了一种新颖的隐式运动表示方法，将每帧运动压缩为紧凑的1D运动token，解决了现有显式方法的空间不匹配问题和隐式方法的身份泄漏问题，实现了更好的角色动画效果。


<details>
  <summary>Details</summary>
Motivation: 现有角色动画方法存在两大问题：显式方法（如骨架、DWPose）难以处理空间不匹配和身体比例变化；隐式方法虽然能捕捉高级运动语义，但存在身份信息泄漏和运动与外观纠缠的问题。

Method: 提出紧凑的1D运动token表示方法，放松了2D表示的严格空间约束；设计了基于时间一致掩码token的重定向模块，通过时间训练瓶颈减少源图像运动的干扰；采用三阶段训练策略提高效率和保真度。

Result: 实验表明，提出的IM-Animation方法在生成能力上达到或超越了现有最先进方法的性能，有效解决了身份泄漏和运动-外观纠缠问题。

Conclusion: 提出的隐式运动表示方法通过1D运动token和掩码token重定向模块，成功解决了角色动画中的关键挑战，为视频扩散模型在角色动画领域的应用提供了有效解决方案。

Abstract: Recent progress in video diffusion models has markedly advanced character animation, which synthesizes motioned videos by animating a static identity image according to a driving video. Explicit methods represent motion using skeleton, DWPose or other explicit structured signals, but struggle to handle spatial mismatches and varying body scales. %proportions. Implicit methods, on the other hand, capture high-level implicit motion semantics directly from the driving video, but suffer from identity leakage and entanglement between motion and appearance. To address the above challenges, we propose a novel implicit motion representation that compresses per-frame motion into compact 1D motion tokens. This design relaxes strict spatial constraints inherent in 2D representations and effectively prevents identity information leakage from the motion video. Furthermore, we design a temporally consistent mask token-based retargeting module that enforces a temporal training bottleneck, mitigating interference from the source images' motion and improving retargeting consistency. Our methodology employs a three-stage training strategy to enhance the training efficiency and ensure high fidelity. Extensive experiments demonstrate that our implicit motion representation and the propose IM-Animation's generative capabilities are achieve superior or competitive performance compared with state-of-the-art methods.

</details>


### [60] [Adaptive Image Zoom-in with Bounding Box Transformation for UAV Object Detection](https://arxiv.org/abs/2602.07512)
*Tao Wang,Chenyu Lin,Chenwei Tang,Jizhe Zhou,Deng Xiong,Jianan Li,Jian Zhao,Jiancheng Lv*

Main category: cs.CV

TL;DR: ZoomDet：一种用于无人机图像目标检测的自适应放大框架，通过非均匀放大物体区域来改善小目标检测性能


<details>
  <summary>Details</summary>
Motivation: 无人机图像中的目标通常较小且稀疏，这阻碍了有效目标检测器的优化。需要自适应放大物体区域以更好地捕获目标特征。

Method: 提出轻量级偏移预测方案和基于边界框的放大目标，学习输入图像的非均匀放大变换。采用角对齐的边界框变换方法，在放大空间训练检测器，在推理时转换回原始空间。

Result: 在VisDrone、UAVDT和SeaDronesSee三个无人机目标检测数据集上进行了广泛实验。在SeaDronesSee数据集上，使用Faster R-CNN模型获得了超过8.4个绝对mAP增益，仅增加约3ms延迟。

Conclusion: ZoomDet是一种架构无关的自适应放大框架，可显著提升无人机图像中小目标检测性能，计算开销小，具有实际应用价值。

Abstract: Detecting objects from UAV-captured images is challenging due to the small object size. In this work, a simple and efficient adaptive zoom-in framework is explored for object detection on UAV images. The main motivation is that the foreground objects are generally smaller and sparser than those in common scene images, which hinders the optimization of effective object detectors. We thus aim to zoom in adaptively on the objects to better capture object features for the detection task. To achieve the goal, two core designs are required: \textcolor{black}{i) How to conduct non-uniform zooming on each image efficiently? ii) How to enable object detection training and inference with the zoomed image space?} Correspondingly, a lightweight offset prediction scheme coupled with a novel box-based zooming objective is introduced to learn non-uniform zooming on the input image. Based on the learned zooming transformation, a corner-aligned bounding box transformation method is proposed. The method warps the ground-truth bounding boxes to the zoomed space to learn object detection, and warps the predicted bounding boxes back to the original space during inference. We conduct extensive experiments on three representative UAV object detection datasets, including VisDrone, UAVDT, and SeaDronesSee. The proposed ZoomDet is architecture-independent and can be applied to an arbitrary object detection architecture. Remarkably, on the SeaDronesSee dataset, ZoomDet offers more than 8.4 absolute gain of mAP with a Faster R-CNN model, with only about 3 ms additional latency. The code is available at https://github.com/twangnh/zoomdet_code.

</details>


### [61] [CA-YOLO: Cross Attention Empowered YOLO for Biomimetic Localization](https://arxiv.org/abs/2602.07523)
*Zhen Zhang,Qing Zhao,Xiuhe Li,Cheng Wang,Guoqiang Zhu,Yu Zhang,Yining Huo,Hongyi Yu,Yi Zhang*

Main category: cs.CV

TL;DR: 提出基于CA-YOLO的仿生稳定定位系统，通过仿生模块改进YOLO主干网络，结合仿生云台跟踪控制策略，显著提升目标定位精度和小目标识别能力。


<details>
  <summary>Details</summary>
Motivation: 现代复杂环境中，现有系统在目标定位精度和小目标识别能力方面存在局限，需要开发更准确高效的定位系统。

Method: 1) 在YOLO主干网络中集成仿生模块：引入小目标检测头和特征融合注意力机制(CFAM)；2) 受人类前庭眼反射启发，开发仿生云台跟踪控制策略，包括中心定位、稳定性优化、自适应控制系数调整和智能重捕获功能。

Result: CA-YOLO在标准数据集(COCO和VisDrone)上优于原始模型，平均精度指标分别提升3.94%和4.90%。时间敏感目标定位实验验证了系统的有效性和实用性。

Conclusion: 提出的仿生稳定定位系统通过仿生视觉聚焦机制和云台跟踪控制策略，显著提高了目标定位精度和小目标识别能力，在复杂环境中具有实际应用价值。

Abstract: In modern complex environments, achieving accurate and efficient target localization is essential in numerous fields. However, existing systems often face limitations in both accuracy and the ability to recognize small targets. In this study, we propose a bionic stabilized localization system based on CA-YOLO, designed to enhance both target localization accuracy and small target recognition capabilities. Acting as the "brain" of the system, the target detection algorithm emulates the visual focusing mechanism of animals by integrating bionic modules into the YOLO backbone network. These modules include the introduction of a small target detection head and the development of a Characteristic Fusion Attention Mechanism (CFAM). Furthermore, drawing inspiration from the human Vestibulo-Ocular Reflex (VOR), a bionic pan-tilt tracking control strategy is developed, which incorporates central positioning, stability optimization, adaptive control coefficient adjustment, and an intelligent recapture function. The experimental results show that CA-YOLO outperforms the original model on standard datasets (COCO and VisDrone), with average accuracy metrics improved by 3.94%and 4.90%, respectively.Further time-sensitive target localization experiments validate the effectiveness and practicality of this bionic stabilized localization system.

</details>


### [62] [Evaluating Object-Centric Models beyond Object Discovery](https://arxiv.org/abs/2602.07532)
*Krishnakant Singh,Simone Schaub-Meyer,Stefan Roth*

Main category: cs.CV

TL;DR: 本文提出了一种新的对象中心学习（OCL）评估框架，使用指令调优的视觉语言模型作为评估器，并引入统一的评估任务和指标来联合评估定位能力和表示有用性。


<details>
  <summary>Details</summary>
Motivation: 当前OCL模型的评估主要关注对象发现和简单推理任务，无法全面衡量表示的有用性，且定位能力和表示有用性使用分离的指标评估，存在局限性。

Method: 1) 使用指令调优的视觉语言模型作为评估器，在多样化的VQA数据集上进行可扩展的基准测试；2) 引入统一的评估任务和指标，联合评估定位（where）和表示有用性（what）；3) 包含简单的多特征重建基线作为参考点。

Result: 提出的评估框架能够更全面地衡量OCL模型在复杂推理任务中的表示有用性，并通过统一指标消除了分离评估带来的不一致性。

Conclusion: 该研究为OCL模型提供了更有效的评估方法，能够更好地衡量模型在组合泛化和OOD鲁棒性方面的表现，推动了OCL研究的发展。

Abstract: Object-centric learning (OCL) aims to learn structured scene representations that support compositional generalization and robustness to out-of-distribution (OOD) data. However, OCL models are often not evaluated regarding these goals. Instead, most prior work focuses on evaluating OCL models solely through object discovery and simple reasoning tasks, such as probing the representation via image classification. We identify two limitations in existing benchmarks: (1) They provide limited insights on the representation usefulness of OCL models, and (2) localization and representation usefulness are assessed using disjoint metrics. To address (1), we use instruction-tuned VLMs as evaluators, enabling scalable benchmarking across diverse VQA datasets to measure how well VLMs leverage OCL representations for complex reasoning tasks. To address (2), we introduce a unified evaluation task and metric that jointly assess localization (where) and representation usefulness (what), thereby eliminating inconsistencies introduced by disjoint evaluation. Finally, we include a simple multi-feature reconstruction baseline as a reference point.

</details>


### [63] [Fine-Grained Cat Breed Recognition with Global Context Vision Transformer](https://arxiv.org/abs/2602.07534)
*Mowmita Parvin Hera,Md. Shahriar Mahmud Kallol,Shohanur Rahman Nirob,Md. Badsha Bulbul,Jubayer Ahmed,M. Zhourul Islam,Hazrat Ali,Mohammmad Farhad Bulbul*

Main category: cs.CV

TL;DR: 使用GCViT-Tiny架构对猫品种进行图像分类，在Oxford-IIIT Pet Dataset子集上达到92.00%测试准确率和94.54%验证准确率


<details>
  <summary>Details</summary>
Motivation: 猫品种识别具有挑战性，因为不同品种在毛皮图案、面部结构和颜色上差异细微。需要准确的方法来支持兽医诊断、动物收容所管理和移动端识别系统等应用。

Method: 采用Global Context Vision Transformer (GCViT)架构的Tiny版本进行猫品种识别。使用Oxford-IIIT Pet Dataset的高分辨率图像子集，通过旋转、水平翻转和亮度调整等数据增强技术提升模型泛化能力。

Result: GCViT-Tiny模型在测试集上达到92.00%准确率，验证集上达到94.54%准确率。结果表明基于Transformer的架构在细粒度图像分类任务中表现优异。

Conclusion: Transformer架构在猫品种识别等细粒度图像分类任务中效果显著。研究提供了Hugging Face演示，潜在应用包括兽医诊断、动物收容所管理和移动端识别系统。

Abstract: Accurate identification of cat breeds from images is a challenging task due to subtle differences in fur patterns, facial structure, and color. In this paper, we present a deep learning-based approach for classifying cat breeds using a subset of the Oxford-IIIT Pet Dataset, which contains high-resolution images of various domestic breeds. We employed the Global Context Vision Transformer (GCViT) architecture-tiny for cat breed recognition. To improve model generalization, we used extensive data augmentation, including rotation, horizontal flipping, and brightness adjustment. Experimental results show that the GCViT-Tiny model achieved a test accuracy of 92.00% and validation accuracy of 94.54%. These findings highlight the effectiveness of transformer-based architectures for fine-grained image classification tasks. Potential applications include veterinary diagnostics, animal shelter management, and mobile-based breed recognition systems. We also provide a hugging face demo at https://huggingface.co/spaces/bfarhad/cat-breed-classifier.

</details>


### [64] [Beyond Core and Penumbra: Bi-Temporal Image-Driven Stroke Evolution Analysis](https://arxiv.org/abs/2602.07535)
*Md Sazidur Rahman,Kjersti Engan,Kathinka Dæhli Kurz,Mahdieh Khanmohammadi*

Main category: cs.CV

TL;DR: 提出双时间点分析框架，利用统计描述符、纹理特征和深度特征嵌入分析脑卒中缺血组织的时空演化，通过特征空间聚类区分可挽救与不可挽救组织。


<details>
  <summary>Details</summary>
Motivation: 单时间点分割无法捕捉脑卒中生物异质性和时间演化，需要开发能表征组织状态转变的分析方法。

Method: 提出双时间点分析框架，从入院CTP和随访DWI提取特征，构建6个ROI区域，使用统计描述符、纹理特征和两种深度网络（mJ-Net和nnU-Net）的特征嵌入进行分析。

Result: 在18名成功再灌注患者中，特征空间聚类显示：可恢复的缺血半暗带区域特征与保留脑组织相似，而梗死区域形成明显分组。深度特征空间（特别是mJ-Net）能显著区分可挽救与不可挽救组织。

Conclusion: 编码器衍生的特征流形反映了潜在的组织表型和状态转变，为基于影像的脑卒中演化量化提供了新见解。

Abstract: Computed tomography perfusion (CTP) at admission is routinely used to estimate the ischemic core and penumbra, while follow-up diffusion-weighted MRI (DWI) provides the definitive infarct outcome. However, single time-point segmentations fail to capture the biological heterogeneity and temporal evolution of stroke. We propose a bi-temporal analysis framework that characterizes ischemic tissue using statistical descriptors, radiomic texture features, and deep feature embeddings from two architectures (mJ-Net and nnU-Net). Bi-temporal refers to admission (T1) and post-treatment follow-up (T2). All features are extracted at T1 from CTP, with follow-up DWI aligned to ensure spatial correspondence. Manually delineated masks at T1 and T2 are intersected to construct six regions of interest (ROIs) encoding both initial tissue state and final outcome. Features were aggregated per region and analyzed in feature space. Evaluation on 18 patients with successful reperfusion demonstrated meaningful clustering of region-level representations. Regions classified as penumbra or healthy at T1 that ultimately recovered exhibited feature similarity to preserved brain tissue, whereas infarct-bound regions formed distinct groupings. Both baseline GLCM and deep embeddings showed a similar trend: penumbra regions exhibit features that are significantly different depending on final state, whereas this difference is not significant for core regions. Deep feature spaces, particularly mJ-Net, showed strong separation between salvageable and non-salvageable tissue, with a penumbra separation index that differed significantly from zero (Wilcoxon signed-rank test). These findings suggest that encoder-derived feature manifolds reflect underlying tissue phenotypes and state transitions, providing insight into imaging-based quantification of stroke evolution.

</details>


### [65] [LLM-Guided Diagnostic Evidence Alignment for Medical Vision-Language Pretraining under Limited Pairing](https://arxiv.org/abs/2602.07540)
*Huimin Yan,Liang Bai,Xian Yang,Long Chen*

Main category: cs.CV

TL;DR: 提出LGDEA方法，通过LLM提取诊断证据构建共享空间，实现证据级别的跨模态对齐，减少对配对数据的依赖


<details>
  <summary>Details</summary>
Motivation: 现有医学视觉-语言预训练方法存在局限性：全局对齐易受非诊断信息干扰，局部对齐无法整合关键诊断证据，导致在配对数据有限时难以学习可靠的诊断表示

Method: LGDEA方法利用LLM从放射学报告中提取关键诊断证据，构建共享诊断证据空间，实现证据感知的跨模态对齐，有效利用大量未配对的医学图像和报告

Result: 在短语定位、图像-文本检索和零样本分类任务上取得一致且显著的改进，性能甚至可与依赖大量配对数据的预训练方法相媲美

Conclusion: LGDEA通过证据级别的对齐方法，更符合医学诊断过程，显著减少了对配对数据的依赖，在医学视觉-语言预训练中表现出优越性能

Abstract: Most existing CLIP-style medical vision--language pretraining methods rely on global or local alignment with substantial paired data. However, global alignment is easily dominated by non-diagnostic information, while local alignment fails to integrate key diagnostic evidence. As a result, learning reliable diagnostic representations becomes difficult, which limits their applicability in medical scenarios with limited paired data. To address this issue, we propose an LLM-Guided Diagnostic Evidence Alignment method (LGDEA), which shifts the pretraining objective toward evidence-level alignment that is more consistent with the medical diagnostic process. Specifically, we leverage LLMs to extract key diagnostic evidence from radiology reports and construct a shared diagnostic evidence space, enabling evidence-aware cross-modal alignment and allowing LGDEA to effectively exploit abundant unpaired medical images and reports, thereby substantially alleviating the reliance on paired data. Extensive experimental results demonstrate that our method achieves consistent and significant improvements on phrase grounding, image--text retrieval, and zero-shot classification, and even rivals pretraining methods that rely on substantial paired data.

</details>


### [66] [MUFASA: A Multi-Layer Framework for Slot Attention](https://arxiv.org/abs/2602.07544)
*Sebastian Bock,Leonie Schüßler,Krishnakant Singh,Simone Schaub-Meyer,Stefan Roth*

Main category: cs.CV

TL;DR: MUFASA：一种轻量级即插即用框架，通过多层级特征融合提升基于slot attention的无监督物体分割性能


<details>
  <summary>Details</summary>
Motivation: 当前基于slot attention的无监督物体中心学习方法仅使用ViT最后一层的特征，忽略了其他层级中丰富的语义信息，导致信息利用不充分

Method: 提出MUFASA框架，在ViT编码器的多个特征层上计算slot attention，并提出融合策略将多层级获得的slot聚合成统一的物体中心表示

Result: 将MUFASA集成到现有OCL方法中，在多个数据集上提升了分割结果，达到新的SOTA，同时改善了训练收敛性，仅带来轻微推理开销

Conclusion: MUFASA通过充分利用ViT多层级语义信息，有效提升了基于slot attention的无监督物体分割性能，是一种高效且通用的改进方案

Abstract: Unsupervised object-centric learning (OCL) decomposes visual scenes into distinct entities. Slot attention is a popular approach that represents individual objects as latent vectors, called slots. Current methods obtain these slot representations solely from the last layer of a pre-trained vision transformer (ViT), ignoring valuable, semantically rich information encoded across the other layers. To better utilize this latent semantic information, we introduce MUFASA, a lightweight plug-and-play framework for slot attention-based approaches to unsupervised object segmentation. Our model computes slot attention across multiple feature layers of the ViT encoder, fully leveraging their semantic richness. We propose a fusion strategy to aggregate slots obtained on multiple layers into a unified object-centric representation. Integrating MUFASA into existing OCL methods improves their segmentation results across multiple datasets, setting a new state of the art while simultaneously improving training convergence with only minor inference overhead.

</details>


### [67] [Revealing the Semantic Selection Gap in DINOv3 through Training-Free Few-Shot Segmentation](https://arxiv.org/abs/2602.07550)
*Hussni Mohd Zakir,Eric Tatt Wei Ho*

Main category: cs.CV

TL;DR: FSSDINO：基于冻结DINOv3特征的训练免费少样本语义分割基线，通过类别原型和Gram矩阵优化，在多个基准测试中表现优异，揭示了"最安全vs最优"的特征层选择困境。


<details>
  <summary>Details</summary>
Motivation: 研究自监督ViT（如DINOv3）在少样本语义分割中的内在能力，探索冻结特征的有效性，避免复杂解码器或测试时适应。

Method: 提出FSSDINO训练免费基线：使用冻结DINOv3特征，通过类别特定原型和Gram矩阵细化进行分割，分析不同特征层的性能差异。

Result: 在二元、多类和跨域少样本分割基准测试中，该方法与复杂方法竞争力相当；发现最后层特征与最优中间表示存在显著性能差距，揭示"语义选择鸿沟"。

Conclusion: 最后层特征是一个强大但可能误导的基线；DINOv3存在未开发的语义潜力；传统启发式方法无法可靠识别高保真特征，需要更好的特征选择机制。

Abstract: Recent self-supervised Vision Transformers (ViTs), such as DINOv3, provide rich feature representations for dense vision tasks. This study investigates the intrinsic few-shot semantic segmentation (FSS) capabilities of frozen DINOv3 features through a training-free baseline, FSSDINO, utilizing class-specific prototypes and Gram-matrix refinement. Our results across binary, multi-class, and cross-domain (CDFSS) benchmarks demonstrate that this minimal approach, applied to the final backbone layer, is highly competitive with specialized methods involving complex decoders or test-time adaptation. Crucially, we conduct an Oracle-guided layer analysis, identifying a significant performance gap between the standard last-layer features and globally optimal intermediate representations. We reveal a "Safest vs. Optimal" dilemma: while the Oracle proves higher performance is attainable, matching the results of compute-intensive adaptation methods, current unsupervised and support-guided selection metrics consistently yield lower performance than the last-layer baseline. This characterizes a "Semantic Selection Gap" in Foundation Models, a disconnect where traditional heuristics fail to reliably identify high-fidelity features. Our work establishes the "Last-Layer" as a deceptively strong baseline and provides a rigorous diagnostic of the latent semantic potentials in DINOv3.The code is publicly available at https://github.com/hussni0997/fssdino.

</details>


### [68] [FlexID: Training-Free Flexible Identity Injection via Intent-Aware Modulation for Text-to-Image Generation](https://arxiv.org/abs/2602.07554)
*Guandong Li,Yijun Ding*

Main category: cs.CV

TL;DR: FlexID是一个无需训练的身份个性化文本到图像生成框架，通过意图感知调制解决身份保真度与文本适应性之间的冲突，在身份一致性和文本遵循性之间达到最优平衡。


<details>
  <summary>Details</summary>
Motivation: 现有无需训练的方法通常依赖刚性的视觉特征注入，导致身份保真度与文本适应性之间存在冲突。需要一种能够动态平衡身份保持和语义变化的方法。

Method: FlexID采用意图感知调制框架，将身份正交解耦为两个维度：语义身份投影器（SIP）在语言空间注入高级先验，视觉特征锚点（VFA）在潜在空间确保结构保真度。关键创新是上下文感知自适应门控（CAG）机制，根据编辑意图和扩散时间步动态调制这两个流的权重。

Result: 在IBench上的大量实验表明，FlexID在身份一致性和文本遵循性之间达到了最先进的平衡，为复杂叙事生成提供了高效解决方案。

Conclusion: FlexID通过意图感知调制成功解决了身份个性化文本到图像生成中的身份保真度与文本适应性冲突问题，实现了无需训练的高效身份个性化生成。

Abstract: Personalized text-to-image generation aims to seamlessly integrate specific identities into textual descriptions. However, existing training-free methods often rely on rigid visual feature injection, creating a conflict between identity fidelity and textual adaptability. To address this, we propose FlexID, a novel training-free framework utilizing intent-aware modulation. FlexID orthogonally decouples identity into two dimensions: a Semantic Identity Projector (SIP) that injects high-level priors into the language space, and a Visual Feature Anchor (VFA) that ensures structural fidelity within the latent space. Crucially, we introduce a Context-Aware Adaptive Gating (CAG) mechanism that dynamically modulates the weights of these streams based on editing intent and diffusion timesteps. By automatically relaxing rigid visual constraints when strong editing intent is detected, CAG achieves synergy between identity preservation and semantic variation. Extensive experiments on IBench demonstrate that FlexID achieves a state-of-the-art balance between identity consistency and text adherence, offering an efficient solution for complex narrative generation.

</details>


### [69] [VISOR: VIsual Spatial Object Reasoning for Language-driven Object Navigation](https://arxiv.org/abs/2602.07555)
*Francesco Taioli,Shiping Yang,Sonia Raychaudhuri,Marco Cristani,Unnat Jain,Angel X Chang*

Main category: cs.CV

TL;DR: 提出一个3B参数的视觉-语言-动作智能体，通过显式图像推理实现目标物体识别和动作选择，替代传统多模型管道，提升可解释性、泛化能力和导航效率。


<details>
  <summary>Details</summary>
Motivation: 现有方法存在两大问题：端到端模型泛化能力差且缺乏动作级可解释性；模块化零样本管道存在错误传播、计算成本高、难以将推理整合到导航策略中。需要一种更高效、可解释且泛化能力强的解决方案。

Method: 提出紧凑的3B参数视觉-语言-动作智能体，采用显式图像推理直接回答"这是目标物体吗？"和"为什么要采取这个动作？"。推理过程分为三个阶段："思考"、"思考总结"和"动作"。

Result: 该方法实现了改进的可解释性、更强的泛化能力和更高效的导航，无需拼接多模型管道，代码和数据集将在论文接受后提供。

Conclusion: 提出的VLA智能体通过人类化的具身推理，在物体识别和动作选择方面优于现有方法，为语言驱动的物体导航提供了更高效、可解释且泛化能力强的解决方案。

Abstract: Language-driven object navigation requires agents to interpret natural language descriptions of target objects, which combine intrinsic and extrinsic attributes for instance recognition and commonsense navigation. Existing methods either (i) use end-to-end trained models with vision-language embeddings, which struggle to generalize beyond training data and lack action-level explainability, or (ii) rely on modular zero-shot pipelines with large language models (LLMs) and open-set object detectors, which suffer from error propagation, high computational cost, and difficulty integrating their reasoning back into the navigation policy. To this end, we propose a compact 3B-parameter Vision-Language-Action (VLA) agent that performs human-like embodied reasoning for both object recognition and action selection, removing the need for stitched multi-model pipelines. Instead of raw embedding matching, our agent employs explicit image-grounded reasoning to directly answer "Is this the target object?" and "Why should I take this action?" The reasoning process unfolds in three stages: "think", "think summary", and "action", yielding improved explainability, stronger generalization, and more efficient navigation. Code and dataset available upon acceptance.

</details>


### [70] [SIGMA: Selective-Interleaved Generation with Multi-Attribute Tokens](https://arxiv.org/abs/2602.07564)
*Xiaoyan Zhang,Zechen Bai,Haofan Wang,Yiren Song*

Main category: cs.CV

TL;DR: SIGMA是一个基于Bagel统一模型的后训练框架，通过引入选择性多属性token实现交错多条件生成，支持组合编辑、选择性属性迁移和细粒度多模态对齐。


<details>
  <summary>Details</summary>
Motivation: 现有统一模型如Bagel仅限于单条件输入，缺乏从多个异构源合成结果的灵活性。需要一种能够处理交错多条件生成的方法。

Method: 提出SIGMA框架，引入选择性多属性token（风格、内容、主题、身份token），使模型能够解释和组合交错文本-图像序列中的多个视觉条件。在Bagel统一骨干网络上使用70万个交错示例进行后训练。

Result: SIGMA在多样化的编辑和生成任务中提高了可控性、跨条件一致性和视觉质量，在组合任务上相比Bagel有显著提升。

Conclusion: SIGMA通过选择性多属性token和后训练框架，成功实现了交错多条件生成，为统一视觉模型提供了更强的灵活性和组合能力。

Abstract: Recent unified models such as Bagel demonstrate that paired image-edit data can effectively align multiple visual tasks within a single diffusion transformer. However, these models remain limited to single-condition inputs and lack the flexibility needed to synthesize results from multiple heterogeneous sources. We present SIGMA (Selective-Interleaved Generation with Multi-Attribute Tokens), a unified post-training framework that enables interleaved multi-condition generation within diffusion transformers. SIGMA introduces selective multi-attribute tokens, including style, content, subject, and identity tokens, which allow the model to interpret and compose multiple visual conditions in an interleaved text-image sequence. Through post-training on the Bagel unified backbone with 700K interleaved examples, SIGMA supports compositional editing, selective attribute transfer, and fine-grained multimodal alignment. Extensive experiments show that SIGMA improves controllability, cross-condition consistency, and visual quality across diverse editing and generation tasks, with substantial gains over Bagel on compositional tasks.

</details>


### [71] [Human Identification at a Distance: Challenges, Methods and Results on the Competition HID 2025](https://arxiv.org/abs/2602.07565)
*Jingzhe Ma,Meng Zhang,Jianlong Yu,Kun Liu,Zunxiao Xu,Xue Cheng,Junjie Zhou,Yanfei Wang,Jiahang Li,Zepeng Wang,Kazuki Osamura,Rujie Liu,Narishige Abe,Jingjie Wang,Shunli Zhang,Haojun Xie,Jiajun Wu,Weiming Wu,Wenxiong Kang,Qingshuo Gao,Jiaming Xiong,Xianye Ben,Lei Chen,Lichen Song,Junjian Cui,Haijun Xiong,Junhao Lu,Bin Feng,Mengyuan Liu,Ji Zhou,Baoquan Zhao,Ke Xu,Yongzhen Huang,Liang Wang,Manuel J Marin-Jimenez,Md Atiqur Rahman Ahad,Shiqi Yu*

Main category: cs.CV

TL;DR: 该论文分析了HID 2025竞赛，该竞赛使用SUSTech-Competition数据集进行步态识别，参赛者在没有专用训练数据的情况下取得了94.2%的准确率，创造了新的基准。


<details>
  <summary>Details</summary>
Motivation: 远距离人体识别(HID)具有挑战性，因为传统生物特征如人脸和指纹在真实场景中难以获取。步态识别提供了实用替代方案，可以在远距离可靠捕获。HID竞赛旨在促进步态识别进展并提供公平评估平台。

Method: 竞赛使用SUSTech-Competition数据集，该数据集包含服装、携带物品和视角的显著变化。不提供专用训练数据，参赛者需使用外部数据集训练模型。每年使用不同随机种子生成不同的评估分割，减少过拟合风险并支持跨域泛化的公平评估。

Result: 尽管难度增加，参赛者取得了进一步改进，最佳方法达到94.2%的准确率，为该数据集设定了新的基准。HID 2025特别检验了算法进展是否能超越先前观察到的准确率极限。

Conclusion: 论文分析了关键技术趋势，并概述了步态识别未来研究的潜在方向。竞赛结果表明算法进步能够突破先前准确率限制，为远距离人体识别提供了新的可能性。

Abstract: Human identification at a distance (HID) is challenging because traditional biometric modalities such as face and fingerprints are often difficult to acquire in real-world scenarios. Gait recognition provides a practical alternative, as it can be captured reliably at a distance. To promote progress in gait recognition and provide a fair evaluation platform, the International Competition on Human Identification at a Distance (HID) has been organized annually since 2020. Since 2023, the competition has adopted the challenging SUSTech-Competition dataset, which features substantial variations in clothing, carried objects, and view angles. No dedicated training data are provided, requiring participants to train their models using external datasets. Each year, the competition applies a different random seed to generate distinct evaluation splits, which reduces the risk of overfitting and supports a fair assessment of cross-domain generalization. While HID 2023 and HID 2024 already used this dataset, HID 2025 explicitly examined whether algorithmic advances could surpass the accuracy limits observed previously. Despite the heightened difficulty, participants achieved further improvements, and the best-performing method reached 94.2% accuracy, setting a new benchmark on this dataset. We also analyze key technical trends and outline potential directions for future research in gait recognition.

</details>


### [72] [Cross-Camera Cow Identification via Disentangled Representation Learning](https://arxiv.org/abs/2602.07566)
*Runcheng Wang,Yaru Chen,Guiguo Zhang,Honghua Jiang,Yongliang Qiao*

Main category: cs.CV

TL;DR: 提出基于解耦表征学习的跨摄像头奶牛识别框架，利用子空间可识别性保证理论，通过特征解耦模块分离身份相关特征，显著提升跨摄像头泛化能力


<details>
  <summary>Details</summary>
Motivation: 现有动物识别方法在受控单摄像头环境下表现良好，但在跨摄像头场景中面临严重泛化挑战。当模型从源摄像头部署到具有不同光照、背景、视角和成像特性的新监控节点时，识别性能急剧下降，限制了非接触技术在动态真实农场环境中的大规模应用

Method: 提出基于解耦表征学习的跨摄像头奶牛识别框架，利用子空间可识别性保证理论，通过建模底层物理数据生成过程，设计原则驱动的特征解耦模块，将观测图像分解为多个正交潜在子空间，有效分离跨摄像头不变的稳定身份相关生物特征

Result: 构建了涵盖5个不同摄像头节点的高质量数据集，包含异构采集设备和复杂的光照角度变化。在7个跨摄像头任务上的广泛实验表明，该方法平均准确率达到86.0%，显著优于仅源摄像头基线（51.9%）和最强的跨摄像头基线方法（79.8%）

Conclusion: 本研究建立了基于子空间理论的特征解耦框架，用于协同跨摄像头奶牛识别，为无控制智能农场环境中的精确动物监测提供了新范式

Abstract: Precise identification of individual cows is a fundamental prerequisite for comprehensive digital management in smart livestock farming. While existing animal identification methods excel in controlled, single-camera settings, they face severe challenges regarding cross-camera generalization. When models trained on source cameras are deployed to new monitoring nodes characterized by divergent illumination, backgrounds, viewpoints, and heterogeneous imaging properties, recognition performance often degrades dramatically. This limits the large-scale application of non-contact technologies in dynamic, real-world farming environments. To address this challenge, this study proposes a cross-camera cow identification framework based on disentangled representation learning. This framework leverages the Subspace Identifiability Guarantee (SIG) theory in the context of bovine visual recognition. By modeling the underlying physical data generation process, we designed a principle-driven feature disentanglement module that decomposes observed images into multiple orthogonal latent subspaces. This mechanism effectively isolates stable, identity-related biometric features that remain invariant across cameras, thereby substantially improving generalization to unseen cameras. We constructed a high-quality dataset spanning five distinct camera nodes, covering heterogeneous acquisition devices and complex variations in lighting and angles. Extensive experiments across seven cross-camera tasks demonstrate that the proposed method achieves an average accuracy of 86.0%, significantly outperforming the Source-only Baseline (51.9%) and the strongest cross-camera baseline method (79.8%). This work establishes a subspace-theoretic feature disentanglement framework for collaborative cross-camera cow identification, offering a new paradigm for precise animal monitoring in uncontrolled smart farming environments.

</details>


### [73] [Visualizing the Invisible: Enhancing Radiologist Performance in Breast Mammography via Task-Driven Chromatic Encoding](https://arxiv.org/abs/2602.07568)
*Hui Ye,Shilong Yang,Yexuan Xing,Juan Yu,Yaoqin Xie,Wei Zhang,Chulong Zhang*

Main category: cs.CV

TL;DR: MammoColor是一个端到端框架，通过任务驱动的色彩编码将单通道乳腺X光片转换为彩色视图，提升致密乳腺中的检测性能，减少假阳性召回。


<details>
  <summary>Details</summary>
Motivation: 乳腺X光筛查在致密乳腺中敏感性较低，组织重叠和细微发现增加了感知难度，需要更好的视觉增强方法来提高检测性能。

Method: 开发了MammoColor框架，包含任务驱动的色彩编码模块，将单通道乳腺X光片转换为TDCE编码视图，与BI-RADS分类器耦合，在VinDr-Mammo数据集上进行端到端训练。

Result: 在VinDr-Mammo上AUC从0.7669提升到0.8461，致密乳腺中提升更明显（AUC 0.749到0.835）。多读者研究中特异性从0.90提高到0.96，敏感性相当。

Conclusion: TDCE提供任务优化的色彩表示，可改善感知显著性，减少乳腺X光分诊中的假阳性召回，特别是在致密乳腺中效果显著。

Abstract: Purpose:Mammography screening is less sensitive in dense breasts, where tissue overlap and subtle findings increase perceptual difficulty. We present MammoColor, an end-to-end framework with a Task-Driven Chromatic Encoding (TDCE) module that converts single-channel mammograms into TDCE-encoded views for visual augmentation. Materials and Methods:MammoColor couples a lightweight TDCE module with a BI-RADS triage classifier and was trained end-to-end on VinDr-Mammo. Performance was evaluated on an internal test set, two public datasets (CBIS-DDSM and INBreast), and three external clinical cohorts. We also conducted a multi-reader, multi-case (MRMC) observer study with a washout period, comparing (1) grayscale-only, (2) TDCE-only, and (3) side-by-side grayscale+TDCE. Results:On VinDr-Mammo, MammoColor improved AUC from 0.7669 to 0.8461 (P=0.004). Gains were larger in dense breasts (AUC 0.749 to 0.835). In the MRMC study, TDCE-encoded images improved specificity (0.90 to 0.96; P=0.052) with comparable sensitivity. Conclusion:TDCE provides a task-optimized chromatic representation that may improve perceptual salience and reduce false-positive recalls in mammography triage.

</details>


### [74] [ViCA: Efficient Multimodal LLMs with Vision-Only Cross-Attention](https://arxiv.org/abs/2602.07574)
*Wenjie Liu,Hao Wu,Xin Qiu,Yingqi Fan,Yihan Zhang,Anhao Zhao,Yunpu Ma,Xiaoyu Shen*

Main category: cs.CV

TL;DR: ViCA是一种高效的MLLM架构，通过稀疏跨注意力机制大幅减少视觉计算开销，仅保留4%的视觉计算量即可达到98%的基线准确率。


<details>
  <summary>Details</summary>
Motivation: 现有MLLM采用统一的self-attention设计，在每个Transformer层都处理视觉和文本token，导致计算开销巨大。研究发现视觉嵌入已经与语言空间对齐，有效的视觉-语言交互仅发生在少数层中。

Method: 提出ViCA架构，视觉token绕过所有self-attention和feed-forward层，仅通过选定的层中的稀疏跨注意力与文本交互，实现最小化的MLLM设计。

Result: 在三个MLLM骨干网络、九个多模态基准和26个剪枝基线方法上评估，ViCA保持98%的基线准确率，同时将视觉侧计算减少到4%，单批次推理加速3.5倍，多批次加速10倍以上。

Conclusion: ViCA提供了规则、硬件友好的推理流程，将视觉基础计算降至接近零开销，且与token剪枝方法正交，可进一步组合提升效率。

Abstract: Modern multimodal large language models (MLLMs) adopt a unified self-attention design that processes visual and textual tokens at every Transformer layer, incurring substantial computational overhead. In this work, we revisit the necessity of such dense visual processing and show that projected visual embeddings are already well-aligned with the language space, while effective vision-language interaction occurs in only a small subset of layers. Based on these insights, we propose ViCA (Vision-only Cross-Attention), a minimal MLLM architecture in which visual tokens bypass all self-attention and feed-forward layers, interacting with text solely through sparse cross-attention at selected layers. Extensive evaluations across three MLLM backbones, nine multimodal benchmarks, and 26 pruning-based baselines show that ViCA preserves 98% of baseline accuracy while reducing visual-side computation to 4%, consistently achieving superior performance-efficiency trade-offs. Moreover, ViCA provides a regular, hardware-friendly inference pipeline that yields over 3.5x speedup in single-batch inference and over 10x speedup in multi-batch inference, reducing visual grounding to near-zero overhead compared with text-only LLMs. It is also orthogonal to token pruning methods and can be seamlessly combined for further efficiency gains. Our code is available at https://github.com/EIT-NLP/ViCA.

</details>


### [75] [Automated rock joint trace mapping using a supervised learning model trained on synthetic data generated by parametric modelling](https://arxiv.org/abs/2602.07590)
*Jessica Ka Yi Chiu,Tom Frode Hansen,Eivind Magnus Paulsen,Ole Jakob Mengshoel*

Main category: cs.CV

TL;DR: 提出了一种地质驱动的机器学习方法，用于从图像中自动映射岩石节理迹线，结合地质建模、合成数据生成和监督图像分割来解决真实数据有限和类别不平衡问题。


<details>
  <summary>Details</summary>
Motivation: 解决岩石节理迹线自动映射中真实数据稀缺、类别不平衡以及标注不一致等问题，提供更可靠的地质节理检测方法。

Method: 1) 使用离散断裂网络模型生成具有地质相关性的合成节理岩石图像；2) 采用混合训练和预训练策略，然后在真实图像上进行微调；3) 在箱体和边坡等不同地质域进行测试。

Result: 合成数据能有效支持监督节理迹线检测；混合训练在标注一致时表现良好，微调在标注噪声较大时更鲁棒；完全零样本预测有限，但少量真实数据微调可实现良好泛化。

Conclusion: 该方法支持可靠的节理映射，为领域适应和评估提供了基础，定性分析显示比定量指标更能反映地质意义的节理迹线。

Abstract: This paper presents a geology-driven machine learning method for automated rock joint trace mapping from images. The approach combines geological modelling, synthetic data generation, and supervised image segmentation to address limited real data and class imbalance. First, discrete fracture network models are used to generate synthetic jointed rock images at field-relevant scales via parametric modelling, preserving joint persistence, connectivity, and node-type distributions. Second, segmentation models are trained using mixed training and pretraining followed by fine-tuning on real images. The method is tested in box and slope domains using several real datasets. The results show that synthetic data can support supervised joint trace detection when real data are scarce. Mixed training performs well when real labels are consistent (e.g. box-domain), while fine-tuning is more robust when labels are noisy (e.g. slope-domain where labels can be biased, incomplete, and inconsistent). Fully zero-shot prediction from synthetic model remains limited, but useful generalisation is achieved by fine-tuning with a small number of real data. Qualitative analysis shows clearer and more geologically meaningful joint traces than indicated by quantitative metrics alone. The proposed method supports reliable joint mapping and provides a basis for further work on domain adaptation and evaluation.

</details>


### [76] [TeleBoost: A Systematic Alignment Framework for High-Fidelity, Controllable, and Robust Video Generation](https://arxiv.org/abs/2602.07595)
*Yuanzhi Liang,Xuan'er Wu,Yirui Liu,Yijie Fang,Yizhen Fan,Ke Hao,Rui Li,Ruiying Liu,Ziqi Ni,Peng Yu,Yanbo Wang,Haibin Huang,Qizhen Weng,Chi Zhang,Xuelong Li*

Main category: cs.CV

TL;DR: 论文提出了一个系统化的视频生成模型后训练框架，将监督策略塑造、奖励驱动的强化学习和基于偏好的精炼整合到单一稳定性约束优化堆栈中，旨在提升生成视频的感知保真度、时间一致性和提示遵循能力。


<details>
  <summary>Details</summary>
Motivation: 后训练是将预训练视频生成器转化为生产级模型的关键步骤，但面临高计算成本、时间累积失败模式以及反馈信息异质、不确定且区分度低等实际挑战。需要系统化方法而非孤立技巧来提升模型性能。

Method: 采用分阶段、诊断驱动的优化框架，整合监督策略塑造、奖励驱动的强化学习和基于偏好的精炼，构建稳定性约束优化堆栈，专门针对视频生成的高计算成本、时间累积错误等约束设计。

Result: 该框架为构建可扩展的后训练流程提供了清晰蓝图，能够有效提升感知保真度、时间一致性和提示遵循能力，同时保持初始化的可控性，确保在现实部署中保持稳定、可扩展和有效。

Conclusion: 系统化的后训练框架通过整合多种优化技术并考虑实际部署约束，为视频生成模型的工业化应用提供了稳定、可扩展的解决方案，是连接预训练模型与生产级应用的关键桥梁。

Abstract: Post-training is the decisive step for converting a pretrained video generator into a production-oriented model that is instruction-following, controllable, and robust over long temporal horizons. This report presents a systematical post-training framework that organizes supervised policy shaping, reward-driven reinforcement learning, and preference-based refinement into a single stability-constrained optimization stack. The framework is designed around practical video-generation constraints, including high rollout cost, temporally compounding failure modes, and feedback that is heterogeneous, uncertain, and often weakly discriminative. By treating optimization as a staged, diagnostic-driven process rather than a collection of isolated tricks, the report summarizes a cohesive recipe for improving perceptual fidelity, temporal coherence, and prompt adherence while preserving the controllability established at initialization. The resulting framework provides a clear blueprint for building scalable post-training pipelines that remain stable, extensible, and effective in real-world deployment settings.

</details>


### [77] [Fine-R1: Make Multi-modal LLMs Excel in Fine-Grained Visual Recognition by Chain-of-Thought Reasoning](https://arxiv.org/abs/2602.07605)
*Hulingxiao He,Zijun Geng,Yuxin Peng*

Main category: cs.CV

TL;DR: Fine-R1：针对细粒度视觉识别的MLLM，通过CoT监督微调和三元组增强策略优化，仅需4-shot训练即可超越现有MLLM和CLIP模型


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型在粗粒度视觉任务上表现良好，但在细粒度视觉识别（FGVR）中存在困难。现有方法需要大量标注数据且容易过拟合已见子类别，泛化能力差。需要一种能够用少量数据适应FGVR并具有良好泛化能力的解决方案。

Method: 提出Fine-R1模型，采用R1风格训练框架：1）思维链监督微调：构建高质量FGVR CoT数据集，包含"视觉分析、候选子类别、比较、预测"的推理过程；2）三元组增强策略优化：类内增强混合同一类别内锚点和正样本图像的轨迹以提高鲁棒性，类间增强最大化跨子类别图像的条件响应差异以增强判别能力。

Result: 仅需4-shot训练，Fine-R1在识别已见和未见子类别方面均优于现有通用MLLM、推理MLLM甚至对比学习CLIP模型，在知识密集型领域显示出潜力。

Conclusion: Fine-R1通过创新的训练框架有效解决了MLLM在细粒度视觉识别中的挑战，实现了用极少标注数据获得优异性能，为难以获取专家标注的知识密集型领域提供了实用解决方案。

Abstract: Any entity in the visual world can be hierarchically grouped based on shared characteristics and mapped to fine-grained sub-categories. While Multi-modal Large Language Models (MLLMs) achieve strong performance on coarse-grained visual tasks, they often struggle with Fine-Grained Visual Recognition (FGVR). Adapting general-purpose MLLMs to FGVR typically requires large amounts of annotated data, which is costly to obtain, leaving a substantial performance gap compared to contrastive CLIP models dedicated for discriminative tasks. Moreover, MLLMs tend to overfit to seen sub-categories and generalize poorly to unseen ones. To address these challenges, we propose Fine-R1, an MLLM tailored for FGVR through an R1-style training framework: (1) Chain-of-Thought Supervised Fine-tuning, where we construct a high-quality FGVR CoT dataset with rationales of "visual analysis, candidate sub-categories, comparison, and prediction", transition the model into a strong open-world classifier; and (2) Triplet Augmented Policy Optimization, where Intra-class Augmentation mixes trajectories from anchor and positive images within the same category to improve robustness to intra-class variance, while Inter-class Augmentation maximizes the response distinction conditioned on images across sub-categories to enhance discriminative ability. With only 4-shot training, Fine-R1 outperforms existing general MLLMs, reasoning MLLMs, and even contrastive CLIP models in identifying both seen and unseen sub-categories, showing promise in working in knowledge-intensive domains where gathering expert annotations for all sub-categories is arduous. Code is available at https://github.com/PKU-ICST-MIPL/FineR1_ICLR2026.

</details>


### [78] [HistoMet: A Pan-Cancer Deep Learning Framework for Prognostic Prediction of Metastatic Progression and Site Tropism from Primary Tumor Histopathology](https://arxiv.org/abs/2602.07608)
*Yixin Chen,Ziyu Su,Lingbin Meng,Elshad Hasanov,Wei Chen,Anil Parwani,M. Khalid Khan Niazi*

Main category: cs.CV

TL;DR: 提出HistoMet框架，通过两阶段决策流程从原发肿瘤病理图像预测转移风险和转移部位，结合病理视觉语言模型提升临床可解释性。


<details>
  <summary>Details</summary>
Motivation: 转移进展是癌症相关死亡的主要原因，但直接从组织病理学预测原发肿瘤是否会转移以及转移部位仍然是一个基本挑战。现有方法通常将转移状态或部位预测作为孤立任务处理，没有明确模拟临床决策流程。

Method: 提出决策感知、概念对齐的MIL框架HistoMet，采用两模块预测流程：首先估计原发肿瘤转移进展的可能性，然后对高风险病例进行条件性转移部位预测。通过预训练的病理视觉语言模型整合语言定义和数据自适应的转移概念。

Result: 在6504名患者的泛癌队列上评估，在95%灵敏度的高灵敏度筛查设置下，显著减少下游工作量同时保持高转移风险召回率。对转移病例，宏观F1为74.6±1.3，宏观一对多AUC为92.1。

Conclusion: 明确模拟临床决策结构能够直接从原发肿瘤组织病理学实现稳健且可部署的转移进展和部位趋向性预后预测。

Abstract: Metastatic Progression remains the leading cause of cancer-related mortality, yet predicting whether a primary tumor will metastasize and where it will disseminate directly from histopathology remains a fundamental challenge. Although whole-slide images (WSIs) provide rich morphological information, prior computational pathology approaches typically address metastatic status or site prediction as isolated tasks, and do not explicitly model the clinically sequential decision process of metastatic risk assessment followed by downstream site-specific evaluation. To address this research gap, we present a decision-aware, concept-aligned MIL framework, HistoMet, for prognostic metastatic outcome prediction from primary tumor WSIs. Our proposed framework adopts a two-module prediction pipeline in which the likelihood of metastatic progression from the primary tumor is first estimated, followed by conditional prediction of metastatic site for high-risk cases. To guide representation learning and improve clinical interpretability, our framework integrates linguistically defined and data-adaptive metastatic concepts through a pretrained pathology vision-language model. We evaluate HistoMet on a multi-institutional pan-cancer cohort of 6504 patients with metastasis follow-up and site annotations. Under clinically relevant high-sensitivity screening settings (95 percent sensitivity), HistoMet significantly reduces downstream workload while maintaining high metastatic risk recall. Conditional on metastatic cases, HistoMet achieves a macro F1 of 74.6 with a standard deviation of 1.3 and a macro one-vs-rest AUC of 92.1. These results demonstrate that explicitly modeling clinical decision structure enables robust and deployable prognostic prediction of metastatic progression and site tropism directly from primary tumor histopathology.

</details>


### [79] [AD-MIR: Bridging the Gap from Perception to Persuasion in Advertising Video Understanding via Structured Reasoning](https://arxiv.org/abs/2602.07625)
*Binxiao Xu,Junyu Feng,Xiaopeng Lin,Haodong Li,Zhiyuan Feng,Bohan Zeng,Shaolin Lu,Ming Lu,Qi She,Wentao Zhang*

Main category: cs.CV

TL;DR: AD-MIR是一个两阶段框架，通过结构化记忆构建和推理代理来解码广告视频的营销意图，在AdsQA基准上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有代理在广告视频理解方面存在认知鸿沟，难以将像素级感知与高级营销逻辑联系起来，需要专门框架来解码广告意图。

Method: 采用两阶段架构：1) 结构感知记忆构建阶段，通过语义检索和精确关键词匹配将原始视频转换为结构化数据库；2) 结构化推理代理阶段，模拟营销专家进行迭代推理，并采用基于证据的自我纠正机制验证洞察。

Result: 在AdsQA基准上达到最先进性能，比最强通用代理DVD在严格准确率上提升1.8%，在宽松准确率上提升9.5%。

Conclusion: 有效的广告理解需要将抽象营销策略明确地基于像素级证据，AD-MIR框架通过结构化记忆和推理实现了这一目标。

Abstract: Multimodal understanding of advertising videos is essential for interpreting the intricate relationship between visual storytelling and abstract persuasion strategies. However, despite excelling at general search, existing agents often struggle to bridge the cognitive gap between pixel-level perception and high-level marketing logic. To address this challenge, we introduce AD-MIR, a framework designed to decode advertising intent via a two-stage architecture. First, in the Structure-Aware Memory Construction phase, the system converts raw video into a structured database by integrating semantic retrieval with exact keyword matching. This approach prioritizes fine-grained brand details (e.g., logos, on-screen text) while dynamically filtering out irrelevant background noise to isolate key protagonists. Second, the Structured Reasoning Agent mimics a marketing expert through an iterative inquiry loop, decomposing the narrative to deduce implicit persuasion tactics. Crucially, it employs an evidence-based self-correction mechanism that rigorously validates these insights against specific video frames, automatically backtracking when visual support is lacking. Evaluation on the AdsQA benchmark demonstrates that AD-MIR achieves state-of-the-art performance, surpassing the strongest general-purpose agent, DVD, by 1.8% in strict and 9.5% in relaxed accuracy. These results underscore that effective advertising understanding demands explicitly grounding abstract marketing strategies in pixel-level evidence. The code is available at https://github.com/Little-Fridge/AD-MIR.

</details>


### [80] [Uncovering Modality Discrepancy and Generalization Illusion for General-Purpose 3D Medical Segmentation](https://arxiv.org/abs/2602.07643)
*Yichi Zhang,Feiyang Xiao,Le Xue,Wenbo Zhang,Gang Feng,Chenguang Zheng,Yuan Qi,Yuan Cheng,Zixin Hu*

Main category: cs.CV

TL;DR: 该研究通过创建UMD数据集（包含490个PET/CT和464个PET/MRI全身扫描）评估3D医学基础模型，发现从结构成像转向功能成像时存在显著性能差距，表明当前模型远未达到真正的通用性。


<details>
  <summary>Details</summary>
Motivation: 当前3D医学基础模型的验证主要局限于区域性和结构性成像，缺乏对模态差异的探索。需要客观评估这些模型在真实世界应用中的鲁棒性，特别是在从结构成像转向功能成像时的表现。

Method: 创建UMD数据集（包含490个PET/CT和464个PET/MRI全身扫描，约675k 2D图像和12k 3D器官标注），通过受试者内配对扫描的对照比较，将成像模态作为主要自变量，对代表性3D分割基础模型进行全面评估。

Result: 评估揭示了文献报道的基准与真实世界效能之间的显著差异，特别是在从结构域转向功能域时。当前3D基础模型远未达到真正的通用性，存在系统性失败。

Conclusion: 当前3D医学基础模型尚未实现真正的通用性，需要向多模态训练和评估的范式转变，以弥合理想化基准测试与全面临床实用性之间的差距。UMD数据集为开发真正模态无关的医学基础模型奠定了基石。

Abstract: While emerging 3D medical foundation models are envisioned as versatile tools with offer general-purpose capabilities, their validation remains largely confined to regional and structural imaging, leaving a significant modality discrepancy unexplored. To provide a rigorous and objective assessment, we curate the UMD dataset comprising 490 whole-body PET/CT and 464 whole-body PET/MRI scans ($\sim$675k 2D images, $\sim$12k 3D organ annotations) and conduct a thorough and comprehensive evaluation of representative 3D segmentation foundation models. Through intra-subject controlled comparisons of paired scans, we isolate imaging modality as the primary independent variable to evaluate model robustness in real-world applications. Our evaluation reveals a stark discrepancy between literature-reported benchmarks and real-world efficacy, particularly when transitioning from structural to functional domains. Such systemic failures underscore that current 3D foundation models are far from achieving truly general-purpose status, necessitating a paradigm shift toward multi-modal training and evaluation to bridge the gap between idealized benchmarking and comprehensive clinical utility. This dataset and analysis establish a foundational cornerstone for future research to develop truly modality-agnostic medical foundation models.

</details>


### [81] [From Dead Pixels to Editable Slides: Infographic Reconstruction into Native Google Slides via Vision-Language Region Understanding](https://arxiv.org/abs/2602.07645)
*Leonardo Gonzalez*

Main category: cs.CV

TL;DR: Images2Slides：基于视觉语言模型的API管道，将静态信息图转换为可编辑的Google Slides幻灯片，实现元素恢复率98.9%


<details>
  <summary>Details</summary>
Motivation: 静态信息图（PNG/JPG）导出后内容被锁定为像素，导致更新、本地化和重用成本高昂，需要一种方法将其转换为可编辑格式

Method: 使用视觉语言模型提取区域级规范，将像素几何映射到幻灯片坐标，通过Google Slides批量更新API重建元素；系统支持多VLM后端，采用通用JSON区域模式和确定性后处理

Result: 在29个程序生成的信息图基准测试中，整体元素恢复率0.989±0.057（文本：0.985±0.083，图像：1.000±0.000），文本转录错误CER=0.033±0.149，文本区域布局保真度IoU=0.364±0.161，图像区域IoU=0.644±0.131

Conclusion: Images2Slides成功将静态信息图转换为可编辑幻灯片，解决了文本大小校准和非均匀背景等工程挑战，为未来工作提供了失败模式指导

Abstract: Infographics are widely used to communicate information with a combination of text, icons, and data visualizations, but once exported as images their content is locked into pixels, making updates, localization, and reuse expensive. We describe \textsc{Images2Slides}, an API-based pipeline that converts a static infographic (PNG/JPG) into a native, editable Google Slides slide by extracting a region-level specification with a vision-language model (VLM), mapping pixel geometry into slide coordinates, and recreating elements using the Google Slides batch update API. The system is model-agnostic and supports multiple VLM backends via a common JSON region schema and deterministic postprocessing. On a controlled benchmark of 29 programmatically generated infographic slides with known ground-truth regions, \textsc{Images2Slides} achieves an overall element recovery rate of $0.989\pm0.057$ (text: $0.985\pm0.083$, images: $1.000\pm0.000$), with mean text transcription error $\mathrm{CER}=0.033\pm0.149$ and mean layout fidelity $\mathrm{IoU}=0.364\pm0.161$ for text regions and $0.644\pm0.131$ for image regions. We also highlight practical engineering challenges in reconstruction, including text size calibration and non-uniform backgrounds, and describe failure modes that guide future work.

</details>


### [82] [Influence of Geometry, Class Imbalance and Alignment on Reconstruction Accuracy -- A Micro-CT Phantom-Based Evaluation](https://arxiv.org/abs/2602.07658)
*Avinash Kumar K M,Samarth S. Raut*

Main category: cs.CV

TL;DR: 该研究评估了医学扫描3D重建流程中的误差，比较了不同分割算法和几何类型在体素和表面精度指标上的表现，发现Otsu方法最适用于各种几何形状，Jaccard指数比Dice更适合薄壁结构评估。


<details>
  <summary>Details</summary>
Motivation: 医学扫描创建3D模型的精度受多种因素影响，包括成像硬件、分割方法和网格处理技术等。几何类型、类别不平衡、体素和点云对齐对精度的影响尚未得到充分探索。

Method: 使用SLA技术打印球体、面罩和AAA（腹主动脉瘤）模型，通过微CT扫描。采用GMM、Otsu和RG方法进行分割。使用KU算法对齐分割模型和参考模型，评估Dice、Jaccard分数和精度等指标。表面网格通过ICP对齐，评估Chamfer距离和平均Hausdorff距离。

Result: Otsu方法对所有几何形状最适用。AAA由于壁薄和对齐问题导致重叠分数较低。类别不平衡对AAA的特异性影响最大。表面精度指标与体素指标趋势不同。RG方法对球体表现最佳，而GMM和Otsu对AAA表现更好。面罩表面误差最大，可能因ICP对齐问题。Jaccard指数比Dice更严格，更适合薄壁结构评估。

Conclusion: 分割精度是重建过程各阶段误差的累积总和。高体素精度指标在类别不平衡和对齐敏感情况下可能误导。Jaccard指数更适合薄壁结构精度评估。体素和点云对齐对可靠评估重建流程至关重要。

Abstract: The accuracy of the 3D models created from medical scans depends on imaging hardware, segmentation methods and mesh processing techniques etc. The effects of geometry type, class imbalance, voxel and point cloud alignment on accuracy remain to be thoroughly explored. This work evaluates the errors across the reconstruction pipeline and explores the use of voxel and surface-based accuracy metrics for different segmentation algorithms and geometry types. A sphere, a facemask, and an AAA were printed using the SLA technique and scanned using a micro-CT machine. Segmentation was performed using GMM, Otsu and RG based methods. Segmented and reference models aligned using the KU algorithm, were quantitatively compared to evaluate metrics like Dice and Jaccard scores, precision. Surface meshes were registered with reference meshes using an ICP-based alignment process. Metrics like chamfer distance, and average Hausdorff distance were evaluated. The Otsu method was found to be the most suitable method for all the geometries. AAA yielded low overlap scores due to its small wall thickness and misalignment. The effect of class imbalance on specificity was observed the most for AAA. Surface-based accuracy metrics differed from the voxel-based trends. The RG method performed best for sphere, while GMM and Otsu perform better for AAA. The facemask surface was most error-prone, possibly due to misalignment during the ICP process. Segmentation accuracy is a cumulative sum of errors across different stages of the reconstruction process. High voxel-based accuracy metrics may be misleading in cases of high class imbalance and sensitivity to alignment. The Jaccard index is found to be more stringent than the Dice and more suitable for accuracy assessment for thin-walled structures. Voxel and point cloud alignment should be ensured to make any reliable assessment of the reconstruction pipeline.

</details>


### [83] [Looking and Listening Inside and Outside: Multimodal Artificial Intelligence Systems for Driver Safety Assessment and Intelligent Vehicle Decision-Making](https://arxiv.org/abs/2602.07668)
*Ross Greer,Laura Fleig,Maitrayee Keskar,Erika Maquiling,Giovanni Tapia Lopez,Angel Martinez-Sanchez,Parthib Roy,Jake Rattigan,Mira Sur,Alejandra Vidrio,Thomas Marcotte,Mohan Trivedi*

Main category: cs.CV

TL;DR: 提出L-LIO框架，在原有LILO（内外视觉）基础上加入音频模态，通过多模态融合增强车辆安全应用


<details>
  <summary>Details</summary>
Motivation: 现有LILO框架主要依赖视觉信息理解车内司机状态和车外场景，但音频作为额外信息源可以增强对司机、乘客和车外环境的理解，特别是在视觉信号不足的复杂场景中

Method: 扩展LILO为L-LIO框架，整合音频信号进行多模态传感器融合，通过三个案例验证：1) 司机语音分类潜在受损状态；2) 乘客自然语言指令分析；3) 音频辅助视觉系统识别外部代理

Result: 初步研究发现音频在安全相关场景中提供重要洞察，特别是在需要声音进行安全决策或视觉信号不足的细微、上下文丰富场景中

Conclusion: L-LIO通过音频和视觉的多模态融合增强了司机和场景理解，为安全干预提供了新途径，但需解决环境噪声干扰、隐私问题和跨主体鲁棒性等挑战

Abstract: The looking-in-looking-out (LILO) framework has enabled intelligent vehicle applications that understand both the outside scene and the driver state to improve safety outcomes, with examples in smart airbag deployment, takeover time prediction in autonomous control transitions, and driver attention monitoring. In this research, we propose an augmentation to this framework, making a case for the audio modality as an additional source of information to understand the driver, and in the evolving autonomy landscape, also the passengers and those outside the vehicle. We expand LILO by incorporating audio signals, forming the looking-and-listening inside-and-outside (L-LIO) framework to enhance driver state assessment and environment understanding through multimodal sensor fusion. We evaluate three example cases where audio enhances vehicle safety: supervised learning on driver speech audio to classify potential impairment states (e.g., intoxication), collection and analysis of passenger natural language instructions (e.g., "turn after that red building") to motivate how spoken language can interface with planning systems through audio-aligned instruction data, and limitations of vision-only systems where audio may disambiguate the guidance and gestures of external agents. Datasets include custom-collected in-vehicle and external audio samples in real-world environments. Pilot findings show that audio yields safety-relevant insights, particularly in nuanced or context-rich scenarios where sound is critical to safe decision-making or visual signals alone are insufficient. Challenges include ambient noise interference, privacy considerations, and robustness across human subjects, motivating further work on reliability in dynamic real-world contexts. L-LIO augments driver and scene understanding through multimodal fusion of audio and visual sensing, offering new paths for safety intervention.

</details>


### [84] [Vision and language: Novel Representations and Artificial intelligence for Driving Scene Safety Assessment and Autonomous Vehicle Planning](https://arxiv.org/abs/2602.07680)
*Ross Greer,Maitrayee Keskar,Angel Martinez-Sanchez,Parthib Roy,Shashank Shriram,Mohan Trivedi*

Main category: cs.CV

TL;DR: 该论文研究了视觉语言模型在自动驾驶安全评估和决策中的应用，探索了三种系统级用例：基于CLIP的轻量级危险筛查、视觉语言嵌入在轨迹规划中的集成、以及自然语言作为运动规划的行为约束。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型能够将视觉观察与自然语言概念对齐，为安全关键自动驾驶中的语义推理提供了新机会。研究旨在探索如何利用视觉语言表示来支持驾驶场景安全评估和决策制定。

Method: 研究采用三种互补的系统级方法：1) 基于CLIP图像-文本相似性的轻量级危险筛查方法；2) 将场景级视觉语言嵌入集成到基于Transformer的轨迹规划框架中；3) 使用自然语言作为运动规划的显式行为约束。

Result: 1) 危险筛查方法能够鲁棒检测多样化和分布外道路危险；2) 简单地将全局嵌入条件化到规划器中不能提高轨迹精度；3) 基于视觉场景元素的自然语言指令能够抑制罕见但严重的规划失败，在模糊场景中改善安全对齐行为。

Conclusion: 视觉语言表示在表达语义风险、意图和行为约束方面对自动驾驶安全具有重要潜力。实现这一潜力本质上是一个工程问题，需要精心设计的系统架构和结构化基础，而不是简单的特征注入。

Abstract: Vision-language models (VLMs) have recently emerged as powerful representation learning systems that align visual observations with natural language concepts, offering new opportunities for semantic reasoning in safety-critical autonomous driving. This paper investigates how vision-language representations support driving scene safety assessment and decision-making when integrated into perception, prediction, and planning pipelines. We study three complementary system-level use cases. First, we introduce a lightweight, category-agnostic hazard screening approach leveraging CLIP-based image-text similarity to produce a low-latency semantic hazard signal. This enables robust detection of diverse and out-of-distribution road hazards without explicit object detection or visual question answering. Second, we examine the integration of scene-level vision-language embeddings into a transformer-based trajectory planning framework using the Waymo Open Dataset. Our results show that naively conditioning planners on global embeddings does not improve trajectory accuracy, highlighting the importance of representation-task alignment and motivating the development of task-informed extraction methods for safety-critical planning. Third, we investigate natural language as an explicit behavioral constraint on motion planning using the doScenes dataset. In this setting, passenger-style instructions grounded in visual scene elements suppress rare but severe planning failures and improve safety-aligned behavior in ambiguous scenarios. Taken together, these findings demonstrate that vision-language representations hold significant promise for autonomous driving safety when used to express semantic risk, intent, and behavioral constraints. Realizing this potential is fundamentally an engineering problem requiring careful system design and structured grounding rather than direct feature injection.

</details>


### [85] [Process-of-Thought Reasoning for Videos](https://arxiv.org/abs/2602.07689)
*Jusheng Zhang,Kaitong Cai,Jian Wang,Yongsen Zheng,Kwok-Yan Lam,Keze Wang*

Main category: cs.CV

TL;DR: 提出视频推理的思维过程框架，通过将推理分解为可验证的步骤来提升视频理解能力


<details>
  <summary>Details</summary>
Motivation: 视频理解需要处理长而嘈杂的观察，进行时间定位和多步推理，现有方法缺乏显式的推理过程和可追溯性

Method: 提出思维过程推理框架，将视频推理结构化为一序列轻量级可验证步骤，包括时间证据选择、逐步状态更新和约束答案合成

Result: 在标准视频推理任务上，该框架持续提升事实正确性和时间定位能力，同时提供可解释的推理轨迹

Conclusion: 思维过程推理框架通过显式结构化推理过程，显著改善了视频推理的准确性、鲁棒性和可解释性

Abstract: Video understanding requires not only recognizing visual content but also performing temporally grounded, multi-step reasoning over long and noisy observations. We propose Process-of-Thought (PoT) Reasoning for Videos, a framework that makes the reasoning process explicit by structuring video inference into a sequence of lightweight, verifiable steps. PoT interleaves (i) temporal evidence selection, (ii) step-wise state updates, and (iii) constrained answer synthesis, enabling the model to progressively refine hypotheses while maintaining traceability to video evidence. The framework is designed to be model-agnostic and can be plugged into existing vision-language backbones, supporting both closed-book reasoning and evidence-augmented reasoning with external tools. We further introduce a unified representation for PoT traces that aligns intermediate decisions with temporal segments, which improves robustness to distractors and reduces hallucinated explanations. Extensive experiments on standard video reasoning tasks demonstrate that PoT consistently improves factual correctness and temporal grounding, while providing interpretable reasoning traces for diagnosis and downstream use.

</details>


### [86] [Semantic-Deviation-Anchored Multi-Branch Fusion for Unsupervised Anomaly Detection and Localization in Unstructured Conveyor-Belt Coal Scenes](https://arxiv.org/abs/2602.07694)
*Wenping Jin,Yuyang Tang,Li Zhu*

Main category: cs.CV

TL;DR: 提出CoalAD基准和互补线索协同感知框架，用于煤矿传送带场景中的无监督异物异常检测与像素级定位


<details>
  <summary>Details</summary>
Motivation: 煤矿传送带场景中的异物异常检测对安全生产至关重要，但由于环境高度非结构化（煤矸石随机堆积、背景复杂多变、异物低对比度、变形遮挡等），现有方法性能显著下降，需要专门解决方案

Method: 提出互补线索协同感知框架，从三个角度提取和融合异常证据：1) 对象级语义组合建模；2) 基于语义属性的全局偏差分析；3) 细粒度纹理匹配

Result: 在CoalAD基准上的实验表明，该方法在图像级和像素级指标上均优于广泛使用的基线方法，消融研究验证了各组件贡献

Conclusion: 提出的CoalAD基准和互补线索协同感知框架为煤矿场景中的无监督异物异常检测提供了有效解决方案，代码已开源

Abstract: Reliable foreign-object anomaly detection and pixel-level localization in conveyor-belt coal scenes are essential for safe and intelligent mining operations. This task is particularly challenging due to the highly unstructured environment: coal and gangue are randomly piled, backgrounds are complex and variable, and foreign objects often exhibit low contrast, deformation, occlusion, resulting in coupling with their surroundings. These characteristics weaken the stability and regularity assumptions that many anomaly detection methods rely on in structured industrial settings, leading to notable performance degradation. To support evaluation and comparison in this setting, we construct \textbf{CoalAD}, a benchmark for unsupervised foreign-object anomaly detection with pixel-level localization in coal-stream scenes. We further propose a complementary-cue collaborative perception framework that extracts and fuses complementary anomaly evidence from three perspectives: object-level semantic composition modeling, semantic-attribution-based global deviation analysis, and fine-grained texture matching. The fused outputs provide robust image-level anomaly scoring and accurate pixel-level localization. Experiments on CoalAD demonstrate that our method outperforms widely used baselines across the evaluated image-level and pixel-level metrics, and ablation studies validate the contribution of each component. The code is available at https://github.com/xjpp2016/USAD.

</details>


### [87] [A hybrid Kolmogorov-Arnold network for medical image segmentation](https://arxiv.org/abs/2602.07702)
*Deep Bhattacharyya,Ali Ayub,A. Ben Hamza*

Main category: cs.CV

TL;DR: 提出U-KABS混合框架，结合KAN网络与U型编码器-解码器架构，通过可学习的Bernstein多项式和B样条激活函数增强医学图像分割性能


<details>
  <summary>Details</summary>
Motivation: 医学图像分割在诊断和治疗规划中至关重要，但由于医学图像的复杂性和变异性，特别是捕捉数据中的非线性关系仍然具有挑战性

Method: 提出U-KABS混合框架，整合Kolmogorov-Arnold网络（KANs）的表达能力与U型编码器-解码器架构。模型包含卷积和挤压-激励阶段（增强通道特征表示）以及KAN Bernstein Spline（KABS）阶段（使用基于Bernstein多项式和B样条的可学习激活函数）。通过跳跃连接实现多尺度特征融合

Result: 在多个医学成像基准数据集上评估，U-KABS表现出优于强基线的性能，特别是在分割复杂解剖结构方面

Conclusion: U-KABS框架通过结合Bernstein多项式的全局平滑性和B样条的局部适应性，有效捕捉医学图像中的上下文趋势和细粒度模式，提升了分割性能

Abstract: Medical image segmentation plays a vital role in diagnosis and treatment planning, but remains challenging due to the inherent complexity and variability of medical images, especially in capturing non-linear relationships within the data. We propose U-KABS, a novel hybrid framework that integrates the expressive power of Kolmogorov-Arnold Networks (KANs) with a U-shaped encoder-decoder architecture to enhance segmentation performance. The U-KABS model combines the convolutional and squeeze-and-excitation stage, which enhances channel-wise feature representations, and the KAN Bernstein Spline (KABS) stage, which employs learnable activation functions based on Bernstein polynomials and B-splines. This hybrid design leverages the global smoothness of Bernstein polynomials and the local adaptability of B-splines, enabling the model to effectively capture both broad contextual trends and fine-grained patterns critical for delineating complex structures in medical images. Skip connections between encoder and decoder layers support effective multi-scale feature fusion and preserve spatial details. Evaluated across diverse medical imaging benchmark datasets, U-KABS demonstrates superior performance compared to strong baselines, particularly in segmenting complex anatomical structures.

</details>


### [88] [All-Optical Segmentation via Diffractive Neural Networks for Autonomous Driving](https://arxiv.org/abs/2602.07717)
*Yingjie Li,Daniel Robinson,Cunxi Yu*

Main category: cs.CV

TL;DR: 提出用于自动驾驶图像分割和车道检测的全光计算框架，利用衍射光学神经网络实现高能效实时处理


<details>
  <summary>Details</summary>
Motivation: 传统深度神经网络在自动驾驶图像分割和车道检测中能耗高，需要大量模数转换和大规模图像计算以实现低延迟实时响应。衍射光学神经网络在能效方面相比传统DNN具有优势。

Method: 提出基于衍射光学神经网络的全光计算框架，通过光衍射实现全光学图像处理，利用全光编码和计算减少模数转换开销，在CityScapes数据集上进行图像分割实验，并在定制室内轨道数据集和CARLA模拟驾驶场景中进行车道检测案例研究。

Result: 实验结果表明DONN系统在CityScapes数据集上的图像分割效果有效，在车道检测案例研究中进一步评估了模型在不同环境条件下的泛化能力。

Conclusion: 衍射光学神经网络为自动驾驶中的图像分割和车道检测任务提供了一种高能效的全光计算解决方案，具有实际应用潜力。

Abstract: Semantic segmentation and lane detection are crucial tasks in autonomous driving systems. Conventional approaches predominantly rely on deep neural networks (DNNs), which incur high energy costs due to extensive analog-to-digital conversions and large-scale image computations required for low-latency, real-time responses. Diffractive optical neural networks (DONNs) have shown promising advantages over conventional DNNs on digital or optoelectronic computing platforms in energy efficiency. By performing all-optical image processing via light diffraction at the speed of light, DONNs save computation energy costs while reducing the overhead associated with analog-to-digital conversions by all-optical encoding and computing. In this work, we propose a novel all-optical computing framework for RGB image segmentation and lane detection in autonomous driving applications. Our experimental results demonstrate the effectiveness of the DONN system for image segmentation on the CityScapes dataset. Additionally, we conduct case studies on lane detection using a customized indoor track dataset and simulated driving scenarios in CARLA, where we further evaluate the model's generalizability under diverse environmental conditions.

</details>


### [89] [PAND: Prompt-Aware Neighborhood Distillation for Lightweight Fine-Grained Visual Classification](https://arxiv.org/abs/2602.07768)
*Qiuming Luo,Yuebing Li,Feng Li,Chang Kong*

Main category: cs.CV

TL;DR: PAND提出两阶段知识蒸馏框架，通过提示感知语义校准和邻域感知结构蒸馏，将大型视觉语言模型知识迁移到轻量级网络，在细粒度视觉分类任务上取得显著提升。


<details>
  <summary>Details</summary>
Motivation: 在细粒度视觉分类中，从大型视觉语言模型蒸馏知识到轻量网络面临挑战，主要因为固定提示和全局对齐的限制。需要解决语义校准和结构转移的问题。

Method: 提出两阶段框架：1) 提示感知语义校准，生成自适应语义锚点；2) 邻域感知结构蒸馏策略，约束学生模型的局部决策结构。

Result: 在四个细粒度视觉分类基准测试中持续优于最先进方法。ResNet-18学生模型在CUB-200上达到76.09%准确率，比VL2Lite基线提升3.4%。

Conclusion: PAND通过解耦语义校准和结构转移，有效解决了细粒度视觉分类中知识蒸馏的挑战，为轻量级网络提供了强大的性能提升。

Abstract: Distilling knowledge from large Vision-Language Models (VLMs) into lightweight networks is crucial yet challenging in Fine-Grained Visual Classification (FGVC), due to the reliance on fixed prompts and global alignment. To address this, we propose PAND (Prompt-Aware Neighborhood Distillation), a two-stage framework that decouples semantic calibration from structural transfer. First, we incorporate Prompt-Aware Semantic Calibration to generate adaptive semantic anchors. Second, we introduce a neighborhood-aware structural distillation strategy to constrain the student's local decision structure. PAND consistently outperforms state-of-the-art methods on four FGVC benchmarks. Notably, our ResNet-18 student achieves 76.09% accuracy on CUB-200, surpassing the strong baseline VL2Lite by 3.4%. Code is available at https://github.com/LLLVTA/PAND.

</details>


### [90] [Rolling Sink: Bridging Limited-Horizon Training and Open-Ended Testing in Autoregressive Video Diffusion](https://arxiv.org/abs/2602.07775)
*Haodong Li,Shaoteng Liu,Zhe Lin,Manmohan Chandraker*

Main category: cs.CV

TL;DR: 提出Rolling Sink方法，无需额外训练即可将自回归视频扩散模型扩展到超长时长的视频生成，解决训练时长有限与测试时长无限之间的差距问题。


<details>
  <summary>Details</summary>
Motivation: 自回归视频扩散模型训练时长有限，导致在测试更长时长视频时出现视觉退化问题。现有研究只关注训练时长内的训练-测试差距，本文研究训练时长之外的差距，即有限训练时长与无限测试时长之间的差距。

Method: 提出Rolling Sink方法，基于自回归缓存维护的系统分析，无需额外训练即可扩展视频生成时长。该方法建立在Self Forcing（仅用5秒片段训练）基础上，通过优化缓存机制实现超长视频生成。

Result: Rolling Sink能够将视频合成扩展到超长时长（5-30分钟，16 FPS），保持主题一致、颜色稳定、结构连贯和运动平滑。在长时程视觉保真度和时间一致性方面优于现有最先进基线方法。

Conclusion: 通过系统分析自回归缓存维护并提出Rolling Sink方法，成功解决了自回归视频扩散模型在有限训练时长与无限测试时长之间的差距问题，实现了高质量的超长视频生成。

Abstract: Recently, autoregressive (AR) video diffusion models has achieved remarkable performance. However, due to their limited training durations, a train-test gap emerges when testing at longer horizons, leading to rapid visual degradations. Following Self Forcing, which studies the train-test gap within the training duration, this work studies the train-test gap beyond the training duration, i.e., the gap between the limited horizons during training and open-ended horizons during testing. Since open-ended testing can extend beyond any finite training window, and long-video training is computationally expensive, we pursue a training-free solution to bridge this gap. To explore a training-free solution, we conduct a systematic analysis of AR cache maintenance. These insights lead to Rolling Sink. Built on Self Forcing (trained on only 5s clips), Rolling Sink effectively scales the AR video synthesis to ultra-long durations (e.g., 5-30 minutes at 16 FPS) at test time, with consistent subjects, stable colors, coherent structures, and smooth motions. As demonstrated by extensive experiments, Rolling Sink achieves superior long-horizon visual fidelity and temporal consistency compared to SOTA baselines. Project page: https://rolling-sink.github.io/

</details>


### [91] [Uncertainty-Aware Counterfactual Traffic Signal Control with Predictive Safety and Starvation-Avoidance Constraints Using Vision-Based Sensing](https://arxiv.org/abs/2602.07784)
*Jayawant Bodagala,Balaji Bodagala*

Main category: cs.CV

TL;DR: UCATSC是一个基于模型的交通信号控制系统，通过随机决策过程建模，考虑视觉感知不确定性，在信念空间中进行反事实推演来预测和执行安全约束，提高交通延迟和排放的同时防止安全关键错误。


<details>
  <summary>Details</summary>
Motivation: 自适应交通信号控制在现实世界部署有限，主要因为：1）基于视觉的感知存在不确定性；2）隐含的安全性问题；3）主要在仿真中学习和验证的非可解释控制策略。需要解决这些挑战以实现实际部署。

Method: 采用基于模型的方法，将交通信号控制建模为具有约束和部分可观测性的随机决策过程。在信念空间中进行反事实推演，预测并强制执行与安全和防饥饿相关的硬约束，而不是通过奖励塑造学习安全性。

Result: 系统设计旨在改善交通延迟和排放，同时防止安全关键错误，并提供基于显式模型的可解释控制策略输出。

Conclusion: UCATSC通过显式建模不确定性、在信念空间中进行约束预测和执行，解决了自适应交通信号控制实际部署的关键挑战，提供了更安全、可解释的控制方案。

Abstract: Real-world deployment of adaptive traffic signal control, to date, remains limited due to the uncertainty associated with vision-based perception, implicit safety, and non-interpretable control policies learned and validated mainly in simulation. In this paper, we introduce UCATSC, a model-based traffic signal control system that models traffic signal control at an intersection using a stochastic decision process with constraints and under partial observability, taking into account the uncertainty associated with vision-based perception. Unlike reinforcement learning methods that learn to predict safety using reward shaping, UCATSC predicts and enforces hard constraints related to safety and starvation prevention during counterfactual rollouts in belief space. The system is designed to improve traffic delay and emission while preventing safety-critical errors and providing interpretable control policy outputs based on explicit models.

</details>


### [92] [VideoTemp-o3: Harmonizing Temporal Grounding and Video Understanding in Agentic Thinking-with-Videos](https://arxiv.org/abs/2602.07801)
*Wenqi Liu,Yunxiao Wang,Shijie Ma,Meng Liu,Qile Su,Tianke Zhang,Haonan Fan,Changyi Liu,Kaiyu Jiang,Jiankang Chen,Kaiyu Tang,Bin Wen,Fan Yang,Tingting Gao,Han Li,Yinwei Wei,Xuemeng Song*

Main category: cs.CV

TL;DR: VideoTemp-o3：一个统一的视频理解框架，通过联合建模视频定位和问答，解决了长视频理解中均匀采样效率低、定位弱的问题。


<details>
  <summary>Details</summary>
Motivation: 传统均匀帧采样在长视频理解中难以捕捉关键视觉证据，导致性能下降和幻觉增加。现有的代理思考范式虽然采用定位-剪辑-回答流程，但仍存在效率低、定位弱、流程僵化的问题。

Method: 提出VideoTemp-o3统一框架，联合建模视频定位和问答。在监督微调阶段设计统一掩码机制，在强化学习阶段引入专用奖励防止奖励黑客攻击。同时构建高质量长视频定位QA数据和相应基准。

Result: 实验结果表明，该方法在长视频理解和定位任务上均取得了显著性能提升。

Conclusion: VideoTemp-o3通过统一的代理思考框架，有效解决了长视频理解中的定位和效率问题，为长视频理解提供了新的解决方案。

Abstract: In long-video understanding, conventional uniform frame sampling often fails to capture key visual evidence, leading to degraded performance and increased hallucinations. To address this, recent agentic thinking-with-videos paradigms have emerged, adopting a localize-clip-answer pipeline in which the model actively identifies relevant video segments, performs dense sampling within those clips, and then produces answers. However, existing methods remain inefficient, suffer from weak localization, and adhere to rigid workflows. To solve these issues, we propose VideoTemp-o3, a unified agentic thinking-with-videos framework that jointly models video grounding and question answering. VideoTemp-o3 exhibits strong localization capability, supports on-demand clipping, and can refine inaccurate localizations. Specifically, in the supervised fine-tuning stage, we design a unified masking mechanism that encourages exploration while preventing noise. For reinforcement learning, we introduce dedicated rewards to mitigate reward hacking. Besides, from the data perspective, we develop an effective pipeline to construct high-quality long video grounded QA data, along with a corresponding benchmark for systematic evaluation across various video durations. Experimental results demonstrate that our method achieves remarkable performance on both long video understanding and grounding.

</details>


### [93] [How well are open sourced AI-generated image detection models out-of-the-box: A comprehensive benchmark study](https://arxiv.org/abs/2602.07814)
*Simiao Ren,Yuchen Zhou,Xingyu Shen,Kidus Zewde,Tommy Duong,George Huang,Hatsanai,Tiangratanakul,Tsang,Ng,En Wei,Jiayu Xue*

Main category: cs.CV

TL;DR: 首次对16种最先进的AI生成图像检测方法进行零样本评估，涵盖23个预训练检测器变体和12个数据集，发现没有通用最佳检测器，性能差异显著，现代商业生成器能击败大多数检测器。


<details>
  <summary>Details</summary>
Motivation: 随着AI生成图像在数字平台上的激增，可靠的检测方法对于打击错误信息和维护内容真实性变得至关重要。现有基准主要评估微调模型，忽略了零样本性能这一最常见部署场景，存在关键研究空白。

Method: 对16种最先进的检测方法（23个预训练检测器变体）进行首次全面的零样本评估，涵盖12个多样化数据集，包含260万张图像样本，涉及291个独特生成器（包括现代扩散模型）。

Result: 研究发现：(1)没有通用最佳检测器，检测器排名极不稳定；(2)最佳和最差检测器性能差距达37个百分点；(3)训练数据对齐对泛化能力影响巨大；(4)现代商业生成器能击败大多数检测器；(5)识别出三种系统性跨数据集泛化失败模式。

Conclusion: 研究挑战了"一刀切"的检测器范式，表明从业者必须根据具体威胁环境仔细选择检测器，而不能依赖已发布的基准性能。提供了可操作的部署指南。

Abstract: As AI-generated images proliferate across digital platforms, reliable detection methods have become critical for combating misinformation and maintaining content authenticity. While numerous deepfake detection methods have been proposed, existing benchmarks predominantly evaluate fine-tuned models, leaving a critical gap in understanding out-of-the-box performance -- the most common deployment scenario for practitioners. We present the first comprehensive zero-shot evaluation of 16 state-of-the-art detection methods, comprising 23 pretrained detector variants (due to multiple released versions of certain detectors), across 12 diverse datasets, comprising 2.6~million image samples spanning 291 unique generators including modern diffusion models. Our systematic analysis reveals striking findings: (1)~no universal winner exists, with detector rankings exhibiting substantial instability (Spearman~$ρ$: 0.01 -- 0.87 across dataset pairs); (2)~a 37~percentage-point performance gap separates the best detector (75.0\% mean accuracy) from the worst (37.5\%); (3)~training data alignment critically impacts generalization, causing up to 20--60\% performance variance within architecturally identical detector families; (4)~modern commercial generators (Flux~Dev, Firefly~v4, Midjourney~v7) defeat most detectors, achieving only 18--30\% average accuracy; and (5)~we identify three systematic failure patterns affecting cross-dataset generalization. Statistical analysis confirms significant performance differences between detectors (Friedman test: $χ^2$=121.01, $p<10^{-16}$, Kendall~$W$=0.524). Our findings challenge the ``one-size-fits-all'' detector paradigm and provide actionable deployment guidelines, demonstrating that practitioners must carefully select detectors based on their specific threat landscape rather than relying on published benchmark performance.

</details>


### [94] [Out of the box age estimation through facial imagery: A Comprehensive Benchmark of Vision-Language Models vs. out-of-the-box Traditional Architectures](https://arxiv.org/abs/2602.07815)
*Simiao Ren*

Main category: cs.CV

TL;DR: VLMs在面部年龄估计任务中显著优于专门化模型，最佳VLM比最佳专门化模型MAE降低15%，挑战了任务特定架构必要性的假设。


<details>
  <summary>Details</summary>
Motivation: 面部年龄估计对内容审核、年龄验证和深度伪造检测至关重要，但此前缺乏系统比较现代视觉语言模型与专门化年龄估计架构的基准测试。

Method: 首次大规模跨范式基准测试，评估34个模型（22个专门化架构和12个通用VLMs），在8个标准数据集上总计1100张测试图像，分析MAE、年龄验证准确性和分层年龄组表现。

Result: 零样本VLMs显著优于大多数专门化模型（平均MAE 5.65年 vs 9.88年），最佳VLM（Gemini 3 Flash Preview，MAE 4.32）比最佳非LLM模型（MiVOLO，MAE 5.10）提升15%。VLMs在18岁阈值年龄验证中假成人率显著更低（13-25% vs 60-100%）。

Conclusion: 研究挑战了任务特定架构对年龄估计必要的假设，建议领域应转向将VLM能力蒸馏到高效专门化模型中，所有模型在极端年龄（<5岁和65+）表现最差。

Abstract: Facial age estimation is critical for content moderation, age verification, and deepfake detection, yet no prior benchmark has systematically compared modern vision-language models (VLMs) against specialized age estimation architectures. We present the first large-scale cross-paradigm benchmark, evaluating \textbf{34 models} -- 22 specialized architectures with publicly available pretrained weights and 12 general-purpose VLMs -- across \textbf{8 standard datasets} (UTKFace, IMDB-WIKI, MORPH, AFAD, CACD, FG-NET, APPA-REAL, AgeDB) totaling 1{,}100 test images per model. Our key finding is striking: \emph{zero-shot VLMs significantly outperform most specialized models}, achieving an average MAE of 5.65 years compared to 9.88 for non-LLM models. The best VLM (Gemini~3 Flash Preview, MAE~4.32) outperforms the best non-LLM model (MiVOLO, MAE~5.10) by 15\%. Only MiVOLO, which uniquely combines face and body features via Vision Transformers, competes with VLMs. We further analyze age verification at the 18-year threshold, revealing that non-LLM models exhibit 60--100\% false adult rates on minors while VLMs achieve 13--25\%, and demonstrate that coarse age binning (8--9 classes) consistently degrades MAE beyond 13 years. Our stratified analysis across 14 age groups reveals that all models struggle most at extreme ages ($<$5 and 65+). These findings challenge the assumption that task-specific architectures are necessary for age estimation and suggest that the field should redirect toward distilling VLM capabilities into efficient specialized models.

</details>


### [95] [Back to Physics: Operator-Guided Generative Paths for SMS MRI Reconstruction](https://arxiv.org/abs/2602.07820)
*Zhibo Chen,Yu Guan,Yajuan Huang,Chaoqi Chen,XiangJi,Qiuyun Fan,Dong Liang,Qiegen Liu*

Main category: cs.CV

TL;DR: 提出一种基于操作符引导的双流交互网络(OCDI-Net)，用于解决同时多层(SMS)MRI重建中的切片间干扰和k空间欠采样问题，通过两阶段推理实现切片分离和平面内补全。


<details>
  <summary>Details</summary>
Motivation: 传统基于扩散的重建方法通常围绕高斯噪声退化设计，需要额外的一致性步骤来整合SMS物理特性，这与SMS采集中的操作符控制退化不匹配。需要一种能直接建模SMS采集退化轨迹的方法。

Method: 提出操作符引导框架，使用已知采集操作符建模退化轨迹，并通过确定性更新反转该过程。引入OCDI-Net网络，显式分离目标切片内容与切片间干扰，预测结构化退化以实现操作符对齐的反转。采用两阶段链式推理：先进行SMS切片分离，再进行平面内补全。

Result: 在fastMRI脑数据和前瞻性采集的体内扩散MRI数据上的实验表明，相比传统和基于学习的SMS重建方法，该方法提高了保真度并减少了切片泄漏。

Conclusion: 提出的操作符引导框架和OCDI-Net能够有效处理SMS MRI中的耦合逆问题，通过显式建模采集退化轨迹和切片间干扰，实现了更准确的重建。

Abstract: Simultaneous multi-slice (SMS) imaging with in-plane undersampling enables highly accelerated MRI but yields a strongly coupled inverse problem with deterministic inter-slice interference and missing k-space data. Most diffusion-based reconstructions are formulated around Gaussian-noise corruption and rely on additional consistency steps to incorporate SMS physics, which can be mismatched to the operator-governed degradations in SMS acquisition. We propose an operator-guided framework that models the degradation trajectory using known acquisition operators and inverts this process via deterministic updates. Within this framework, we introduce an operator-conditional dual-stream interaction network (OCDI-Net) that explicitly disentangles target-slice content from inter-slice interference and predicts structured degradations for operator-aligned inversion, and we instantiate reconstruction as a two-stage chained inference procedure that performs SMS slice separation followed by in-plane completion. Experiments on fastMRI brain data and prospectively acquired in vivo diffusion MRI data demonstrate improved fidelity and reduced slice leakage over conventional and learning-based SMS reconstructions.

</details>


### [96] [Open-Text Aerial Detection: A Unified Framework For Aerial Visual Grounding And Detection](https://arxiv.org/abs/2602.07827)
*Guoting Wei,Xia Yuan,Yang Zhou,Haizhao Jing,Yu Liu,Xianbiao Qi,Chunxia Zhao,Haokui Zhang,Rong Xiao*

Main category: cs.CV

TL;DR: OTA-Det是一个统一框架，将开放词汇航空检测（OVAD）和遥感视觉定位（RSVG）两个范式结合，支持丰富的语义理解和多目标检测，在保持实时推理的同时在六个基准测试中达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有OVAD方法仅限于粗粒度的类别级语义，而RSVG在结构上仅限于单目标定位，这两种孤立范式都无法同时支持丰富的语义理解和多目标检测。

Method: 提出任务重构策略统一任务目标和监督机制，实现跨范式数据集的联合训练；提出密集语义对齐策略建立从整体表达到个体属性的多粒度对应关系；基于RT-DETR架构扩展，引入高效模块实现从闭集检测到开放文本检测的转变。

Result: 在六个涵盖OVAD和RSVG任务的基准测试中达到最先进性能，同时保持34 FPS的实时推理速度。

Conclusion: OTA-Det成功将OVAD和RSVG两个关键范式统一到一个框架中，实现了同时支持丰富语义理解和多目标检测的目标，为航空场景理解提供了更全面的解决方案。

Abstract: Open-Vocabulary Aerial Detection (OVAD) and Remote Sensing Visual Grounding (RSVG) have emerged as two key paradigms for aerial scene understanding. However, each paradigm suffers from inherent limitations when operating in isolation: OVAD is restricted to coarse category-level semantics, while RSVG is structurally limited to single-target localization. These limitations prevent existing methods from simultaneously supporting rich semantic understanding and multi-target detection. To address this, we propose OTA-Det, the first unified framework that bridges both paradigms into a cohesive architecture. Specifically, we introduce a task reformulation strategy that unifies task objectives and supervision mechanisms, enabling joint training across datasets from both paradigms with dense supervision signals. Furthermore, we propose a dense semantic alignment strategy that establishes explicit correspondence at multiple granularities, from holistic expressions to individual attributes, enabling fine-grained semantic understanding. To ensure real-time efficiency, OTA-Det builds upon the RT-DETR architecture, extending it from closed-set detection to open-text detection by introducing several high efficient modules, achieving state-of-the-art performance on six benchmarks spanning both OVAD and RSVG tasks while maintaining real-time inference at 34 FPS.

</details>


### [97] [SPD-Faith Bench: Diagnosing and Improving Faithfulness in Chain-of-Thought for Multimodal Large Language Models](https://arxiv.org/abs/2602.07833)
*Weijiang Lv,Yaoxuan Feng,Xiaobo Xia,Jiayu Wang,Yan Jing,Wenchao Chen,Bo Chen*

Main category: cs.CV

TL;DR: 该论文提出了SPD-Faith Bench基准，用于评估多模态大语言模型推理的忠实性，发现了两种系统性失败模式，并提出了无需训练的SAGE框架来改善视觉证据校准。


<details>
  <summary>Details</summary>
Motivation: 虽然思维链推理被广泛用于提高多模态大语言模型的可解释性，但生成的推理轨迹的忠实性仍不清楚。先前工作主要关注感知幻觉，而推理层面的不忠实性尚未得到充分探索。

Method: 1) 引入SPD-Faith Bench诊断基准，基于细粒度图像差异推理，强制进行显式视觉比较；2) 分析失败模式的原因，发现视觉注意力衰减和残差流中的表示偏移；3) 提出SAGE框架，无需训练，通过改善视觉路由和使推理与感知对齐来校准视觉证据。

Result: 评估最先进的多模态大语言模型揭示了两种系统性失败模式：感知盲区和感知-推理分离。SAGE框架能有效改善视觉路由并校准推理过程。

Conclusion: 研究强调了在响应正确性之外显式评估忠实性的重要性。提出的基准和框架为理解和改善多模态推理的忠实性提供了工具。

Abstract: Chain-of-Thought reasoning is widely used to improve the interpretability of multimodal large language models (MLLMs), yet the faithfulness of the generated reasoning traces remains unclear. Prior work has mainly focused on perceptual hallucinations, leaving reasoning level unfaithfulness underexplored. To isolate faithfulness from linguistic priors, we introduce SPD-Faith Bench, a diagnostic benchmark based on fine-grained image difference reasoning that enforces explicit visual comparison. Evaluations on state-of-the-art MLLMs reveal two systematic failure modes, perceptual blindness and perception-reasoning dissociation. We trace these failures to decaying visual attention and representation shifts in the residual stream. Guided by this analysis, we propose SAGE, a train-free visual evidence-calibrated framework that improves visual routing and aligns reasoning with perception. Our results highlight the importance of explicitly evaluating faithfulness beyond response correctness. Our benchmark and codes are available at https://github.com/Johanson-colab/SPD-Faith-Bench.

</details>


### [98] [VFace: A Training-Free Approach for Diffusion-Based Video Face Swapping](https://arxiv.org/abs/2602.07835)
*Sanoojan Baliah,Yohan Abeysinghe,Rusiru Thushara,Khan Muhammad,Abhinav Dhall,Karthik Nandakumar,Muhammad Haris Khan*

Main category: cs.CV

TL;DR: VFace是一个无需训练、即插即用的视频人脸交换方法，可与基于扩散模型的图像人脸交换方法无缝集成，通过频率谱注意力插值、目标结构引导和流引导注意力时间平滑三大技术提升时间一致性和视觉质量。


<details>
  <summary>Details</summary>
Motivation: 现有的视频人脸交换方法通常存在时间不一致性问题，需要额外的训练或视频特定微调。作者希望开发一种无需训练、即插即用的方法，能够与现有图像人脸交换方法无缝集成，同时解决时间一致性和视觉质量问题。

Method: 1. 频率谱注意力插值：促进生成并保持关键身份特征；2. 目标结构引导：通过即插即用的注意力注入，将目标帧的结构特征更好地对齐到生成过程；3. 流引导注意力时间平滑：在不修改底层扩散模型的情况下强制时空一致性，减少帧级生成中常见的时间不一致性。

Result: 大量实验表明，该方法显著提升了时间一致性和视觉保真度，为视频人脸交换提供了一个实用且模块化的解决方案。代码已开源。

Conclusion: VFace是一个无需训练、即插即用的视频人脸交换方法，能够与基于扩散模型的图像人脸交换方法无缝集成，通过三大创新技术有效解决了时间一致性和视觉质量问题，为视频人脸交换提供了实用且模块化的解决方案。

Abstract: We present a training-free, plug-and-play method, namely VFace, for high-quality face swapping in videos. It can be seamlessly integrated with image-based face swapping approaches built on diffusion models. First, we introduce a Frequency Spectrum Attention Interpolation technique to facilitate generation and intact key identity characteristics. Second, we achieve Target Structure Guidance via plug-and-play attention injection to better align the structural features from the target frame to the generation. Third, we present a Flow-Guided Attention Temporal Smoothening mechanism that enforces spatiotemporal coherence without modifying the underlying diffusion model to reduce temporal inconsistencies typically encountered in frame-wise generation. Our method requires no additional training or video-specific fine-tuning. Extensive experiments show that our method significantly enhances temporal consistency and visual fidelity, offering a practical and modular solution for video-based face swapping. Our code is available at https://github.com/Sanoojan/VFace.

</details>


### [99] [Geometry-Aware Rotary Position Embedding for Consistent Video World Model](https://arxiv.org/abs/2602.07854)
*Chendong Xiang,Jiajun Liu,Jintao Zhang,Xiao Yang,Zhengwei Fang,Shizun Wang,Zijun Wang,Yingtian Zou,Hang Su,Jun Zhu*

Main category: cs.CV

TL;DR: ViewRope：一种几何感知编码方法，通过将相机射线方向直接注入视频Transformer自注意力层，解决了预测世界模型中空间持久性不足的问题，显著提升了长期一致性并降低了计算成本。


<details>
  <summary>Details</summary>
Motivation: 当前预测世界模型缺乏空间持久性，在长轨迹中无法保持稳定的场景结构，当相机重新访问先前观察的位置时经常产生幻觉细节。这种几何漂移源于对屏幕空间位置嵌入的依赖，这与3D一致性所需的投影几何相冲突。

Method: 提出了ViewRope几何感知编码，将相机射线方向直接注入视频Transformer自注意力层；提出几何感知帧稀疏注意力，利用几何线索选择性关注相关历史帧；还提出了ViewBench诊断套件来测量闭环保真度和几何漂移。

Result: ViewRope显著改善了长期一致性，同时减少了计算成本。通过几何感知编码和帧稀疏注意力机制，系统能够在长轨迹中保持稳定的场景结构，避免重新访问位置时的幻觉问题。

Conclusion: 通过引入几何感知的ViewRope编码和几何感知帧稀疏注意力，成功解决了预测世界模型中的空间持久性问题，为交互式AI提供了更稳定、高效的3D一致世界模型。

Abstract: Predictive world models that simulate future observations under explicit camera control are fundamental to interactive AI. Despite rapid advances, current systems lack spatial persistence: they fail to maintain stable scene structures over long trajectories, frequently hallucinating details when cameras revisit previously observed locations. We identify that this geometric drift stems from reliance on screen-space positional embeddings, which conflict with the projective geometry required for 3D consistency. We introduce \textbf{ViewRope}, a geometry-aware encoding that injects camera-ray directions directly into video transformer self-attention layers. By parameterizing attention with relative ray geometry rather than pixel locality, ViewRope provides a model-native inductive bias for retrieving 3D-consistent content across temporal gaps. We further propose \textbf{Geometry-Aware Frame-Sparse Attention}, which exploits these geometric cues to selectively attend to relevant historical frames, improving efficiency without sacrificing memory consistency. We also present \textbf{ViewBench}, a diagnostic suite measuring loop-closure fidelity and geometric drift. Our results demonstrate that ViewRope substantially improves long-term consistency while reducing computational costs.

</details>


### [100] [Recovering 3D Shapes from Ultra-Fast Motion-Blurred Images](https://arxiv.org/abs/2602.07860)
*Fei Yu,Shudan Guo,Shiqing Xin,Beibei Wang,Haisen Zhao,Wenzheng Chen*

Main category: cs.CV

TL;DR: 提出一种从超快运动模糊图像中恢复3D形状的逆渲染方法，通过快速重心坐标求解器显著提升计算效率，实现高效且逼真的高速运动模拟和3D重建。


<details>
  <summary>Details</summary>
Motivation: 在自然和工业场景中（如体育中的快速移动物体或旋转机械），超快运动导致图像严重模糊，传统多视角立体视觉等3D重建技术失效，需要新的方法来从极端运动模糊图像中恢复几何形状。

Method: 提出一种新颖的逆渲染方法，包含快速重心坐标求解器，显著减少计算重心权重的重复计算开销，实现4.57倍加速。该方法完全可微分，允许梯度从渲染图像传播到底层3D形状，从而通过逆渲染实现形状恢复。

Result: 在快速平移和旋转两种代表性运动类型上验证了方法有效性。实验结果表明，该方法能够高效逼真地模拟超快运动物体的前向仿真，并成功从经历极端平移和旋转运动的物体2D图像中恢复3D形状。

Conclusion: 该方法突破了基于视觉的3D重建边界，为从超快运动模糊图像中恢复3D形状提供了高效可行的解决方案，在计算效率和重建质量方面均取得显著进展。

Abstract: We consider the problem of 3D shape recovery from ultra-fast motion-blurred images. While 3D reconstruction from static images has been extensively studied, recovering geometry from extreme motion-blurred images remains challenging. Such scenarios frequently occur in both natural and industrial settings, such as fast-moving objects in sports (e.g., balls) or rotating machinery, where rapid motion distorts object appearance and makes traditional 3D reconstruction techniques like Multi-View Stereo (MVS) ineffective.
  In this paper, we propose a novel inverse rendering approach for shape recovery from ultra-fast motion-blurred images. While conventional rendering techniques typically synthesize blur by averaging across multiple frames, we identify a major computational bottleneck in the repeated computation of barycentric weights. To address this, we propose a fast barycentric coordinate solver, which significantly reduces computational overhead and achieves a speedup of up to 4.57x, enabling efficient and photorealistic simulation of high-speed motion. Crucially, our method is fully differentiable, allowing gradients to propagate from rendered images to the underlying 3D shape, thereby facilitating shape recovery through inverse rendering.
  We validate our approach on two representative motion types: rapid translation and rotation. Experimental results demonstrate that our method enables efficient and realistic modeling of ultra-fast moving objects in the forward simulation. Moreover, it successfully recovers 3D shapes from 2D imagery of objects undergoing extreme translational and rotational motion, advancing the boundaries of vision-based 3D reconstruction. Project page: https://maxmilite.github.io/rec-from-ultrafast-blur/

</details>


### [101] [Thinking in Structures: Evaluating Spatial Intelligence through Reasoning on Constrained Manifolds](https://arxiv.org/abs/2602.07864)
*Chen Yang,Guanxin Lin,Youquan He,Peiyao Chen,Guanghe Liu,Yufan Mo,Zhouyuan Xu,Linhao Wang,Guohui Zhang,Zihang Zhang,Shenxiang Zeng,Chen Wang,Jiansheng Fan*

Main category: cs.CV

TL;DR: SSI-Bench是一个用于评估视觉语言模型空间推理能力的基准测试，专注于受约束的3D结构，包含1000个排序问题，测试几何和拓扑推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试大多评估无约束场景，模型可以利用2D捷径，无法真正测试空间智能。需要创建专注于受约束流形上空间推理的基准，以评估模型在物理世界中的实际空间智能。

Method: 通过完全人工中心化的流程创建：10名研究人员花费400多小时精心挑选图像、标注结构组件、设计问题以最小化像素级线索。基准包含1000个排序问题，涵盖几何和拓扑推理，需要组合空间操作。

Result: 评估31个广泛使用的VLM显示与人类存在巨大差距：最佳开源模型准确率22.2%，最强闭源模型33.6%，而人类得分91.6%。鼓励模型思考仅带来边际收益，错误分析显示模型在结构基础和约束一致的3D推理方面存在失败。

Conclusion: SSI-Bench揭示了当前VLM在空间推理方面的严重不足，特别是在受约束的3D结构上。模型缺乏结构基础和约束一致的3D推理能力，这限制了它们在物理世界应用中的实用性。

Abstract: Spatial intelligence is crucial for vision--language models (VLMs) in the physical world, yet many benchmarks evaluate largely unconstrained scenes where models can exploit 2D shortcuts. We introduce SSI-Bench, a VQA benchmark for spatial reasoning on constrained manifolds, built from complex real-world 3D structures whose feasible configurations are tightly governed by geometric, topological, and physical constraints. SSI-Bench contains 1,000 ranking questions spanning geometric and topological reasoning and requiring a diverse repertoire of compositional spatial operations, such as mental rotation, cross-sectional inference, occlusion reasoning, and force-path reasoning. It is created via a fully human-centered pipeline: ten researchers spent over 400 hours curating images, annotating structural components, and designing questions to minimize pixel-level cues. Evaluating 31 widely used VLMs reveals a large gap to humans: the best open-source model achieves 22.2% accuracy and the strongest closed-source model reaches 33.6%, while humans score 91.6%. Encouraging models to think yields only marginal gains, and error analysis points to failures in structural grounding and constraint-consistent 3D reasoning. Project page: https://ssi-bench.github.io.

</details>


### [102] [WristMIR: Coarse-to-Fine Region-Aware Retrieval of Pediatric Wrist Radiographs with Radiology Report-Driven Learning](https://arxiv.org/abs/2602.07872)
*Mert Sonmezer,Serge Vasylechko,Duygu Atasoy,Seyda Ertekin,Sila Kurugol*

Main category: cs.CV

TL;DR: WristMIR：一种基于区域感知的儿科腕部X光片检索框架，通过全局和局部对比编码器实现两阶段检索，显著提升骨折模式检索和诊断性能。


<details>
  <summary>Details</summary>
Motivation: 腕部X光片骨折模式检索具有挑战性，因为临床重要线索细微、高度局部化，常被重叠解剖结构或不同成像视角掩盖。现有进展受限于缺乏大规模、高质量标注的医学图像检索数据集。

Method: 使用MedGemma结构化报告挖掘生成全局和区域级描述，结合预处理腕部图像和特定骨骼（远端桡骨、远端尺骨、尺骨茎突）裁剪。联合训练全局和局部对比编码器，采用两阶段检索：1）粗粒度全局匹配识别候选检查；2）基于预定义解剖骨骼区域的区域条件重排序。

Result: WristMIR显著提升检索性能，图像到文本Recall@5从0.82%提高到9.35%。嵌入表示在骨折分类上表现更强（AUROC 0.949，AUPRC 0.953）。在区域感知评估中，两阶段设计显著改善基于检索的骨折诊断，平均F1分数从0.568提升到0.753。放射科医生评价其检索病例临床相关性更高，平均评分从3.36提高到4.35。

Conclusion: 该研究展示了解剖引导检索在增强儿科肌肉骨骼影像诊断推理和临床决策支持方面的潜力。WristMIR无需手动图像级标注，通过密集放射学报告和骨骼特定定位学习细粒度、临床有意义的图像表示。

Abstract: Retrieving wrist radiographs with analogous fracture patterns is challenging because clinically important cues are subtle, highly localized and often obscured by overlapping anatomy or variable imaging views. Progress is further limited by the scarcity of large, well-annotated datasets for case-based medical image retrieval. We introduce WristMIR, a region-aware pediatric wrist radiograph retrieval framework that leverages dense radiology reports and bone-specific localization to learn fine-grained, clinically meaningful image representations without any manual image-level annotations. Using MedGemma-based structured report mining to generate both global and region-level captions, together with pre-processed wrist images and bone-specific crops of the distal radius, distal ulna, and ulnar styloid, WristMIR jointly trains global and local contrastive encoders and performs a two-stage retrieval process: (1) coarse global matching to identify candidate exams, followed by (2) region-conditioned reranking aligned to a predefined anatomical bone region. WristMIR improves retrieval performance over strong vision-language baselines, raising image-to-text Recall@5 from 0.82% to 9.35%. Its embeddings also yield stronger fracture classification (AUROC 0.949, AUPRC 0.953). In region-aware evaluation, the two-stage design markedly improves retrieval-based fracture diagnosis, increasing mean $F_1$ from 0.568 to 0.753, and radiologists rate its retrieved cases as more clinically relevant, with mean scores rising from 3.36 to 4.35. These findings highlight the potential of anatomically guided retrieval to enhance diagnostic reasoning and support clinical decision-making in pediatric musculoskeletal imaging. The source code is publicly available at https://github.com/quin-med-harvard-edu/WristMIR.

</details>


### [103] [Scalable Adaptation of 3D Geometric Foundation Models via Weak Supervision from Internet Video](https://arxiv.org/abs/2602.07891)
*Zihui Gao,Ke Liu,Donny Y. Chen,Duochao Shi,Guosheng Lin,Hao Chen,Chunhua Shen*

Main category: cs.CV

TL;DR: SAGE提出了一种从原始视频流中自适应几何基础模型的框架，通过分层挖掘管道将视频转化为训练轨迹，结合稀疏几何锚点和密集可微分一致性监督，显著提升了零样本泛化能力。


<details>
  <summary>Details</summary>
Motivation: 几何基础模型在3D重建中表现出潜力，但受到大规模3D标注数据稀缺的限制。虽然互联网视频提供了几乎无限的原始数据，但由于缺乏真实几何信息和存在观测噪声，将其用作几何学习的扩展源具有挑战性。

Method: SAGE采用分层挖掘管道：1) 信息丰富的训练轨迹选择；2) 通过SfM点云进行稀疏几何锚定，提供全局结构指导；3) 通过3D高斯渲染实现密集可微分一致性，提供多视角约束。为防止灾难性遗忘，引入基于锚点数据的正则化策略。

Result: 实验表明，SAGE显著增强了零样本泛化能力，在未见过的基准测试（7Scenes、TUM-RGBD、Matterport3D）上，相比最先进的基线方法，将Chamfer距离降低了20-42%。

Conclusion: SAGE开创了通过互联网视频自适应几何基础模型的先河，为通用3D学习建立了可扩展的范式，为解决3D标注数据稀缺问题提供了有效解决方案。

Abstract: Geometric foundation models show promise in 3D reconstruction, yet their progress is severely constrained by the scarcity of diverse, large-scale 3D annotations. While Internet videos offer virtually unlimited raw data, utilizing them as a scaling source for geometric learning is challenging due to the absence of ground-truth geometry and the presence of observational noise. To address this, we propose SAGE, a framework for Scalable Adaptation of GEometric foundation models from raw video streams. SAGE leverages a hierarchical mining pipeline to transform videos into training trajectories and hybrid supervision: (1) Informative training trajectory selection; (2) Sparse Geometric Anchoring via SfM point clouds for global structural guidance; and (3) Dense Differentiable Consistency via 3D Gaussian rendering for multi-view constraints. To prevent catastrophic forgetting, we introduce a regularization strategy using anchor data. Extensive experiments show that SAGE significantly enhances zero-shot generalization, reducing Chamfer Distance by 20-42% on unseen benchmarks (7Scenes, TUM-RGBD, Matterport3D) compared to state-of-the-art baselines. To our knowledge, SAGE pioneers the adaptation of geometric foundation models via Internet video, establishing a scalable paradigm for general-purpose 3D learning.

</details>


### [104] [Rethinking Practical and Efficient Quantization Calibration for Vision-Language Models](https://arxiv.org/abs/2602.07899)
*Zhenhao Shang,Haizhao Jing,Guoting Wei,Haokui Zhang,Rong Xiao,Jianqing Gao,Peng Wang*

Main category: cs.CV

TL;DR: TLQ：针对视觉语言模型的后训练量化框架，通过token级重要性感知和层级校准，解决视觉与文本token分布差异带来的量化挑战


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型中视觉token和文本token在激活分布和量化误差敏感性方面存在显著差异，这给后训练量化的校准带来了重大挑战。传统PTQ方法难以有效处理这种跨模态差异。

Method: 提出Token-level Importance-aware Layer-wise Quantization (TLQ)框架：1) 基于梯度信息设计token级重要性集成机制来量化误差；2) 构建token级校准集实现细粒度校准；3) 引入多GPU、量化暴露的层级校准方案，保持校准与真实量化推理路径一致，并将复杂计算分布到多个RTX3090 GPU上。

Result: 在两个模型、三种模型规模和两种量化设置下进行评估，在所有设置中都实现了性能提升，显示出强大的量化稳定性。

Conclusion: TLQ通过token级重要性感知和层级校准，有效解决了视觉语言模型中的跨模态量化挑战，提供了一种稳定且高效的量化框架，降低了对A100等大内存GPU的依赖。

Abstract: Post-training quantization (PTQ) is a primary approach for deploying large language models without fine-tuning, and the quantized performance is often strongly affected by the calibration in PTQ. By contrast, in vision-language models (VLMs), substantial differences between visual and text tokens in their activation distributions and sensitivities to quantization error pose significant challenges for effective calibration during PTQ. In this work, we rethink what PTQ calibration should align with in VLMs and propose the Token-level Importance-aware Layer-wise Quantization framework (TLQ). Guided by gradient information, we design a token-level importance integration mechanism for quantization error, and use it to construct a token-level calibration set, enabling a more fine-grained calibration strategy. Furthermore, TLQ introduces a multi-GPU, quantization-exposed layer-wise calibration scheme. This scheme keeps the layer-wise calibration procedure consistent with the true quantized inference path and distributes the complex layer-wise calibration workload across multiple RTX3090 GPUs, thereby reducing reliance on the large memory of A100 GPUs. TLQ is evaluated across two models, three model scales, and two quantization settings, consistently achieving performance improvements across all settings, indicating its strong quantization stability. The code will be released publicly.

</details>


### [105] [Which private attributes do VLMs agree on and predict well?](https://arxiv.org/abs/2602.07931)
*Olena Hrynenko,Darya Baranouskaya,Alina Elena Baia,Andrea Cavallaro*

Main category: cs.CV

TL;DR: 评估开源视觉语言模型在隐私相关属性识别中的零样本表现，发现VLM倾向于比人类标注者更频繁预测隐私属性存在，且在VLM间高一致性时能补充人类标注遗漏


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型常用于图像视觉属性的零样本检测，但对其在隐私相关属性识别方面的表现缺乏评估。需要了解VLM在隐私属性识别中的能力、与人类标注的一致性，以及其在隐私标注任务中的潜在价值

Method: 对开源视觉语言模型进行零样本评估，识别VLM表现出强标注者间一致性的属性，分析VLM与人类标注之间的分歧案例，比较VLM与人类标注在隐私属性识别上的差异

Result: VLM倾向于比人类标注者更频繁地预测隐私属性的存在；在VLM间高一致性的情况下，VLM能够识别被人类标注者忽略的属性，从而补充人类标注；VLM在隐私属性识别方面展现出支持大规模图像数据集隐私标注的潜力

Conclusion: 视觉语言模型在隐私相关属性识别中具有实用价值，特别是在VLM间高一致性的情况下能够补充人类标注的不足，这为利用VLM支持大规模图像数据集的隐私标注提供了依据

Abstract: Visual Language Models (VLMs) are often used for zero-shot detection of visual attributes in the image. We present a zero-shot evaluation of open-source VLMs for privacy-related attribute recognition. We identify the attributes for which VLMs exhibit strong inter-annotator agreement, and discuss the disagreement cases of human and VLM annotations. Our results show that when evaluated against human annotations, VLMs tend to predict the presence of privacy attributes more often than human annotators. In addition to this, we find that in cases of high inter-annotator agreement between VLMs, they can complement human annotation by identifying attributes overlooked by human annotators. This highlights the potential of VLMs to support privacy annotations in large-scale image datasets.

</details>


### [106] [Integrating Specialized and Generic Agent Motion Prediction with Dynamic Occupancy Grid Maps](https://arxiv.org/abs/2602.07938)
*Rabbia Asghar,Lukas Rummelhard,Wenqian Liu,Anne Spalanzani,Christian Laugier*

Main category: cs.CV

TL;DR: 提出统一框架，通过动态占用网格地图同时预测未来占用状态、车辆和场景流网格，解决现有方法在行为复杂性和泛化性方面的局限


<details>
  <summary>Details</summary>
Motivation: 现有预测方法存在局限性：基于占用网格的agent-agnostic方法难以捕捉动态参与者的复杂行为，而agent-specific方法对感知不佳或未识别代理泛化能力差。结合两者可实现更鲁棒安全的运动预测

Method: 使用动态占用网格地图，在精简的时间解码管道中同时预测未来占用状态网格、车辆网格和场景流网格。基于轻量级时空骨干网络，采用定制化的相互依赖损失函数捕捉网格间依赖关系并实现多样化未来预测

Result: 在nuScenes和Woven Planet真实数据集上的评估显示，相比基线方法，在动态车辆和通用动态场景元素预测方面表现出优越性能

Conclusion: 提出的统一框架能够同时预测车辆特定行为和其他动态实体演化，通过占用状态信息强制执行流引导的过渡，损失函数作为正则化器指导占用演化并考虑障碍物和遮挡

Abstract: Accurate prediction of driving scene is a challenging task due to uncertainty in sensor data, the complex behaviors of agents, and the possibility of multiple feasible futures. Existing prediction methods using occupancy grid maps primarily focus on agent-agnostic scene predictions, while agent-specific predictions provide specialized behavior insights with the help of semantic information. However, both paradigms face distinct limitations: agent-agnostic models struggle to capture the behavioral complexities of dynamic actors, whereas agent-specific approaches fail to generalize to poorly perceived or unrecognized agents; combining both enables robust and safer motion forecasting. To address this, we propose a unified framework by leveraging Dynamic Occupancy Grid Maps within a streamlined temporal decoding pipeline to simultaneously predict future occupancy state grids, vehicle grids, and scene flow grids. Relying on a lightweight spatiotemporal backbone, our approach is centered on a tailored, interdependent loss function that captures inter-grid dependencies and enables diverse future predictions. By using occupancy state information to enforce flow-guided transitions, the loss function acts as a regularizer that directs occupancy evolution while accounting for obstacles and occlusions. Consequently, the model not only predicts the specific behaviors of vehicle agents, but also identifies other dynamic entities and anticipates their evolution within the complex scene. Evaluations on real-world nuScenes and Woven Planet datasets demonstrate superior prediction performances for dynamic vehicles and generic dynamic scene elements compared to baseline methods.

</details>


### [107] [One-Shot Crowd Counting With Density Guidance For Scene Adaptaion](https://arxiv.org/abs/2602.07955)
*Jiwei Chen,Qi Wang,Junyu Gao,Jing Zhang,Dingyi Li,Jing-Jia Luo*

Main category: cs.CV

TL;DR: 提出一种基于少样本学习的跨监控场景人群计数方法，通过局部和全局密度特征指导模型适应未见过的监控场景


<details>
  <summary>Details</summary>
Motivation: 不同监控摄像头捕获的人群场景差异很大，现有模型对未见过的监控场景泛化能力有限。为提高模型泛化性，将不同监控场景视为不同类别场景，引入少样本学习使模型适应属于给定示例类别场景的未见监控场景。

Method: 提出利用局部和全局密度特征指导未见监控场景的人群计数模型。具体包括：1）多局部密度学习器学习支持场景中代表不同密度分布的多原型；2）编码多个局部密度相似性矩阵，以局部方式指导模型；3）从支持图像提取全局密度特征，以全局方式指导模型。

Result: 在三个监控数据集上的实验表明，该方法能够适应未见过的监控场景，在少样本人群计数任务中优于最近的最先进方法。

Conclusion: 通过结合局部和全局密度特征指导，提出的少样本学习方法能有效提升人群计数模型对未见监控场景的泛化能力。

Abstract: Crowd scenes captured by cameras at different locations vary greatly, and existing crowd models have limited generalization for unseen surveillance scenes. To improve the generalization of the model, we regard different surveillance scenes as different category scenes, and introduce few-shot learning to make the model adapt to the unseen surveillance scene that belongs to the given exemplar category scene. To this end, we propose to leverage local and global density characteristics to guide the model of crowd counting for unseen surveillance scenes. Specifically, to enable the model to adapt to the varying density variations in the target scene, we propose the multiple local density learner to learn multi prototypes which represent different density distributions in the support scene. Subsequently, these multiple local density similarity matrixes are encoded. And they are utilized to guide the model in a local way. To further adapt to the global density in the target scene, the global density features are extracted from the support image, then it is used to guide the model in a global way. Experiments on three surveillance datasets shows that proposed method can adapt to the unseen surveillance scene and outperform recent state-of-the-art methods in the few-shot crowd counting.

</details>


### [108] [D-ORCA: Dialogue-Centric Optimization for Robust Audio-Visual Captioning](https://arxiv.org/abs/2602.07960)
*Changli Tang,Tianyi Wang,Fengyun Rao,Jing Lyu,Chao Zhang*

Main category: cs.CV

TL;DR: D-ORCA是一个面向对话的跨模态大语言模型，专门用于鲁棒的视听字幕生成，在说话人识别、语音识别和时间定位方面显著优于现有开源模型。


<details>
  <summary>Details</summary>
Motivation: 视频中的对话是重要信息来源，准确识别谁在何时说了什么对于深度视频理解至关重要。当前开源生态中缺乏大规模、高质量的多方对话视频数据集。

Method: 1) 构建DVD双语数据集（4万训练+2千评估视频）；2) 采用群体相对策略优化，引入三个新颖的奖励函数：说话人归属准确性、全局语音内容准确性、句子级时间边界对齐；3) 首次将语音处理评估指标用作强化学习目标。

Result: D-ORCA在说话人识别、语音识别和时间定位方面大幅超越现有开源模型。仅80亿参数，却在多个通用视听理解基准上与Qwen3-Omni竞争。

Conclusion: D-ORCA通过对话中心的设计、大规模双语数据集和创新的强化学习奖励机制，实现了高质量的视听字幕生成，填补了开源生态的空白。

Abstract: Spoken dialogue is a primary source of information in videos; therefore, accurately identifying who spoke what and when is essential for deep video understanding. We introduce D-ORCA, a \textbf{d}ialogue-centric \textbf{o}mni-modal large language model optimized for \textbf{r}obust audio-visual \textbf{ca}ptioning. We further curate DVD, a large-scale, high-quality bilingual dataset comprising nearly 40,000 multi-party dialogue videos for training and 2000 videos for evaluation in English and Mandarin, addressing a critical gap in the open-source ecosystem. To ensure fine-grained captioning accuracy, we adopt group relative policy optimization with three novel reward functions that assess speaker attribution accuracy, global speech content accuracy, and sentence-level temporal boundary alignment. These rewards are derived from evaluation metrics widely used in speech processing and, to our knowledge, are applied for the first time as reinforcement learning objectives for audio-visual captioning. Extensive experiments demonstrate that D-ORCA substantially outperforms existing open-source models in speaker identification, speech recognition, and temporal grounding. Notably, despite having only 8 billion parameters, D-ORCA achieves performance competitive with Qwen3-Omni across several general-purpose audio-visual understanding benchmarks. Demos are available at \href{https://d-orca-llm.github.io/}{https://d-orca-llm.github.io/}. Our code, data, and checkpoints will be available at \href{https://github.com/WeChatCV/D-ORCA/}{https://github.com/WeChatCV/D-ORCA/}.

</details>


### [109] [EasyTune: Efficient Step-Aware Fine-Tuning for Diffusion-Based Motion Generation](https://arxiv.org/abs/2602.07967)
*Xiaofeng Tan,Wanjiang Weng,Haodong Lei,Hongsong Wang*

Main category: cs.CV

TL;DR: EasyTune提出了一种针对扩散模型的高效对齐方法，通过分步微调解决现有方法在优化效率和内存消耗上的问题，并引入自优化偏好学习机制来缓解偏好数据稀缺问题。


<details>
  <summary>Details</summary>
Motivation: 当前基于可微分奖励的扩散模型对齐方法存在两个主要问题：1）优化效率低且粒度粗糙；2）内存消耗高。这些问题的根源在于去噪轨迹中不同步骤之间的递归依赖关系。

Method: 1）提出EasyTune方法，在去噪过程的每个步骤单独微调扩散模型，解耦递归依赖，实现密集细粒度且内存高效的优化；2）引入自优化偏好学习机制，动态识别偏好对并进行偏好学习，解决偏好运动数据稀缺问题。

Result: 实验表明，EasyTune在MM-Dist对齐指标上比DRaFT-50提升8.2%，同时仅需其31.16%的额外内存开销，并实现7.3倍的训练加速。

Conclusion: 通过理论分析和实证验证，识别出扩散模型对齐问题的核心是递归依赖，提出的EasyTune方法有效解决了现有方法的局限性，实现了高效、内存友好的模型对齐。

Abstract: In recent years, motion generative models have undergone significant advancement, yet pose challenges in aligning with downstream objectives. Recent studies have shown that using differentiable rewards to directly align the preference of diffusion models yields promising results. However, these methods suffer from (1) inefficient and coarse-grained optimization with (2) high memory consumption. In this work, we first theoretically and empirically identify the key reason of these limitations: the recursive dependence between different steps in the denoising trajectory. Inspired by this insight, we propose EasyTune, which fine-tunes diffusion at each denoising step rather than over the entire trajectory. This decouples the recursive dependence, allowing us to perform (1) a dense and fine-grained, and (2) memory-efficient optimization. Furthermore, the scarcity of preference motion pairs restricts the availability of motion reward model training. To this end, we further introduce a Self-refinement Preference Learning (SPL) mechanism that dynamically identifies preference pairs and conducts preference learning. Extensive experiments demonstrate that EasyTune outperforms DRaFT-50 by 8.2% in alignment (MM-Dist) improvement while requiring only 31.16% of its additional memory overhead and achieving a 7.3x training speedup. The project page is available at this link {https://xiaofeng-tan.github.io/projects/EasyTune/index.html}.

</details>


### [110] [FSP-Diff: Full-Spectrum Prior-Enhanced DualDomain Latent Diffusion for Ultra-Low-Dose Spectral CT Reconstruction](https://arxiv.org/abs/2602.07979)
*Peng Peng,Xinrui Zhang,Junlin Wang,Lei Li,Shaoyu Wang,Qiegen Liu*

Main category: cs.CV

TL;DR: 提出FSP-Diff框架，通过全光谱先验增强的双域潜在扩散方法，解决超低剂量能谱CT重建中的噪声和伪影问题


<details>
  <summary>Details</summary>
Motivation: 超低剂量条件下能谱CT的能量特定投影信噪比严重下降，导致重建图像出现严重伪影和结构细节丢失，需要有效解决方案

Method: 提出全光谱先验增强的双域潜在扩散框架，包含三个核心策略：互补特征构建（整合直接重建和投影域去噪结果）、全光谱先验集成（融合多能量投影为高信噪比全光谱图像）、高效潜在扩散合成（在紧凑潜在空间中进行特征融合）

Result: 在模拟和真实数据集上的大量实验表明，FSP-Diff在图像质量和计算效率方面显著优于现有最先进方法

Conclusion: FSP-Diff框架在保持细粒度细节恢复的同时实现加速重建，展示了在临床可行超低剂量能谱CT成像方面的潜力

Abstract: Spectral computed tomography (CT) with photon-counting detectors holds immense potential for material discrimination and tissue characterization. However, under ultra-low-dose conditions, the sharply degraded signal-to-noise ratio (SNR) in energy-specific projections poses a significant challenge, leading to severe artifacts and loss of structural details in reconstructed images. To address this, we propose FSP-Diff, a full-spectrum prior-enhanced dual-domain latent diffusion framework for ultra-low-dose spectral CT reconstruction. Our framework integrates three core strategies: 1) Complementary Feature Construction: We integrate direct image reconstructions with projection-domain denoised results. While the former preserves latent textural nuances amidst heavy noise, the latter provides a stable structural scaffold to balance detail fidelity and noise suppression. 2) Full-Spectrum Prior Integration: By fusing multi-energy projections into a high-SNR full-spectrum image, we establish a unified structural reference that guides the reconstruction across all energy bins. 3) Efficient Latent Diffusion Synthesis: To alleviate the high computational burden of high-dimensional spectral data, multi-path features are embedded into a compact latent space. This allows the diffusion process to facilitate interactive feature fusion in a lower-dimensional manifold, achieving accelerated reconstruction while maintaining fine-grained detail restoration. Extensive experiments on simulated and real-world datasets demonstrate that FSP-Diff significantly outperforms state-of-the-art methods in both image quality and computational efficiency, underscoring its potential for clinically viable ultra-low-dose spectral CT imaging.

</details>


### [111] [Continuity-driven Synergistic Diffusion with Neural Priors for Ultra-Sparse-View CBCT Reconstruction](https://arxiv.org/abs/2602.07980)
*Junlin Wang,Jiancheng Fang,Peng Peng,Shaoyu Wang,Qiegen Liu*

Main category: cs.CV

TL;DR: 提出CSDN方法用于超稀疏角度CBCT重建，通过神经先验编码连续3D衰减表示，结合协同扩散策略恢复角度连续性和切片一致性，显著提升图像质量。


<details>
  <summary>Details</summary>
Motivation: CBCT临床应用面临辐射剂量与图像质量的权衡问题。超稀疏角度采样虽能降低剂量，但会导致严重的欠采样伪影和切片间不一致性，影响诊断可靠性。现有重建方法难以平衡角度连续性与空间细节保真度。

Method: 提出CSDN方法：1) 引入神经先验作为结构基础，编码连续3D衰减表示，从超稀疏测量合成物理一致的密集投影；2) 基于神经先验初始化，开发协同扩散策略，包含两个协作优化路径：正弦图细化扩散(Sino-RD)恢复角度连续性，数字放射摄影细化扩散(DR-RD)从投影图像角度强制切片一致性；3) 通过双投影重建融合(DPRF)模块自适应融合两个扩散路径输出，实现连贯体积重建。

Result: 大量实验表明，CSDN在超稀疏角度条件下能有效抑制伪影并恢复精细纹理，性能优于现有最先进技术。

Conclusion: CSDN方法通过神经先验和协同扩散策略，成功解决了超稀疏角度CBCT重建中的角度连续性和切片一致性问题，为低剂量高质量CBCT成像提供了有效解决方案。

Abstract: The clinical application of cone-beam computed tomography (CBCT) is constrained by the inherent trade-off between radiation exposure and image quality. Ultra-sparse angular sampling, employed to reduce dose, introduces severe undersampling artifacts and inter-slice inconsistencies, compromising diagnostic reliability. Existing reconstruction methods often struggle to balance angular continuity with spatial detail fidelity. To address these challenges, we propose a Continuity-driven Synergistic Diffusion with Neural priors (CSDN) for ultra-sparse-view CBCT reconstruction. Neural priors are introduced as a structural foundation to encode a continuous threedimensional attenuation representation, enabling the synthesis of physically consistent dense projections from ultra-sparse measurements. Building upon this neural-prior-based initialization, a synergistic diffusion strategy is developed, consisting of two collaborative refinement paths: a Sinogram Refinement Diffusion (Sino-RD) process that restores angular continuity and a Digital Radiography Refinement Diffusion (DR-RD) process that enforces inter-slice consistency from the projection image perspective. The outputs of the two diffusion paths are adaptively fused by the Dual-Projection Reconstruction Fusion (DPRF) module to achieve coherent volumetric reconstruction. Extensive experiments demonstrate that the proposed CSDN effectively suppresses artifacts and recovers fine textures under ultra-sparse-view conditions, outperforming existing state-of-the-art techniques.

</details>


### [112] [Deepfake Synthesis vs. Detection: An Uneven Contest](https://arxiv.org/abs/2602.07986)
*Md. Tarek Hasan,Sanjay Saha,Shaojing Fan,Swakkhar Shatabda,Terence Sim*

Main category: cs.CV

TL;DR: 最新深度伪造检测模型在面对现代合成技术生成的深度伪造内容时表现不佳，包括人类评估者也难以识别最高质量的深度伪造，凸显检测技术发展滞后于生成技术进步的严峻现实。


<details>
  <summary>Details</summary>
Motivation: 随着扩散模型、NeRF等先进生成技术的快速发展，深度伪造的逼真度和可及性大幅提升，而现有检测方法是否能有效应对这些新型合成技术尚不明确，需要系统性评估。

Method: 采用综合实证分析方法，对最先进的深度伪造检测技术进行全面评估，包括与前沿合成方法进行对比的人类评估实验，通过大量实验验证检测模型的性能。

Result: 研究发现许多最先进的检测模型在面对现代合成技术生成的深度伪造时表现显著下降，人类参与者在面对最高质量深度伪造时也难以有效识别，检测效果令人担忧。

Conclusion: 当前检测方法与新一代深度伪造生成技术的成熟度之间存在严重差距，迫切需要持续改进检测模型以跟上快速发展的生成技术，这是该研究领域的关键挑战。

Abstract: The rapid advancement of deepfake technology has significantly elevated the realism and accessibility of synthetic media. Emerging techniques, such as diffusion-based models and Neural Radiance Fields (NeRF), alongside enhancements in traditional Generative Adversarial Networks (GANs), have contributed to the sophisticated generation of deepfake videos. Concurrently, deepfake detection methods have seen notable progress, driven by innovations in Transformer architectures, contrastive learning, and other machine learning approaches. In this study, we conduct a comprehensive empirical analysis of state-of-the-art deepfake detection techniques, including human evaluation experiments against cutting-edge synthesis methods. Our findings highlight a concerning trend: many state-of-the-art detection models exhibit markedly poor performance when challenged with deepfakes produced by modern synthesis techniques, including poor performance by human participants against the best quality deepfakes. Through extensive experimentation, we provide evidence that underscores the urgent need for continued refinement of detection models to keep pace with the evolving capabilities of deepfake generation technologies. This research emphasizes the critical gap between current detection methodologies and the sophistication of new generation techniques, calling for intensified efforts in this crucial area of study.

</details>


### [113] [MCIE: Multimodal LLM-Driven Complex Instruction Image Editing with Spatial Guidance](https://arxiv.org/abs/2602.07993)
*Xuehai Bai,Xiaoling Gu,Akide Liu,Hangjie Yuan,YiFan Zhang,Jack Ma*

Main category: cs.CV

TL;DR: MCIE-E1是一种基于多模态大语言模型的复杂指令图像编辑方法，通过空间感知交叉注意力和背景一致性交叉注意力模块，显著提升了指令遵循能力和背景一致性，在复杂指令编辑任务上比现有方法有23.96%的改进。


<details>
  <summary>Details</summary>
Motivation: 现有基于指令的图像编辑方法局限于简单操作，难以处理现实应用中需要的复杂组合指令。作者识别出当前模型的两个关键挑战：指令遵循不足和背景不一致。

Method: 提出MCIE-E1方法，包含两个关键模块：1) 空间感知交叉注意力模块，通过去噪过程中的空间引导显式对齐语义指令与空间区域；2) 背景一致性交叉注意力模块，保留未编辑区域特征以维持背景一致性。同时构建专门的数据管道，结合强大的MLLM进行细粒度自动筛选和人工验证。

Result: 在提出的CIE-Bench基准测试中，MCIE-E1在定量和定性评估中均优于先前最先进方法，指令遵循能力提升了23.96%。

Conclusion: MCIE-E1通过创新的架构设计、专门的数据管道和全面的评估协议，有效解决了复杂指令图像编辑中的关键挑战，为现实应用提供了更强大的图像编辑能力。

Abstract: Recent advances in instruction-based image editing have shown remarkable progress. However, existing methods remain limited to relatively simple editing operations, hindering real-world applications that require complex and compositional instructions. In this work, we address these limitations from the perspectives of architectural design, data, and evaluation protocols. Specifically, we identify two key challenges in current models: insufficient instruction compliance and background inconsistency. To this end, we propose MCIE-E1, a Multimodal Large Language Model-Driven Complex Instruction Image Editing method that integrates two key modules: a spatial-aware cross-attention module and a background-consistent cross-attention module. The former enhances instruction-following capability by explicitly aligning semantic instructions with spatial regions through spatial guidance during the denoising process, while the latter preserves features in unedited regions to maintain background consistency. To enable effective training, we construct a dedicated data pipeline to mitigate the scarcity of complex instruction-based image editing datasets, combining fine-grained automatic filtering via a powerful MLLM with rigorous human validation. Finally, to comprehensively evaluate complex instruction-based image editing, we introduce CIE-Bench, a new benchmark with two new evaluation metrics. Experimental results on CIE-Bench demonstrate that MCIE-E1 consistently outperforms previous state-of-the-art methods in both quantitative and qualitative assessments, achieving a 23.96% improvement in instruction compliance.

</details>


### [114] [ForecastOcc: Vision-based Semantic Occupancy Forecasting](https://arxiv.org/abs/2602.08006)
*Riya Mohan,Juana Valeria Hurtado,Rohit Mohan,Abhinav Valada*

Main category: cs.CV

TL;DR: ForecastOcc：首个从相机图像直接预测未来语义占据的视觉框架，无需外部地图，在多个数据集上超越基线方法


<details>
  <summary>Details</summary>
Motivation: 现有视觉占据预测方法主要关注运动类别（静态/动态），缺乏语义信息；而现有语义占据预测方法依赖单独网络获取历史占据预测，导致误差累积且无法直接从图像学习时空特征

Method: 提出首个联合预测未来占据状态和语义类别的框架，包含时间交叉注意力预测模块、2D到3D视图变换器、3D编码器和语义占据头，直接从历史相机图像生成多时间步的体素级预测

Result: 在Occ3D-nuScenes（多视角）和SemanticKITTI（单目）数据集上建立首个基准，提出的方法在两种设置下均一致超越基线，生成语义丰富、未来感知的预测

Conclusion: ForecastOcc框架能够直接从图像预测未来语义占据，无需外部地图，为自动驾驶提供了捕捉场景动态和语义的关键能力，在多个数据集上验证了其有效性

Abstract: Autonomous driving requires forecasting both geometry and semantics over time to effectively reason about future environment states. Existing vision-based occupancy forecasting methods focus on motion-related categories such as static and dynamic objects, while semantic information remains largely absent. Recent semantic occupancy forecasting approaches address this gap but rely on past occupancy predictions obtained from separate networks. This makes current methods sensitive to error accumulation and prevents learning spatio-temporal features directly from images. In this work, we present ForecastOcc, the first framework for vision-based semantic occupancy forecasting that jointly predicts future occupancy states and semantic categories. Our framework yields semantic occupancy forecasts for multiple horizons directly from past camera images, without relying on externally estimated maps. We evaluate ForecastOcc in two complementary settings: multi-view forecasting on the Occ3D-nuScenes dataset and monocular forecasting on SemanticKITTI, where we establish the first benchmark for this task. We introduce the first baselines by adapting two 2D forecasting modules within our framework. Importantly, we propose a novel architecture that incorporates a temporal cross-attention forecasting module, a 2D-to-3D view transformer, a 3D encoder for occupancy prediction, and a semantic occupancy head for voxel-level forecasts across multiple horizons. Extensive experiments on both datasets show that ForecastOcc consistently outperforms baselines, yielding semantically rich, future-aware predictions that capture scene dynamics and semantics critical for autonomous driving.

</details>


### [115] [Improved cystic hygroma detection from prenatal imaging using ultrasound-specific self-supervised representation learning](https://arxiv.org/abs/2512.22730)
*Youssef Megahed,Robin Ducharme,Inok Lee,Inbal Willner,Adrian D. C. Chan,Mark Walker,Steven Hawken*

Main category: cs.CV

TL;DR: 使用自监督预训练的超声基础模型USF-MAE，在囊性水瘤检测任务上显著优于传统DenseNet-169基线模型，实现了96%的准确率和98%的ROC-AUC。


<details>
  <summary>Details</summary>
Motivation: 囊性水瘤是高风险产前超声发现，与染色体异常、结构畸形和不良妊娠结局相关。自动检测可提高可重复性并支持大规模早期筛查，但监督深度学习方法受限于小规模标注数据集。

Method: 使用在37万张未标注超声图像上预训练的USF-MAE（超声自监督基础模型），针对囊性水瘤与正常对照进行微调。采用与DenseNet-169基线相同的预处理流程和4折交叉验证协议，使用Score-CAM进行模型可解释性分析。

Result: USF-MAE在所有评估指标上均优于DenseNet-169基线：准确率0.96 vs 0.93，敏感性0.94 vs 0.92，特异性0.98 vs 0.94，ROC-AUC 0.98 vs 0.94。Wilcoxon符号秩检验显示性能提升具有统计学显著性(p=0.0057)。Score-CAM可视化显示模型关注胎儿颈部相关区域。

Conclusion: 超声特定的自监督预训练能够显著提升囊性水瘤检测的准确性和鲁棒性，为基于深度学习的产前超声筛查提供了有效的解决方案，特别是在标注数据有限的情况下。

Abstract: Cystic hygroma is a high-risk prenatal ultrasound finding that portends high rates of chromosomal abnormalities, structural malformations, and adverse pregnancy outcomes. Automated detection can increase reproducibility and support scalable early screening programs, but supervised deep learning methods are limited by small labelled datasets. This study assesses whether ultrasound-specific self-supervised pretraining can facilitate accurate, robust deep learning detection of cystic hygroma in first-trimester ultrasound images. We fine-tuned the Ultrasound Self-Supervised Foundation Model with Masked Autoencoding (USF-MAE), pretrained on over 370,000 unlabelled ultrasound images, for binary classification of normal controls and cystic hygroma cases used in this study. Performance was evaluated on the same curated ultrasound dataset, preprocessing pipeline, and 4-fold cross-validation protocol as for the DenseNet-169 baseline, using accuracy, sensitivity, specificity, and the area under the receiver operating characteristic curve (ROC-AUC). Model interpretability was analyzed qualitatively using Score-CAM visualizations. USF-MAE outperformed the DenseNet-169 baseline on all evaluation metrics. The proposed model yielded a mean accuracy of 0.96, sensitivity of 0.94, specificity of 0.98, and ROC-AUC of 0.98 compared to 0.93, 0.92, 0.94, and 0.94 for the DenseNet-169 baseline, respectively. Qualitative Score-CAM visualizations of model predictions demonstrated clinical relevance by highlighting expected regions in the fetal neck for both positive and negative cases. Paired statistical analysis using a Wilcoxon signed-rank test confirmed that performance improvements achieved by USF-MAE were statistically significant (p = 0.0057).

</details>


### [116] [FlashVID: Efficient Video Large Language Models via Training-free Tree-based Spatiotemporal Token Merging](https://arxiv.org/abs/2602.08024)
*Ziyang Fan,Keyu Chen,Ruilong Xing,Yulin Li,Li Jiang,Zhuotao Tian*

Main category: cs.CV

TL;DR: FlashVID是一个无需训练的视频大语言模型推理加速框架，通过注意力与多样性令牌选择和树状时空令牌合并技术，在保留99.1%性能的同时减少90%视觉令牌，实现10倍视频帧输入扩展。


<details>
  <summary>Details</summary>
Motivation: 现有视频大语言模型需要处理大量视觉令牌，计算效率低下。现有加速框架通常独立压缩空间和时间冗余，忽略了时空关系，导致次优压缩效果。视频的动态特性使得视觉特征在时空位置、尺度、方向等属性上随时间变化。

Method: FlashVID采用两种核心技术：1) 注意力与多样性令牌选择(ADTS)选择最具代表性的令牌进行基础视频表示；2) 树状时空令牌合并(TSTM)进行细粒度时空冗余消除。这是一个无需训练、即插即用的推理加速框架。

Result: 在三个代表性VLLM和五个视频理解基准测试上的实验表明，仅保留10%视觉令牌时，FlashVID能保留LLaVA-OneVision 99.1%的性能。使Qwen2.5-VL的视频帧输入增加10倍，在相同计算预算下相对提升8.6%。

Conclusion: FlashVID是一个有效的训练免费推理加速框架，通过考虑时空关系实现更优的令牌压缩，显著提升视频大语言模型的计算效率，支持长视频帧处理扩展。

Abstract: Although Video Large Language Models (VLLMs) have shown remarkable capabilities in video understanding, they are required to process high volumes of visual tokens, causing significant computational inefficiency. Existing VLLMs acceleration frameworks usually compress spatial and temporal redundancy independently, which overlooks the spatiotemporal relationships, thereby leading to suboptimal spatiotemporal compression. The highly correlated visual features are likely to change in spatial position, scale, orientation, and other attributes over time due to the dynamic nature of video. Building on this insight, we introduce FlashVID, a training-free inference acceleration framework for VLLMs. Specifically, FlashVID utilizes Attention and Diversity-based Token Selection (ADTS) to select the most representative tokens for basic video representation, then applies Tree-based Spatiotemporal Token Merging (TSTM) for fine-grained spatiotemporal redundancy elimination. Extensive experiments conducted on three representative VLLMs across five video understanding benchmarks demonstrate the effectiveness and generalization of our method. Notably, by retaining only 10% of visual tokens, FlashVID preserves 99.1% of the performance of LLaVA-OneVision. Consequently, FlashVID can serve as a training-free and plug-and-play module for extending long video frames, which enables a 10x increase in video frame input to Qwen2.5-VL, resulting in a relative improvement of 8.6% within the same computational budget. Code is available at https://github.com/Fanziyang-v/FlashVID.

</details>


### [117] [PhysDrape: Learning Explicit Forces and Collision Constraints for Physically Realistic Garment Draping](https://arxiv.org/abs/2602.08020)
*Minghai Chen,Mingyuan Liu,Yuxiang Huan*

Main category: cs.CV

TL;DR: PhysDrape：一种混合神经物理求解器，通过显式力和约束实现物理真实的服装悬垂，解决了现有方法在几何可行性和物理合理性之间的权衡问题。


<details>
  <summary>Details</summary>
Motivation: 基于深度学习的服装悬垂方法已成为传统物理模拟的有前景替代方案，但鲁棒的碰撞处理仍是关键瓶颈。现有方法通过软惩罚强制物理有效性，导致几何可行性与物理合理性之间的内在权衡：惩罚碰撞会扭曲网格结构，而保持形状又会导致穿透。

Method: 提出PhysDrape混合神经物理求解器，将神经推理与显式几何求解器集成到完全可微的流程中。使用物理信息图神经网络预测残差位移，并集成可微两阶段求解器：1) 可学习力求解器迭代解决来自StVK模型的不平衡力以确保准静态平衡；2) 可微投影严格强制执行与身体表面的碰撞约束。

Result: PhysDrape实现了最先进的性能，确保可忽略的穿透，与现有基线相比显著降低应变能，在实时应用中实现卓越的物理保真度和鲁棒性。

Conclusion: PhysDrape通过显式约束保证物理有效性，同时支持端到端学习优化网络以实现物理一致的预测，解决了深度学习服装悬垂中碰撞处理的根本问题。

Abstract: Deep learning-based garment draping has emerged as a promising alternative to traditional Physics-Based Simulation (PBS), yet robust collision handling remains a critical bottleneck. Most existing methods enforce physical validity through soft penalties, creating an intrinsic trade-off between geometric feasibility and physical plausibility: penalizing collisions often distorts mesh structure, while preserving shape leads to interpenetration. To resolve this conflict, we present PhysDrape, a hybrid neural-physical solver for physically realistic garment draping driven by explicit forces and constraints. Unlike soft-constrained frameworks, PhysDrape integrates neural inference with explicit geometric solvers in a fully differentiable pipeline. Specifically, we propose a Physics-Informed Graph Neural Network conditioned on a physics-enriched graph -- encoding material parameters and body proximity -- to predict residual displacements. Crucially, we integrate a differentiable two-stage solver: first, a learnable Force Solver iteratively resolves unbalanced forces derived from the Saint Venant-Kirchhoff (StVK) model to ensure quasi-static equilibrium; second, a Differentiable Projection strictly enforces collision constraints against the body surface. This differentiable design guarantees physical validity through explicit constraints, while enabling end-to-end learning to optimize the network for physically consistent predictions. Extensive experiments demonstrate that PhysDrape achieves state-of-the-art performance, ensuring negligible interpenetration with significantly lower strain energy compared to existing baselines, achieving superior physical fidelity and robustness in real-time.

</details>


### [118] [When and How Much to Imagine: Adaptive Test-Time Scaling with World Models for Visual Spatial Reasoning](https://arxiv.org/abs/2602.08236)
*Shoubin Yu,Yue Zhang,Zun Wang,Jaehong Yoon,Huaxiu Yao,Mingyu Ding,Mohit Bansal*

Main category: cs.CV

TL;DR: 论文提出AVIC框架，通过选择性调用视觉想象来优化空间推理，分析何时需要想象、多少想象有益、何时想象有害，实现更高效可靠的空间推理。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型在视觉空间推理中，当正确答案依赖于未见过或替代视角时表现不可靠。现有方法通过世界模型增强视觉想象，但何时需要想象、多少想象有益、何时想象有害等问题尚未明确。不加区分的想象会增加计算成本甚至引入误导证据降低性能。

Method: 提出AVIC自适应测试时框架，使用世界模型明确推理当前视觉证据是否足够，然后选择性地调用和扩展视觉想象。框架在空间推理基准（SAT、MMSI）和具身导航基准（R2R）上进行评估。

Result: 研究揭示了想象在空间推理中关键、边缘或有害的明确场景。选择性控制策略能够匹配或优于固定想象策略，同时显著减少世界模型调用和语言标记数量。

Conclusion: 分析并控制测试时视觉想象对于高效可靠的空间推理至关重要。AVIC框架通过自适应选择想象时机和规模，在保持性能的同时显著提升效率。

Abstract: Despite rapid progress in Multimodal Large Language Models (MLLMs), visual spatial reasoning remains unreliable when correct answers depend on how a scene would appear under unseen or alternative viewpoints. Recent work addresses this by augmenting reasoning with world models for visual imagination, but questions such as when imagination is actually necessary, how much of it is beneficial, and when it becomes harmful, remain poorly understood. In practice, indiscriminate imagination can increase computation and even degrade performance by introducing misleading evidence. In this work, we present an in-depth analysis of test-time visual imagination as a controllable resource for spatial reasoning. We study when static visual evidence is sufficient, when imagination improves reasoning, and how excessive or unnecessary imagination affects accuracy and efficiency. To support this analysis, we introduce AVIC, an adaptive test-time framework with world models that explicitly reasons about the sufficiency of current visual evidence before selectively invoking and scaling visual imagination. Across spatial reasoning benchmarks (SAT, MMSI) and an embodied navigation benchmark (R2R), our results reveal clear scenarios where imagination is critical, marginal, or detrimental, and show that selective control can match or outperform fixed imagination strategies with substantially fewer world-model calls and language tokens. Overall, our findings highlight the importance of analyzing and controlling test-time imagination for efficient and reliable spatial reasoning.

</details>


### [119] [MIND: Benchmarking Memory Consistency and Action Control in World Models](https://arxiv.org/abs/2602.08025)
*Yixuan Ye,Xuanyu Lu,Yuxin Jiang,Yuchao Gu,Rui Zhao,Qiwei Liang,Jiachun Pan,Fengda Zhang,Weijia Wu,Alex Jinpeng Wang*

Main category: cs.CV

TL;DR: MIND是首个开放域闭环重访基准，用于评估世界模型的记忆一致性和动作控制能力，包含250个高质量视频和多样化场景，并提出了MIND-World基线方法。


<details>
  <summary>Details</summary>
Motivation: 目前缺乏统一的基准来评估世界模型在动态视觉环境中的核心能力，包括理解、记忆和预测能力，这限制了世界模型的系统评估和比较。

Method: 构建了包含250个1080p/24FPS视频的MIND基准，包括第一人称和第三人称视角，设计高效评估框架测量记忆一致性和动作控制两个核心能力，并引入MIND-World作为基线方法。

Result: 实验验证了MIND基准的完整性，揭示了当前世界模型的关键挑战：难以保持长期记忆一致性，以及在不同动作空间之间的泛化能力有限。

Conclusion: MIND为世界模型评估提供了首个开放域闭环重访基准，有助于推动世界模型在记忆一致性和动作控制方面的研究，并为未来性能比较提供了标准化框架。

Abstract: World models aim to understand, remember, and predict dynamic visual environments, yet a unified benchmark for evaluating their fundamental abilities remains lacking. To address this gap, we introduce MIND, the first open-domain closed-loop revisited benchmark for evaluating Memory consIstency and action coNtrol in worlD models. MIND contains 250 high-quality videos at 1080p and 24 FPS, including 100 (first-person) + 100 (third-person) video clips under a shared action space and 25 + 25 clips across varied action spaces covering eight diverse scenes. We design an efficient evaluation framework to measure two core abilities: memory consistency and action control, capturing temporal stability and contextual coherence across viewpoints. Furthermore, we design various action spaces, including different character movement speeds and camera rotation angles, to evaluate the action generalization capability across different action spaces under shared scenes. To facilitate future performance benchmarking on MIND, we introduce MIND-World, a novel interactive Video-to-World baseline. Extensive experiments demonstrate the completeness of MIND and reveal key challenges in current world models, including the difficulty of maintaining long-term memory consistency and generalizing across action spaces. Project page: https://csu-jpg.github.io/MIND.github.io/

</details>


### [120] [Enhanced Mixture 3D CGAN for Completion and Generation of 3D Objects](https://arxiv.org/abs/2602.08046)
*Yahia Hamdi,Nicolas Andrialovanirina,Kélig Mahé,Emilie Poisson Caillault*

Main category: cs.CV

TL;DR: 提出MoE-DCGAN架构，结合深度3D卷积GAN与专家混合框架，用于高质量3D模型生成和缺损物体重建，通过动态容量约束机制提升性能与效率。


<details>
  <summary>Details</summary>
Motivation: 传统GAN在3D物体生成和补全任务中面临挑战：难以捕捉复杂多样的数据分布，特别是在输入不完整或缺失区域较大的情况下；计算需求高，对异构和结构复杂数据建模困难，限制了实际应用。

Method: 集成深度3D卷积GAN与专家混合框架，包含多个专门捕捉数据集中不同模态的生成器；引入无辅助损失的动态容量约束机制，指导分类生成器的选择，平衡专业化、训练稳定性和计算效率。

Result: 评估了模型在不同大小缺失区域的形状生成和补全能力，与最先进方法比较；定量和定性结果均证实MoE-DCGAN在处理复杂3D数据方面的有效性。

Conclusion: 提出的MoE-DCGAN架构成功解决了3D物体生成和补全中的挑战，通过专家混合框架和动态容量约束机制实现了高质量3D模型生成和缺损物体重建，在性能和效率方面表现优异。

Abstract: The generation and completion of 3D objects represent a transformative challenge in computer vision. Generative Adversarial Networks (GANs) have recently demonstrated strong potential in synthesizing realistic visual data. However, they often struggle to capture complex and diverse data distributions, particularly in scenarios involving incomplete inputs or significant missing regions. These challenges arise mainly from the high computational requirements and the difficulty of modeling heterogeneous and structurally intricate data, which restrict their applicability in real-world settings. Mixture of Experts (MoE) models have emerged as a promising solution to these limitations. By dynamically selecting and activating the most relevant expert sub-networks for a given input, MoEs improve both performance and efficiency. In this paper, we investigate the integration of Deep 3D Convolutional GANs (CGANs) with a MoE framework to generate high-quality 3D models and reconstruct incomplete or damaged objects. The proposed architecture incorporates multiple generators, each specialized to capture distinct modalities within the dataset. Furthermore, an auxiliary loss-free dynamic capacity constraint (DCC) mechanism is introduced to guide the selection of categorical generators, ensuring a balance between specialization, training stability, and computational efficiency, which is critical for 3D voxel processing. We evaluated the model's ability to generate and complete shapes with missing regions of varying sizes and compared its performance with state-of-the-art approaches. Both quantitative and qualitative results confirm the effectiveness of the proposed MoE-DCGAN in handling complex 3D data.

</details>


### [121] [Learning Self-Correction in Vision-Language Models via Rollout Augmentation](https://arxiv.org/abs/2602.08503)
*Yi Ding,Ziliang Qiu,Bolian Li,Ruqi Zhang*

Main category: cs.CV

TL;DR: Octopus框架通过重组现有rollouts合成密集的自校正示例，解决RL方法中自校正行为稀疏的问题，实现了高效稳定的强化学习优化。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习方法在视觉语言模型中学习自校正行为时面临挑战，因为有效的自校正行为很少出现，导致学习信号极其稀疏。

Method: 提出correction-specific rollouts (Octopus)框架，通过重组现有rollouts合成密集的自校正示例；引入response-masking策略将自校正与直接推理解耦；构建Octopus-8B模型。

Result: 在7个基准测试中，Octopus-8B在开源VLM中达到最先进性能，比最佳RLVR基线提升1.0分，同时每个训练步骤仅需0.72倍时间。

Conclusion: Octopus框架有效解决了自校正学习中的稀疏性问题，通过rollout重用和平衡监督实现了高效稳定的强化学习优化，为视觉语言模型的复杂推理问题提供了可控的自校正能力。

Abstract: Self-correction is essential for solving complex reasoning problems in vision-language models (VLMs). However, existing reinforcement learning (RL) methods struggle to learn it, as effective self-correction behaviors emerge only rarely, making learning signals extremely sparse. To address this challenge, we propose correction-specific rollouts (Octopus), an RL rollout augmentation framework that synthesizes dense self-correction examples by recombining existing rollouts. This augmentation simultaneously improves sample efficiency due to rollout reuse and stabilizes RL optimization through balanced supervision. Furthermore, we introduce a response-masking strategy that decouples self-correction from direct reasoning, avoiding signal conflicts and enabling both behaviors to be learned effectively. Building on this, we introduce Octopus-8B, a reasoning VLM with controllable self-correction capability. Across 7 benchmarks, it achieves SoTA performance among open-source VLMs, outperforming the best RLVR baseline by 1.0 score while requiring only $0.72\times$ training time per step.

</details>


### [122] [Vanilla Group Equivariant Vision Transformer: Simple and Effective](https://arxiv.org/abs/2602.08047)
*Jiahong Fu,Qi Xie,Deyu Meng,Zongben Xu*

Main category: cs.CV

TL;DR: 提出一种系统化构建等变Vision Transformer的框架，通过使ViT关键组件（包括patch embedding、self-attention、位置编码和采样模块）等变化，实现理论保证的等变性，提升性能和数据效率。


<details>
  <summary>Details</summary>
Motivation: 现有等变ViT难以平衡性能与等变性，主要因为难以在ViT的多样化模块中实现整体等变修改，特别是在协调Self-Attention机制与Patch Embedding方面存在挑战。

Method: 提出一个简单框架，系统化地使ViT关键组件等变化，包括patch embedding、self-attention、位置编码和Down/Up-Sampling，构建具有理论保证等变性的ViT架构，可作为即插即用替代方案，并可扩展到Swin Transformers。

Result: 广泛的实验表明，所提出的等变ViT在广泛的视觉任务中持续提升性能和数据效率。

Conclusion: 该框架提供了一种理论可靠且实际通用的方法，通过系统化等变化ViT组件来构建等变ViT，解决了现有方法在平衡性能与等变性方面的挑战。

Abstract: Incorporating symmetry priors as inductive biases to design equivariant Vision Transformers (ViTs) has emerged as a promising avenue for enhancing their performance. However, existing equivariant ViTs often struggle to balance performance with equivariance, primarily due to the challenge of achieving holistic equivariant modifications across the diverse modules in ViTs-particularly in harmonizing the Self-Attention mechanism with Patch Embedding. To address this, we propose a straightforward framework that systematically renders key ViT components, including patch embedding, self-attention, positional encodings, and Down/Up-Sampling, equivariant, thereby constructing ViTs with guaranteed equivariance. The resulting architecture serves as a plug-and-play replacement that is both theoretically grounded and practically versatile, scaling seamlessly even to Swin Transformers. Extensive experiments demonstrate that our equivariant ViTs consistently improve performance and data efficiency across a wide spectrum of vision tasks.

</details>


### [123] [Weak to Strong: VLM-Based Pseudo-Labeling as a Weakly Supervised Training Strategy in Multimodal Video-based Hidden Emotion Understanding Tasks](https://arxiv.org/abs/2602.08057)
*Yufei Wang,Haixu Liu,Tianxiang Xu,Chuancheng Shi,Hongsheng Xing*

Main category: cs.CV

TL;DR: 提出多模态弱监督框架，用于视频中"隐藏情绪"的自动识别，在iMiGUE网球采访数据集上达到SOTA结果，准确率从0.6提升至0.69。


<details>
  <summary>Details</summary>
Motivation: 解决视频中"隐藏情绪"自动识别的挑战，现有方法在iMiGUE数据集上准确率较低（<0.6），需要更有效的多模态融合和弱监督策略。

Method: 1) YOLO 11x检测裁剪人像，DINOv2提取视觉特征；2) Gemini 2.5 Pro通过CoT+Reflection生成伪标签和推理文本作为弱监督；3) OpenPose提取关键点序列，简化GNN为MLP建模时空关系；4) 超长序列Transformer编码图像和关键点序列，与BERT编码的文本特征拼接；5) 各模态先单独预训练，再联合微调，伪标签样本融入训练集。

Result: 在严重类别不平衡情况下，准确率从先前工作的0.6以下提升至0.69以上，建立新的公开基准；验证了"MLP化"的关键点骨干网络可以匹配甚至超越基于GCN的方法。

Conclusion: 提出的多模态弱监督框架有效提升了隐藏情绪识别的性能，证明了简化MLP骨干在关键点建模中的有效性，以及大语言模型生成伪标签的弱监督策略的可行性。

Abstract: To tackle the automatic recognition of "concealed emotions" in videos, this paper proposes a multimodal weak-supervision framework and achieves state-of-the-art results on the iMiGUE tennis-interview dataset. First, YOLO 11x detects and crops human portraits frame-by-frame, and DINOv2-Base extracts visual features from the cropped regions. Next, by integrating Chain-of-Thought and Reflection prompting (CoT + Reflection), Gemini 2.5 Pro automatically generates pseudo-labels and reasoning texts that serve as weak supervision for downstream models. Subsequently, OpenPose produces 137-dimensional key-point sequences, augmented with inter-frame offset features; the usual graph neural network backbone is simplified to an MLP to efficiently model the spatiotemporal relationships of the three key-point streams. An ultra-long-sequence Transformer independently encodes both the image and key-point sequences, and their representations are concatenated with BERT-encoded interview transcripts. Each modality is first pre-trained in isolation, then fine-tuned jointly, with pseudo-labeled samples merged into the training set for further gains. Experiments demonstrate that, despite severe class imbalance, the proposed approach lifts accuracy from under 0.6 in prior work to over 0.69, establishing a new public benchmark. The study also validates that an "MLP-ified" key-point backbone can match - or even surpass - GCN-based counterparts in this task.

</details>


### [124] [Picasso: Holistic Scene Reconstruction with Physics-Constrained Sampling](https://arxiv.org/abs/2602.08058)
*Xihang Yu,Rajat Talak,Lorenzo Shaikewitz,Luca Carlone*

Main category: cs.CV

TL;DR: Picasso：一个物理约束的多物体场景重建系统，通过考虑几何、非穿透和物理约束来构建物理上合理的场景重建，并提出了包含接触丰富场景的数据集和物理合理性评估指标。


<details>
  <summary>Details</summary>
Motivation: 在遮挡和测量噪声存在的情况下，几何上准确但物理上不合理的场景重建会导致物体相互穿透或不稳定平衡等问题，这使得难以使用数字孪生预测场景的动态行为，而这对基于仿真的接触丰富行为的规划和控制至关重要。

Method: 提出了Picasso物理约束重建管道，通过快速拒绝采样方法考虑多物体交互，利用推断的物体接触图来指导采样，同时考虑几何、非穿透和物理约束。

Result: 在新建的Picasso数据集和YCB-V数据集上进行了广泛评估，结果显示Picasso大幅优于现有技术，同时提供既物理合理又更符合人类直觉的重建结果。

Conclusion: 物体姿态和形状估计需要整体考虑场景而非孤立处理单个物体，Picasso通过物理约束重建实现了物理上合理的多物体场景重建，为基于仿真的规划和控制提供了更好的数字孪生基础。

Abstract: In the presence of occlusions and measurement noise, geometrically accurate scene reconstructions -- which fit the sensor data -- can still be physically incorrect. For instance, when estimating the poses and shapes of objects in the scene and importing the resulting estimates into a simulator, small errors might translate to implausible configurations including object interpenetration or unstable equilibrium. This makes it difficult to predict the dynamic behavior of the scene using a digital twin, an important step in simulation-based planning and control of contact-rich behaviors. In this paper, we posit that object pose and shape estimation requires reasoning holistically over the scene (instead of reasoning about each object in isolation), accounting for object interactions and physical plausibility. Towards this goal, our first contribution is Picasso, a physics-constrained reconstruction pipeline that builds multi-object scene reconstructions by considering geometry, non-penetration, and physics. Picasso relies on a fast rejection sampling method that reasons over multi-object interactions, leveraging an inferred object contact graph to guide samples. Second, we propose the Picasso dataset, a collection of 10 contact-rich real-world scenes with ground truth annotations, as well as a metric to quantify physical plausibility, which we open-source as part of our benchmark. Finally, we provide an extensive evaluation of Picasso on our newly introduced dataset and on the YCB-V dataset, and show it largely outperforms the state of the art while providing reconstructions that are both physically plausible and more aligned with human intuition.

</details>


### [125] [DICE: Disentangling Artist Style from Content via Contrastive Subspace Decomposition in Diffusion Models](https://arxiv.org/abs/2602.08059)
*Tong Zhang,Ru Zhang,Jianyi Liu*

Main category: cs.CV

TL;DR: DICE是一个无需训练的艺术风格擦除框架，通过对比子空间分解实现风格与内容的解耦，能动态识别并抑制风格特征，有效防止未经授权的风格模仿。


<details>
  <summary>Details</summary>
Motivation: 扩散模型的普及使得风格模仿变得容易，引发了版权和知识产权风险。现有对策要么需要昂贵的权重编辑，要么依赖明确指定的编辑风格，限制了实际部署的实用性。

Method: 提出DICE框架：1）构建对比三元组让模型区分风格与非风格特征；2）将解耦过程形式化为可解的广义特征值问题，精确识别风格子空间；3）引入自适应注意力解耦编辑策略，动态评估每个token的风格浓度，对QKV向量进行差异化抑制和内容增强。

Result: DICE在风格擦除的彻底性和内容完整性保护之间实现了优越的平衡，仅增加3秒的解耦开销，为遏制风格模仿提供了实用高效的技术。

Conclusion: DICE通过对比子空间分解实现了无需训练的艺术风格擦除，解决了现有方法在实用性和部署效率方面的限制，为平台侧安全提供了可行的解决方案。

Abstract: The recent proliferation of diffusion models has made style mimicry effortless, enabling users to imitate unique artistic styles without authorization. In deployed platforms, this raises copyright and intellectual-property risks and calls for reliable protection. However, existing countermeasures either require costly weight editing as new styles emerge or rely on an explicitly specified editing style, limiting their practicality for deployment-side safety. To address this challenge, we propose DICE (Disentanglement of artist Style from Content via Contrastive Subspace Decomposition), a training-free framework for on-the-fly artist style erasure. Unlike style editing that require an explicitly specified replacement style, DICE performs style purification, removing the artist's characteristics while preserving the user-intended content. Our core insight is that a model cannot truly comprehend the artist style from a single text or image alone. Consequently, we abandon the traditional paradigm of identifying style from isolated samples. Instead, we construct contrastive triplets to compel the model to distinguish between style and non-style features in the latent space. By formalizing this disentanglement process as a solvable generalized eigenvalue problem, we achieve precise identification of the style subspace. Furthermore, we introduce an Adaptive Attention Decoupling Editing strategy dynamically assesses the style concentration of each token and performs differential suppression and content enhancement on the QKV vectors. Extensive experiments demonstrate that DICE achieves a superior balance between the thoroughness of style erasure and the preservation of content integrity. DICE introduces an additional overhead of only 3 seconds to disentangle style, providing a practical and efficient technique for curbing style mimicry.

</details>


### [126] [ReRoPE: Repurposing RoPE for Relative Camera Control](https://arxiv.org/abs/2602.08068)
*Chunyang Li,Yuanbo Yang,Jiahao Shao,Hongyu Zhou,Katja Schwarz,Yiyi Liao*

Main category: cs.CV

TL;DR: ReRoPE：一种即插即用框架，通过将相对相机姿态信息注入预训练视频扩散模型的RoPE低频带，实现可控视角视频生成，无需大量训练或架构修改。


<details>
  <summary>Details</summary>
Motivation: 现有可控视角视频生成方法通常使用相对于固定参考帧（如第一帧）的相机姿态编码，缺乏平移不变性，导致泛化能力差和累积漂移问题。相对相机姿态嵌入更鲁棒，但难以在不增加大量训练成本或修改架构的情况下集成到预训练视频扩散模型中。

Method: 提出ReRoPE框架，基于Rotary Positional Embeddings（RoPE）在现有模型中未充分利用其全频谱带宽（特别是低频分量）的洞察。通过将相对相机姿态信息无缝注入这些未充分利用的频带，实现精确的相机控制，同时保留强大的预训练生成先验。

Result: 在图像到视频（I2V）和视频到视频（V2V）任务上评估，ReRoPE在相机控制精度和视觉保真度方面表现出色，提供了一种训练高效的可控高保真视频生成路径。

Conclusion: ReRoPE是一种即插即用框架，能够在不损害预训练模型生成能力的情况下，将相对相机信息集成到预训练视频扩散模型中，为可控高保真视频生成提供了训练高效的解决方案。

Abstract: Video generation with controllable camera viewpoints is essential for applications such as interactive content creation, gaming, and simulation. Existing methods typically adapt pre-trained video models using camera poses relative to a fixed reference, e.g., the first frame. However, these encodings lack shift-invariance, often leading to poor generalization and accumulated drift. While relative camera pose embeddings defined between arbitrary view pairs offer a more robust alternative, integrating them into pre-trained video diffusion models without prohibitive training costs or architectural changes remains challenging. We introduce ReRoPE, a plug-and-play framework that incorporates relative camera information into pre-trained video diffusion models without compromising their generation capability. Our approach is based on the insight that Rotary Positional Embeddings (RoPE) in existing models underutilize their full spectral bandwidth, particularly in the low-frequency components. By seamlessly injecting relative camera pose information into these underutilized bands, ReRoPE achieves precise control while preserving strong pre-trained generative priors. We evaluate our method on both image-to-video (I2V) and video-to-video (V2V) tasks in terms of camera control accuracy and visual fidelity. Our results demonstrate that ReRoPE offers a training-efficient path toward controllable, high-fidelity video generation. See project page for more results: https://sisyphe-lee.github.io/ReRoPE/

</details>


### [127] [ViT-5: Vision Transformers for The Mid-2020s](https://arxiv.org/abs/2602.08071)
*Feng Wang,Sucheng Ren,Tiezheng Zhang,Predrag Neskovic,Anand Bhattad,Cihang Xie,Alan Yuille*

Main category: cs.CV

TL;DR: ViT-5：通过整合过去五年架构进展对Vision Transformer进行现代化改造，在理解和生成任务上均超越现有plain ViT，提供简单即插即用的升级方案。


<details>
  <summary>Details</summary>
Motivation: 虽然Vision Transformer已成为视觉基础模型的核心架构，但过去五年的架构进展（如归一化、激活函数、位置编码等）尚未系统性地整合到ViT中。本文旨在通过组件级优化来现代化ViT骨干网络。

Method: 在保持经典Attention-FFN结构的基础上，对归一化、激活函数、位置编码、门控机制和可学习token等组件进行系统性优化，形成新一代Vision Transformer（ViT-5）。

Result: ViT-5在理解和生成任务上均超越现有plain ViT：ImageNet-1k分类达到84.2% top-1准确率（优于DeiT-III的83.8%）；在SiT扩散框架中实现1.84 FID（优于原始ViT的2.06）。同时表现出更好的表征学习和空间推理能力。

Conclusion: ViT-5通过整合现代架构进展，为2020年代中期视觉骨干网络提供了简单有效的即插即用升级方案，在保持ViT简洁性的同时显著提升性能，并具有良好的任务迁移能力。

Abstract: This work presents a systematic investigation into modernizing Vision Transformer backbones by leveraging architectural advancements from the past five years. While preserving the canonical Attention-FFN structure, we conduct a component-wise refinement involving normalization, activation functions, positional encoding, gating mechanisms, and learnable tokens. These updates form a new generation of Vision Transformers, which we call ViT-5. Extensive experiments demonstrate that ViT-5 consistently outperforms state-of-the-art plain Vision Transformers across both understanding and generation benchmarks. On ImageNet-1k classification, ViT-5-Base reaches 84.2\% top-1 accuracy under comparable compute, exceeding DeiT-III-Base at 83.8\%. ViT-5 also serves as a stronger backbone for generative modeling: when plugged into an SiT diffusion framework, it achieves 1.84 FID versus 2.06 with a vanilla ViT backbone. Beyond headline metrics, ViT-5 exhibits improved representation learning and favorable spatial reasoning behavior, and transfers reliably across tasks. With a design aligned with contemporary foundation-model practices, ViT-5 offers a simple drop-in upgrade over vanilla ViT for mid-2020s vision backbones.

</details>


### [128] [VidVec: Unlocking Video MLLM Embeddings for Video-Text Retrieval](https://arxiv.org/abs/2602.08099)
*Issar Tzachor,Dvir Samuel,Rami Ben-Ari*

Main category: cs.CV

TL;DR: 该论文提出了一种利用多模态大语言模型进行视频文本嵌入和检索的新方法，通过中间层分析和文本对齐策略，无需视觉监督即可实现零样本检索的SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 当前生成式多模态大语言模型通过微调作为视觉任务嵌入提取器时，在视频任务上的表现仍不如专门的视频基础模型。研究者希望探索如何更好地利用MLLMs进行视频文本嵌入和检索。

Method: 1. 进行层间分析，发现中间层已编码大量任务相关信息；2. 结合中间层嵌入和校准的MLLM头部实现零样本检索；3. 引入轻量级文本对齐策略，将密集视频描述映射为简短摘要，实现无视觉监督的视频文本嵌入学习。

Result: 该方法在无需视觉微调的情况下，超越了当前方法，在常见视频检索基准测试中取得了最先进的结果，且优势显著。

Conclusion: MLLMs的中间层包含丰富的任务相关信息，通过适当的组合和文本对齐策略，可以在无需视觉监督的情况下实现强大的视频文本检索性能，为视频理解任务提供了新的有效途径。

Abstract: Recent studies have adapted generative Multimodal Large Language Models (MLLMs) into embedding extractors for vision tasks, typically through fine-tuning to produce universal representations. However, their performance on video remains inferior to Video Foundation Models (VFMs). In this paper, we focus on leveraging MLLMs for video-text embedding and retrieval. We first conduct a systematic layer-wise analysis, showing that intermediate (pre-trained) MLLM layers already encode substantial task-relevant information. Leveraging this insight, we demonstrate that combining intermediate-layer embeddings with a calibrated MLLM head yields strong zero-shot retrieval performance without any training. Building on these findings, we introduce a lightweight text-based alignment strategy which maps dense video captions to short summaries and enables task-related video-text embedding learning without visual supervision. Remarkably, without any fine-tuning beyond text, our method outperforms current methods, often by a substantial margin, achieving state-of-the-art results across common video retrieval benchmarks.

</details>


### [129] [MMLSv2: A Multimodal Dataset for Martian Landslide Detection in Remote Sensing Imagery](https://arxiv.org/abs/2602.08112)
*Sidike Paheding,Abel Reyes-Angulo,Leo Thomas Ramos,Angel D. Sappa,Rajaneesh A.,Hiral P. B.,Sajin Kumar K. S.,Thomas Oommen*

Main category: cs.CV

TL;DR: MMLSv2是一个用于火星表面滑坡分割的多模态数据集，包含七波段图像和地理隔离的测试集，用于评估模型的空间泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有火星滑坡分割数据集有限，需要包含多模态数据且能评估模型空间泛化能力的数据集，以支持更稳健的滑坡检测研究。

Method: 构建包含RGB、数字高程模型、坡度、热惯性和灰度通道的七波段多模态数据集，包含664张图像的标准划分和276张地理隔离图像的独立测试集。

Result: 数据集支持稳定训练并达到竞争性性能，但在碎片化、细长和小规模滑坡区域仍具挑战性；地理隔离测试集导致性能显著下降，验证了其评估模型泛化能力的价值。

Conclusion: MMLSv2为火星滑坡分割提供了高质量多模态基准，其地理隔离测试集能有效评估模型的空间泛化能力，促进更稳健的滑坡检测算法发展。

Abstract: We present MMLSv2, a dataset for landslide segmentation on Martian surfaces. MMLSv2 consists of multimodal imagery with seven bands: RGB, digital elevation model, slope, thermal inertia, and grayscale channels. MMLSv2 comprises 664 images distributed across training, validation, and test splits. In addition, an isolated test set of 276 images from a geographically disjoint region from the base dataset is released to evaluate spatial generalization. Experiments conducted with multiple segmentation models show that the dataset supports stable training and achieves competitive performance, while still posing challenges in fragmented, elongated, and small-scale landslide regions. Evaluation on the isolated test set leads to a noticeable performance drop, indicating increased difficulty and highlighting its value for assessing model robustness and generalization beyond standard in-distribution settings. Dataset will be available at: https://github.com/MAIN-Lab/MMLS_v2

</details>


### [130] [Building Damage Detection using Satellite Images and Patch-Based Transformer Methods](https://arxiv.org/abs/2602.08117)
*Smriti Siva,Jan Cross-Zamirski*

Main category: cs.CV

TL;DR: 本研究评估了Vision Transformer（ViT）模型在xBD数据集上的性能，提出了一种针对性的基于补丁的预处理流程和冻结头微调策略，在噪声和不平衡数据上实现了与CNN基线相当的灾害分类性能。


<details>
  <summary>Details</summary>
Motivation: 快速建筑损伤评估对灾后响应至关重要。卫星影像损伤分类模型可提供可扩展的态势感知，但卫星数据中的标签噪声和严重类别不平衡带来了重大挑战。xBD数据集为跨地理区域的建筑级损伤提供了标准化基准。

Method: 评估DINOv2-small和DeiT模型进行多类损伤分类，提出针对性的基于补丁的预处理流程以隔离结构特征并最小化训练中的背景噪声，采用冻结头微调策略以保持计算需求可控。

Result: 通过准确率、精确率、召回率和宏平均F1分数评估模型性能，显示小型ViT架构配合新训练方法在灾害分类方面实现了与先前CNN基线相当的竞争性宏平均F1分数。

Conclusion: 小型Vision Transformer架构配合提出的训练方法能够在噪声和不平衡的卫星数据上有效进行建筑损伤分类，为灾后快速评估提供了可行的技术方案。

Abstract: Rapid building damage assessment is critical for post-disaster response. Damage classification models built on satellite imagery provide a scalable means of obtaining situational awareness. However, label noise and severe class imbalance in satellite data create major challenges. The xBD dataset offers a standardized benchmark for building-level damage across diverse geographic regions. In this study, we evaluate Vision Transformer (ViT) model performance on the xBD dataset, specifically investigating how these models distinguish between types of structural damage when training on noisy, imbalanced data.
  In this study, we specifically evaluate DINOv2-small and DeiT for multi-class damage classification. We propose a targeted patch-based pre-processing pipeline to isolate structural features and minimize background noise in training. We adopt a frozen-head fine-tuning strategy to keep computational requirements manageable. Model performance is evaluated through accuracy, precision, recall, and macro-averaged F1 scores. We show that small ViT architectures with our novel training method achieves competitive macro-averaged F1 relative to prior CNN baselines for disaster classification.

</details>


### [131] [MambaFusion: Adaptive State-Space Fusion for Multimodal 3D Object Detection](https://arxiv.org/abs/2602.08126)
*Venkatraman Narayanan,Bala Sai,Rahul Ahuja,Pratik Likhar,Varun Ravi Kumar,Senthil Yogamani*

Main category: cs.CV

TL;DR: MambaFusion：一种用于自动驾驶的3D目标检测多模态融合框架，结合选择性状态空间模型和窗口Transformer，实现高效、自适应且物理基础的感知。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶中可靠的3D目标检测至关重要，但现有的相机-LiDAR多模态融合方法存在效率低、空间不变融合和不确定性推理困难等问题。

Method: 1. 交替使用选择性状态空间模型和窗口Transformer传播全局上下文；2. 多模态token对齐模块和可靠性感知融合门动态重加权特征；3. 结构条件扩散头结合图推理和不确定性感知去噪。

Result: 在nuScenes基准测试中达到新的最先进性能，同时保持线性时间复杂度，实现了鲁棒、时间稳定且可解释的3D感知。

Conclusion: 将SSM的效率与可靠性驱动的融合相结合，能够为真实世界的自动驾驶系统提供鲁棒、时间稳定且可解释的3D感知。

Abstract: Reliable 3D object detection is fundamental to autonomous driving, and multimodal fusion algorithms using cameras and LiDAR remain a persistent challenge. Cameras provide dense visual cues but ill posed depth; LiDAR provides a precise 3D structure but sparse coverage. Existing BEV-based fusion frameworks have made good progress, but they have difficulties including inefficient context modeling, spatially invariant fusion, and reasoning under uncertainty. We introduce MambaFusion, a unified multi-modal detection framework that achieves efficient, adaptive, and physically grounded 3D perception. MambaFusion interleaves selective state-space models (SSMs) with windowed transformers to propagate the global context in linear time while preserving local geometric fidelity. A multi-modal token alignment (MTA) module and reliability-aware fusion gates dynamically re-weight camera-LiDAR features based on spatial confidence and calibration consistency. Finally, a structure-conditioned diffusion head integrates graph-based reasoning with uncertainty-aware denoising, enforcing physical plausibility, and calibrated confidence. MambaFusion establishes new state-of-the-art performance on nuScenes benchmarks while operating with linear-time complexity. The framework demonstrates that coupling SSM-based efficiency with reliability-driven fusion yields robust, temporally stable, and interpretable 3D perception for real-world autonomous driving systems.

</details>


### [132] [Fields of The World: A Field Guide for Extracting Agricultural Field Boundaries](https://arxiv.org/abs/2602.08131)
*Isaac Corley,Hannah Kerner,Caleb Robinson,Jennifer Marcus*

Main category: cs.CV

TL;DR: FTW生态系统提供全球农田边界数据集、预训练模型和工具，支持从本地到国家尺度的农田边界提取与作物分类


<details>
  <summary>Details</summary>
Motivation: 农田边界地图是农业数据产品的基础，对作物监测、产量估算和病害评估至关重要，但缺乏标准化的全球数据集和工具

Method: 构建包含160万农田多边形的基准数据集，开发预训练分割模型和命令行推理工具，使用MOSAIKS随机卷积特征进行作物分类

Result: 在有限标签下实现作物分类宏F1分数0.65-0.75，在5个国家（476万平方公里）展示预测结果，中位农田面积从0.06公顷到0.28公顷

Conclusion: FTW生态系统为农田边界提取和作物分类提供了标准化工具和数据集，支持多尺度农业监测应用

Abstract: Field boundary maps are a building block for agricultural data products and support crop monitoring, yield estimation, and disease estimation. This tutorial presents the Fields of The World (FTW) ecosystem: a benchmark of 1.6M field polygons across 24 countries, pre-trained segmentation models, and command-line inference tools. We provide two notebooks that cover (1) local-scale field boundary extraction with crop classification and forest loss attribution, and (2) country-scale inference using cloud-optimized data. We use MOSAIKS random convolutional features and FTW derived field boundaries to map crop type at the field level and report macro F1 scores of 0.65--0.75 for crop type classification with limited labels. Finally, we show how to explore pre-computed predictions over five countries (4.76M km\textsuperscript{2}), with median predicted field areas from 0.06 ha (Rwanda) to 0.28 ha (Switzerland).

</details>


### [133] [Robustness of Vision Language Models Against Split-Image Harmful Input Attacks](https://arxiv.org/abs/2602.08136)
*Md Rafi Ur Rashid,MD Sadik Hossain Shanto,Vishnu Asutosh Dasu,Shagufta Mehnaz*

Main category: cs.CV

TL;DR: 本文提出了一种新的视觉语言模型安全漏洞：分割图像视觉越狱攻击（SIVA），利用VLM安全对齐仅针对完整图像而忽略跨多个图像片段的有害语义的缺陷，实现了比现有方法高60%的跨模型转移成功率。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型（VLMs）通过偏好优化（如RLHF）进行了广泛的安全对齐，对单张/完整图像的视觉越狱攻击表现出强鲁棒性。然而，作者发现VLM的预训练和指令调优能很好地泛化到分割图像输入，但安全对齐通常只在完整图像上进行，没有考虑有害语义分布在多个图像片段中的情况，导致VLM无法检测和拒绝有害的分割图像输入。

Method: 提出了分割图像视觉越狱攻击（SIVA），采用渐进式攻击策略：从简单的图像分割开始，发展到自适应白盒攻击，最终形成黑盒转移攻击。最强的攻击策略采用新颖的对抗知识蒸馏（Adv-KD）算法来显著提高跨模型转移能力。

Result: 在三个最先进的现代VLMs和三个越狱数据集上的评估表明，最强的攻击比现有基线实现了高达60%的转移成功率提升。

Conclusion: 揭示了当前VLM安全对齐中的关键漏洞，并提出了有效的解决方案来应对这一安全问题。分割图像攻击暴露了VLM安全对齐的局限性，需要更全面的安全训练方法。

Abstract: Vision-Language Models (VLMs) are now a core part of modern AI. Recent work proposed several visual jailbreak attacks using single/ holistic images. However, contemporary VLMs demonstrate strong robustness against such attacks due to extensive safety alignment through preference optimization (e.g., RLHF). In this work, we identify a new vulnerability: while VLM pretraining and instruction tuning generalize well to split-image inputs, safety alignment is typically performed only on holistic images and does not account for harmful semantics distributed across multiple image fragments. Consequently, VLMs often fail to detect and refuse harmful split-image inputs, where unsafe cues emerge only after combining images. We introduce novel split-image visual jailbreak attacks (SIVA) that exploit this misalignment. Unlike prior optimization-based attacks, which exhibit poor black-box transferability due to architectural and prior mismatches across models, our attacks evolve in progressive phases from naive splitting to an adaptive white-box attack, culminating in a black-box transfer attack. Our strongest strategy leverages a novel adversarial knowledge distillation (Adv-KD) algorithm to substantially improve cross-model transferability. Evaluations on three state-of-the-art modern VLMs and three jailbreak datasets demonstrate that our strongest attack achieves up to 60% higher transfer success than existing baselines. Lastly, we propose efficient ways to address this critical vulnerability in the current VLM safety alignment.

</details>


### [134] [DAS-SK: An Adaptive Model Integrating Dual Atrous Separable and Selective Kernel CNN for Agriculture Semantic Segmentation](https://arxiv.org/abs/2602.08168)
*Mei Ling Chee,Thangarajah Akilan,Aparna Ravindra Phalke,Kanchan Keisham*

Main category: cs.CV

TL;DR: DAS-SK是一个轻量级语义分割架构，将选择性卷积核集成到双空洞可分离卷积中，增强多尺度特征学习，在农业图像分割中实现精度与效率的平衡。


<details>
  <summary>Details</summary>
Motivation: 高分辨率农业图像语义分割需要平衡精度和计算效率，以适应无人机等边缘设备部署。现有模型存在数据集需求大、光谱泛化能力有限、计算成本高等限制。

Method: 提出DAS-SK架构，将选择性卷积核（SK-Conv）集成到双空洞可分离卷积（DAS-Conv）模块中，增强多尺度特征学习。改进空洞空间金字塔池化（ASPP）模块，同时捕获细粒度局部结构和全局上下文信息。基于改进的DeepLabV3框架，采用MobileNetV3-Large和EfficientNet-B3双互补骨干网络。

Result: 在LandCover.ai、VDD和PhenoBench三个基准测试中，DAS-SK始终达到最先进性能，同时比CNN、transformer和混合模型更高效。相比顶级transformer模型，参数减少21倍，GFLOPs减少19倍。

Conclusion: DAS-SK是一个鲁棒、高效、可扩展的解决方案，适用于实时农业机器人和高分辨率遥感，在其他视觉领域也有广泛部署潜力。

Abstract: Semantic segmentation in high-resolution agricultural imagery demands models that strike a careful balance between accuracy and computational efficiency to enable deployment in practical systems. In this work, we propose DAS-SK, a novel lightweight architecture that retrofits selective kernel convolution (SK-Conv) into the dual atrous separable convolution (DAS-Conv) module to strengthen multi-scale feature learning. The model further enhances the atrous spatial pyramid pooling (ASPP) module, enabling the capture of fine-grained local structures alongside global contextual information. Built upon a modified DeepLabV3 framework with two complementary backbones - MobileNetV3-Large and EfficientNet-B3, the DAS-SK model mitigates limitations associated with large dataset requirements, limited spectral generalization, and the high computational cost that typically restricts deployment on UAVs and other edge devices. Comprehensive experiments across three benchmarks: LandCover.ai, VDD, and PhenoBench, demonstrate that DAS-SK consistently achieves state-of-the-art performance, while being more efficient than CNN-, transformer-, and hybrid-based competitors. Notably, DAS-SK requires up to 21x fewer parameters and 19x fewer GFLOPs than top-performing transformer models. These findings establish DAS-SK as a robust, efficient, and scalable solution for real-time agricultural robotics and high-resolution remote sensing, with strong potential for broader deployment in other vision domains.

</details>


### [135] [PEGAsus: 3D Personalization of Geometry and Appearance](https://arxiv.org/abs/2602.08198)
*Jingyu Hu,Bin Hu,Ka-Hei Hui,Haipeng Li,Zhengzhe Liu,Daniel Cohen-Or,Chi-Wing Fu*

Main category: cs.CV

TL;DR: PEGAsus是一个能够生成个性化3D形状的新框架，通过在几何和外观两个层面学习形状概念，实现从参考形状提取可重用属性并与文本结合生成新形状。


<details>
  <summary>Details</summary>
Motivation: 现有3D形状生成方法缺乏细粒度控制和个性化能力，难以从参考形状中提取可重用的几何和外观属性，并灵活地将其与文本描述结合生成新形状。

Method: 1) 将3D形状个性化定义为从参考形状提取类别无关的几何和外观属性；2) 设计渐进优化策略，在几何和外观层面解耦学习形状概念；3) 扩展到区域级概念学习，使用上下文感知和无上下文损失。

Result: PEGAsus能够有效从各种参考形状中提取属性，并灵活地与文本结合生成新形状，实现细粒度控制，支持创建多样化的个性化结果，甚至在跨类别场景中表现优异，超越现有最先进方法。

Conclusion: PEGAsus框架通过解耦的几何和外观概念学习，实现了有效的3D形状个性化生成，为细粒度控制和跨类别形状合成提供了新解决方案。

Abstract: We present PEGAsus, a new framework capable of generating Personalized 3D shapes by learning shape concepts at both Geometry and Appearance levels. First, we formulate 3D shape personalization as extracting reusable, category-agnostic geometric and appearance attributes from reference shapes, and composing these attributes with text to generate novel shapes. Second, we design a progressive optimization strategy to learn shape concepts at both the geometry and appearance levels, decoupling the shape concept learning process. Third, we extend our approach to region-wise concept learning, enabling flexible concept extraction, with context-aware and context-free losses. Extensive experimental results show that PEGAsus is able to effectively extract attributes from a wide range of reference shapes and then flexibly compose these concepts with text to synthesize new shapes. This enables fine-grained control over shape generation and supports the creation of diverse, personalized results, even in challenging cross-category scenarios. Both quantitative and qualitative experiments demonstrate that our approach outperforms existing state-of-the-art solutions.

</details>


### [136] [Generative Regression for Left Ventricular Ejection Fraction Estimation from Echocardiography Video](https://arxiv.org/abs/2602.08202)
*Jinrong Lv,Xun Gong,Zhaohuan Li,Weili Jiang*

Main category: cs.CV

TL;DR: 提出MCSDR模型，使用基于分数的扩散模型进行生成式回归，解决超声心动图LVEF估计中的多模态后验分布问题。


<details>
  <summary>Details</summary>
Motivation: 超声心动图估计LVEF是一个病态逆问题，存在噪声、伪影和有限视角，导致单一视频序列对应的是可能生理值的分布而非唯一真值。传统深度学习方法采用MSE回归，只能学习条件期望，当后验分布为多模态或重尾时会产生误导性预测。

Method: 提出MCSDR（多模态条件分数扩散回归模型），这是一个概率框架，用于建模以超声心动图视频和患者人口统计学属性先验为条件的LVEF连续后验分布。采用基于分数的扩散模型进行生成式回归。

Result: 在EchoNet-Dynamic、EchoNet-Pediatric和CAMUS数据集上的广泛实验表明，MCSDR实现了最先进的性能。定性分析显示，在高噪声或显著生理变异的情况下，模型的生成轨迹表现出独特行为，为AI辅助诊断提供了新的可解释性层。

Conclusion: 从确定性回归向生成式回归的范式转变能更好地处理LVEF估计中的多模态后验分布问题。MCSDR不仅性能优越，还通过生成轨迹提供了新的可解释性视角。

Abstract: Estimating Left Ventricular Ejection Fraction (LVEF) from echocardiograms constitutes an ill-posed inverse problem. Inherent noise, artifacts, and limited viewing angles introduce ambiguity, where a single video sequence may map not to a unique ground truth, but rather to a distribution of plausible physiological values. Prevailing deep learning approaches typically formulate this task as a standard regression problem that minimizes the Mean Squared Error (MSE). However, this paradigm compels the model to learn the conditional expectation, which may yield misleading predictions when the underlying posterior distribution is multimodal or heavy-tailed -- a common phenomenon in pathological scenarios. In this paper, we investigate the paradigm shift from deterministic regression toward generative regression. We propose the Multimodal Conditional Score-based Diffusion model for Regression (MCSDR), a probabilistic framework designed to model the continuous posterior distribution of LVEF conditioned on echocardiogram videos and patient demographic attribute priors. Extensive experiments conducted on the EchoNet-Dynamic, EchoNet-Pediatric, and CAMUS datasets demonstrate that MCSDR achieves state-of-the-art performance. Notably, qualitative analysis reveals that the generation trajectories of our model exhibit distinct behaviors in cases characterized by high noise or significant physiological variability, thereby offering a novel layer of interpretability for AI-aided diagnosis.

</details>


### [137] [Geospatial-Reasoning-Driven Vocabulary-Agnostic Remote Sensing Semantic Segmentation](https://arxiv.org/abs/2602.08206)
*Chufeng Zhou,Jian Wang,Xinyuan Liu,Xiaokang Zhang*

Main category: cs.CV

TL;DR: 提出GR-CoT框架，通过地理空间推理链增强MLLMs的场景理解能力，解决遥感开放词汇分割中相似光谱特征但不同语义类别的歧义问题。


<details>
  <summary>Details</summary>
Motivation: 现有开放词汇语义分割方法主要依赖视觉特征和文本嵌入的被动映射，这种"基于外观"的范式缺乏地理空间上下文感知，导致遇到光谱特征相似但语义属性不同的地物类别时产生严重语义歧义和误分类。

Method: 提出地理空间推理链(GR-CoT)框架，包含两个协作组件：离线知识蒸馏流和在线实例推理流。离线流建立细粒度类别解释标准以解决相似地物类型间的语义冲突；在线推理执行顺序推理过程，包括宏观场景锚定、视觉特征解耦和知识驱动决策合成，生成图像自适应词汇表来指导下游模型。

Result: 在LoveDA和GID5基准测试上的广泛实验证明了该方法的优越性。

Conclusion: GR-CoT框架通过增强MLLMs的地理空间推理能力，有效解决了遥感开放词汇分割中的语义歧义问题，实现了更精确的地理语义映射。

Abstract: Open-vocabulary semantic segmentation has emerged as a promising research direction in remote sensing, enabling the recognition of diverse land-cover types beyond pre-defined category sets. However, existing methods predominantly rely on the passive mapping of visual features and textual embeddings. This ``appearance-based" paradigm lacks geospatial contextual awareness, leading to severe semantic ambiguity and misclassification when encountering land-cover classes with similar spectral features but distinct semantic attributes. To address this, we propose a Geospatial Reasoning Chain-of-Thought (GR-CoT) framework designed to enhance the scene understanding capabilities of Multimodal Large Language Models (MLLMs), thereby guiding open-vocabulary segmentation models toward precise mapping. The framework comprises two collaborative components: an offline knowledge distillation stream and an online instance reasoning stream. The offline stream establishes fine-grained category interpretation standards to resolve semantic conflicts between similar land-cover types. During online inference, the framework executes a sequential reasoning process involving macro-scenario anchoring, visual feature decoupling, and knowledge-driven decision synthesis. This process generates an image-adaptive vocabulary that guides downstream models to achieve pixel-level alignment with correct geographical semantics. Extensive experiments on the LoveDA and GID5 benchmarks demonstrate the superiority of our approach.

</details>


### [138] [Chain-of-Caption: Training-free improvement of multimodal large language model on referring expression comprehension](https://arxiv.org/abs/2602.08211)
*Yik Lung Pang,Changjae Oh*

Main category: cs.CV

TL;DR: 提出Chain-of-Caption训练免费框架，通过结合多种视觉和文本上下文，在REC任务上实现5-30%的性能提升


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型在指代表达理解任务上已取得高精度，但通过工具使用提供额外视觉或文本上下文可以进一步提升性能。本文旨在分析不同上下文提供技术对REC任务的影响。

Method: 提出Chain-of-Caption训练免费框架，通过工具使用为MLLM提供多种视觉和文本上下文，包括图像描述、物体检测、OCR等，无需微调即可提升REC性能。

Result: 在RefCOCO/RefCOCOg/RefCOCO+和Ref-L4数据集上实验表明，单独的文本或视觉上下文都能提升REC性能。结合多种上下文后，在不同IoU阈值下相比基线模型获得5-30%的性能增益。

Conclusion: 通过工具使用为MLLM提供多种视觉和文本上下文能显著提升REC性能，提出的Chain-of-Caption框架无需训练即可实现这一目标，为MLLM在视觉语言任务中的应用提供了有效方法。

Abstract: Given a textual description, the task of referring expression comprehension (REC) involves the localisation of the referred object in an image. Multimodal large language models (MLLMs) have achieved high accuracy on REC benchmarks through scaling up the model size and training data. Moreover, the performance of MLLMs can be further improved using techniques such as Chain-of-Thought and tool use, which provides additional visual or textual context to the model. In this paper, we analyse the effect of various techniques for providing additional visual and textual context via tool use to the MLLM and its effect on the REC task. Furthermore, we propose a training-free framework named Chain-of-Caption to improve the REC performance of MLLMs. We perform experiments on RefCOCO/RefCOCOg/RefCOCO+ and Ref-L4 datasets and show that individual textual or visual context can improve the REC performance without any fine-tuning. By combining multiple contexts, our training-free framework shows between 5% to 30% performance gain over the baseline model on accuracy at various Intersection over Union (IoU) thresholds.

</details>


### [139] [Efficient-SAM2: Accelerating SAM2 with Object-Aware Visual Encoding and Memory Retrieval](https://arxiv.org/abs/2602.08224)
*Jing Zhang,Zhikai Li,Xuewen Liu,Qingyi Gu*

Main category: cs.CV

TL;DR: 提出Efficient-SAM2方法，通过对象感知的稀疏窗口路由和稀疏内存检索技术，在保持SAM2分割精度的同时实现1.68倍加速，仅损失1.0%准确率。


<details>
  <summary>Details</summary>
Motivation: SAM2在视频对象分割任务中表现出色，但计算负担重，难以应用于实时视频处理。现有改进方法主要关注重新训练轻量级骨干网络，缺乏对训练后加速的探索。研究发现SAM2具有类似生物视觉的稀疏感知模式，为消除冗余计算提供了机会。

Method: 提出Efficient-SAM2框架：1) 对象感知稀疏窗口路由(SWR)：利用前一帧解码器的连续性和显著性线索，将背景区域路由到轻量级捷径分支；2) 对象感知稀疏内存检索(SMR)：仅让每帧中的显著内存标记参与计算，显著性模式从首次记忆开始重用。

Result: 在SAM2.1-L模型上实现1.68倍加速，在SA-V测试集上仅损失1.0%准确率。方法仅增加可忽略的额外参数和最小训练开销。

Conclusion: 通过利用SAM2的稀疏感知特性，提出的Efficient-SAM2能够自适应聚焦对象区域，消除任务无关计算，显著提升推理效率，为实时视频处理应用提供了可行解决方案。

Abstract: Segment Anything Model 2 (SAM2) shows excellent performance in video object segmentation tasks; however, the heavy computational burden hinders its application in real-time video processing. Although there have been efforts to improve the efficiency of SAM2, most of them focus on retraining a lightweight backbone, with little exploration into post-training acceleration. In this paper, we observe that SAM2 exhibits sparse perception pattern as biological vision, which provides opportunities for eliminating redundant computation and acceleration: i) In mask decoder, the attention primarily focuses on the foreground objects, whereas the image encoder in the earlier stage exhibits a broad attention span, which results in unnecessary computation to background regions. ii) In memory bank, only a small subset of tokens in each frame contribute significantly to memory attention, and the salient regions exhibit temporal consistency, making full-token computation redundant. With these insights, we propose Efficient-SAM2, which promotes SAM2 to adaptively focus on object regions while eliminating task-irrelevant computations, thereby significantly improving inference efficiency. Specifically, for image encoder, we propose object-aware Sparse Window Routing (SWR), a window-level computation allocation mechanism that leverages the consistency and saliency cues from the previous-frame decoder to route background regions into a lightweight shortcut branch. Moreover, for memory attention, we propose object-aware Sparse Memory Retrieval (SMR), which allows only the salient memory tokens in each frame to participate in computation, with the saliency pattern reused from their first recollection. With negligible additional parameters and minimal training overhead, Efficient-SAM2 delivers 1.68x speedup on SAM2.1-L model with only 1.0% accuracy drop on SA-V test set.

</details>


### [140] [Generating Adversarial Events: A Motion-Aware Point Cloud Framework](https://arxiv.org/abs/2602.08230)
*Hongwei Ren,Youxin Jiang,Qifei Gu,Xiangqian Wu*

Main category: cs.CV

TL;DR: MA-ADV是首个利用点云表示生成对抗性事件的方法，通过运动感知框架实现100%攻击成功率，揭示了事件感知系统的安全挑战


<details>
  <summary>Details</summary>
Motivation: 事件相机已广泛应用于自动驾驶、机器人等安全关键领域，但深度神经网络对对抗样本的脆弱性威胁着事件系统的可靠性。目前针对事件的对抗攻击研究稀缺，主要因为主流事件表示的非可微性阻碍了基于梯度的攻击方法扩展。

Method: 提出MA-ADV运动感知对抗框架：1) 利用点云表示生成对抗事件；2) 考虑事件中的高频噪声，采用基于扩散的方法平滑扰动；3) 充分利用事件间的时空关系；4) 结合样本级Adam优化、迭代精炼和二分搜索寻找最小成本扰动。

Result: 实验验证MA-ADV能确保100%攻击成功率且扰动成本最小，同时展示了对防御机制的增强鲁棒性。

Conclusion: MA-ADV揭示了未来事件感知系统面临的关键安全挑战，为事件相机的对抗攻击研究提供了新思路。

Abstract: Event cameras have been widely adopted in safety-critical domains such as autonomous driving, robotics, and human-computer interaction. A pressing challenge arises from the vulnerability of deep neural networks to adversarial examples, which poses a significant threat to the reliability of event-based systems. Nevertheless, research into adversarial attacks on events is scarce. This is primarily due to the non-differentiable nature of mainstream event representations, which hinders the extension of gradient-based attack methods. In this paper, we propose MA-ADV, a novel \textbf{M}otion-\textbf{A}ware \textbf{Adv}ersarial framework. To the best of our knowledge, this is the first work to generate adversarial events by leveraging point cloud representations. MA-ADV accounts for high-frequency noise in events and employs a diffusion-based approach to smooth perturbations, while fully leveraging the spatial and temporal relationships among events. Finally, MA-ADV identifies the minimal-cost perturbation through a combination of sample-wise Adam optimization, iterative refinement, and binary search. Extensive experimental results validate that MA-ADV ensures a 100\% attack success rate with minimal perturbation cost, and also demonstrate enhanced robustness against defenses, underscoring the critical security challenges facing future event-based perception systems.

</details>


### [141] [Moving Beyond Functional Connectivity: Time-Series Modeling for fMRI-Based Brain Disorder Classification](https://arxiv.org/abs/2602.08262)
*Guoqi Yu,Xiaowei Hu,Angelica I. Aviles-Rivero,Anqi Qiu,Shujun Wang*

Main category: cs.CV

TL;DR: DeCI框架通过周期-漂移分解和通道独立建模，直接处理原始BOLD信号，在fMRI脑疾病分类中优于传统功能连接方法。


<details>
  <summary>Details</summary>
Motivation: 现有fMRI分析方法主要依赖基于皮尔逊相关的功能连接，将4D BOLD信号简化为静态2D矩阵，丢失了时间动态信息且只能捕捉线性关系。需要直接建模时间信息以更好地理解复杂脑动力学。

Method: 提出DeCI框架：1) 周期-漂移分解：将每个ROI的时间序列分解为周期振荡波动和缓慢基线漂移；2) 通道独立：分别建模每个ROI，提高鲁棒性并减少过拟合。

Result: 在五个公共数据集上的实验表明，DeCI在分类准确率和泛化能力上均优于传统FC方法和现有时间序列模型基准。

Conclusion: 研究支持在fMRI分析中转向端到端的时间建模，以更好地捕捉复杂的脑动力学。DeCI框架简单有效，为脑疾病分类提供了新方向。

Abstract: Functional magnetic resonance imaging (fMRI) enables non-invasive brain disorder classification by capturing blood-oxygen-level-dependent (BOLD) signals. However, most existing methods rely on functional connectivity (FC) via Pearson correlation, which reduces 4D BOLD signals to static 2D matrices, discarding temporal dynamics and capturing only linear inter-regional relationships. In this work, we benchmark state-of-the-art temporal models (e.g., time-series models such as PatchTST, TimesNet, and TimeMixer) on raw BOLD signals across five public datasets. Results show these models consistently outperform traditional FC-based approaches, highlighting the value of directly modeling temporal information such as cycle-like oscillatory fluctuations and drift-like slow baseline trends. Building on this insight, we propose DeCI, a simple yet effective framework that integrates two key principles: (i) Cycle and Drift Decomposition to disentangle cycle and drift within each ROI (Region of Interest); and (ii) Channel-Independence to model each ROI separately, improving robustness and reducing overfitting. Extensive experiments demonstrate that DeCI achieves superior classification accuracy and generalization compared to both FC-based and temporal baselines. Our findings advocate for a shift toward end-to-end temporal modeling in fMRI analysis to better capture complex brain dynamics. The code is available at https://github.com/Levi-Ackman/DeCI.

</details>


### [142] [PISCO: Precise Video Instance Insertion with Sparse Control](https://arxiv.org/abs/2602.08277)
*Xiangbo Gao,Renjie Li,Xinghao Chen,Yuheng Wu,Suofei Feng,Qing Yin,Zhengzhong Tu*

Main category: cs.CV

TL;DR: PISCO是一个视频扩散模型，用于通过任意稀疏关键帧控制实现精确的视频实例插入，解决了传统视频编辑中空间-时间定位、物理一致性和原始动态保持的挑战。


<details>
  <summary>Details</summary>
Motivation: AI视频生成正从依赖大量提示工程和筛选的通用生成，转向细粒度可控生成和高保真后处理。在专业AI辅助电影制作中，需要进行精确、有针对性的修改，视频实例插入是这一转变的关键，需要在保持场景完整性的同时将特定实例插入现有素材。

Method: 提出PISCO视频扩散模型，支持单关键帧、起止关键帧或任意时间戳的稀疏关键帧控制。引入变量信息引导实现鲁棒条件化，分布保持时间掩码稳定时间生成，以及几何感知条件化实现真实场景适应。

Result: 构建了PISCO-Bench基准测试集，使用基于参考和无参考的感知指标进行评估。实验表明PISCO在稀疏控制下持续优于强基线方法，并且随着控制信号的增加表现出清晰、单调的性能提升。

Conclusion: PISCO通过创新的条件化技术和时间稳定方法，实现了精确的视频实例插入，为专业AI辅助电影制作提供了有效的解决方案，推动了视频生成从通用生成向可控生成的转变。

Abstract: The landscape of AI video generation is undergoing a pivotal shift: moving beyond general generation - which relies on exhaustive prompt-engineering and "cherry-picking" - towards fine-grained, controllable generation and high-fidelity post-processing. In professional AI-assisted filmmaking, it is crucial to perform precise, targeted modifications. A cornerstone of this transition is video instance insertion, which requires inserting a specific instance into existing footage while maintaining scene integrity. Unlike traditional video editing, this task demands several requirements: precise spatial-temporal placement, physically consistent scene interaction, and the faithful preservation of original dynamics - all achieved under minimal user effort. In this paper, we propose PISCO, a video diffusion model for precise video instance insertion with arbitrary sparse keyframe control. PISCO allows users to specify a single keyframe, start-and-end keyframes, or sparse keyframes at arbitrary timestamps, and automatically propagates object appearance, motion, and interaction. To address the severe distribution shift induced by sparse conditioning in pretrained video diffusion models, we introduce Variable-Information Guidance for robust conditioning and Distribution-Preserving Temporal Masking to stabilize temporal generation, together with geometry-aware conditioning for realistic scene adaptation. We further construct PISCO-Bench, a benchmark with verified instance annotations and paired clean background videos, and evaluate performance using both reference-based and reference-free perceptual metrics. Experiments demonstrate that PISCO consistently outperforms strong inpainting and video editing baselines under sparse control, and exhibits clear, monotonic performance improvements as additional control signals are provided. Project page: xiangbogaobarry.github.io/PISCO.

</details>


### [143] [Tighnari v2: Mitigating Label Noise and Distribution Shift in Multimodal Plant Distribution Prediction via Mixture of Experts and Weakly Supervised Learning](https://arxiv.org/abs/2602.08282)
*Haixu Liu,Yufei Wang,Tianxiang Xu,Chuancheng Shi,Hongsheng Xing*

Main category: cs.CV

TL;DR: 提出多模态融合框架，结合PA和PO数据优势，通过地理对齐策略和专家混合方法解决数据稀疏、偏差和分布偏移问题，在GeoLifeCLEF 2025数据集上取得优异性能。


<details>
  <summary>Details</summary>
Motivation: 大规模跨物种植物分布预测对生物多样性保护至关重要，但面临观测数据稀疏和偏差的挑战。PA数据准确但成本高数量少，PO数据覆盖广但负样本标签噪声严重，需要有效融合两种数据。

Method: 1) 基于卫星影像地理覆盖的PO数据伪标签聚合策略，实现标签空间与遥感特征空间的地理对齐；2) 多模态融合架构：Swin Transformer处理卫星影像，TabM网络提取表格特征，Temporal Swin Transformer建模时间序列，串行三模态交叉注意力机制融合异质模态；3) 专家混合方法：根据空间邻近性划分测试样本，使用不同数据集训练的模型进行分区推理和后处理。

Result: 在GeoLifeCLEF 2025数据集上的实验表明，该方法在PA覆盖有限且分布偏移显著的情况下，取得了优越的预测性能。

Conclusion: 提出的多模态融合框架有效结合了PA和PO数据的优势，通过地理对齐策略和专家混合方法解决了数据稀疏、偏差和分布偏移问题，为大规模植物分布预测提供了有效解决方案。

Abstract: Large-scale, cross-species plant distribution prediction plays a crucial role in biodiversity conservation, yet modeling efforts in this area still face significant challenges due to the sparsity and bias of observational data. Presence-Absence (PA) data provide accurate and noise-free labels, but are costly to obtain and limited in quantity; Presence-Only (PO) data, by contrast, offer broad spatial coverage and rich spatiotemporal distribution, but suffer from severe label noise in negative samples. To address these real-world constraints, this paper proposes a multimodal fusion framework that fully leverages the strengths of both PA and PO data. We introduce an innovative pseudo-label aggregation strategy for PO data based on the geographic coverage of satellite imagery, enabling geographic alignment between the label space and remote sensing feature space. In terms of model architecture, we adopt Swin Transformer Base as the backbone for satellite imagery, utilize the TabM network for tabular feature extraction, retain the Temporal Swin Transformer for time-series modeling, and employ a stackable serial tri-modal cross-attention mechanism to optimize the fusion of heterogeneous modalities. Furthermore, empirical analysis reveals significant geographic distribution shifts between PA training and test samples, and models trained by directly mixing PO and PA data tend to experience performance degradation due to label noise in PO data. To address this, we draw on the mixture-of-experts paradigm: test samples are partitioned according to their spatial proximity to PA samples, and different models trained on distinct datasets are used for inference and post-processing within each partition. Experiments on the GeoLifeCLEF 2025 dataset demonstrate that our approach achieves superior predictive performance in scenarios with limited PA coverage and pronounced distribution shifts.

</details>


### [144] [CAE-AV: Improving Audio-Visual Learning via Cross-modal Interactive Enrichment](https://arxiv.org/abs/2602.08309)
*Yunzuo Hu,Wen Li,Jing Zhang*

Main category: cs.CV

TL;DR: CAE-AV框架通过两个互补模块（CASTE和CASE）解决音视频学习中的模态不对齐问题，利用跨模态语义引导和轻量级目标函数提升表示质量，在多个基准测试中达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 音视频学习面临模态不对齐的挑战，包括屏幕外声源和背景干扰，现有方法容易放大不相关区域或时刻，导致训练不稳定和表示质量下降。

Method: 提出CAE-AV框架，包含两个互补模块：1) CASTE：通过评估帧级音视频一致性动态平衡时空关系；2) CASE：将跨模态语义引导注入选定的时空位置。还设计了caption-to-modality InfoNCE、视觉-音频一致性和熵正则化等轻量级目标函数。

Result: 在冻结骨干网络的情况下，CAE-AV在AVE、AVVP、AVS和AVQA基准测试中实现了最先进的性能，定性分析进一步验证了其对音视频不对齐的鲁棒性。

Conclusion: CAE-AV框架通过跨模态一致性引导和语义对齐，有效缓解了音视频学习中的模态不对齐问题，提高了表示质量和模型鲁棒性。

Abstract: Audio-visual learning suffers from modality misalignment caused by off-screen sources and background clutter, and current methods usually amplify irrelevant regions or moments, leading to unstable training and degraded representation quality. To address this challenge, we proposed a novel Caption-aligned and Agreement-guided Enhancement framework (CAE-AV) for audio-visual learning, which used two complementary modules: Cross-modal Agreement-guided Spatio-Temporal Enrichment (CASTE) and Caption-Aligned Saliency-guided Enrichment (CASE) to relieve audio-visual misalignment. CASTE dynamically balances spatial and temporal relations by evaluating frame-level audio-visual agreement, ensuring that key information is captured from both preceding and subsequent frames under misalignment. CASE injects cross-modal semantic guidance into selected spatio-temporal positions, leveraging high-level semantic cues to further alleviate misalignment. In addition, we design lightweight objectives, caption-to-modality InfoNCE, visual-audio consistency, and entropy regularization to guide token selection and strengthen cross-modal semantic alignment. With frozen backbones, CAE-AV achieves state-of-the-art performance on AVE, AVVP, AVS, and AVQA benchmarks, and qualitative analyses further validate its robustness against audio-visual misalignment.

</details>


### [145] [Language-Guided Transformer Tokenizer for Human Motion Generation](https://arxiv.org/abs/2602.08337)
*Sheng Yan,Yong Wang,Xin Du,Junsong Yuan,Mengyuan Liu*

Main category: cs.CV

TL;DR: 提出语言引导的标记化方法(LG-Tok)，通过自然语言对齐实现高效运动离散标记化，在减少标记数量的同时保持高质量重建，简化生成模型学习


<details>
  <summary>Details</summary>
Motivation: 传统运动离散标记化方法增加标记数量来提高重建质量，但这会使生成模型学习更困难。需要一种方法在保持高质量重建的同时降低生成复杂度

Method: 1. 提出语言引导标记化(LG-Tok)，在标记化阶段对齐自然语言与运动，产生紧凑的高层语义表示；2. 设计基于Transformer的标记器，利用注意力机制支持全局语言引导；3. 提出语言丢弃方案，训练时随机移除语言条件，使解标记器支持无语言引导生成

Result: 在HumanML3D和Motion-X基准测试中，LG-Tok获得Top-1分数0.542和0.582，优于SOTA方法(MARDM: 0.500和0.528)；FID分数分别为0.057和0.088，优于0.114和0.147。LG-Tok-mini仅使用一半标记仍保持竞争力

Conclusion: 语言引导的标记化方法能有效对齐语言与运动，产生紧凑语义表示，在减少标记数量的同时保持高质量重建，简化生成模型学习，在运动生成任务中优于现有方法

Abstract: In this paper, we focus on motion discrete tokenization, which converts raw motion into compact discrete tokens--a process proven crucial for efficient motion generation. In this paradigm, increasing the number of tokens is a common approach to improving motion reconstruction quality, but more tokens make it more difficult for generative models to learn. To maintain high reconstruction quality while reducing generation complexity, we propose leveraging language to achieve efficient motion tokenization, which we term Language-Guided Tokenization (LG-Tok). LG-Tok aligns natural language with motion at the tokenization stage, yielding compact, high-level semantic representations. This approach not only strengthens both tokenization and detokenization but also simplifies the learning of generative models. Furthermore, existing tokenizers predominantly adopt convolutional architectures, whose local receptive fields struggle to support global language guidance. To this end, we propose a Transformer-based Tokenizer that leverages attention mechanisms to enable effective alignment between language and motion. Additionally, we design a language-drop scheme, in which language conditions are randomly removed during training, enabling the detokenizer to support language-free guidance during generation. On the HumanML3D and Motion-X generation benchmarks, LG-Tok achieves Top-1 scores of 0.542 and 0.582, outperforming state-of-the-art methods (MARDM: 0.500 and 0.528), and with FID scores of 0.057 and 0.088, respectively, versus 0.114 and 0.147. LG-Tok-mini uses only half the tokens while maintaining competitive performance (Top-1: 0.521/0.588, FID: 0.085/0.071), validating the efficiency of our semantic representations.

</details>


### [146] [UrbanGraphEmbeddings: Learning and Evaluating Spatially Grounded Multimodal Embeddings for Urban Science](https://arxiv.org/abs/2602.08342)
*Jie Zhang,Xingtong Yu,Yuan Fang,Rudi Stouffs,Zdravko Trivic*

Main category: cs.CV

TL;DR: UGData数据集将街景图像与空间图对齐，UGE两阶段训练策略结合指令引导对比学习和图空间编码，UGBench评估基准显示在空间密集型城市任务上显著提升性能


<details>
  <summary>Details</summary>
Motivation: 城市理解本质上是空间性的，但现有数据集缺乏街景图像与城市结构的显式对齐，这限制了可迁移多模态嵌入的学习

Method: 1) 引入UGData数据集，将街景图像锚定到结构化空间图，提供空间推理路径和空间上下文描述；2) 提出UGE两阶段训练策略，结合指令引导对比学习和基于图的空间编码；3) 使用LoRA微调在多个VLM骨干上训练固定维度空间嵌入

Result: 基于Qwen2.5-VL-7B骨干的UGE在训练城市上图像检索提升44%，地理位置排名提升30%；在未见城市上分别提升30%和22%，证明了显式空间接地对空间密集型城市任务的有效性

Conclusion: 显式空间接地对于学习可迁移的城市多模态嵌入至关重要，UGData、UGE和UGBench为城市空间理解提供了数据集、训练策略和评估基准

Abstract: Learning transferable multimodal embeddings for urban environments is challenging because urban understanding is inherently spatial, yet existing datasets and benchmarks lack explicit alignment between street-view images and urban structure. We introduce UGData, a spatially grounded dataset that anchors street-view images to structured spatial graphs and provides graph-aligned supervision via spatial reasoning paths and spatial context captions, exposing distance, directionality, connectivity, and neighborhood context beyond image content. Building on UGData, we propose UGE, a two-stage training strategy that progressively and stably aligns images, text, and spatial structures by combining instruction-guided contrastive learning with graph-based spatial encoding. We finally introduce UGBench, a comprehensive benchmark to evaluate how spatially grounded embeddings support diverse urban understanding tasks -- including geolocation ranking, image retrieval, urban perception, and spatial grounding. We develop UGE on multiple state-of-the-art VLM backbones, including Qwen2-VL, Qwen2.5-VL, Phi-3-Vision, and LLaVA1.6-Mistral, and train fixed-dimensional spatial embeddings with LoRA tuning. UGE built upon Qwen2.5-VL-7B backbone achieves up to 44% improvement in image retrieval and 30% in geolocation ranking on training cities, and over 30% and 22% gains respectively on held-out cities, demonstrating the effectiveness of explicit spatial grounding for spatially intensive urban tasks.

</details>


### [147] [What, Whether and How? Unveiling Process Reward Models for Thinking with Images Reasoning](https://arxiv.org/abs/2602.08346)
*Yujin Zhou,Pengcheng Wen,Jiale Chen,Boqin Yin,Han Zhu,Jiaming Ji,Juntao Dai,Chi-Min Chan,Sirui Han*

Main category: cs.CV

TL;DR: 首个针对"图像思维"范式中过程奖励模型(PRMs)的综合基准，包含1206条人工标注的推理轨迹，定义了7种细粒度错误类型，揭示了当前大视觉语言模型作为PRMs的局限性。


<details>
  <summary>Details</summary>
Motivation: 随着大视觉语言模型(LVLMs)的发展，"图像思维"范式允许模型在推理过程中动态编辑和重新编码视觉信息。然而，这种范式引入了推理过程中的各种错误，需要过程奖励模型(PRMs)来区分正负推理步骤。现有PRM基准主要是文本中心的，缺乏针对这种范式的全面评估。

Method: 1. 通过分析推理轨迹和PRMs引导搜索实验，定义了7种细粒度错误类型；2. 构建包含1206条人工标注的"图像思维"推理轨迹的基准，涵盖4个类别和16个子类别；3. 实验分析当前LVLMs作为PRMs的性能。

Result: 当前LVLMs作为PRMs表现不足：1. 视觉推理过程评估能力有限；2. 在不同错误类型间性能差异显著；3. 存在正向评估偏差；4. 对推理步骤位置敏感。这些发现证明了基准的有效性。

Conclusion: 该工作建立了首个针对"图像思维"范式的PRM综合基准，揭示了当前LVLMs作为PRMs的局限性，为推进LVLMs中PRMs的发展奠定了重要基础。

Abstract: The rapid advancement of Large Vision Language Models (LVLMs) has demonstrated excellent abilities in various visual tasks. Building upon these developments, the thinking with images paradigm has emerged, enabling models to dynamically edit and re-encode visual information at each reasoning step, mirroring human visual processing. However, this paradigm introduces significant challenges as diverse errors may occur during reasoning processes. This necessitates Process Reward Models (PRMs) for distinguishing positive and negative reasoning steps, yet existing benchmarks for PRMs are predominantly text-centric and lack comprehensive assessment under this paradigm. To address these gaps, this work introduces the first comprehensive benchmark specifically designed for evaluating PRMs under the thinking with images paradigm. Our main contributions are: (1) Through extensive analysis of reasoning trajectories and guided search experiments with PRMs, we define 7 fine-grained error types and demonstrate both the necessity for specialized PRMs and the potential for improvement. (2) We construct a comprehensive benchmark comprising 1,206 manually annotated thinking with images reasoning trajectories spanning 4 categories and 16 subcategories for fine-grained evaluation of PRMs. (3) Our experimental analysis reveals that current LVLMs fall short as effective PRMs, exhibiting limited capabilities in visual reasoning process evaluation with significant performance disparities across error types, positive evaluation bias, and sensitivity to reasoning step positions. These findings demonstrate the effectiveness of our benchmark and establish crucial foundations for advancing PRMs in LVLMs.

</details>


### [148] [E-VAds: An E-commerce Short Videos Understanding Benchmark for MLLMs](https://arxiv.org/abs/2602.08355)
*Xianjie Liu,Yiman Hu,Liang Wu,Ping Hu,Yixiong Zou,Jian Xu,Bo Zheng*

Main category: cs.CV

TL;DR: 提出了首个电商短视频理解基准E-VAds，包含3,961个淘宝视频和19,785个问答对，并开发了基于强化学习的E-VAds-R1模型，在商业意图推理上获得109.2%性能提升。


<details>
  <summary>Details</summary>
Motivation: 电商短视频具有目标驱动和多模态信号密集的特点，现有模型难以处理，因为现有基准主要关注通用任务而忽略了商业意图推理。

Method: 1) 提出多模态信息密度评估框架量化电商内容复杂度；2) 构建E-VAds基准，包含3,961个淘宝视频和19,785个问答对，分为感知与认知推理两个维度五个任务；3) 开发E-VAds-R1模型，采用基于MG-GRPO多粒度奖励设计的强化学习方法。

Result: 评估显示电商内容在多模态上密度显著高于主流数据集；E-VAds-R1仅用数百个训练样本就在商业意图推理上实现了109.2%的性能提升。

Conclusion: 电商短视频理解是一个具有挑战性的前沿领域，E-VAds基准填补了该领域空白，E-VAds-R1模型展示了强化学习在商业意图推理上的有效性。

Abstract: E-commerce short videos represent a high-revenue segment of the online video industry characterized by a goal-driven format and dense multi-modal signals. Current models often struggle with these videos because existing benchmarks focus primarily on general-purpose tasks and neglect the reasoning of commercial intent. In this work, we first propose a \textbf{multi-modal information density assessment framework} to quantify the complexity of this domain. Our evaluation reveals that e-commerce content exhibits substantially higher density across visual, audio, and textual modalities compared to mainstream datasets, establishing a more challenging frontier for video understanding. To address this gap, we introduce \textbf{E-commerce Video Ads Benchmark (E-VAds)}, which is the first benchmark specifically designed for e-commerce short video understanding. We curated 3,961 high-quality videos from Taobao covering a wide range of product categories and used a multi-agent system to generate 19,785 open-ended Q&A pairs. These questions are organized into two primary dimensions, namely Perception and Cognition and Reasoning, which consist of five distinct tasks. Finally, we develop \textbf{E-VAds-R1}, an RL-based reasoning model featuring a multi-grained reward design called \textbf{MG-GRPO}. This strategy provides smooth guidance for early exploration while creating a non-linear incentive for expert-level precision. Experimental results demonstrate that E-VAds-R1 achieves a 109.2% performance gain in commercial intent reasoning with only a few hundred training samples.

</details>


### [149] [Geometric Image Editing via Effects-Sensitive In-Context Inpainting with Diffusion Transformers](https://arxiv.org/abs/2602.08388)
*Shuo Zhang,Wenzhuo Wu,Huayu Zhang,Jiarong Cheng,Xianghao Zang,Chao Ban,Hao Sun,Zhongjiang He,Tianwei Cao,Kongming Liang,Zhanyu Ma*

Main category: cs.CV

TL;DR: GeoEdit是一个基于扩散模型的图像编辑框架，通过扩散变换器模块实现精确的几何变换（平移、旋转、缩放），并引入效果敏感注意力机制来增强光照和阴影效果的真实感。


<details>
  <summary>Details</summary>
Motivation: 现有扩散模型在图像编辑中面临两大挑战：1）难以实现精确的几何变换（平移、旋转、缩放）；2）对复杂光照和阴影效果建模不足，导致结果不真实。这些问题在复杂场景中尤为突出。

Method: 提出GeoEdit框架，包含两个核心组件：1）基于扩散变换器模块的上下文生成机制，集成几何变换实现精确对象编辑；2）效果敏感注意力机制，增强复杂光照和阴影效果的建模。此外构建了RS-Objects数据集（包含12万+高质量图像对）用于训练。

Result: 在公开基准测试中，GeoEdit在视觉质量、几何精度和真实感方面均优于现有最先进方法，能够实现精确的几何编辑并生成逼真的光照和阴影效果。

Conclusion: GeoEdit通过创新的扩散变换器架构和效果敏感注意力机制，有效解决了扩散模型在几何变换和光照效果建模方面的局限性，为复杂场景下的精确图像编辑提供了有效解决方案。

Abstract: Recent advances in diffusion models have significantly improved image editing. However, challenges persist in handling geometric transformations, such as translation, rotation, and scaling, particularly in complex scenes. Existing approaches suffer from two main limitations: (1) difficulty in achieving accurate geometric editing of object translation, rotation, and scaling; (2) inadequate modeling of intricate lighting and shadow effects, leading to unrealistic results. To address these issues, we propose GeoEdit, a framework that leverages in-context generation through a diffusion transformer module, which integrates geometric transformations for precise object edits. Moreover, we introduce Effects-Sensitive Attention, which enhances the modeling of intricate lighting and shadow effects for improved realism. To further support training, we construct RS-Objects, a large-scale geometric editing dataset containing over 120,000 high-quality image pairs, enabling the model to learn precise geometric editing while generating realistic lighting and shadows. Extensive experiments on public benchmarks demonstrate that GeoEdit consistently outperforms state-of-the-art methods in terms of visual quality, geometric accuracy, and realism.

</details>


### [150] [D$^2$-VR: Degradation-Robust and Distilled Video Restoration with Synergistic Optimization Strategy](https://arxiv.org/abs/2602.08395)
*Jianfeng Liang,Shaocheng Shen,Botao Xu,Qiang Hu,Xiaoyun Zhang*

Main category: cs.CV

TL;DR: D²-VR：基于单图像扩散的视频修复框架，通过退化鲁棒流对齐和对抗蒸馏实现12倍加速，在保持感知质量的同时提升时间稳定性


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散先验和时间对齐的视频修复方法虽然能提供优秀的感知质量，但在面对复杂真实世界退化时存在推理延迟高和时间不稳定的问题，限制了实际部署

Method: 1. 设计退化鲁棒流对齐（DRFA）模块，利用置信度感知注意力过滤不可靠运动线索；2. 采用对抗蒸馏范式将扩散采样轨迹压缩到快速少步机制；3. 设计协同优化策略平衡感知质量和时间一致性

Result: D²-VR在保持最先进性能的同时，将采样过程加速12倍，显著提升了时间稳定性

Conclusion: 提出的D²-VR框架有效解决了现有扩散视频修复方法的延迟和不稳定问题，为实际部署提供了高效可靠的解决方案

Abstract: The integration of diffusion priors with temporal alignment has emerged as a transformative paradigm for video restoration, delivering fantastic perceptual quality, yet the practical deployment of such frameworks is severely constrained by prohibitive inference latency and temporal instability when confronted with complex real-world degradations. To address these limitations, we propose \textbf{D$^2$-VR}, a single-image diffusion-based video-restoration framework with low-step inference. To obtain precise temporal guidance under severe degradation, we first design a Degradation-Robust Flow Alignment (DRFA) module that leverages confidence-aware attention to filter unreliable motion cues. We then incorporate an adversarial distillation paradigm to compress the diffusion sampling trajectory into a rapid few-step regime. Finally, a synergistic optimization strategy is devised to harmonize perceptual quality with rigorous temporal consistency. Extensive experiments demonstrate that D$^2$-VR achieves state-of-the-art performance while accelerating the sampling process by \textbf{12$\times$}

</details>


### [151] [RealSynCol: a high-fidelity synthetic colon dataset for 3D reconstruction applications](https://arxiv.org/abs/2602.08397)
*Chiara Lena,Davide Milesi,Alessandro Casella,Luca Carlini,Joseph C. Norton,James Martin,Bruno Scaglioni,Keith L. Obstein,Roberto De Sire,Marco Spadaccini,Cesare Hassan,Pietro Valdastri,Elena De Momi*

Main category: cs.CV

TL;DR: RealSynCol是一个高度真实的合成结肠镜数据集，用于解决结肠镜3D重建中真实标注数据稀缺的问题，显著提升深度学习模型在临床图像上的泛化性能。


<details>
  <summary>Details</summary>
Motivation: 深度学习有潜力通过3D重建改善结肠镜检查，提供全面的黏膜表面和病变视图，并帮助识别未探索区域。然而，大规模真实标注数据的稀缺限制了稳健方法的发展。

Method: 从10个CT扫描中提取结肠几何结构，导入到模拟术中条件的虚拟环境中，使用真实血管纹理进行渲染。生成28,130帧图像，配对了深度图、光流、3D网格和相机轨迹等真实标注。

Result: 基准研究表明，RealSynCol的高真实性和多样性显著提升了在临床图像上的泛化性能，证明它是开发支持内镜诊断的深度学习算法的强大工具。

Conclusion: RealSynCol合成数据集通过高度真实的模拟解决了结肠镜数据稀缺问题，为开发用于内镜诊断的深度学习算法提供了有效支持。

Abstract: Deep learning has the potential to improve colonoscopy by enabling 3D reconstruction of the colon, providing a comprehensive view of mucosal surfaces and lesions, and facilitating the identification of unexplored areas. However, the development of robust methods is limited by the scarcity of large-scale ground truth data. We propose RealSynCol, a highly realistic synthetic dataset designed to replicate the endoscopic environment. Colon geometries extracted from 10 CT scans were imported into a virtual environment that closely mimics intraoperative conditions and rendered with realistic vascular textures. The resulting dataset comprises 28\,130 frames, paired with ground truth depth maps, optical flow, 3D meshes, and camera trajectories. A benchmark study was conducted to evaluate the available synthetic colon datasets for the tasks of depth and pose estimation. Results demonstrate that the high realism and variability of RealSynCol significantly enhance generalization performance on clinical images, proving it to be a powerful tool for developing deep learning algorithms to support endoscopic diagnosis.

</details>


### [152] [Understanding and Optimizing Attention-Based Sparse Matching for Diverse Local Features](https://arxiv.org/abs/2602.08430)
*Qiang Wang*

Main category: cs.CV

TL;DR: 研究发现注意力稀疏图像匹配模型的关键设计选择，指出检测器而非描述子是性能差异主因，提出通过多检测器关键点微调的通用模型，实现零样本匹配达到专用模型精度


<details>
  <summary>Details</summary>
Motivation: 重新审视基于注意力的稀疏图像匹配模型训练，识别先前被忽视的关键设计选择对LightGlue模型性能的重要影响，探究检测器和描述子在transformer匹配框架中的角色差异

Method: 首先识别关键设计选择，然后分析检测器与描述子在transformer匹配框架中的作用，最后提出使用多种检测器的关键点对现有图像匹配模型进行微调，构建通用的检测器无关模型

Result: 当作为零样本匹配器用于新检测器时，所提出的通用模型达到或超过专门为这些特征训练的模型的准确性，检测器而非描述子是性能差异的主要来源

Conclusion: 研究结果为transformer匹配模型的部署和局部特征的未来设计提供了有价值的见解，证明了构建检测器无关的通用匹配模型的可行性

Abstract: We revisit the problem of training attention-based sparse image matching models for various local features. We first identify one critical design choice that has been previously overlooked, which significantly impacts the performance of the LightGlue model. We then investigate the role of detectors and descriptors within the transformer-based matching framework, finding that detectors, rather than descriptors, are often the primary cause for performance difference. Finally, we propose a novel approach to fine-tune existing image matching models using keypoints from a diverse set of detectors, resulting in a universal, detector-agnostic model. When deployed as a zero-shot matcher for novel detectors, the resulting model achieves or exceeds the accuracy of models specifically trained for those features. Our findings offer valuable insights for the deployment of transformer-based matching models and the future design of local features.

</details>


### [153] [Demo-ICL: In-Context Learning for Procedural Video Knowledge Acquisition](https://arxiv.org/abs/2602.08439)
*Yuhao Dong,Shulin Tian,Shuai Liu,Shuangrui Ding,Yuhang Zang,Xiaoyi Dong,Yuhang Cao,Jiaqi Wang,Ziwei Liu*

Main category: cs.CV

TL;DR: 论文提出了Demo驱动的视频上下文学习新任务和相应基准Demo-ICL-Bench，并开发了Demo-ICL模型来应对这一挑战，通过两阶段训练策略提升模型从少量示例中学习的能力。


<details>
  <summary>Details</summary>
Motivation: 现有视频基准主要评估模型基于静态内部知识理解视频的能力，而非从动态新颖上下文中通过少量示例学习和适应的能力。为填补这一空白，需要新的任务和基准来评估视频上下文学习能力。

Method: 1) 提出Demo驱动的视频上下文学习新任务；2) 构建Demo-ICL-Bench基准，包含1200个教学YouTube视频及相关问题，提供文本演示（总结视频字幕）和视频演示两种演示类型；3) 开发Demo-ICL模型，采用两阶段训练策略：视频监督微调和信息辅助直接偏好优化。

Result: 实验表明Demo-ICL-Bench对现有最先进MLLMs具有挑战性，而Demo-ICL模型在该基准上表现出有效性，揭示了未来研究方向。

Conclusion: 论文成功填补了视频上下文学习评估的空白，提出的新任务、基准和模型为视频理解领域提供了重要进展，展示了从少量演示中学习的能力对视频理解的重要性。

Abstract: Despite the growing video understanding capabilities of recent Multimodal Large Language Models (MLLMs), existing video benchmarks primarily assess understanding based on models' static, internal knowledge, rather than their ability to learn and adapt from dynamic, novel contexts from few examples. To bridge this gap, we present Demo-driven Video In-Context Learning, a novel task focused on learning from in-context demonstrations to answer questions about the target videos. Alongside this, we propose Demo-ICL-Bench, a challenging benchmark designed to evaluate demo-driven video in-context learning capabilities. Demo-ICL-Bench is constructed from 1200 instructional YouTube videos with associated questions, from which two types of demonstrations are derived: (i) summarizing video subtitles for text demonstration; and (ii) corresponding instructional videos as video demonstrations. To effectively tackle this new challenge, we develop Demo-ICL, an MLLM with a two-stage training strategy: video-supervised fine-tuning and information-assisted direct preference optimization, jointly enhancing the model's ability to learn from in-context examples. Extensive experiments with state-of-the-art MLLMs confirm the difficulty of Demo-ICL-Bench, demonstrate the effectiveness of Demo-ICL, and thereby unveil future research directions.

</details>


### [154] [Vista: Scene-Aware Optimization for Streaming Video Question Answering under Post-Hoc Queries](https://arxiv.org/abs/2602.08448)
*Haocheng Lu,Nan Zhang,Wei Tao,Xiaoyang Qu,Guokuan Li,Jiguang Wan,Jianzong Wang*

Main category: cs.CV

TL;DR: Vista是一个用于流式视频问答的新型框架，通过场景感知的分割、压缩和召回机制，实现高效可扩展的连续视频流推理。


<details>
  <summary>Details</summary>
Motivation: 流式视频问答对多模态大语言模型提出独特挑战：视频帧顺序到达，用户查询可在任意时间点发出。现有基于固定大小内存或简单压缩的方法常导致上下文丢失或内存溢出，限制了在长时、实时场景中的有效性。

Method: Vista框架包含三个创新方面：1) 场景感知分割：动态将传入帧聚类为时空和视觉一致的场景单元；2) 场景感知压缩：将每个场景压缩为紧凑的token表示存储在GPU内存中，全分辨率帧卸载到CPU内存；3) 场景感知召回：收到查询时选择性召回相关场景并重新整合到模型输入中。

Result: 在StreamingBench上的大量实验表明，Vista实现了最先进的性能，为真实世界的流式视频理解建立了强大的基线。

Conclusion: Vista是一个模型无关的框架，可无缝集成多种视觉语言骨干网络，在不影响延迟或内存效率的情况下实现长上下文推理，为流式视频问答提供了高效可扩展的解决方案。

Abstract: Streaming video question answering (Streaming Video QA) poses distinct challenges for multimodal large language models (MLLMs), as video frames arrive sequentially and user queries can be issued at arbitrary time points. Existing solutions relying on fixed-size memory or naive compression often suffer from context loss or memory overflow, limiting their effectiveness in long-form, real-time scenarios. We present Vista, a novel framework for scene-aware streaming video QA that enables efficient and scalable reasoning over continuous video streams. The innovation of Vista can be summarized in three aspects: (1) scene-aware segmentation, where Vista dynamically clusters incoming frames into temporally and visually coherent scene units; (2) scene-aware compression, where each scene is compressed into a compact token representation and stored in GPU memory for efficient index-based retrieval, while full-resolution frames are offloaded to CPU memory; and (3) scene-aware recall, where relevant scenes are selectively recalled and reintegrated into the model input upon receiving a query, enabling both efficiency and completeness. Vista is model-agnostic and integrates seamlessly with a variety of vision-language backbones, enabling long-context reasoning without compromising latency or memory efficiency. Extensive experiments on StreamingBench demonstrate that Vista achieves state-of-the-art performance, establishing a strong baseline for real-world streaming video understanding.

</details>


### [155] [TriC-Motion: Tri-Domain Causal Modeling Grounded Text-to-Motion Generation](https://arxiv.org/abs/2602.08462)
*Yiyang Cao,Yunze Deng,Ziyu Lin,Bin Feng,Xinggang Wang,Wenyu Liu,Dandan Zheng,Jingdong Chen*

Main category: cs.CV

TL;DR: TriC-Motion：基于扩散的三域因果文本到动作生成框架，通过时空频三域联合建模与因果干预，提升动作生成质量


<details>
  <summary>Details</summary>
Motivation: 现有文本到动作生成方法主要关注时空建模或独立的频域分析，缺乏跨空间、时间和频率域的联合优化框架，导致无法同时利用所有域的信息，生成质量受限。此外，动作生成框架中常存在动作无关噪声与有益特征的纠缠，导致动作失真。

Method: 提出TriC-Motion框架：1）三个核心建模模块：时间动作编码、空间拓扑建模、混合频率分析；2）分数引导的三域融合模块整合三域有价值信息；3）基于因果的反事实动作解耦器，通过暴露动作无关线索消除噪声，解耦各域的真实建模贡献。

Result: 在HumanML3D数据集上达到R@1为0.612的优异性能，优于现有最先进方法，能够生成高保真、连贯、多样且与文本对齐的动作序列。

Conclusion: TriC-Motion通过时空频三域联合建模与因果干预，有效解决了现有方法的局限性，显著提升了文本到动作生成的质量和一致性。

Abstract: Text-to-motion generation, a rapidly evolving field in computer vision, aims to produce realistic and text-aligned motion sequences. Current methods primarily focus on spatial-temporal modeling or independent frequency domain analysis, lacking a unified framework for joint optimization across spatial, temporal, and frequency domains. This limitation hinders the model's ability to leverage information from all domains simultaneously, leading to suboptimal generation quality. Additionally, in motion generation frameworks, motion-irrelevant cues caused by noise are often entangled with features that contribute positively to generation, thereby leading to motion distortion. To address these issues, we propose Tri-Domain Causal Text-to-Motion Generation (TriC-Motion), a novel diffusion-based framework integrating spatial-temporal-frequency-domain modeling with causal intervention. TriC-Motion includes three core modeling modules for domain-specific modeling, namely Temporal Motion Encoding, Spatial Topology Modeling, and Hybrid Frequency Analysis. After comprehensive modeling, a Score-guided Tri-domain Fusion module integrates valuable information from the triple domains, simultaneously ensuring temporal consistency, spatial topology, motion trends, and dynamics. Moreover, the Causality-based Counterfactual Motion Disentangler is meticulously designed to expose motion-irrelevant cues to eliminate noise, disentangling the real modeling contributions of each domain for superior generation. Extensive experimental results validate that TriC-Motion achieves superior performance compared to state-of-the-art methods, attaining an outstanding R@1 of 0.612 on the HumanML3D dataset. These results demonstrate its capability to generate high-fidelity, coherent, diverse, and text-aligned motion sequences. Code is available at: https://caoyiyang1105.github.io/TriC-Motion/.

</details>


### [156] [Gesture Matters: Pedestrian Gesture Recognition for AVs Through Skeleton Pose Evaluation](https://arxiv.org/abs/2602.08479)
*Alif Rizqullah Mahdi,Mahdi Rezaei,Natasha Merat*

Main category: cs.CV

TL;DR: 提出基于2D姿态估计的手势分类框架，用于自动驾驶车辆识别行人手势，在真实世界WIVW数据集上实现87%的分类准确率。


<details>
  <summary>Details</summary>
Motivation: 交通中手势是非语言交流的关键组成部分，有助于行人-驾驶员交互，但自动驾驶车辆难以解释这些手势，需要解决这一感知能力不足的问题。

Method: 使用2D姿态估计处理WIVW数据集视频序列，将手势分为四类（停止、前进、感谢/问候、无手势），从归一化关键点提取76个静态和动态特征。

Result: 研究发现手部位置和移动速度对区分手势类别特别有效，分类准确率达到87%，显著提升了自动驾驶系统的感知能力。

Conclusion: 该框架不仅提高了自动驾驶车辆的手势识别能力，还增进了对交通场景中行人行为的理解，有助于更安全的车辆-行人交互。

Abstract: Gestures are a key component of non-verbal communication in traffic, often helping pedestrian-to-driver interactions when formal traffic rules may be insufficient. This problem becomes more apparent when autonomous vehicles (AVs) struggle to interpret such gestures. In this study, we present a gesture classification framework using 2D pose estimation applied to real-world video sequences from the WIVW dataset. We categorise gestures into four primary classes (Stop, Go, Thank & Greet, and No Gesture) and extract 76 static and dynamic features from normalised keypoints. Our analysis demonstrates that hand position and movement velocity are especially discriminative in distinguishing between gesture classes, achieving a classification accuracy score of 87%. These findings not only improve the perceptual capabilities of AV systems but also contribute to the broader understanding of pedestrian behaviour in traffic contexts.

</details>


### [157] [Enhanced Food Category Recognition under Illumination-Induced Domain Shift](https://arxiv.org/abs/2602.08491)
*Keonvin Park,Aditya Pal,Jin Hong Mok*

Main category: cs.CV

TL;DR: 该研究探讨了光照变化对多类别食品识别系统的影响，通过合成光照增强数据集和跨数据集评估，提出了提升光照鲁棒性的方法。


<details>
  <summary>Details</summary>
Motivation: 现实环境中的视觉食品识别系统（如自动传送带检测）对光照变化引起的领域偏移非常敏感。现有研究通常局限于单一食品类别或受控环境，且大多数公开食品数据集缺乏明确的光照标注，因此需要研究光照变化对多类别食品识别的影响。

Method: 使用Food-101和Fruits-360两个广泛采用的数据集，通过系统变化光照色温和强度构建合成光照增强数据集，进行跨数据集评估和领域泛化分析，特别关注苹果类等光照敏感目标类别。

Result: 实验结果显示，由于视觉条件不匹配，跨数据集评估存在显著的准确率下降。光照感知增强方法显著提高了在领域偏移下的识别鲁棒性，同时保持了实时性能。

Conclusion: 研究强调了光照鲁棒性的重要性，为在现实世界检测场景中部署可靠的食品识别系统提供了实用见解。光照感知增强是提升系统在光照变化环境下性能的有效方法。

Abstract: Visual food recognition systems deployed in real-world environments, such as automated conveyor-belt inspection, are highly sensitive to domain shifts caused by illumination changes. While recent studies have shown that lighting variations can significantly distort food perception by both humans and AI, existing works are often limited to single food categories or controlled settings, and most public food datasets lack explicit illumination annotations.
  In this work, we investigate illumination-induced domain shift in multi-class food category recognition using two widely adopted datasets, Food-101 and Fruits-360. We demonstrate substantial accuracy degradation under cross-dataset evaluation due to mismatched visual conditions. To address this challenge, we construct synthetic illumination-augmented datasets by systematically varying light temperature and intensity, enabling controlled robustness analysis without additional labels.
  We further evaluate cross-dataset transfer learning and domain generalization, with a focus on illumination-sensitive target categories such as apple-based classes. Experimental results show that illumination-aware augmentation significantly improves recognition robustness under domain shift while preserving real-time performance. Our findings highlight the importance of illumination robustness and provide practical insights for deploying reliable food recognition systems in real-world inspection scenarios.

</details>


### [158] [Are Vision Foundation Models Foundational for Electron Microscopy Image Segmentation?](https://arxiv.org/abs/2602.08505)
*Caterina Fuster-Barceló,Virginie Uhlmann*

Main category: cs.CV

TL;DR: 研究评估了视觉基础模型在生物医学图像分析中的迁移能力，发现虽然单个电子显微镜数据集上能获得良好分割性能，但跨数据集训练会导致性能显著下降，表明当前参数高效微调策略不足以处理异构数据集间的领域差异。


<details>
  <summary>Details</summary>
Motivation: 尽管视觉基础模型越来越多地被用于生物医学图像分析，但尚不清楚其潜在表示是否足够通用，能够有效支持跨异构显微镜图像数据集的迁移和重用。本研究旨在探索这一问题，特别针对电子显微镜图像中的线粒体分割任务。

Method: 使用两个流行的公开EM数据集（Lucchi++和VNC）和三个代表性视觉基础模型（DINOv2、DINOv3和OpenCLIP）。评估两种模型适应方案：1）冻结主干网络，仅训练轻量级分割头；2）通过低秩适应进行参数高效微调。使用多种技术（PCA、Fréchet Dinov2距离和线性探针）探索潜在表示空间。

Result: 在单个EM数据集上训练时，所有主干网络都能获得良好的分割性能（前景交并比），LoRA能持续提升域内性能。然而，在多个EM数据集上训练会导致所有模型性能严重下降，PEFT仅带来边际改善。潜在表示空间分析显示两个EM数据集间存在显著且持久的领域不匹配，尽管它们视觉上相似。

Conclusion: 视觉基础模型在单个领域内通过轻量级适应可以获得有竞争力的EM分割结果，但当前的PEFT策略不足以获得跨异构EM数据集的单一鲁棒模型，需要额外的领域对齐机制。

Abstract: Although vision foundation models (VFMs) are increasingly reused for biomedical image analysis, it remains unclear whether the latent representations they provide are general enough to support effective transfer and reuse across heterogeneous microscopy image datasets. Here, we study this question for the problem of mitochondria segmentation in electron microscopy (EM) images, using two popular public EM datasets (Lucchi++ and VNC) and three recent representative VFMs (DINOv2, DINOv3, and OpenCLIP). We evaluate two practical model adaptation regimes: a frozen-backbone setting in which only a lightweight segmentation head is trained on top of the VFM, and parameter-efficient fine-tuning (PEFT) via Low-Rank Adaptation (LoRA) in which the VFM is fine-tuned in a targeted manner to a specific dataset. Across all backbones, we observe that training on a single EM dataset yields good segmentation performance (quantified as foreground Intersection-over-Union), and that LoRA consistently improves in-domain performance. In contrast, training on multiple EM datasets leads to severe performance degradation for all models considered, with only marginal gains from PEFT. Exploration of the latent representation space through various techniques (PCA, Fréchet Dinov2 distance, and linear probes) reveals a pronounced and persistent domain mismatch between the two considered EM datasets in spite of their visual similarity, which is consistent with the observed failure of paired training. These results suggest that, while VFMs can deliver competitive results for EM segmentation within a single domain under lightweight adaptation, current PEFT strategies are insufficient to obtain a single robust model across heterogeneous EM datasets without additional domain-alignment mechanisms.

</details>


### [159] [GeoFocus: Blending Efficient Global-to-Local Perception for Multimodal Geometry Problem-Solving](https://arxiv.org/abs/2602.08524)
*Linger Deng,Yuliang Liu,Wenwen Yu,Zujia Zhang,Jianzhong Ju,Zhenbo Luo,Xiang Bai*

Main category: cs.CV

TL;DR: GeoFocus是一个解决几何问题的多模态模型框架，通过关键局部感知器和VertexLang语言提升几何推理能力


<details>
  <summary>Details</summary>
Motivation: 几何问题解决对大型多模态模型具有挑战性，需要全局形状识别和关注与几何理论相关的复杂局部关系

Method: 提出GeoFocus框架，包含两个核心模块：1) 关键局部感知器，通过13个基于理论的感知模板自动识别和强调关键局部结构；2) VertexLang，紧凑的拓扑形式语言，通过顶点坐标和连接关系编码全局图形

Result: 在Geo3K、GeoQA和FormalGeo7K评估中，GeoFocus比领先的专业模型准确率提升4.7%，在MATHVERSE不同视觉条件下表现出优越鲁棒性

Conclusion: GeoFocus通过增强局部特征感知和高效全局编码，显著提升了多模态模型在几何问题解决上的性能

Abstract: Geometry problem-solving remains a significant challenge for Large Multimodal Models (LMMs), requiring not only global shape recognition but also attention to intricate local relationships related to geometric theory. To address this, we propose GeoFocus, a novel framework comprising two core modules. 1) Critical Local Perceptor, which automatically identifies and emphasizes critical local structure (e.g., angles, parallel lines, comparative distances) through thirteen theory-based perception templates, boosting critical local feature coverage by 61% compared to previous methods. 2) VertexLang, a compact topology formal language, encodes global figures through vertex coordinates and connectivity relations. By replacing bulky code-based encodings, VertexLang reduces global perception training time by 20% while improving topology recognition accuracy. When evaluated in Geo3K, GeoQA, and FormalGeo7K, GeoFocus achieves a 4.7% accuracy improvement over leading specialized models and demonstrates superior robustness in MATHVERSE under diverse visual conditions. Project Page -- https://github.com/dle666/GeoFocus

</details>


### [160] [Automatic regularization parameter choice for tomography using a double model approach](https://arxiv.org/abs/2602.08528)
*Chuyang Wu,Samuli Siltanen*

Main category: cs.CV

TL;DR: 提出一种基于双网格离散化的自动正则化参数选择方法，通过反馈控制算法动态调整参数，使两个网格上的重建结果达到足够相似性


<details>
  <summary>Details</summary>
Motivation: X射线断层扫描中的图像重建是病态逆问题，特别是在数据有限的情况下。正则化至关重要，但其效果取决于正则化参数的选择，该参数需要在数据保真度和先验信息之间取得平衡。传统参数选择方法需要人工干预或计算成本高。

Method: 提出一种新颖的自动参数选择方法，基于同一问题的两个不同计算离散化。使用反馈控制算法动态调整正则化强度，驱动迭代重建趋向于能够使两个网格上重建结果达到足够相似性的最小参数。

Result: 该方法在实际断层扫描数据上证明了有效性，能够自动选择适当的正则化参数，提高重建质量。

Conclusion: 提出的双网格方法提供了一种有效的自动正则化参数选择策略，解决了X射线断层扫描中病态逆问题的参数选择难题，无需人工干预即可获得良好的重建结果。

Abstract: Image reconstruction in X-ray tomography is an ill-posed inverse problem, particularly with limited available data. Regularization is thus essential, but its effectiveness hinges on the choice of a regularization parameter that balances data fidelity against a priori information. We present a novel method for automatic parameter selection based on the use of two distinct computational discretizations of the same problem. A feedback control algorithm dynamically adjusts the regularization strength, driving an iterative reconstruction toward the smallest parameter that yields sufficient similarity between reconstructions on the two grids. The effectiveness of the proposed approach is demonstrated using real tomographic data.

</details>


### [161] [Thegra: Graph-based SLAM for Thermal Imagery](https://arxiv.org/abs/2602.08531)
*Anastasiia Kornilova,Ivan Moskalenko,Arabella Gromova,Gonzalo Ferrer,Alexander Menshchikov*

Main category: cs.CV

TL;DR: 提出一种基于稀疏单目图SLAM系统，利用在可见光谱数据上训练的通用学习特征（SuperPoint检测器和LightGlue匹配器）来处理热成像数据，通过预处理和置信度加权因子图提高在低纹理热图像上的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 热成像在视觉退化环境（如低光照、烟雾、恶劣天气）中具有实用价值，但热图像通常具有低纹理、低对比度和高噪声的特点，这使得基于特征的SLAM变得困难。现有方法需要针对热数据进行特定训练，而高质量热数据稀缺。

Method: 1. 使用在可见光谱大数据上训练的通用学习特征（SuperPoint检测器和LightGlue匹配器）实现跨域泛化；2. 引入预处理管道增强热图像输入适应性；3. 修改核心SLAM模块处理稀疏和异常值特征匹配；4. 将SuperPoint的关键点置信度分数整合到置信度加权因子图中。

Result: 在公开热数据集上的评估表明，所提出的系统实现了可靠的性能，无需针对特定数据集进行训练或微调特征检测器，解决了高质量热数据稀缺的问题。

Conclusion: 该工作提出了一种有效的热成像SLAM系统，利用可见光谱训练的通用学习特征实现跨域泛化，通过预处理和置信度加权因子图提高鲁棒性，为视觉退化环境中的定位与建图提供了实用解决方案。

Abstract: Thermal imaging provides a practical sensing modality for visual SLAM in visually degraded environments such as low illumination, smoke, or adverse weather. However, thermal imagery often exhibits low texture, low contrast, and high noise, complicating feature-based SLAM. In this work, we propose a sparse monocular graph-based SLAM system for thermal imagery that leverages general-purpose learned features -- the SuperPoint detector and LightGlue matcher, trained on large-scale visible-spectrum data to improve cross-domain generalization. To adapt these components to thermal data, we introduce a preprocessing pipeline to enhance input suitability and modify core SLAM modules to handle sparse and outlier-prone feature matches. We further incorporate keypoint confidence scores from SuperPoint into a confidence-weighted factor graph to improve estimation robustness. Evaluations on public thermal datasets demonstrate that the proposed system achieves reliable performance without requiring dataset-specific training or fine-tuning a desired feature detector, given the scarcity of quality thermal data. Code will be made available upon publication.

</details>


### [162] [TIBR4D: Tracing-Guided Iterative Boundary Refinement for Efficient 4D Gaussian Segmentation](https://arxiv.org/abs/2602.08540)
*He Wu,Xia Yan,Yanghui Xu,Liegang Xia,Jiazhou Chen*

Main category: cs.CV

TL;DR: 提出TIBR4D框架，通过两阶段迭代边界细化实现动态4D高斯场景中的高效免学习对象分割，提升边界清晰度和分割准确性


<details>
  <summary>Details</summary>
Motivation: 动态4D高斯场景中的对象级分割面临复杂运动、遮挡和模糊边界的挑战，现有方法难以处理这些问题

Method: 提出TIBR4D框架：1) IGIT阶段通过迭代高斯实例追踪在时间片段级细化高斯到实例的概率；2) RCC阶段通过抑制边界附近不确定性高斯实现帧级渲染范围控制；3) 提出时间分割合并策略平衡身份一致性和动态感知

Result: 在HyperNeRF和Neu3D数据集上实验表明，相比SOTA方法，本方法能生成边界更清晰、效率更高的对象高斯点云

Conclusion: TIBR4D框架有效解决了动态4D高斯场景中的对象分割问题，通过两阶段边界细化策略显著提升了分割质量和效率

Abstract: Object-level segmentation in dynamic 4D Gaussian scenes remains challenging due to complex motion, occlusions, and ambiguous boundaries. In this paper, we present an efficient learning-free 4D Gaussian segmentation framework that lifts video segmentation masks to 4D spaces, whose core is a two-stage iterative boundary refinement, TIBR4D. The first stage is an Iterative Gaussian Instance Tracing (IGIT) at the temporal segment level. It progressively refines Gaussian-to-instance probabilities through iterative tracing, and extracts corresponding Gaussian point clouds that better handle occlusions and preserve completeness of object structures compared to existing one-shot threshold-based methods. The second stage is a frame-wise Gaussian Rendering Range Control (RCC) via suppressing highly uncertain Gaussians near object boundaries while retaining their core contributions for more accurate boundaries. Furthermore, a temporal segmentation merging strategy is proposed for IGIT to balance identity consistency and dynamic awareness. Longer segments enforce stronger multi-frame constraints for stable identities, while shorter segments allow identity changes to be captured promptly. Experiments on HyperNeRF and Neu3D demonstrate that our method produces accurate object Gaussian point clouds with clearer boundaries and higher efficiency compared to SOTA methods.

</details>


### [163] [GOT-Edit: Geometry-Aware Generic Object Tracking via Online Model Editing](https://arxiv.org/abs/2602.08550)
*Shih-Fang Chen,Jun-Cheng Chen,I-Hong Jhuo,Yen-Yu Lin*

Main category: cs.CV

TL;DR: GOT-Edit：一种在线跨模态模型编辑方法，通过将几何感知线索整合到通用目标跟踪器中，结合2D语义和3D几何推理，提升跟踪性能


<details>
  <summary>Details</summary>
Motivation: 人类感知结合了3D先验知识和语义推理，而现有通用目标跟踪方法主要依赖2D特征，忽略了3D几何线索，导致对部分遮挡、干扰物以及几何和外观变化的鲁棒性不足

Method: 提出GOT-Edit在线跨模态模型编辑方法：1) 利用预训练的视觉几何基础Transformer从少量2D图像推断几何线索；2) 通过零空间约束更新进行在线模型编辑，在保持语义判别能力的同时融入几何信息

Result: 在多个通用目标跟踪基准测试上的广泛实验表明，GOT-Edit实现了优越的鲁棒性和准确性，特别是在遮挡和杂乱场景下，为结合2D语义和3D几何推理建立了新范式

Conclusion: GOT-Edit通过在线模型编辑成功将几何感知线索整合到通用目标跟踪中，显著提升了跟踪性能，特别是在具有挑战性的场景下，为2D语义与3D几何推理的结合提供了有效解决方案

Abstract: Human perception for effective object tracking in a 2D video stream arises from the implicit use of prior 3D knowledge combined with semantic reasoning. In contrast, most generic object tracking (GOT) methods primarily rely on 2D features of the target and its surroundings while neglecting 3D geometric cues, which makes them susceptible to partial occlusion, distractors, and variations in geometry and appearance. To address this limitation, we introduce GOT-Edit, an online cross-modality model editing approach that integrates geometry-aware cues into a generic object tracker from a 2D video stream. Our approach leverages features from a pre-trained Visual Geometry Grounded Transformer to enable geometric cue inference from only a few 2D images. To tackle the challenge of seamlessly combining geometry and semantics, GOT-Edit performs online model editing with null-space constrained updates that incorporate geometric information while preserving semantic discrimination, yielding consistently better performance across diverse scenarios. Extensive experiments on multiple GOT benchmarks demonstrate that GOT-Edit achieves superior robustness and accuracy, particularly under occlusion and clutter, establishing a new paradigm for combining 2D semantics with 3D geometric reasoning for generic object tracking.

</details>


### [164] [FLAG-4D: Flow-Guided Local-Global Dual-Deformation Model for 4D Reconstruction](https://arxiv.org/abs/2602.08558)
*Guan Yuan Tan,Ngoc Tuan Vu,Arghya Pal,Sailaja Rajanala,Raphael Phan C. -W.,Mettu Srinivas,Chee-Ming Ting*

Main category: cs.CV

TL;DR: FLAG-4D是一个新颖的动态场景新视角生成框架，通过双变形网络建模3D高斯原语在时空中的演化，解决了现有方法在复杂点运动和细粒度动态细节建模上的不足。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常依赖单个MLP建模时间变形，难以从稀疏输入视图中一致地捕捉复杂点运动和细粒度动态细节，特别是在长时间序列中。

Method: 采用双变形网络动态扭曲规范3D高斯集：瞬时变形网络(IDN)建模细粒度局部变形，全局运动网络(GMN)捕捉长程动态，通过相互学习优化。融合预训练光流骨干的密集运动特征，使用变形引导注意力机制对齐光流信息与每个演化3D高斯的当前状态。

Result: 大量实验表明，FLAG-4D相比最先进方法实现了更高保真度、更时间一致的重建，并更好地保留了细粒度细节。

Conclusion: FLAG-4D通过双变形网络和光流特征融合，显著提升了动态场景新视角生成的质量和时间一致性，为复杂动态场景建模提供了有效解决方案。

Abstract: We introduce FLAG-4D, a novel framework for generating novel views of dynamic scenes by reconstructing how 3D Gaussian primitives evolve through space and time. Existing methods typically rely on a single Multilayer Perceptron (MLP) to model temporal deformations, and they often struggle to capture complex point motions and fine-grained dynamic details consistently over time, especially from sparse input views. Our approach, FLAG-4D, overcomes this by employing a dual-deformation network that dynamically warps a canonical set of 3D Gaussians over time into new positions and anisotropic shapes. This dual-deformation network consists of an Instantaneous Deformation Network (IDN) for modeling fine-grained, local deformations and a Global Motion Network (GMN) for capturing long-range dynamics, refined through mutual learning. To ensure these deformations are both accurate and temporally smooth, FLAG-4D incorporates dense motion features from a pretrained optical flow backbone. We fuse these motion cues from adjacent timeframes and use a deformation-guided attention mechanism to align this flow information with the current state of each evolving 3D Gaussian. Extensive experiments demonstrate that FLAG-4D achieves higher-fidelity and more temporally coherent reconstructions with finer detail preservation than state-of-the-art methods.

</details>


### [165] [SemiNFT: Learning to Transfer Presets from Imitation to Appreciation via Hybrid-Sample Reinforcement Learning](https://arxiv.org/abs/2602.08582)
*Melany Yang,Yuhang Yu,Diwang Weng,Jinwei Chen,Wei Dong*

Main category: cs.CV

TL;DR: SemiNFT是一个基于扩散Transformer的彩色修图框架，通过模仿人类艺术训练轨迹（从刚性模仿到直觉创作），在保持结构的同时实现高质量的色彩迁移。


<details>
  <summary>Details</summary>
Motivation: 现有基于参考图像的色彩迁移方法主要依赖像素级统计进行全局色彩映射，缺乏对语义上下文和人类美学的真正理解，无法满足专业级修图需求。

Method: 采用Diffusion Transformer架构，分两阶段训练：1）使用配对三元组学习基本结构保持和色彩映射技能；2）在无配对数据上进行强化学习，培养细腻美学感知，并设计混合在线-离线奖励机制防止技能遗忘。

Result: 在标准预设迁移基准测试中超越现有方法，在零样本任务（如黑白照片着色、动漫到照片的跨域预设迁移）中表现出色，证明其超越了简单的统计匹配，达到了高级美学理解水平。

Conclusion: SemiNFT通过模仿人类艺术学习轨迹，实现了从刚性模仿到直觉创作的过渡，在色彩修图任务中展现出超越统计匹配的语义理解和美学感知能力。

Abstract: Photorealistic color retouching plays a vital role in visual content creation, yet manual retouching remains inaccessible to non-experts due to its reliance on specialized expertise. Reference-based methods offer a promising alternative by transferring the preset color of a reference image to a source image. However, these approaches often operate as novice learners, performing global color mappings derived from pixel-level statistics, without a true understanding of semantic context or human aesthetics. To address this issue, we propose SemiNFT, a Diffusion Transformer (DiT)-based retouching framework that mirrors the trajectory of human artistic training: beginning with rigid imitation and evolving into intuitive creation. Specifically, SemiNFT is first taught with paired triplets to acquire basic structural preservation and color mapping skills, and then advanced to reinforcement learning (RL) on unpaired data to cultivate nuanced aesthetic perception. Crucially, during the RL stage, to prevent catastrophic forgetting of old skills, we design a hybrid online-offline reward mechanism that anchors aesthetic exploration with structural review. % experiments Extensive experiments show that SemiNFT not only outperforms state-of-the-art methods on standard preset transfer benchmarks but also demonstrates remarkable intelligence in zero-shot tasks, such as black-and-white photo colorization and cross-domain (anime-to-photo) preset transfer. These results confirm that SemiNFT transcends simple statistical matching and achieves a sophisticated level of aesthetic comprehension. Our project can be found at https://melanyyang.github.io/SemiNFT/.

</details>


### [166] [Overview and Comparison of AVS Point Cloud Compression Standard](https://arxiv.org/abs/2602.08613)
*Wei Gao,Wenxu Gao,Xingming Mu,Changhao Peng,Ge Li*

Main category: cs.CV

TL;DR: 本文回顾了中国AVS PCC点云压缩标准，从技术工具和性能比较两个角度进行分析，展示了其与MPEG标准（G-PCC和V-PCC）的不同之处。


<details>
  <summary>Details</summary>
Motivation: 点云作为重要的3D数据表示格式，在沉浸式媒体、自动驾驶、数字遗产保护等领域有广泛应用价值，但其大数据量对传输和存储带来挑战，因此点云压缩在实际应用中至关重要。

Method: 从两个视角回顾AVS PCC标准：1) 相关技术工具分析，2) 性能比较。重点介绍AVS PCC采用的新编码工具和技术，这些与MPEG的G-PCC和V-PCC标准有所不同。

Result: 中国AVS工作组已完成第一代点云压缩标准AVS PCC的开发，该标准采用了多项新的编码工具和技术，与MPEG标准形成差异化。

Conclusion: AVS PCC作为中国自主的点云压缩标准，通过采用新的编码工具和技术，为点云压缩提供了另一种标准化解决方案，有助于推动点云技术在实际应用中的广泛部署。

Abstract: Point cloud is a prevalent 3D data representation format with significant application values in immersive media, autonomous driving, digital heritage protection, etc. However, the large data size of point clouds poses challenges to transmission and storage, which influences the wide deployments. Therefore, point cloud compression plays a crucial role in practical applications for both human and machine perception optimization. To this end, the Moving Picture Experts Group (MPEG) has established two standards for point cloud compression, including Geometry-based Point Cloud Compression (G-PCC) and Video-based Point Cloud Compression (V-PCC). In the meantime, the Audio Video coding Standard (AVS) Workgroup of China also have launched and completed the development for its first generation point cloud compression standard, namely AVS PCC. This new standardization effort has adopted many new coding tools and techniques, which are different from the other counterpart standards. This paper reviews the AVS PCC standard from two perspectives, i.e., the related technologies and performance comparisons.

</details>


### [167] [Inspiration Seeds: Learning Non-Literal Visual Combinations for Generative Exploration](https://arxiv.org/abs/2602.08615)
*Kfir Goldberg,Elad Richardson,Yael Vinker*

Main category: cs.CV

TL;DR: 提出Inspiration Seeds框架，将图像生成从最终执行转向探索性构思，通过视觉输入而非文本提示生成多样化组合，揭示输入图像间的潜在关系


<details>
  <summary>Details</summary>
Motivation: 现有生成模型主要针对精心设计的文本提示进行优化，不支持开放式的视觉探索，而设计师经常从松散连接的视觉参考中寻找灵感，需要能揭示潜在关系、激发新想法的工具

Method: 使用前馈模型，基于合成三元组训练：利用CLIP稀疏自编码器在CLIP潜在空间中提取编辑方向，隔离概念对，完全通过视觉手段分解视觉方面，无需用户指定文本提示

Result: 模型能够给定两个输入图像，生成多样化且视觉连贯的组合，揭示输入之间的潜在关系，支持快速直观的视觉重组

Conclusion: 通过消除对语言的依赖并实现快速直观的重组，该方法支持创意工作早期和模糊阶段的视觉构思，将生成模型从最终执行工具转变为探索性构思工具

Abstract: While generative models have become powerful tools for image synthesis, they are typically optimized for executing carefully crafted textual prompts, offering limited support for the open-ended visual exploration that often precedes idea formation. In contrast, designers frequently draw inspiration from loosely connected visual references, seeking emergent connections that spark new ideas. We propose Inspiration Seeds, a generative framework that shifts image generation from final execution to exploratory ideation. Given two input images, our model produces diverse, visually coherent compositions that reveal latent relationships between inputs, without relying on user-specified text prompts. Our approach is feed-forward, trained on synthetic triplets of decomposed visual aspects derived entirely through visual means: we use CLIP Sparse Autoencoders to extract editing directions in CLIP latent space and isolate concept pairs. By removing the reliance on language and enabling fast, intuitive recombination, our method supports visual ideation at the early and ambiguous stages of creative work.

</details>


### [168] [Improving Reconstruction of Representation Autoencoder](https://arxiv.org/abs/2602.08620)
*Siyu Liu,Chujie Qin,Hubery Yin,Qixin Yan,Zheng-Peng Duan,Chen Li,Jing Lyu,Chun-Le Guo,Chongyi Li*

Main category: cs.CV

TL;DR: LV-RAE是一种表示自编码器，通过增强语义特征的低级信息来提升潜在扩散模型的生成质量，同时保持语义对齐。


<details>
  <summary>Details</summary>
Motivation: 现有视觉基础模型作为图像编码器虽然能提升潜在扩散模型的生成性能，但其语义特征缺乏低级信息（如颜色和纹理），导致重建保真度下降，成为进一步扩展LDMs的主要瓶颈。

Method: 提出LV-RAE表示自编码器，通过增强语义特征的低级信息实现高保真重建；同时通过微调解码器增强鲁棒性，并通过受控噪声注入平滑生成潜在表示。

Result: 实验表明LV-RAE显著提高了重建保真度，同时保持了语义抽象能力，实现了强大的生成质量。

Conclusion: LV-RAE通过增强语义特征的低级信息解决了现有方法的局限性，同时通过增强解码器鲁棒性和潜在表示平滑化，显著提升了生成质量。

Abstract: Recent work leverages Vision Foundation Models as image encoders to boost the generative performance of latent diffusion models (LDMs), as their semantic feature distributions are easy to learn. However, such semantic features often lack low-level information (\eg, color and texture), leading to degraded reconstruction fidelity, which has emerged as a primary bottleneck in further scaling LDMs. To address this limitation, we propose LV-RAE, a representation autoencoder that augments semantic features with missing low-level information, enabling high-fidelity reconstruction while remaining highly aligned with the semantic distribution. We further observe that the resulting high-dimensional, information-rich latent make decoders sensitive to latent perturbations, causing severe artifacts when decoding generated latent and consequently degrading generation quality. Our analysis suggests that this sensitivity primarily stems from excessive decoder responses along directions off the data manifold. Building on these insights, we propose fine-tuning the decoder to increase its robustness and smoothing the generated latent via controlled noise injection, thereby enhancing generation quality. Experiments demonstrate that LV-RAE significantly improves reconstruction fidelity while preserving the semantic abstraction and achieving strong generative quality. Our code is available at https://github.com/modyu-liu/LVRAE.

</details>


### [169] [Revisiting [CLS] and Patch Token Interaction in Vision Transformers](https://arxiv.org/abs/2602.08626)
*Alexis Marouani,Oriane Siméoni,Hervé Jégou,Piotr Bojanowski,Huy V. Vo*

Main category: cs.CV

TL;DR: 论文提出通过专门化处理路径来分离类别token和补丁token的计算流，特别是在归一化层和早期QKV投影中，从而提升密集预测任务的性能。


<details>
  <summary>Details</summary>
Motivation: Vision Transformers中类别token和补丁token虽然性质不同（全局vs局部特征），但在整个模型中却被相同处理。作者研究了不同预训练策略下全局和局部特征学习之间的摩擦，发现标准归一化层在这两种token类型之间引入了隐式区分。

Method: 提出专门化处理路径，选择性地解耦类别token和补丁token的计算流，特别是在归一化层和早期查询-键-值投影中。这种方法针对性地专门化处理两种token类型。

Result: 在标准基准测试中，分割性能提升了超过2 mIoU点，同时保持了强大的分类准确性。提出的修改仅增加了8%的参数，没有额外的计算开销。

Conclusion: 通过专门化处理路径分离类别token和补丁token的计算流，可以显著提升密集预测任务的补丁表示质量，同时保持分类性能，且计算开销很小。

Abstract: Vision Transformers have emerged as powerful, scalable and versatile representation learners. To capture both global and local features, a learnable [CLS] class token is typically prepended to the input sequence of patch tokens. Despite their distinct nature, both token types are processed identically throughout the model. In this work, we investigate the friction between global and local feature learning under different pre-training strategies by analyzing the interactions between class and patch tokens. Our analysis reveals that standard normalization layers introduce an implicit differentiation between these token types. Building on this insight, we propose specialized processing paths that selectively disentangle the computational flow of class and patch tokens, particularly within normalization layers and early query-key-value projections. This targeted specialization leads to significantly improved patch representation quality for dense prediction tasks. Our experiments demonstrate segmentation performance gains of over 2 mIoU points on standard benchmarks, while maintaining strong classification accuracy. The proposed modifications introduce only an 8% increase in parameters, with no additional computational overhead. Through comprehensive ablations, we provide insights into which architectural components benefit most from specialization and how our approach generalizes across model scales and learning frameworks.

</details>


### [170] [Deep Learning-Based Fixation Type Prediction for Quality Assurance in Digital Pathology](https://arxiv.org/abs/2602.08652)
*Oskar Thaeter,Tanja Niedermair,Johannes Raffler,Ralf Huss,Peter J. Schüffler*

Main category: cs.CV

TL;DR: 提出基于深度学习的模型，使用低分辨率预扫描缩略图预测病理切片固定类型，相比现有方法速度提升400倍，在TCGA数据集上AUROC达0.88


<details>
  <summary>Details</summary>
Motivation: 病理切片固定类型（FFPE和FS）的手动标注容易出错，影响下游分析和诊断准确性。现有方法需要全分辨率全切片图像，限制了高通量质量控制的可扩展性。

Method: 开发深度学习模型，利用低分辨率预扫描缩略图预测固定类型。在TUM病理研究所的1200张WSI上训练，在TCGA（8800张）、奥格斯堡（695张）和雷根斯堡（202张）数据集上评估。

Result: 模型在TCGA数据集上AUROC达到0.88，比可比预扫描方法提升4.8%。在雷根斯堡和奥格斯堡数据集上AUROC为0.72。处理每张切片仅需21毫秒，比现有高倍率全分辨率方法快400倍。

Conclusion: 该方法为检测标注错误提供了高效解决方案，无需依赖高倍率扫描，是病理高通量工作流程中质量控制的有价值工具。未来工作将改进模型对不同扫描仪类型的泛化能力。

Abstract: Accurate annotation of fixation type is a critical step in slide preparation for pathology laboratories. However, this manual process is prone to
  errors, impacting downstream analyses and diagnostic accuracy. Existing methods for verifying formalin-fixed, paraffin-embedded (FFPE), and frozen
  section (FS) fixation types typically require full-resolution whole-slide images (WSIs), limiting scalability for high-throughput quality control.
  We propose a deep-learning model to predict fixation types using low-resolution, pre-scan thumbnail images. The model was trained on WSIs from
  the TUM Institute of Pathology (n=1,200, Leica GT450DX) and evaluated on a class-balanced subset of The Cancer Genome Atlas dataset (TCGA, n=8,800,
  Leica AT2), as well as on class-balanced datasets from Augsburg (n=695 [392 FFPE, 303 FS], Philips UFS) and Regensburg (n=202, 3DHISTECH P1000).
  Our model achieves an AUROC of 0.88 on TCGA, outperforming comparable pre-scan methods by 4.8%. It also achieves AUROCs of 0.72 on Regensburg and
  Augsburg slides, underscoring challenges related to scanner-induced domain shifts. Furthermore, the model processes each slide in 21 ms, $400\times$
  faster than existing high-magnification, full-resolution methods, enabling rapid, high-throughput processing.
  This approach provides an efficient solution for detecting labelling errors without relying on high-magnification scans, offering a valuable tool for
  quality control in high-throughput pathology workflows. Future work will improve and evaluate the model's generalisation to additional scanner
  types. Our findings suggest that this method can increase accuracy and efficiency in digital pathology workflows and may be extended to other
  low-resolution slide annotations.

</details>


### [171] [WiFlow: A Lightweight WiFi-based Continuous Human Pose Estimation Network with Spatio-Temporal Feature Decoupling](https://arxiv.org/abs/2602.08661)
*Yi Dao,Lankai Zhang,Hao Liu,Haiwei Zhang,Wenbo Wang*

Main category: cs.CV

TL;DR: WiFlow：基于WiFi信号的连续人体姿态估计框架，采用编码器-解码器架构，通过时空特征提取和轴向注意力机制，在自收集数据集上达到97% PCK@20精度，显著降低计算复杂度。


<details>
  <summary>Details</summary>
Motivation: 现有WiFi姿态估计方法在处理连续运动和计算开销方面存在不足，需要一种更高效、准确的连续人体姿态估计方案，以支持物联网智能感知应用。

Method: 提出WiFlow框架，采用编码器-解码器架构：编码器使用时序和非对称卷积提取CSI信号的时空特征，保持信号原始序列结构；通过轴向注意力机制精炼关键点特征并捕捉结构依赖；解码器将高维特征映射为关键点坐标。

Result: 在5名受试者8种日常活动的36万同步CSI-姿态样本数据集上，WiFlow达到PCK@20为97.00%，PCK@50为99.48%，平均关节位置误差0.008米，仅需482万参数，显著降低模型复杂度和计算成本。

Conclusion: WiFlow为实用的WiFi人体姿态估计建立了新的性能基准，在保持高精度的同时大幅降低计算复杂度，为物联网智能感知应用提供了高效解决方案。

Abstract: Human pose estimation is fundamental to intelligent perception in the Internet of Things (IoT), enabling applications ranging from smart healthcare to human-computer interaction. While WiFi-based methods have gained traction, they often struggle with continuous motion and high computational overhead. This work presents WiFlow, a novel framework for continuous human pose estimation using WiFi signals. Unlike vision-based approaches such as two-dimensional deep residual networks that treat Channel State Information (CSI) as images, WiFlow employs an encoder-decoder architecture. The encoder captures spatio-temporal features of CSI using temporal and asymmetric convolutions, preserving the original sequential structure of signals. It then refines keypoint features of human bodies to be tracked and capture their structural dependencies via axial attention. The decoder subsequently maps the encoded high-dimensional features into keypoint coordinates. Trained on a self-collected dataset of 360,000 synchronized CSI-pose samples from 5 subjects performing continuous sequences of 8 daily activities, WiFlow achieves a Percentage of Correct Keypoints (PCK) of 97.00% at a threshold of 20% (PCK@20) and 99.48% at PCK@50, with a mean per-joint position error of 0.008m. With only 4.82M parameters, WiFlow significantly reduces model complexity and computational cost, establishing a new performance baseline for practical WiFi-based human pose estimation. Our code and datasets are available at https://github.com/DY2434/WiFlow-WiFi-Pose-Estimation-with-Spatio-Temporal-Decoupling.git.

</details>


### [172] [A Machine Learning accelerated geophysical fluid solver](https://arxiv.org/abs/2602.08670)
*Yang Bai*

Main category: cs.CV

TL;DR: 该论文研究如何将机器学习应用于求解偏微分方程，特别是通过数据驱动的离散化方法改进结构化网格上的传统求解器，并在浅水方程和欧拉方程上验证了ML求解器的有效性。


<details>
  <summary>Details</summary>
Motivation: 机器学习在图像分类和自然语言处理等领域已取得成功，但在具有数学约束的领域（如求解偏微分方程）中的应用仍待探索。需要找到将ML技术有效应用于PDE求解的方法，以加速和改进现有求解器。

Method: 采用数据驱动的离散化方法，在结构化网格上预测准线性模板的系数，用于计算给定位置处的函数值或导数值。实现了浅水方程和欧拉方程的传统求解器，并提出了四种不同的深度神经网络用于ML求解器。

Result: 实验表明，传统求解器性能优于Pyclaw求解器。在提出的四种深度神经网络方法中，有两种能够输出令人满意的解。

Conclusion: 数据驱动的离散化方法为将机器学习应用于PDE求解提供了有前景的途径，能够提高低分辨率模拟的精度和稳定性，同时受益于传统数值格式的优势，如通过有限体积型公式实现守恒律。

Abstract: Machine learning methods have been successful in many areas, like image classification and natural language processing. However, it still needs to be determined how to apply ML to areas with mathematical constraints, like solving PDEs. Among various approaches to applying ML techniques to solving PDEs, the data-driven discretization method presents a promising way of accelerating and improving existing PDE solver on structured grids where it predicts the coefficients of quasi-linear stencils for computing values or derivatives of a function at given positions. It can improve the accuracy and stability of low-resolution simulation compared with using traditional finite difference or finite volume schemes. Meanwhile, it can also benefit from traditional numerical schemes like achieving conservation law by adapting finite volume type formulations. In this thesis, we have implemented the shallow water equation and Euler equation classic solver under a different framework. Experiments show that our classic solver performs much better than the Pyclaw solver. Then we propose four different deep neural networks for the ML-based solver. The results indicate that two of these approaches could output satisfactory solutions.

</details>


### [173] [ALIVE: Animate Your World with Lifelike Audio-Video Generation](https://arxiv.org/abs/2602.08682)
*Ying Guo,Qijun Gan,Yifu Zhang,Jinlai Liu,Yifei Hu,Pan Xie,Dongjun Qian,Yu Zhang,Ruiqi Li,Yuqi Zhang,Ruibiao Lu,Xiaofeng Mei,Bo Han,Xiang Yin,Bingyue Peng,Zehuan Yuan*

Main category: cs.CV

TL;DR: ALIVE是一个音频-视频生成模型，通过改造预训练的文本到视频(T2V)模型，实现了类似Sora的音频-视频生成和动画功能，在音频-视频同步和参考动画方面表现优异。


<details>
  <summary>Details</summary>
Motivation: 视频生成正快速向统一的音频-视频生成发展，现有T2V模型缺乏音频生成和动画能力，需要开发能够同时处理文本到音频视频(T2VA)和参考到音频视频(动画)的模型。

Method: 1. 在MMDiT架构基础上增加联合音频-视频分支，包含TA-CrossAttn用于时间对齐的跨模态融合和UniTemp-RoPE用于精确的音频-视频对齐；2. 设计全面的数据管道进行高质量微调数据收集；3. 引入新的基准测试进行模型评估；4. 在百万级高质量数据上进行持续预训练和微调。

Result: ALIVE表现出色，在性能上持续超越开源模型，匹配甚至超越最先进的商业解决方案，在音频-视频同步和参考动画方面表现优异。

Conclusion: ALIVE通过详细的实现方案和基准测试，为社区开发音频-视频生成模型提供了高效的工具，推动了音频-视频生成技术的发展。

Abstract: Video generation is rapidly evolving towards unified audio-video generation. In this paper, we present ALIVE, a generation model that adapts a pretrained Text-to-Video (T2V) model to Sora-style audio-video generation and animation. In particular, the model unlocks the Text-to-Video&Audio (T2VA) and Reference-to-Video&Audio (animation) capabilities compared to the T2V foundation models. To support the audio-visual synchronization and reference animation, we augment the popular MMDiT architecture with a joint audio-video branch which includes TA-CrossAttn for temporally-aligned cross-modal fusion and UniTemp-RoPE for precise audio-visual alignment. Meanwhile, a comprehensive data pipeline consisting of audio-video captioning, quality control, etc., is carefully designed to collect high-quality finetuning data. Additionally, we introduce a new benchmark to perform a comprehensive model test and comparison. After continue pretraining and finetuning on million-level high-quality data, ALIVE demonstrates outstanding performance, consistently outperforming open-source models and matching or surpassing state-of-the-art commercial solutions. With detailed recipes and benchmarks, we hope ALIVE helps the community develop audio-video generation models more efficiently. Official page: https://github.com/FoundationVision/Alive.

</details>


### [174] [OneVision-Encoder: Codec-Aligned Sparsity as a Foundational Principle for Multimodal Intelligence](https://arxiv.org/abs/2602.08683)
*Feilong Tang,Xiang An,Yunyao Yan,Yin Xie,Bin Qin,Kaicheng Yang,Yifei Shen,Yuanhan Zhang,Chunyuan Li,Shikun Feng,Changrui Chen,Huajie Tan,Ming Hu,Manyuan Zhang,Bo Li,Ziyong Feng,Ziwei Liu,Zongyuan Ge,Jiankang Deng*

Main category: cs.CV

TL;DR: 该论文提出视觉通用智能本质上是压缩问题，通过Codec Patchification技术聚焦信号熵丰富的区域（3.1%-25%），实现效率与精度的正相关，在16个基准测试中超越现有视觉骨干模型。


<details>
  <summary>Details</summary>
Motivation: 现代视觉架构偏离了信息论基本原则：视觉信号高度冗余而判别信息稀疏。当前模型均匀处理密集像素网格，浪费大量计算在静态背景而非定义运动和意义的预测残差上。需要将架构与视频的信息论原理（即编解码器）对齐。

Method: 采用Codec Patchification技术，放弃均匀计算，专注于信号熵丰富的区域（3.1%-25%）。使用共享3D RoPE统一空间和时间推理，通过大规模聚类判别目标在超过100万个语义概念上进行训练，联合捕捉对象持久性和运动动态。

Result: 在集成到LLM后，在16个图像、视频和文档理解基准测试中一致优于Qwen3-ViT和SigLIP2等强视觉骨干模型，尽管使用更少的视觉token和预训练数据。在视频理解任务上平均提升4.1%超过Qwen3-ViT。

Conclusion: 编解码器对齐的补丁级稀疏性是基本原则，使OV-Encoder成为下一代视觉通用智能的可扩展引擎。效率与精度不是权衡关系，而是正相关的。

Abstract: Hypothesis. Artificial general intelligence is, at its core, a compression problem. Effective compression demands resonance: deep learning scales best when its architecture aligns with the fundamental structure of the data. These are the fundamental principles. Yet, modern vision architectures have strayed from these truths: visual signals are highly redundant, while discriminative information, the surprise, is sparse. Current models process dense pixel grids uniformly, wasting vast compute on static background rather than focusing on the predictive residuals that define motion and meaning. We argue that to solve visual understanding, we must align our architectures with the information-theoretic principles of video, i.e., Codecs.
  Method. OneVision-Encoder encodes video by compressing predictive visual structure into semantic meaning. By adopting Codec Patchification, OV-Encoder abandons uniform computation to focus exclusively on the 3.1%-25% of regions rich in signal entropy. To unify spatial and temporal reasoning under irregular token layouts, OneVision-Encoder employs a shared 3D RoPE and is trained with a large-scale cluster discrimination objective over more than one million semantic concepts, jointly capturing object permanence and motion dynamics.
  Evidence. The results validate our core hypothesis: efficiency and accuracy are not a trade-off; they are positively correlated. When integrated into LLM, it consistently outperforms strong vision backbones such as Qwen3-ViT and SigLIP2 across 16 image, video, and document understanding benchmarks, despite using substantially fewer visual tokens and pretraining data. Notably, on video understanding tasks, OV-Encoder achieves an average improvement of 4.1% over Qwen3-ViT. Codec-aligned, patch-level sparsity is a foundational principle, enabling OV-Encoder as a scalable engine for next-generation visual generalists.

</details>


### [175] [Low-Light Video Enhancement with An Effective Spatial-Temporal Decomposition Paradigm](https://arxiv.org/abs/2602.08699)
*Xiaogang Xu,Kun Zhou,Tao Hu,Jiafei Wu,Ruixing Wang,Hao Peng,Bei Yu*

Main category: cs.CV

TL;DR: 提出VLLVE和VLLVE++框架，通过视图无关和视图相关分量分解策略增强低光视频，引入交叉帧交互和残差项提升性能。


<details>
  <summary>Details</summary>
Motivation: 低光视频增强面临严重不可见性和噪声问题，现有方法难以处理动态场景和真实世界挑战性情况。

Method: 1. VLLVE：视图无关分量（捕获内在外观）使用动态交叉帧对应关系，视图相关分量（描述光照条件）施加场景级连续性约束；2. 双结构增强网络带交叉帧交互机制；3. VLLVE++：引入加性残差项模拟场景自适应退化，支持双向学习和退化感知对应关系细化。

Result: 在广泛认可的低光视频增强基准测试上进行了大量实验，VLLVE++在处理真实世界场景和高动态视频等挑战性案例方面表现出强大能力。

Conclusion: 提出的视图感知低光视频增强框架通过创新的分解策略和网络设计，有效提升了低光视频增强性能，特别是在处理复杂动态场景方面具有优势。

Abstract: Low-Light Video Enhancement (LLVE) seeks to restore dynamic or static scenes plagued by severe invisibility and noise. In this paper, we present an innovative video decomposition strategy that incorporates view-independent and view-dependent components to enhance the performance of LLVE. The framework is called View-aware Low-light Video Enhancement (VLLVE). We leverage dynamic cross-frame correspondences for the view-independent term (which primarily captures intrinsic appearance) and impose a scene-level continuity constraint on the view-dependent term (which mainly describes the shading condition) to achieve consistent and satisfactory decomposition results. To further ensure consistent decomposition, we introduce a dual-structure enhancement network featuring a cross-frame interaction mechanism. By supervising different frames simultaneously, this network encourages them to exhibit matching decomposition features. This mechanism can seamlessly integrate with encoder-decoder single-frame networks, incurring minimal additional parameter costs. Building upon VLLVE, we propose a more comprehensive decomposition strategy by introducing an additive residual term, resulting in VLLVE++. This residual term can simulate scene-adaptive degradations, which are difficult to model using a decomposition formulation for common scenes, thereby further enhancing the ability to capture the overall content of videos. In addition, VLLVE++ enables bidirectional learning for both enhancement and degradation-aware correspondence refinement (end-to-end manner), effectively increasing reliable correspondences while filtering out incorrect ones. Notably, VLLVE++ demonstrates strong capability in handling challenging cases, such as real-world scenes and videos with high dynamics. Extensive experiments are conducted on widely recognized LLVE benchmarks.

</details>


### [176] [TimeChat-Captioner: Scripting Multi-Scene Videos with Time-Aware and Structural Audio-Visual Captions](https://arxiv.org/abs/2602.08711)
*Linli Yao,Yuancheng Wei,Yaojie Zhang,Lei Li,Xinlong Chen,Feifan Song,Ziyue Wang,Kun Ouyang,Yuanxin Liu,Lingpeng Kong,Qi Liu,Pengfei Wan,Kun Gai,Yuanxing Zhang,Xu Sun*

Main category: cs.CV

TL;DR: 提出Omni Dense Captioning新任务，构建高质量基准OmniDCBench和训练数据集TimeChatCap-42K，开发TimeChat-Captioner-7B模型，在密集描述生成和相关下游任务上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有视频描述任务通常生成简短、不连续的描述，缺乏细粒度和时间结构。需要一种能够生成连续、细粒度、结构化音视频叙事的方法，类似于电影剧本，让读者能够生动地想象视频内容。

Method: 1. 提出六维结构模式创建"脚本式"描述；2. 构建高质量人工标注基准OmniDCBench；3. 提出SodaM统一评估指标；4. 构建训练数据集TimeChatCap-42K；5. 开发TimeChat-Captioner-7B模型，采用SFT和GRPO训练，结合任务特定奖励。

Result: TimeChat-Captioner-7B在密集描述生成上超越Gemini-2.5-Pro达到SOTA，生成的密集描述显著提升音视频推理（DailyOmni和WorldSense）和时间定位（Charades-STA）等下游任务性能。

Conclusion: Omni Dense Captioning任务和TimeChat-Captioner-7B模型为生成连续、细粒度、结构化的音视频叙事提供了有效解决方案，在多个基准测试中表现出色，并显著提升下游任务能力。

Abstract: This paper proposes Omni Dense Captioning, a novel task designed to generate continuous, fine-grained, and structured audio-visual narratives with explicit timestamps. To ensure dense semantic coverage, we introduce a six-dimensional structural schema to create "script-like" captions, enabling readers to vividly imagine the video content scene by scene, akin to a cinematographic screenplay. To facilitate research, we construct OmniDCBench, a high-quality, human-annotated benchmark, and propose SodaM, a unified metric that evaluates time-aware detailed descriptions while mitigating scene boundary ambiguity. Furthermore, we construct a training dataset, TimeChatCap-42K, and present TimeChat-Captioner-7B, a strong baseline trained via SFT and GRPO with task-specific rewards. Extensive experiments demonstrate that TimeChat-Captioner-7B achieves state-of-the-art performance, surpassing Gemini-2.5-Pro, while its generated dense descriptions significantly boost downstream capabilities in audio-visual reasoning (DailyOmni and WorldSense) and temporal grounding (Charades-STA). All datasets, models, and code will be made publicly available at https://github.com/yaolinli/TimeChat-Captioner.

</details>


### [177] [Towards Understanding Multimodal Fine-Tuning: Spatial Features](https://arxiv.org/abs/2602.08713)
*Lachin Naghashyar,Hunar Batra,Ashkan Khakzar,Philip Torr,Ronald Clark,Christian Schroeder de Witt,Constantin Venhoff*

Main category: cs.CV

TL;DR: 该论文提出了一种机制分析方法，通过阶段式模型差异技术揭示视觉语言模型在微调过程中语言骨干如何学习"看"的能力，识别出视觉偏好特征及其空间关系编码机制。


<details>
  <summary>Details</summary>
Motivation: 尽管视觉语言模型在各种任务上表现优异，但语言骨干表示在多模态训练中如何适应以及视觉特定能力何时出现仍不清楚。需要理解预训练语言模型如何获得视觉基础能力。

Method: 采用阶段式模型差异技术，隔离多模态微调引入的表示变化。识别视觉偏好特征，分析空间关系编码，追踪特征因果激活到特定注意力头。

Result: 揭示了视觉偏好特征在多模态微调中出现或重新定向；这些特征的一个选择性子集可靠地编码空间关系；这些特征的因果激活可追溯到一小群注意力头。

Conclusion: 阶段式模型差异技术揭示了时空基础多模态特征何时何地出现，展示了视觉基础如何重塑原本仅用于文本的特征，增强了多模态训练的可解释性，为理解和改进预训练语言模型获取视觉基础能力提供了基础。

Abstract: Contemporary Vision-Language Models (VLMs) achieve strong performance on a wide range of tasks by pairing a vision encoder with a pre-trained language model, fine-tuned for visual-text inputs. Yet despite these gains, it remains unclear how language backbone representations adapt during multimodal training and when vision-specific capabilities emerge. In this work, we present the first mechanistic analysis of VLM adaptation. Using stage-wise model diffing, a technique that isolates representational changes introduced during multimodal fine-tuning, we reveal how a language model learns to "see". We first identify vision-preferring features that emerge or reorient during fine-tuning. We then show that a selective subset of these features reliably encodes spatial relations, revealed through controlled shifts to spatial prompts. Finally, we trace the causal activation of these features to a small group of attention heads. Our findings show that stage-wise model diffing reveals when and where spatially grounded multimodal features arise. It also provides a clearer view of modality fusion by showing how visual grounding reshapes features that were previously text-only. This methodology enhances the interpretability of multimodal training and provides a foundation for understanding and refining how pretrained language models acquire vision-grounded capabilities.

</details>


### [178] [Zero-shot System for Automatic Body Region Detection for Volumetric CT and MR Images](https://arxiv.org/abs/2602.08717)
*Farnaz Khun Jush,Grit Werner,Mark Klemens,Matthias Lenga*

Main category: cs.CV

TL;DR: 提出三种无需训练的零样本方法，利用预训练基础模型进行CT/MR图像体区域检测，其中基于分割的规则方法表现最佳。


<details>
  <summary>Details</summary>
Motivation: 现有解剖体区域识别方法过度依赖不可靠的DICOM元数据，且主要使用监督学习，限制了实际应用。需要探索零样本方法利用预训练基础模型的知识。

Method: 提出三种无需训练的流水线：1）基于预训练多器官分割模型的规则系统；2）遵循放射科医师规则的多模态大语言模型；3）结合视觉输入和解剖证据的分割感知MLLM。

Result: 在887个CT/MR扫描上评估，基于分割的规则方法表现最佳（CT加权F1分数0.947，MR 0.914），MLLM在视觉显著区域有竞争力，分割感知MLLM存在根本限制。

Conclusion: 基于分割的规则方法在零样本体区域检测中表现最优，展示了预训练基础模型的潜力，为不依赖DICOM元数据的可靠解剖识别提供了可行方案。

Abstract: Reliable identification of anatomical body regions is a prerequisite for many automated medical imaging workflows, yet existing solutions remain heavily dependent on unreliable DICOM metadata. Current solutions mainly use supervised learning, which limits their applicability in many real-world scenarios. In this work, we investigate whether body region detection in volumetric CT and MR images can be achieved in a fully zero-shot manner by using knowledge embedded in large pre-trained foundation models. We propose and systematically evaluate three training-free pipelines: (1) a segmentation-driven rule-based system leveraging pre-trained multi-organ segmentation models, (2) a Multimodal Large Language Model (MLLM) guided by radiologist-defined rules, and (3) a segmentation-aware MLLM that combines visual input with explicit anatomical evidence. All methods are evaluated on 887 heterogeneous CT and MR scans with manually verified anatomical region labels. The segmentation-driven rule-based approach achieves the strongest and most consistent performance, with weighted F1-scores of 0.947 (CT) and 0.914 (MR), demonstrating robustness across modalities and atypical scan coverage. The MLLM performs competitively in visually distinctive regions, while the segmentation-aware MLLM reveals fundamental limitations.

</details>


### [179] [Rotated Lights for Consistent and Efficient 2D Gaussians Inverse Rendering](https://arxiv.org/abs/2602.08724)
*Geng Lin,Matthias Zwicker*

Main category: cs.CV

TL;DR: RotLight：通过简单旋转拍摄解决逆渲染中的材质估计歧义问题，结合代理网格提升2DGS逆渲染效果


<details>
  <summary>Details</summary>
Motivation: 现有逆渲染方法在从神经辐射场或高斯泼溅分解场景时，材质和光照估计存在高度歧义，导致反照率估计出现不准确的颜色和烘焙阴影问题

Method: 提出RotLight简单拍摄设置，只需物体旋转几次即可减少歧义；引入代理网格支持精确入射光追踪、残差约束和改进全局光照处理

Result: 在合成和真实数据集上验证，仅需两次旋转即可有效减少伪影，实现更优的反照率估计同时保持计算效率

Conclusion: RotLight通过简单拍摄设置和代理网格改进，有效解决了逆渲染中的材质估计歧义问题，提升了反照率估计质量

Abstract: Inverse rendering aims to decompose a scene into its geometry, material properties and light conditions under a certain rendering model. It has wide applications like view synthesis, relighting, and scene editing. In recent years, inverse rendering methods have been inspired by view synthesis approaches like neural radiance fields and Gaussian splatting, which are capable of efficiently decomposing a scene into its geometry and radiance. They then further estimate the material and lighting that lead to the observed scene radiance. However, the latter step is highly ambiguous and prior works suffer from inaccurate color and baked shadows in their albedo estimation albeit their regularization. To this end, we propose RotLight, a simple capturing setup, to address the ambiguity. Compared to a usual capture, RotLight only requires the object to be rotated several times during the process. We show that as few as two rotations is effective in reducing artifacts. To further improve 2DGS-based inverse rendering, we additionally introduce a proxy mesh that not only allows accurate incident light tracing, but also enables a residual constraint and improves global illumination handling. We demonstrate with both synthetic and real world datasets that our method achieves superior albedo estimation while keeping efficient computation.

</details>


### [180] [FusionEdit: Semantic Fusion and Attention Modulation for Training-Free Image Editing](https://arxiv.org/abs/2602.08725)
*Yongwen Lai,Chaoqun Wang,Shaobo Min*

Main category: cs.CV

TL;DR: FusionEdit是一个无需训练的文本引导图像编辑框架，通过语义差异自动识别编辑区域，采用距离感知潜在融合和统计注意力融合，实现精确可控的编辑，避免硬掩码边界带来的伪影。


<details>
  <summary>Details</summary>
Motivation: 现有方法使用显式二进制掩码约束编辑，但硬掩码边界会引入伪影并降低可编辑性。需要一种能够实现精确可控编辑、避免边界伪影并保持图像一致性的解决方案。

Method: 1) 通过测量源提示词和目标提示词语义差异自动识别编辑和保留区域；2) 沿区域边界进行距离感知潜在融合生成软掩码，并使用总变差损失确保平滑过渡；3) 在DiT注意力层中采用AdaIN调制进行统计注意力融合，增强可编辑性同时保持全局一致性。

Result: 大量实验表明，FusionEdit在文本引导图像编辑任务上显著优于现有最先进方法，能够实现更自然、精确的编辑效果。

Conclusion: FusionEdit通过软掩码生成和统计注意力融合，有效解决了硬掩码边界带来的伪影问题，实现了精确可控的图像编辑，同时保持了源图像的身份特征。

Abstract: Text-guided image editing aims to modify specific regions according to the target prompt while preserving the identity of the source image. Recent methods exploit explicit binary masks to constrain editing, but hard mask boundaries introduce artifacts and reduce editability. To address these issues, we propose FusionEdit, a training-free image editing framework that achieves precise and controllable edits. First, editing and preserved regions are automatically identified by measuring semantic discrepancies between source and target prompts. To mitigate boundary artifacts, FusionEdit performs distance-aware latent fusion along region boundaries to yield the soft and accurate mask, and employs a total variation loss to enforce smooth transitions, obtaining natural editing results. Second, FusionEdit leverages AdaIN-based modulation within DiT attention layers to perform a statistical attention fusion in the editing region, enhancing editability while preserving global consistency with the source image. Extensive experiments demonstrate that our FusionEdit significantly outperforms state-of-the-art methods. Code is available at \href{https://github.com/Yvan1001/FusionEdit}{https://github.com/Yvan1001/FusionEdit}.

</details>


### [181] [SynSacc: A Blender-to-V2E Pipeline for Synthetic Neuromorphic Eye-Movement Data and Sim-to-Real Spiking Model Training](https://arxiv.org/abs/2602.08726)
*Khadija Iddrisu,Waseem Shariff,Suzanne Little,Noel OConnor*

Main category: cs.CV

TL;DR: 使用Blender生成合成事件相机数据集模拟眼动，结合脉冲神经网络实现高效的眼动分类，准确率达0.83


<details>
  <summary>Details</summary>
Motivation: 传统帧相机存在运动模糊问题，而事件相机能异步记录光强变化，提供更高时间分辨率和数据效率，适合捕捉快速眼动。但缺乏高质量事件数据集限制了相关研究发展。

Method: 1. 使用Blender生成合成数据集模拟扫视和注视眼动；2. 采用脉冲神经网络架构；3. 在真实事件数据上进行微调；4. 评估不同时间分辨率下的性能稳定性。

Result: 模型达到0.83准确率，在不同时间分辨率下保持稳定性能。脉冲神经网络相比人工神经网络获得显著计算效率提升，合成数据增强在事件视觉研究中具有实用价值。

Conclusion: 合成事件数据集结合脉冲神经网络为眼动分类提供了有效解决方案，展示了合成数据增强在事件视觉研究中的潜力，所有代码和数据集已开源。

Abstract: The study of eye movements, particularly saccades and fixations, are fundamental to understanding the mechanisms of human cognition and perception. Accurate classification of these movements requires sensing technologies capable of capturing rapid dynamics without distortion. Event cameras, also known as Dynamic Vision Sensors (DVS), provide asynchronous recordings of changes in light intensity, thereby eliminating motion blur inherent in conventional frame-based cameras and offering superior temporal resolution and data efficiency. In this study, we introduce a synthetic dataset generated with Blender to simulate saccades and fixations under controlled conditions. Leveraging Spiking Neural Networks (SNNs), we evaluate its robustness by training two architectures and finetuning on real event data. The proposed models achieve up to 0.83 accuracy and maintain consistent performance across varying temporal resolutions, demonstrating stability in eye movement classification. Moreover, the use of SNNs with synthetic event streams yields substantial computational efficiency gains over artificial neural network (ANN) counterparts, underscoring the utility of synthetic data augmentation in advancing event-based vision. All code and datasets associated with this work is available at https: //github.com/Ikhadija-5/SynSacc-Dataset.

</details>


### [182] [Artifact Reduction in Undersampled 3D Cone-Beam CTs using a Hybrid 2D-3D CNN Framework](https://arxiv.org/abs/2602.08727)
*Johannes Thalhammer,Tina Dorosti,Sebastian Peterhansl,Daniela Pfeiffer,Franz Pfeiffer,Florian Schaff*

Main category: cs.CV

TL;DR: 提出一种结合2D和3D模型的混合深度学习框架，用于从欠采样CT体积中去除伪影，平衡计算效率与体积一致性。


<details>
  <summary>Details</summary>
Motivation: 欠采样CT体积虽然减少了采集时间和辐射暴露，但会引入伪影，降低图像质量和诊断价值。需要有效去除这些伪影以获得高质量成像。

Method: 采用两阶段混合框架：首先使用2D U-Net处理单个CT切片提取特征图，然后将这些切片特征图堆叠成体积，输入到3D解码器中，利用跨切片上下文信息预测无伪影的3D CT体积。

Result: 在冠状面和矢状面方向上显著改善了切片间一致性，同时保持了较低的计算开销。

Conclusion: 该混合框架为高质量3D CT图像后处理提供了一个鲁棒且高效的解决方案。

Abstract: Undersampled CT volumes minimize acquisition time and radiation exposure but introduce artifacts degrading image quality and diagnostic utility. Reducing these artifacts is critical for high-quality imaging. We propose a computationally efficient hybrid deep-learning framework that combines the strengths of 2D and 3D models. First, a 2D U-Net operates on individual slices of undersampled CT volumes to extract feature maps. These slice-wise feature maps are then stacked across the volume and used as input to a 3D decoder, which utilizes contextual information across slices to predict an artifact-free 3D CT volume. The proposed two-stage approach balances the computational efficiency of 2D processing with the volumetric consistency provided by 3D modeling. The results show substantial improvements in inter-slice consistency in coronal and sagittal direction with low computational overhead. This hybrid framework presents a robust and efficient solution for high-quality 3D CT image post-processing. The code of this project can be found on github: https://github.com/J-3TO/2D-3DCNN_sparseview/.

</details>


### [183] [Closing the Confusion Loop: CLIP-Guided Alignment for Source-Free Domain Adaptation](https://arxiv.org/abs/2602.08730)
*Shanshan Wang,Ziying Feng,Xiaozheng Shen,Xun Yang,Pichao Wang,Zhenwei He,Xingyi Zhang*

Main category: cs.CV

TL;DR: 本文提出CLIP引导对齐(CGA)框架，通过显式建模和缓解类别混淆来改进无源域自适应(SFDA)，特别针对细粒度场景中源模型预测的不对称动态类别混淆问题。


<details>
  <summary>Details</summary>
Motivation: 现有SFDA方法通常忽略源模型在目标域中存在的非对称动态类别混淆问题，这种混淆在细粒度场景中尤为严重，导致伪标签噪声大和目标域判别性差。

Method: CGA包含三个核心组件：MCA检测定向混淆对，MCC利用CLIP构建混淆感知文本提示进行上下文敏感伪标注，FAM构建混淆引导特征库并通过对比学习对齐CLIP和源模型表示。

Result: 在多个数据集上的实验表明，CGA在SFDA方法中表现最优，特别是在易混淆和细粒度场景中取得显著提升。

Conclusion: 显式建模类别间混淆对有效的无源域自适应至关重要，CGA框架通过检测混淆、构建混淆感知提示和对齐表示空间，显著提升了SFDA性能。

Abstract: Source-Free Domain Adaptation (SFDA) tackles the problem of adapting a pre-trained source model to an unlabeled target domain without accessing any source data, which is quite suitable for the field of data security. Although recent advances have shown that pseudo-labeling strategies can be effective, they often fail in fine-grained scenarios due to subtle inter-class similarities. A critical but underexplored issue is the presence of asymmetric and dynamic class confusion, where visually similar classes are unequally and inconsistently misclassified by the source model. Existing methods typically ignore such confusion patterns, leading to noisy pseudo-labels and poor target discrimination. To address this, we propose CLIP-Guided Alignment(CGA), a novel framework that explicitly models and mitigates class confusion in SFDA. Generally, our method consists of three parts: (1) MCA: detects first directional confusion pairs by analyzing the predictions of the source model in the target domain; (2) MCC: leverages CLIP to construct confusion-aware textual prompts (e.g. a truck that looks like a bus), enabling more context-sensitive pseudo-labeling; and (3) FAM: builds confusion-guided feature banks for both CLIP and the source model and aligns them using contrastive learning to reduce ambiguity in the representation space. Extensive experiments on various datasets demonstrate that CGA consistently outperforms state-of-the-art SFDA methods, with especially notable gains in confusion-prone and fine-grained scenarios. Our results highlight the importance of explicitly modeling inter-class confusion for effective source-free adaptation. Our code can be find at https://github.com/soloiro/CGA

</details>


### [184] [From Correspondence to Actions: Human-Like Multi-Image Spatial Reasoning in Multi-modal Large Language Models](https://arxiv.org/abs/2602.08735)
*Masanari Oi,Koki Maeda,Ryuto Koike,Daisuke Oba,Nakamasa Inoue,Naoaki Okazaki*

Main category: cs.CV

TL;DR: HATCH是一个训练框架，通过补丁级空间对齐和动作-答案推理机制，提升多模态大语言模型在多图像空间推理任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型在单图像空间推理方面取得进展，但在需要整合多个视角信息的多图像空间推理任务上仍面临挑战。人类通过跨视图对应和逐步视角变换两种机制解决此类任务，但现有研究仅部分且隐式地融入这些机制，缺乏对两者的明确监督。

Method: 提出HATCH训练框架，包含两个互补目标：1) 补丁级空间对齐：鼓励不同视图中空间对应区域的补丁表示对齐；2) 动作-答案推理：要求模型在预测最终答案前生成明确的视角转换动作。

Result: 在三个基准测试中，HATCH始终以明显优势超越同等规模基线模型，并与更大模型取得竞争性结果，同时保持单图像推理能力。

Conclusion: 通过显式监督跨视图对应和逐步视角变换机制，HATCH有效提升了多模态大语言模型在多图像空间推理任务中的性能，实现了与人类认知机制更接近的推理过程。

Abstract: While multimodal large language models (MLLMs) have made substantial progress in single-image spatial reasoning, multi-image spatial reasoning, which requires integration of information from multiple viewpoints, remains challenging. Cognitive studies suggest that humans address such tasks through two mechanisms: cross-view correspondence, which identifies regions across different views that correspond to the same physical locations, and stepwise viewpoint transformation, which composes relative viewpoint changes sequentially. However, existing studies incorporate these mechanisms only partially and often implicitly, without explicit supervision for both. We propose Human-Aware Training for Cross-view correspondence and viewpoint cHange (HATCH), a training framework with two complementary objectives: (1) Patch-Level Spatial Alignment, which encourages patch representations to align across views for spatially corresponding regions, and (2) Action-then-Answer Reasoning, which requires the model to generate explicit viewpoint transition actions before predicting the final answer. Experiments on three benchmarks demonstrate that HATCH consistently outperforms baselines of comparable size by a clear margin and achieves competitive results against much larger models, while preserving single-image reasoning capabilities.

</details>


### [185] [Shifting the Breaking Point of Flow Matching for Multi-Instance Editing](https://arxiv.org/abs/2602.08749)
*Carmine Zaccagnino,Fabio Quattrini,Enis Simsar,Marta Tintoré Gazulla,Rita Cucchiara,Alessio Tonioni,Silvia Cascianelli*

Main category: cs.CV

TL;DR: 提出Instance-Disentangled Attention机制，解决流匹配模型在多实例编辑中语义干扰问题，实现单次推理的实例级图像编辑


<details>
  <summary>Details</summary>
Motivation: 现有基于流的图像编辑器主要支持全局或单指令编辑，难以处理多实例场景（需要独立编辑参考输入的多个部分而不产生语义干扰）。这种限制源于全局条件化的速度场和联合注意力机制，导致并发编辑纠缠在一起。

Method: 引入Instance-Disentangled Attention机制，该机制划分联合注意力操作，在速度场估计期间强制绑定实例特定的文本指令和空间区域，实现编辑解耦和局部性。

Result: 在自然图像编辑和新引入的文本密集信息图基准测试中，该方法促进了编辑解耦和局部性，同时保持全局输出一致性，实现了单次推理的实例级编辑。

Conclusion: 提出的Instance-Disentangled Attention机制有效解决了流匹配模型在多实例编辑中的局限性，为复杂图像编辑任务提供了更精细的控制能力。

Abstract: Flow matching models have recently emerged as an efficient alternative to diffusion, especially for text-guided image generation and editing, offering faster inference through continuous-time dynamics. However, existing flow-based editors predominantly support global or single-instruction edits and struggle with multi-instance scenarios, where multiple parts of a reference input must be edited independently without semantic interference. We identify this limitation as a consequence of globally conditioned velocity fields and joint attention mechanisms, which entangle concurrent edits. To address this issue, we introduce Instance-Disentangled Attention, a mechanism that partitions joint attention operations, enforcing binding between instance-specific textual instructions and spatial regions during velocity field estimation. We evaluate our approach on both natural image editing and a newly introduced benchmark of text-dense infographics with region-level editing instructions. Experimental results demonstrate that our approach promotes edit disentanglement and locality while preserving global output coherence, enabling single-pass, instance-level editing.

</details>


### [186] [MVAnimate: Enhancing Character Animation with Multi-View Optimization](https://arxiv.org/abs/2602.08753)
*Tianyu Sun,Zhoujie Fu,Bang Zhang,Guosheng Lin*

Main category: cs.CV

TL;DR: MVAnimate是一个利用多视角先验信息生成高质量2D和3D角色动画的新框架，解决了现有动画生成方法输出质量低和训练数据不足的问题。


<details>
  <summary>Details</summary>
Motivation: 当前角色动画生成算法面临两个主要问题：1）输出内容质量低，2）训练数据不足。无论是基于2D还是3D人体姿态建模的方法都存在这些问题，导致无法生成高质量的动画视频。

Method: MVAnimate框架基于多视角先验信息合成动态人物的2D和3D信息。该方法利用多视角先验生成时间一致和空间连贯的动画输出，并优化目标角色的多视角视频，从不同视角提升视频质量。

Result: 实验结果表明，MVAnimate在多种数据集上表现出鲁棒性，能够处理各种运动模式和外观，相比现有动画方法有明显改进。

Conclusion: MVAnimate通过整合多视角信息有效提升了角色动画生成的质量，为高质量动画视频生成提供了新的解决方案。

Abstract: The demand for realistic and versatile character animation has surged, driven by its wide-ranging applications in various domains. However, the animation generation algorithms modeling human pose with 2D or 3D structures all face various problems, including low-quality output content and training data deficiency, preventing the related algorithms from generating high-quality animation videos. Therefore, we introduce MVAnimate, a novel framework that synthesizes both 2D and 3D information of dynamic figures based on multi-view prior information, to enhance the generated video quality. Our approach leverages multi-view prior information to produce temporally consistent and spatially coherent animation outputs, demonstrating improvements over existing animation methods. Our MVAnimate also optimizes the multi-view videos of the target character, enhancing the video quality from different views. Experimental results on diverse datasets highlight the robustness of our method in handling various motion patterns and appearances.

</details>


### [187] [VedicTHG: Symbolic Vedic Computation for Low-Resource Talking-Head Generation in Educational Avatars](https://arxiv.org/abs/2602.08775)
*Vineet Kumar Rakesh,Ahana Bhattacharjee,Soumya Mazumdar,Tapas Samanta,Hemendra Kumar Pandey,Amitabha Das,Sarbajit Pal*

Main category: cs.CV

TL;DR: 提出了一种基于符号吠陀计算的轻量级说话头像生成框架，可在CPU上实时运行，适用于教育资源受限环境。


<details>
  <summary>Details</summary>
Motivation: 当前说话头像生成方法依赖GPU渲染、大量训练数据或高容量扩散模型，难以在离线或资源受限的教育环境中部署，需要一种轻量级、CPU友好的解决方案。

Method: 采用符号吠陀计算框架：1) 将语音转换为时间对齐的音素流；2) 将音素映射到紧凑的视素库；3) 使用吠陀经Urdhva Tiryakbhyam启发的符号协同发音生成平滑视素轨迹；4) 轻量级2D渲染器进行ROI扭曲和嘴部合成与稳定。

Result: 在仅CPU执行下实现了可接受的唇同步质量，显著降低了计算负载和延迟，支持在低端硬件上部署实用的教育用头像。

Conclusion: 提出的符号吠陀计算框架为教育资源受限环境提供了一种可行的说话头像生成方案，平衡了质量与计算效率。

Abstract: Talking-head avatars are increasingly adopted in educational technology to deliver content with social presence and improved engagement. However, many recent talking-head generation (THG) methods rely on GPU-centric neural rendering, large training sets, or high-capacity diffusion models, which limits deployment in offline or resource-constrained learning environments. A deterministic and CPU-oriented THG framework is described, termed Symbolic Vedic Computation, that converts speech to a time-aligned phoneme stream, maps phonemes to a compact viseme inventory, and produces smooth viseme trajectories through symbolic coarticulation inspired by Vedic sutra Urdhva Tiryakbhyam. A lightweight 2D renderer performs region-of-interest (ROI) warping and mouth compositing with stabilization to support real-time synthesis on commodity CPUs. Experiments report synchronization accuracy, temporal stability, and identity consistency under CPU-only execution, alongside benchmarking against representative CPU-feasible baselines. Results indicate that acceptable lip-sync quality can be achieved while substantially reducing computational load and latency, supporting practical educational avatars on low-end hardware. GitHub: https://vineetkumarrakesh.github.io/vedicthg

</details>


### [188] [Multimodal Learning for Arcing Detection in Pantograph-Catenary Systems](https://arxiv.org/abs/2602.08792)
*Hao Dong,Eleni Chatzi,Olga Fink*

Main category: cs.CV

TL;DR: 提出多模态框架结合视觉与力测量数据，用于检测受电弓-接触网接口的电弧事件，解决传统方法在瞬态、噪声环境下检测困难的问题。


<details>
  <summary>Details</summary>
Motivation: 受电弓-接触网接口的电弧现象会加速部件磨损、降低系统性能并可能导致服务中断。由于电弧的瞬态特性、噪声环境、数据稀缺以及难以区分其他瞬态现象，传统检测方法面临挑战。

Method: 构建包含同步视觉和力测量的两个电弧检测数据集（一个来自瑞士联邦铁路，另一个来自公开视频和合成力数据）。提出MultiDeepSAD算法，扩展DeepSAD以处理多模态数据，并引入针对每种数据类型的伪异常生成技术（如图像中的合成电弧伪影和模拟力不规则性）来增强训练数据。

Result: 通过大量实验和消融研究，证明该框架显著优于基线方法，即使在域转移和真实电弧观测数据有限的情况下，对真实电弧事件也表现出增强的敏感性。

Conclusion: 提出的多模态框架通过结合视觉和力测量数据，有效解决了受电弓-接触网接口电弧检测的挑战，提高了检测准确性和鲁棒性，为铁路系统维护提供了可靠的技术支持。

Abstract: The pantograph-catenary interface is essential for ensuring uninterrupted and reliable power delivery in electrified rail systems. However, electrical arcing at this interface poses serious risks, including accelerated wear of contact components, degraded system performance, and potential service disruptions. Detecting arcing events at the pantograph-catenary interface is challenging due to their transient nature, noisy operating environment, data scarcity, and the difficulty of distinguishing arcs from other similar transient phenomena. To address these challenges, we propose a novel multimodal framework that combines high-resolution image data with force measurements to more accurately and robustly detect arcing events. First, we construct two arcing detection datasets comprising synchronized visual and force measurements. One dataset is built from data provided by the Swiss Federal Railways (SBB), and the other is derived from publicly available videos of arcing events in different railway systems and synthetic force data that mimic the characteristics observed in the real dataset. Leveraging these datasets, we propose MultiDeepSAD, an extension of the DeepSAD algorithm for multiple modalities with a new loss formulation. Additionally, we introduce tailored pseudo-anomaly generation techniques specific to each data type, such as synthetic arc-like artifacts in images and simulated force irregularities, to augment training data and improve the discriminative ability of the model. Through extensive experiments and ablation studies, we demonstrate that our framework significantly outperforms baseline approaches, exhibiting enhanced sensitivity to real arcing events even under domain shifts and limited availability of real arcing observations.

</details>


### [189] [MOVA: Towards Scalable and Synchronized Video-Audio Generation](https://arxiv.org/abs/2602.08794)
*SII-OpenMOSS Team,:,Donghua Yu,Mingshu Chen,Qi Chen,Qi Luo,Qianyi Wu,Qinyuan Cheng,Ruixiao Li,Tianyi Liang,Wenbo Zhang,Wenming Tu,Xiangyu Peng,Yang Gao,Yanru Huo,Ying Zhu,Yinze Luo,Yiyang Zhang,Yuerong Song,Zhe Xu,Zhiyu Zhang,Chenchen Yang,Cheng Chang,Chushu Zhou,Hanfu Chen,Hongnan Ma,Jiaxi Li,Jingqi Tong,Junxi Liu,Ke Chen,Shimin Li,Songlin Wang,Wei Jiang,Zhaoye Fei,Zhiyuan Ning,Chunguo Li,Chenhui Li,Ziwei He,Zengfeng Huang,Xie Chen,Xipeng Qiu*

Main category: cs.CV

TL;DR: MOVA是一个开源的音视频生成模型，采用混合专家架构，能够生成高质量、同步的音视频内容，包括唇语同步、环境音效和内容对齐的音乐。


<details>
  <summary>Details</summary>
Motivation: 当前音视频生成主要依赖级联管道，成本高、误差累积且质量下降。现有系统如Veo 3和Sora 2强调同时生成的重要性，但闭源性质限制了领域发展。需要开源解决方案来推动研究和创作社区发展。

Method: 采用混合专家架构，总参数量320亿，推理时激活180亿参数。支持图像-文本到视频-音频的生成任务，具备高效推理、LoRA微调和提示增强功能。

Result: 开发出能够生成高质量同步音视频内容的开源模型，包括真实的唇语同步、环境感知音效和内容对齐音乐，并公开发布模型权重和代码。

Conclusion: MOVA作为开源音视频生成模型，解决了现有闭源系统的限制，通过发布代码和权重促进研究和创作者社区发展，推动音视频生成领域的进步。

Abstract: Audio is indispensable for real-world video, yet generation models have largely overlooked audio components. Current approaches to producing audio-visual content often rely on cascaded pipelines, which increase cost, accumulate errors, and degrade overall quality. While systems such as Veo 3 and Sora 2 emphasize the value of simultaneous generation, joint multimodal modeling introduces unique challenges in architecture, data, and training. Moreover, the closed-source nature of existing systems limits progress in the field. In this work, we introduce MOVA (MOSS Video and Audio), an open-source model capable of generating high-quality, synchronized audio-visual content, including realistic lip-synced speech, environment-aware sound effects, and content-aligned music. MOVA employs a Mixture-of-Experts (MoE) architecture, with a total of 32B parameters, of which 18B are active during inference. It supports IT2VA (Image-Text to Video-Audio) generation task. By releasing the model weights and code, we aim to advance research and foster a vibrant community of creators. The released codebase features comprehensive support for efficient inference, LoRA fine-tuning, and prompt enhancement.

</details>


### [190] [Addressing data annotation scarcity in Brain Tumor Segmentation on 3D MRI scan Using a Semi-Supervised Teacher-Student Framework](https://arxiv.org/abs/2602.08797)
*Jiaming Liu,Cheng Ding,Daoqiang Zhang*

Main category: cs.CV

TL;DR: 提出了一种半监督教师-学生框架，结合不确定性感知伪标签和渐进式置信度课程，用于有限标注下的脑肿瘤MRI分割，显著提高了数据效率和分割精度。


<details>
  <summary>Details</summary>
Motivation: 脑肿瘤MRI分割面临标注成本高和数据异质性（不同扫描仪和站点）的挑战，需要开发在有限监督下鲁棒的分割方法。

Method: 采用教师-学生框架：教师生成概率掩码和逐像素不确定性；基于图像级置信度对未标注扫描排序并分阶段引入；学生使用双损失目标学习高置信度区域并遗忘低置信度区域；通过一致性细化提高伪标签质量。

Result: 在BraTS 2021上，验证集DSC从0.393（10%数据）提升到0.872（100%），早期阶段提升最大；教师达到0.922 DSC，学生在肿瘤子区域（如NCR/NET 0.797和Edema 0.980）超越教师，特别是在教师失败的增强类别上恢复分割（DSC 0.620）。

Conclusion: 置信度驱动的课程学习和选择性遗忘能够在有限监督和噪声伪标签下提供鲁棒的分割性能，展示了该方法在数据效率和分割精度方面的优势。

Abstract: Accurate brain tumor segmentation from MRI is limited by expensive annotations and data heterogeneity across scanners and sites. We propose a semi-supervised teacher-student framework that combines an uncertainty-aware pseudo-labeling teacher with a progressive, confidence-based curriculum for the student. The teacher produces probabilistic masks and per-pixel uncertainty; unlabeled scans are ranked by image-level confidence and introduced in stages, while a dual-loss objective trains the student to learn from high-confidence regions and unlearn low-confidence ones. Agreement-based refinement further improves pseudo-label quality. On BraTS 2021, validation DSC increased from 0.393 (10% data) to 0.872 (100%), with the largest gains in early stages, demonstrating data efficiency. The teacher reached a validation DSC of 0.922, and the student surpassed the teacher on tumor subregions (e.g., NCR/NET 0.797 and Edema 0.980); notably, the student recovered the Enhancing class (DSC 0.620) where the teacher failed. These results show that confidence-driven curricula and selective unlearning provide robust segmentation under limited supervision and noisy pseudo-labels.

</details>


### [191] [Omni-Video 2: Scaling MLLM-Conditioned Diffusion for Unified Video Generation and Editing](https://arxiv.org/abs/2602.08820)
*Hao Yang,Zhiyu Tan,Jia Gong,Luozheng Qin,Hesen Chen,Xiaomeng Yang,Yuqing Sun,Yuetan Lin,Mengping Yang,Hao Li*

Main category: cs.CV

TL;DR: Omni-Video 2 是一个可扩展的高效视频生成与编辑模型，通过连接预训练多模态大语言模型和视频扩散模型，利用MLLM的理解能力生成明确的目标描述来指导生成过程，实现高质量的视频生成和复杂编辑任务。


<details>
  <summary>Details</summary>
Motivation: 现有视频生成和编辑模型在处理复杂组合指令时存在局限性，需要开发一个能够理解用户意图并生成高质量视频的统一框架。

Method: 1. 利用预训练多模态大语言模型的理解和推理能力生成明确的目标描述；2. 开发轻量级适配器将多模态条件标记注入预训练文本到视频扩散模型；3. 在精心策划的训练数据上扩展到140亿参数的视频扩散模型。

Result: 在FiVE基准测试中展现出遵循复杂组合指令的卓越能力，在VBench基准测试中实现竞争性或更优的视频生成质量，支持高质量文本到视频生成和各种视频编辑任务。

Conclusion: Omni-Video 2通过连接理解模型和生成模型，以参数高效的方式实现了高质量的视频生成和复杂编辑，为统一视频处理提供了可扩展的解决方案。

Abstract: We present Omni-Video 2, a scalable and computationally efficient model that connects pretrained multimodal large-language models (MLLMs) with video diffusion models for unified video generation and editing. Our key idea is to exploit the understanding and reasoning capabilities of MLLMs to produce explicit target captions to interpret user instructions. In this way, the rich contextual representations from the understanding model are directly used to guide the generative process, thereby improving performance on complex and compositional editing. Moreover, a lightweight adapter is developed to inject multimodal conditional tokens into pretrained text-to-video diffusion models, allowing maximum reuse of their powerful generative priors in a parameter-efficient manner. Benefiting from these designs, we scale up Omni-Video 2 to a 14B video diffusion model on meticulously curated training data with quality, supporting high quality text-to-video generation and various video editing tasks such as object removal, addition, background change, complex motion editing, \emph{etc.} We evaluate the performance of Omni-Video 2 on the FiVE benchmark for fine-grained video editing and the VBench benchmark for text-to-video generation. The results demonstrate its superior ability to follow complex compositional instructions in video editing, while also achieving competitive or superior quality in video generation tasks.

</details>


### [192] [Any-to-All MRI Synthesis: A Unified Foundation Model for Nasopharyngeal Carcinoma and Its Downstream Applications](https://arxiv.org/abs/2602.08822)
*Yao Pu,Yiming Shi,Zhenxi Zhang,Peixin Yu,Yitao Zhuang,Xiang Wang,Hongzhao Chen,Jing Cai,Ge Ren*

Main category: cs.CV

TL;DR: 开发了一个统一的基础模型，通过对比视觉表示学习和视觉语言对齐，实现任意到所有MRI合成，用于鼻咽癌放疗规划，在多个验证站点表现出色并增强下游放疗相关任务。


<details>
  <summary>Details</summary>
Motivation: MRI对鼻咽癌放疗至关重要，但临床实践中患者不适、扫描时间长、成本高等因素常导致模态不完整，影响放疗规划准确性。传统MRI合成方法模态特定、解剖适应性有限且缺乏临床可解释性，无法满足鼻咽癌放疗需求。

Method: 开发统一基础模型，整合对比视觉表示学习和视觉语言对齐。使用对比编码器提取模态不变表示，基于CLIP的文本信息解码器进行语义一致合成，支持通过单一统一模型实现任意到所有MRI合成。

Result: 在13个机构的40,825张图像上训练，在26个内部/外部验证站点（15,748张图像）上取得一致高性能（平均SSIM 0.90，PSNR 27），合成保真度高，对噪声和域偏移具有鲁棒性。统一表示还增强了下游放疗相关任务（如分割）。

Conclusion: 这项工作通过利用基础模型桥接技术合成与临床实用性，推进了鼻咽癌护理的数字医学解决方案，为临床实践提供了更准确、高效的MRI合成方法。

Abstract: Magnetic resonance imaging (MRI) is essential for nasopharyngeal carcinoma (NPC) radiotherapy (RT), but practical constraints, such as patient discomfort, long scan times, and high costs often lead to incomplete modalities in clinical practice, compromising RT planning accuracy. Traditional MRI synthesis methods are modality-specific, limited in anatomical adaptability, and lack clinical interpretability-failing to meet NPC's RT needs. Here, we developed a unified foundation model integrating contrastive visual representation learning and vision-language alignment (VLA) to enable any-to-all MRI synthesis. The model uses a contrastive encoder for modality-invariant representations and a CLIP-based text-informed decoder for semantically consistent synthesis, supporting any-to-all MRI synthesis via one unified foundation model. Trained on 40,825 images from 13 institutions, it achieves consistently high performance (average SSIM 0.90, PSNR 27) across 26 internal/external validation sites (15,748 images), with superior synthesis fidelity and robustness to noise and domain shifts. Meanwhile, its unified representation enhances downstream RT-relevant tasks (e.g., segmentation). This work advances digital medicine solutions for NPC care by leveraging foundation models to bridge technical synthesis and clinical utility.

</details>


### [193] [VideoVeritas: AI-Generated Video Detection via Perception Pretext Reinforcement Learning](https://arxiv.org/abs/2602.08828)
*Hao Tan,Jun Lan,Senyuan Shi,Zichang Tan,Zijian Yu,Huijia Zhu,Weiqiang Wang,Jun Wan,Zhen Lei*

Main category: cs.CV

TL;DR: VideoVeritas是一个结合细粒度感知和事实推理的视频检测框架，通过联合偏好对齐和感知预文本强化学习提升检测性能，并在新数据集MintVid上验证了其平衡性能。


<details>
  <summary>Details</summary>
Motivation: 视频生成能力的增强带来了安全风险，需要可靠的检测方法。当前多模态大语言模型虽然推理能力强，但细粒度感知能力有限，需要改进。

Method: 提出VideoVeritas框架，结合细粒度感知和事实推理。引入联合偏好对齐和感知预文本强化学习（PPRL），在强化学习阶段采用通用的时空定位和自监督物体计数作为感知预文本任务，而不是直接优化检测任务。

Result: 实验结果表明，现有方法倾向于偏向表面推理或机械分析，而VideoVeritas在多样化基准测试中实现了更平衡的性能。

Conclusion: VideoVeritas通过结合感知和推理能力，为视频检测提供了更平衡有效的解决方案，并引入了新的高质量数据集MintVid用于评估。

Abstract: The growing capability of video generation poses escalating security risks, making reliable detection increasingly essential. In this paper, we introduce VideoVeritas, a framework that integrates fine-grained perception and fact-based reasoning. We observe that while current multi-modal large language models (MLLMs) exhibit strong reasoning capacity, their granular perception ability remains limited. To mitigate this, we introduce Joint Preference Alignment and Perception Pretext Reinforcement Learning (PPRL). Specifically, rather than directly optimizing for detection task, we adopt general spatiotemporal grounding and self-supervised object counting in the RL stage, enhancing detection performance with simple perception pretext tasks. To facilitate robust evaluation, we further introduce MintVid, a light yet high-quality dataset containing 3K videos from 9 state-of-the-art generators, along with a real-world collected subset that has factual errors in content. Experimental results demonstrate that existing methods tend to bias towards either superficial reasoning or mechanical analysis, while VideoVeritas achieves more balanced performance across diverse benchmarks.

</details>


### [194] [FlattenGPT: Depth Compression for Transformer with Layer Flattening](https://arxiv.org/abs/2602.08858)
*Ruihan Xu,Qingpei Guo,Yao Zhu,Xiangyang Ji,Ming Yang,Shiliang Zhang*

Main category: cs.CV

TL;DR: FlattenGPT是一种新的Transformer模型压缩方法，通过将相邻块扁平化为一个块来压缩网络深度，同时更有效地检测和移除参数冗余，在保持性能的同时提升模型效率。


<details>
  <summary>Details</summary>
Motivation: 现有方法存在局限性：整块剪枝会丢弃已学习的有用信息导致性能下降；通道剪枝虽能保持性能但不能减少模型深度，且各层剪枝比例不一致。需要一种既能压缩深度又能保持性能的方法。

Method: 提出FlattenGPT方法，将两个相邻的Transformer块扁平化为一个块，压缩网络深度。这种方法能更有效地检测和移除参数冗余，保留所有块中学到的知识，同时保持原始Transformer架构的一致性。

Result: 在LLaMA-2/3和Qwen-1.5等模型上，FlattenGPT在20%压缩比下能保持90-96%的零样本性能。在零样本准确率和WikiText-2困惑度方面优于现有剪枝方法，同时加速LLM推理。

Conclusion: FlattenGPT通过扁平化相邻块实现了更好的深度压缩和参数冗余检测，在保持性能的同时显著提升模型效率，为Transformer模型的高效化提供了有前景的解决方案。

Abstract: Recent works have indicated redundancy across transformer blocks, prompting the research of depth compression to prune less crucial blocks. However, current ways of entire-block pruning suffer from risks of discarding meaningful cues learned in those blocks, leading to substantial performance degradation. As another line of model compression, channel pruning can better preserve performance, while it cannot reduce model depth and is challenged by inconsistent pruning ratios for individual layers. To pursue better model compression and acceleration, this paper proposes \textbf{FlattenGPT}, a novel way to detect and reduce depth-wise redundancies. By flatting two adjacent blocks into one, it compresses the network depth, meanwhile enables more effective parameter redundancy detection and removal. FlattenGPT allows to preserve the knowledge learned in all blocks, and remains consistent with the original transformer architecture. Extensive experiments demonstrate that FlattenGPT enhances model efficiency with a decent trade-off to performance. It outperforms existing pruning methods in both zero-shot accuracies and WikiText-2 perplexity across various model types and parameter sizes. On LLaMA-2/3 and Qwen-1.5 models, FlattenGPT retains 90-96\% of zero-shot performance with a compression ratio of 20\%. It also outperforms other pruning methods in accelerating LLM inference, making it promising for enhancing the efficiency of transformers.

</details>


### [195] [TiFRe: Text-guided Video Frame Reduction for Efficient Video Multi-modal Large Language Models](https://arxiv.org/abs/2602.08861)
*Xiangtian Zheng,Zishuo Wang,Yuxin Peng*

Main category: cs.CV

TL;DR: TiFRe是一个文本引导的视频帧减少框架，通过智能选择关键帧和合并非关键帧信息来降低计算成本，同时保持视频语义完整性。


<details>
  <summary>Details</summary>
Motivation: 视频多模态大语言模型在处理大量视频帧时面临高计算成本问题，特别是注意力计算开销大。简单地减少输入帧数会丢失非关键帧中的有价值信息，导致性能下降。

Method: 提出TiFRe框架：1) 文本引导帧采样(TFS)：使用LLM根据用户输入生成CLIP风格提示，通过CLIP编码器计算提示与每帧的语义相似度，选择最相关的关键帧；2) 帧匹配与合并(FMM)：将非关键帧信息整合到选定的关键帧中，最小化信息损失。

Result: 实验表明TiFRe能有效降低计算成本，同时在视频-语言任务上提高性能。

Conclusion: TiFRe通过文本引导的智能帧选择和语义保留机制，在减少计算开销的同时保持了视频理解性能，为视频MLLMs的高效部署提供了有效解决方案。

Abstract: With the rapid development of Large Language Models (LLMs), Video Multi-Modal Large Language Models (Video MLLMs) have achieved remarkable performance in video-language tasks such as video understanding and question answering. However, Video MLLMs face high computational costs, particularly in processing numerous video frames as input, which leads to significant attention computation overhead. A straightforward approach to reduce computational costs is to decrease the number of input video frames. However, simply selecting key frames at a fixed frame rate (FPS) often overlooks valuable information in non-key frames, resulting in notable performance degradation. To address this, we propose Text-guided Video Frame Reduction (TiFRe), a framework that reduces input frames while preserving essential video information. TiFRe uses a Text-guided Frame Sampling (TFS) strategy to select key frames based on user input, which is processed by an LLM to generate a CLIP-style prompt. Pre-trained CLIP encoders calculate the semantic similarity between the prompt and each frame, selecting the most relevant frames as key frames. To preserve video semantics, TiFRe employs a Frame Matching and Merging (FMM) mechanism, which integrates non-key frame information into the selected key frames, minimizing information loss. Experiments show that TiFRe effectively reduces computational costs while improving performance on video-language tasks.

</details>


### [196] [Analysis of Converged 3D Gaussian Splatting Solutions: Density Effects and Prediction Limit](https://arxiv.org/abs/2602.08909)
*Zhendong Wang,Cihan Ruan,Jingchuan Xiao,Chuqing Shi,Wei Jiang,Wei Wang,Wenjie Liu,Nam Ling*

Main category: cs.CV

TL;DR: 论文分析了3D高斯泼溅（3DGS）标准多视图优化中出现的结构模式，称为渲染最优参考（RORs），揭示了其统计特性，并探讨了密度分层现象对参数可学习性的影响。


<details>
  <summary>Details</summary>
Motivation: 研究3D高斯泼溅在多视图优化中形成的结构化模式，理解这些模式背后的统计规律，以及不同密度区域参数可学习性的差异，为改进训练鲁棒性和系统架构提供理论基础。

Method: 1) 分析RORs的统计特性；2) 使用可学习性探针训练预测器从点云重建RORs；3) 通过方差分解形式化密度分层现象；4) 提出密度感知策略改进训练鲁棒性。

Result: 发现RORs具有稳定的统计模式：混合结构尺度和双峰辐射分布。揭示了密度分层现象：密集区域参数与几何相关且可预测，稀疏区域参数存在系统性失败。形式化了可见性异质性导致的几何与外观参数耦合。

Conclusion: RORs具有双重特性：在密集区域表现为几何基元（点云足够），在稀疏区域表现为视图合成基元（需要多视图约束）。这为自适应平衡前馈预测和渲染优化的系统架构提供了理论基础。

Abstract: We investigate what structure emerges in 3D Gaussian Splatting (3DGS) solutions from standard multi-view optimization. We term these Rendering-Optimal References (RORs) and analyze their statistical properties, revealing stable patterns: mixture-structured scales and bimodal radiance across diverse scenes. To understand what determines these parameters, we apply learnability probes by training predictors to reconstruct RORs from point clouds without rendering supervision. Our analysis uncovers fundamental density-stratification. Dense regions exhibit geometry-correlated parameters amenable to render-free prediction, while sparse regions show systematic failure across architectures. We formalize this through variance decomposition, demonstrating that visibility heterogeneity creates covariance-dominated coupling between geometric and appearance parameters in sparse regions. This reveals the dual character of RORs: geometric primitives where point clouds suffice, and view synthesis primitives where multi-view constraints are essential. We provide density-aware strategies that improve training robustness and discuss architectural implications for systems that adaptively balance feed-forward prediction and rendering-based refinement.

</details>


### [197] [Grow with the Flow: 4D Reconstruction of Growing Plants with Gaussian Flow Fields](https://arxiv.org/abs/2602.08958)
*Weihan Luo,Lily Goli,Sherwin Bahmani,Felix Taubner,Andrea Tagliasacchi,David B. Lindell*

Main category: cs.CV

TL;DR: 提出一种用于植物生长建模的3D高斯流场表示方法，通过时间变化的高斯参数导数模拟非线性连续生长动态，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 植物生长建模面临独特挑战：植物随时间生成新几何结构（扩展、分枝、分化），现有动态建模技术不适用。变形场无法引入新几何，4D高斯溅射将运动限制为线性轨迹且无法随时间跟踪同一组高斯。

Method: 引入3D高斯流场表示，将植物生长建模为高斯参数（位置、尺度、方向、颜色、不透明度）的时间变化导数。通过重建成熟植物并学习反向生长过程来初始化足够的高斯基元。

Result: 在多视角植物生长时间序列数据集上，该方法在图像质量和几何精度方面优于现有方法。

Conclusion: 该方法为生长中的3D结构的外观建模提供了新方法，能够有效模拟非线性连续生长动态。

Abstract: Modeling the time-varying 3D appearance of plants during their growth poses unique challenges: unlike many dynamic scenes, plants generate new geometry over time as they expand, branch, and differentiate. Recent motion modeling techniques are ill-suited to this problem setting. For example, deformation fields cannot introduce new geometry, and 4D Gaussian splatting constrains motion to a linear trajectory in space and time and cannot track the same set of Gaussians over time. Here, we introduce a 3D Gaussian flow field representation that models plant growth as a time-varying derivative over Gaussian parameters -- position, scale, orientation, color, and opacity -- enabling nonlinear and continuous-time growth dynamics. To initialize a sufficient set of Gaussian primitives, we reconstruct the mature plant and learn a process of reverse growth, effectively simulating the plant's developmental history in reverse. Our approach achieves superior image quality and geometric accuracy compared to prior methods on multi-view timelapse datasets of plant growth, providing a new approach for appearance modeling of growing 3D structures.

</details>


### [198] [MotionCrafter: Dense Geometry and Motion Reconstruction with a 4D VAE](https://arxiv.org/abs/2602.08961)
*Ruijie Zhu,Jiahao Lu,Wenbo Hu,Xiaoguang Han,Jianfei Cai,Ying Shan,Chuanxia Zheng*

Main category: cs.CV

TL;DR: MotionCrafter：基于视频扩散的框架，从单目视频联合重建4D几何和估计密集运动，无需后优化即实现SOTA性能


<details>
  <summary>Details</summary>
Motivation: 现有方法强制3D值和潜在空间与RGB VAE潜在空间严格对齐，尽管它们的分布根本不同，这导致次优性能。需要一种更好的方法来联合表示4D几何和运动。

Method: 提出新颖的联合表示方法：在共享坐标系中表示密集3D点图和3D场景流；设计新的4D VAE来有效学习这种表示；采用新的数据归一化和VAE训练策略，更好地传递扩散先验。

Result: 在多个数据集上的实验表明，MotionCrafter在几何重建和密集场景流估计方面均达到最先进性能，几何重建提升38.64%，运动重建提升25.0%，且无需任何后优化。

Conclusion: MotionCrafter证明了强制3D值与RGB VAE潜在空间对齐是不必要的，通过新的联合表示和训练策略，能够更有效地从单目视频中重建4D几何和估计密集运动。

Abstract: We introduce MotionCrafter, a video diffusion-based framework that jointly reconstructs 4D geometry and estimates dense motion from a monocular video. The core of our method is a novel joint representation of dense 3D point maps and 3D scene flows in a shared coordinate system, and a novel 4D VAE to effectively learn this representation. Unlike prior work that forces the 3D value and latents to align strictly with RGB VAE latents-despite their fundamentally different distributions-we show that such alignment is unnecessary and leads to suboptimal performance. Instead, we introduce a new data normalization and VAE training strategy that better transfers diffusion priors and greatly improves reconstruction quality. Extensive experiments across multiple datasets demonstrate that MotionCrafter achieves state-of-the-art performance in both geometry reconstruction and dense scene flow estimation, delivering 38.64% and 25.0% improvements in geometry and motion reconstruction, respectively, all without any post-optimization. Project page: https://ruijiezhu94.github.io/MotionCrafter_Page

</details>


### [199] [Modeling 3D Pedestrian-Vehicle Interactions for Vehicle-Conditioned Pose Forecasting](https://arxiv.org/abs/2602.08962)
*Guangxun Zhu,Xuan Liu,Nicolas Pugeault,Chongfeng Wei,Edmond S. L. Ho*

Main category: cs.CV

TL;DR: 提出一个3D车辆条件行人姿态预测框架，通过显式结合周围车辆信息来提升自动驾驶中的行人运动预测准确性。


<details>
  <summary>Details</summary>
Motivation: 准确预测行人运动对于复杂城市环境中自动驾驶的安全性和可靠性至关重要。现有方法往往忽视车辆对行人行为的影响，需要开发能够建模行人-车辆交互的预测框架。

Method: 1) 增强Waymo-3DSkelMo数据集，添加对齐的3D车辆边界框；2) 提出场景分类采样方案，按行人和车辆数量分类场景；3) 基于TBIFormer架构构建网络，添加专用车辆编码器和行人-车辆交互交叉注意力模块，融合行人和车辆特征。

Result: 大量实验表明，该方法在预测准确性方面有显著提升，验证了不同行人-车辆交互建模方法的有效性，突出了车辆感知的3D姿态预测对自动驾驶的重要性。

Conclusion: 提出的3D车辆条件行人姿态预测框架通过显式建模行人-车辆交互，显著提升了行人运动预测的准确性，为自动驾驶系统提供了更可靠的行人行为理解能力。

Abstract: Accurately predicting pedestrian motion is crucial for safe and reliable autonomous driving in complex urban environments. In this work, we present a 3D vehicle-conditioned pedestrian pose forecasting framework that explicitly incorporates surrounding vehicle information. To support this, we enhance the Waymo-3DSkelMo dataset with aligned 3D vehicle bounding boxes, enabling realistic modeling of multi-agent pedestrian-vehicle interactions. We introduce a sampling scheme to categorize scenes by pedestrian and vehicle count, facilitating training across varying interaction complexities. Our proposed network adapts the TBIFormer architecture with a dedicated vehicle encoder and pedestrian-vehicle interaction cross-attention module to fuse pedestrian and vehicle features, allowing predictions to be conditioned on both historical pedestrian motion and surrounding vehicles. Extensive experiments demonstrate substantial improvements in forecasting accuracy and validate different approaches for modeling pedestrian-vehicle interactions, highlighting the importance of vehicle-aware 3D pose prediction for autonomous driving. Code is available at: https://github.com/GuangxunZhu/VehCondPose3D

</details>


### [200] [WorldArena: A Unified Benchmark for Evaluating Perception and Functional Utility of Embodied World Models](https://arxiv.org/abs/2602.08971)
*Yu Shang,Zhuohang Li,Yiding Ma,Weikang Su,Xin Jin,Ziyou Wang,Xin Zhang,Yinzhou Tang,Chen Gao,Wei Wu,Xihui Liu,Dhruv Shah,Zhaoxiang Zhang,Zhibo Chen,Jun Zhu,Yonghong Tian,Tat-Seng Chua,Wenwu Zhu,Yong Li*

Main category: cs.CV

TL;DR: WorldArena是一个统一的基准测试，用于系统评估具身世界模型在感知和功能两个维度上的表现，揭示了感知质量与任务功能之间的显著差距。


<details>
  <summary>Details</summary>
Motivation: 当前对具身世界模型的评估主要关注感知保真度（如视频生成质量），而忽视了这些模型在下游决策任务中的功能效用，导致评估碎片化。

Method: 提出WorldArena基准测试，通过三个维度评估模型：1) 视频感知质量（16个指标覆盖6个子维度）；2) 具身任务功能（作为数据引擎、策略评估器和动作规划器）；3) 结合主观人类评估。同时提出EWMScore综合指标。

Result: 通过对14个代表性模型的广泛实验，揭示了显著的感知-功能差距，表明高视觉质量不一定转化为强大的具身任务能力。

Conclusion: WorldArena为追踪具身AI中真正功能性世界模型的进展提供了一个框架，公开排行榜已发布在worldarena.ai。

Abstract: While world models have emerged as a cornerstone of embodied intelligence by enabling agents to reason about environmental dynamics through action-conditioned prediction, their evaluation remains fragmented. Current evaluation of embodied world models has largely focused on perceptual fidelity (e.g., video generation quality), overlooking the functional utility of these models in downstream decision-making tasks. In this work, we introduce WorldArena, a unified benchmark designed to systematically evaluate embodied world models across both perceptual and functional dimensions. WorldArena assesses models through three dimensions: video perception quality, measured with 16 metrics across six sub-dimensions; embodied task functionality, which evaluates world models as data engines, policy evaluators, and action planners integrating with subjective human evaluation. Furthermore, we propose EWMScore, a holistic metric integrating multi-dimensional performance into a single interpretable index. Through extensive experiments on 14 representative models, we reveal a significant perception-functionality gap, showing that high visual quality does not necessarily translate into strong embodied task capability. WorldArena benchmark with the public leaderboard is released at https://worldarena.ai, providing a framework for tracking progress toward truly functional world models in embodied AI.

</details>


### [201] [Generalizing Sports Feedback Generation by Watching Competitions and Reading Books: A Rock Climbing Case Study](https://arxiv.org/abs/2602.08996)
*Arushi Rai,Adriana Kovashka*

Main category: cs.CV

TL;DR: 提出利用辅助网络数据改进视频-LLM在体育反馈生成任务上的性能，并设计新的评估指标解决传统指标不适用的问题


<details>
  <summary>Details</summary>
Motivation: 现有视频-LLM在体育反馈生成任务上表现不佳，需要昂贵的微调数据且泛化能力差，同时传统文本生成评估指标无法准确评估体育反馈质量

Method: 1) 利用目标领域的免费网络数据（如比赛视频和教练手册）结合源领域的现有体育反馈数据；2) 提出两个新评估指标：特异性和可操作性

Result: 该方法在有限标注条件下实现了更有意义和实用的体育反馈生成

Conclusion: 通过利用辅助网络数据和设计领域特定评估指标，可以有效提升视频-LLM在体育反馈生成任务上的性能，特别是在标注数据有限的情况下

Abstract: While there is rapid progress in video-LLMs with advanced reasoning capabilities, prior work shows that these models struggle on the challenging task of sports feedback generation and require expensive and difficult-to-collect finetuning feedback data for each sport. This limitation is evident from the poor generalization to sports unseen during finetuning. Furthermore, traditional text generation evaluation metrics (e.g., BLEU-4, METEOR, ROUGE-L, BERTScore), originally developed for machine translation and summarization, fail to capture the unique aspects of sports feedback quality. To address the first problem, using rock climbing as our case study, we propose using auxiliary freely-available web data from the target domain, such as competition videos and coaching manuals, in addition to existing sports feedback from a disjoint, source domain to improve sports feedback generation performance on the target domain. To improve evaluation, we propose two evaluation metrics: (1) specificity and (2) actionability. Together, our approach enables more meaningful and practical generation of sports feedback under limited annotations.

</details>


### [202] [ArcFlow: Unleashing 2-Step Text-to-Image Generation via High-Precision Non-Linear Flow Distillation](https://arxiv.org/abs/2602.09014)
*Zihan Yang,Shuyuan Tu,Licheng Zhang,Qi Dai,Yu-Gang Jiang,Zuxuan Wu*

Main category: cs.CV

TL;DR: ArcFlow提出了一种使用非线性流轨迹来近似预训练教师轨迹的少步蒸馏框架，通过参数化连续动量过程的混合来捕捉速度演化，实现40倍加速且质量无明显下降。


<details>
  <summary>Details</summary>
Motivation: 扩散模型虽然生成质量优秀，但依赖多步去噪导致推理成本高昂。现有蒸馏方法使用线性捷径近似教师轨迹，难以匹配随时间步变化的切线方向，导致质量下降。

Method: ArcFlow将底层速度场参数化为连续动量过程的混合，捕捉速度演化并外推形成连续非线性轨迹。该参数化允许解析积分，避免数值离散误差。通过轻量适配器在预训练教师模型上进行轨迹蒸馏训练。

Result: 基于大规模模型（Qwen-Image-20B和FLUX.1-dev），ArcFlow仅微调不到5%的原始参数，在2个NFEs下实现40倍加速，且无明显质量下降。基准实验验证了其定性和定量有效性。

Conclusion: ArcFlow通过非线性流轨迹近似教师轨迹，有效解决了现有线性蒸馏方法的质量下降问题，实现了高质量、高效率的少步扩散模型蒸馏。

Abstract: Diffusion models have achieved remarkable generation quality, but they suffer from significant inference cost due to their reliance on multiple sequential denoising steps, motivating recent efforts to distill this inference process into a few-step regime. However, existing distillation methods typically approximate the teacher trajectory by using linear shortcuts, which makes it difficult to match its constantly changing tangent directions as velocities evolve across timesteps, thereby leading to quality degradation. To address this limitation, we propose ArcFlow, a few-step distillation framework that explicitly employs non-linear flow trajectories to approximate pre-trained teacher trajectories. Concretely, ArcFlow parameterizes the velocity field underlying the inference trajectory as a mixture of continuous momentum processes. This enables ArcFlow to capture velocity evolution and extrapolate coherent velocities to form a continuous non-linear trajectory within each denoising step. Importantly, this parameterization admits an analytical integration of this non-linear trajectory, which circumvents numerical discretization errors and results in high-precision approximation of the teacher trajectory. To train this parameterization into a few-step generator, we implement ArcFlow via trajectory distillation on pre-trained teacher models using lightweight adapters. This strategy ensures fast, stable convergence while preserving generative diversity and quality. Built on large-scale models (Qwen-Image-20B and FLUX.1-dev), ArcFlow only fine-tunes on less than 5% of original parameters and achieves a 40x speedup with 2 NFEs over the original multi-step teachers without significant quality degradation. Experiments on benchmarks show the effectiveness of ArcFlow both qualitatively and quantitatively.

</details>


### [203] [Raster2Seq: Polygon Sequence Generation for Floorplan Reconstruction](https://arxiv.org/abs/2602.09016)
*Hao Phung,Hadar Averbuch-Elor*

Main category: cs.CV

TL;DR: Raster2Seq：将平面图重建视为序列到序列任务，通过自回归解码器预测多边形角点，在多个基准测试中达到SOTA性能


<details>
  <summary>Details</summary>
Motivation: 现有技术难以准确重建复杂平面图的结构和语义，特别是包含大量房间和不同多边形角点数量的室内空间平面图。需要一种能够有效处理复杂几何结构和语义信息的重建方法。

Method: 将平面图重建框架化为序列到序列任务，将房间、门窗等元素表示为带标签的多边形序列。引入自回归解码器，在图像特征和已生成角点的条件下预测下一个角点，使用可学习锚点引导注意力机制聚焦于信息丰富的图像区域。

Result: 在Structure3D、CubiCasa5K和Raster2Graph等标准基准测试中达到最先进性能，同时在包含多样化房间结构和复杂几何变化的WAFFLE数据集上表现出强大的泛化能力。

Conclusion: Raster2Seq通过序列到序列的自回归方法，能够灵活处理具有大量房间和多样化多边形结构的复杂平面图，在准确重建几何结构和语义信息方面表现出色，为后续的自动理解和CAD工作流提供了可靠的基础。

Abstract: Reconstructing a structured vector-graphics representation from a rasterized floorplan image is typically an important prerequisite for computational tasks involving floorplans such as automated understanding or CAD workflows. However, existing techniques struggle in faithfully generating the structure and semantics conveyed by complex floorplans that depict large indoor spaces with many rooms and a varying numbers of polygon corners. To this end, we propose Raster2Seq, framing floorplan reconstruction as a sequence-to-sequence task in which floorplan elements--such as rooms, windows, and doors--are represented as labeled polygon sequences that jointly encode geometry and semantics. Our approach introduces an autoregressive decoder that learns to predict the next corner conditioned on image features and previously generated corners using guidance from learnable anchors. These anchors represent spatial coordinates in image space, hence allowing for effectively directing the attention mechanism to focus on informative image regions. By embracing the autoregressive mechanism, our method offers flexibility in the output format, enabling for efficiently handling complex floorplans with numerous rooms and diverse polygon structures. Our method achieves state-of-the-art performance on standard benchmarks such as Structure3D, CubiCasa5K, and Raster2Graph, while also demonstrating strong generalization to more challenging datasets like WAFFLE, which contain diverse room structures and complex geometric variations.

</details>


### [204] [WorldCompass: Reinforcement Learning for Long-Horizon World Models](https://arxiv.org/abs/2602.09022)
*Zehan Wang,Tengfei Wang,Haiyu Zhang,Xuhui Zuo,Junta Wu,Haoyuan Wang,Wenqiang Sun,Zhenwei Wang,Chenjie Cao,Hengshuang Zhao,Chunchao Guo,Zhou Zhao*

Main category: cs.CV

TL;DR: WorldCompass是一个用于长时程交互视频世界模型的强化学习后训练框架，通过交互信号引导世界模型更准确、一致地探索环境，显著提升了交互准确性和视觉保真度。


<details>
  <summary>Details</summary>
Motivation: 现有的长时程交互视频世界模型在探索环境时缺乏准确性和一致性，需要一种能够基于交互信号有效引导模型探索的后训练框架。

Method: 提出了三个核心创新：1) 片段级展开策略 - 在单个目标片段生成和评估多个样本以提高效率和提供细粒度奖励信号；2) 互补奖励函数 - 设计交互跟随准确性和视觉质量的奖励函数，提供直接监督并抑制奖励黑客行为；3) 高效RL算法 - 采用负感知微调策略结合多种效率优化，高效增强模型能力。

Result: 在SoTA开源世界模型WorldPlay上的评估表明，WorldCompass在各种场景下显著提升了交互准确性和视觉保真度。

Conclusion: WorldCompass是一个有效的强化学习后训练框架，能够显著提升长时程交互视频世界模型的探索准确性和视觉质量，为基于交互的世界模型提供了新的训练范式。

Abstract: This work presents WorldCompass, a novel Reinforcement Learning (RL) post-training framework for the long-horizon, interactive video-based world models, enabling them to explore the world more accurately and consistently based on interaction signals. To effectively "steer" the world model's exploration, we introduce three core innovations tailored to the autoregressive video generation paradigm: 1) Clip-level rollout Strategy: We generate and evaluate multiple samples at a single target clip, which significantly boosts rollout efficiency and provides fine-grained reward signals. 2) Complementary Reward Functions: We design reward functions for both interaction-following accuracy and visual quality, which provide direct supervision and effectively suppress reward-hacking behaviors. 3) Efficient RL Algorithm: We employ the negative-aware fine-tuning strategy coupled with various efficiency optimizations to efficiently and effectively enhance model capacity. Evaluations on the SoTA open-source world model, WorldPlay, demonstrate that WorldCompass significantly improves interaction accuracy and visual fidelity across various scenarios.

</details>


### [205] [Autoregressive Image Generation with Masked Bit Modeling](https://arxiv.org/abs/2602.09024)
*Qihang Yu,Qihao Liu,Ju He,Xinyang Zhang,Yang Liu,Liang-Chieh Chen,Xi Chen*

Main category: cs.CV

TL;DR: 本文挑战了视觉生成中连续管道的统治地位，通过研究发现离散与连续方法的性能差距主要源于潜在空间的总比特分配（压缩比），并提出BAR框架通过扩展码本大小使离散方法达到或超越连续方法性能。


<details>
  <summary>Details</summary>
Motivation: 当前视觉生成领域普遍认为连续方法优于离散方法，但作者质疑这种观点，认为离散方法性能不佳的真正原因在于潜在空间的比特分配不足，而非离散表示本身的内在缺陷。

Method: 提出掩码比特自回归建模（BAR）框架，通过为自回归变换器配备掩码比特建模头，支持任意大小的码本，通过逐步生成构成离散令牌的比特来预测离散令牌。

Result: BAR在ImageNet-256上实现了0.99的gFID新SOTA，超越了连续和离散方法中的领先方法，同时显著降低了采样成本，收敛速度也比之前的连续方法更快。

Conclusion: 离散方法在视觉生成中具有与连续方法相当甚至更优的潜力，关键在于码本大小的扩展，BAR框架为此提供了可扩展的解决方案，挑战了连续管道的主导地位。

Abstract: This paper challenges the dominance of continuous pipelines in visual generation. We systematically investigate the performance gap between discrete and continuous methods. Contrary to the belief that discrete tokenizers are intrinsically inferior, we demonstrate that the disparity arises primarily from the total number of bits allocated in the latent space (i.e., the compression ratio). We show that scaling up the codebook size effectively bridges this gap, allowing discrete tokenizers to match or surpass their continuous counterparts. However, existing discrete generation methods struggle to capitalize on this insight, suffering from performance degradation or prohibitive training costs with scaled codebook. To address this, we propose masked Bit AutoRegressive modeling (BAR), a scalable framework that supports arbitrary codebook sizes. By equipping an autoregressive transformer with a masked bit modeling head, BAR predicts discrete tokens through progressively generating their constituent bits. BAR achieves a new state-of-the-art gFID of 0.99 on ImageNet-256, outperforming leading methods across both continuous and discrete paradigms, while significantly reducing sampling costs and converging faster than prior continuous approaches. Project page is available at https://bar-gen.github.io/

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [206] [Anchored Decoding: Provably Reducing Copyright Risk for Any Language Model](https://arxiv.org/abs/2602.07120)
*Jacqueline He,Jonathan Hayase,Wen-tau Yih,Sewoong Oh,Luke Zettlemoyer,Pang Wei Koh*

Main category: cs.CL

TL;DR: 提出Anchored Decoding方法，在推理时抑制语言模型的逐字复制行为，通过将生成限制在安全模型附近，实现可调节的风险-效用权衡


<details>
  <summary>Details</summary>
Motivation: 现代语言模型倾向于记忆训练数据并逐字输出，当涉及敏感或受版权保护的内容时，这会引发创作者同意与补偿问题以及开发者的合规风险

Method: 提出Anchored Decoding方法：1）在推理时使用，通过将生成限制在安全模型附近来抑制逐字复制；2）自适应分配用户选择的信息预算；3）引入字节级变体Anchored$_{\mathrm{Byte}}$ Decoding实现跨词汇融合；4）训练新的安全模型TinyComma 1.8B

Result: 在六个模型对的长篇评估中，Anchored Decoding方法定义了新的帕累托前沿，在保持接近原始流畅度和事实性的同时，将可测量的复制差距（平均六个复制指标）减少了高达75%，推理开销适中

Conclusion: Anchored Decoding是一种即插即用的推理时方法，能够有效抑制语言模型的逐字复制行为，在风险模型和许可混合数据训练的情况下提供可调节的风险-效用权衡解决方案

Abstract: Modern language models (LMs) tend to memorize portions of their training data and emit verbatim spans. When the underlying sources are sensitive or copyright-protected, such reproduction raises issues of consent and compensation for creators and compliance risks for developers. We propose Anchored Decoding, a plug-and-play inference-time method for suppressing verbatim copying: it enables decoding from any risky LM trained on mixed-license data by keeping generation in bounded proximity to a permissively trained safe LM. Anchored Decoding adaptively allocates a user-chosen information budget over the generation trajectory and enforces per-step constraints that yield a sequence-level guarantee, enabling a tunable risk-utility trade-off. To make Anchored Decoding practically useful, we introduce a new permissively trained safe model (TinyComma 1.8B), as well as Anchored$_{\mathrm{Byte}}$ Decoding, a byte-level variant of our method that enables cross-vocabulary fusion via the ByteSampler framework (Hayase et al., 2025). We evaluate our methods across six model pairs on long-form evaluations of copyright risk and utility. Anchored and Anchored$_{\mathrm{Byte}}$ Decoding define a new Pareto frontier, preserving near-original fluency and factuality while eliminating up to 75% of the measurable copying gap (averaged over six copying metrics) between the risky baseline and a safe reference, at a modest inference overhead.

</details>


### [207] [Free Energy Mixer](https://arxiv.org/abs/2602.07160)
*Jiecheng Lu,Shihao Yang*

Main category: cs.CL

TL;DR: 提出Free Energy Mixer(FEM)，一种基于自由能（log-sum-exp）的注意力读取机制，通过值驱动的每通道对数线性倾斜来改进标准注意力，实现从平均到每通道选择的平滑过渡。


<details>
  <summary>Details</summary>
Motivation: 标准注意力通过每头凸平均读取键值，但无法进行通道级选择。需要一种既能保持并行性和复杂度，又能实现值感知读取的机制。

Method: FEM将标准注意力中的(q,k)评分分布作为先验，应用值驱动的每通道对数线性倾斜，形成值感知的后验读取。采用两级门控FEM，可即插即用标准注意力、线性注意力、线性RNN和SSM。

Result: 在NLP、视觉和时间序列任务上，FEM在相同参数预算下持续优于强基线模型。

Conclusion: FEM提供了一种高效的值感知注意力读取机制，在保持原始复杂度（softmax为O(T²)，线性变体为O(T)）的同时，实现了从平均到通道选择的平滑过渡。

Abstract: Standard attention stores keys/values losslessly but reads them via a per-head convex average, blocking channel-wise selection. We propose the Free Energy Mixer (FEM): a free-energy (log-sum-exp) read that applies a value-driven, per-channel log-linear tilt to a fast prior (e.g., from queries/keys in standard attention) over indices. Unlike methods that attempt to improve and enrich the $(q,k)$ scoring distribution, FEM treats it as a prior and yields a value-aware posterior read at unchanged complexity, smoothly moving from averaging to per-channel selection as the learnable inverse temperature increases, while still preserving parallelism and the original asymptotic complexity ($O(T^2)$ for softmax; $O(T)$ for linearizable variants). We instantiate a two-level gated FEM that is plug-and-play with standard and linear attention, linear RNNs and SSMs. It consistently outperforms strong baselines on NLP, vision, and time-series at matched parameter budgets.

</details>


### [208] [Your Language Model Secretly Contains Personality Subnetworks](https://arxiv.org/abs/2602.07164)
*Ruimeng Ye,Zihan Wang,Zinan Ling,Yang Xiao,Manling Li,Xiaolong Ma,Bo Hui*

Main category: cs.CL

TL;DR: LLMs already contain persona-specialized subnetworks in their parameters, which can be identified and isolated using calibration data and masking strategies without external knowledge or training.


<details>
  <summary>Details</summary>
Motivation: 探索LLMs是否真的需要外部知识（如提示、RAG或微调）来适应不同行为，还是这些知识已经嵌入在模型参数中。研究LLMs是否已经包含了特定人格的子网络。

Method: 使用小型校准数据集识别不同人格的激活特征，基于这些统计特征开发掩码策略来隔离轻量级人格子网络。对于二元对立人格，引入对比剪枝策略来识别导致统计差异的参数。

Result: 生成的子网络在多样化评估设置中表现出比需要外部知识的基线方法更强的人格对齐性，同时更高效。该方法完全无需训练，仅依赖语言模型的现有参数空间。

Conclusion: 多样的人类行为并非仅仅在LLMs中被诱导产生，而是已经嵌入在它们的参数空间中，这为大型语言模型的可控和可解释个性化提供了新视角。

Abstract: Humans shift between different personas depending on social context. Large Language Models (LLMs) demonstrate a similar flexibility in adopting different personas and behaviors. Existing approaches, however, typically adapt such behavior through external knowledge such as prompting, retrieval-augmented generation (RAG), or fine-tuning. We ask: do LLMs really need external context or parameters to adapt to different behaviors, or do they already have such knowledge embedded in their parameters? In this work, we show that LLMs already contain persona-specialized subnetworks in their parameter space. Using small calibration datasets, we identify distinct activation signatures associated with different personas. Guided by these statistics, we develop a masking strategy that isolates lightweight persona subnetworks. Building on the findings, we further discuss: how can we discover opposing subnetwork from the model that lead to binary-opposing personas, such as introvert-extrovert? To further enhance separation in binary opposition scenarios, we introduce a contrastive pruning strategy that identifies parameters responsible for the statistical divergence between opposing personas. Our method is entirely training-free and relies solely on the language model's existing parameter space. Across diverse evaluation settings, the resulting subnetworks exhibit significantly stronger persona alignment than baselines that require external knowledge while being more efficient. Our findings suggest that diverse human-like behaviors are not merely induced in LLMs, but are already embedded in their parameter space, pointing toward a new perspective on controllable and interpretable personalization in large language models.

</details>


### [209] [Open TutorAI: An Open-source Platform for Personalized and Immersive Learning with Generative AI](https://arxiv.org/abs/2602.07176)
*Mohamed El Hajji,Tarek Ait Baha,Aicha Dakir,Hammou Fadili,Youssef Es-Saady*

Main category: cs.CL

TL;DR: Open TutorAI是一个基于LLM和生成技术的开源教育平台，通过动态个性化辅导、3D虚拟化身和嵌入式学习分析，为学习者提供自适应支持，无需技术专业知识。


<details>
  <summary>Details</summary>
Motivation: 现有教育聊天机器人系统缺乏上下文适应性、实时响应性和教学灵活性，限制了学习者参与度和教学效果。需要开放、集成的平台结合AI和沉浸式技术来支持个性化、有意义的学习体验。

Method: 基于LLM和生成技术的开源平台，集成自然语言处理与可定制3D虚拟化身，通过结构化引导流程捕获学习者目标和偏好，配置个性化的AI助手，提供文本和虚拟化身驱动的界面，包含内容组织、嵌入式反馈和学习者、教育者、家长的专用界面。

Result: 开发了Open TutorAI平台，结合模块化架构、生成AI和学习分析，通过助手生成流程和虚拟化身集成增强参与度和情感存在感，嵌入式学习分析支持自主学习，创建更加人性化、沉浸式的学习环境。

Conclusion: Open TutorAI将模块化架构、生成AI和学习分析统一在开源框架中，为下一代智能辅导系统的发展做出贡献，提供无需技术专业知识的自适应支持工具。

Abstract: Recent advances in artificial intelligence have created new possibilities for making education more scalable, adaptive, and learner-centered. However, existing educational chatbot systems often lack contextual adaptability, real-time responsiveness, and pedagogical agility. which can limit learner engagement and diminish instructional effectiveness. Thus, there is a growing need for open, integrative platforms that combine AI and immersive technologies to support personalized, meaningful learning experiences. This paper presents Open TutorAI, an open-source educational platform based on LLMs and generative technologies that provides dynamic, personalized tutoring. The system integrates natural language processing with customizable 3D avatars to enable multimodal learner interaction. Through a structured onboarding process, it captures each learner's goals and preferences in order to configure a learner-specific AI assistant. This assistant is accessible via both text-based and avatar-driven interfaces. The platform includes tools for organizing content, providing embedded feedback, and offering dedicated interfaces for learners, educators, and parents. This work focuses on learner-facing components, delivering a tool for adaptive support that responds to individual learner profiles without requiring technical expertise. Its assistant-generation pipeline and avatar integration enhance engagement and emotional presence, creating a more humanized, immersive learning environment. Embedded learning analytics support self-regulated learning by tracking engagement patterns and generating actionable feedback. The result is Open TutorAI, which unites modular architecture, generative AI, and learner analytics within an open-source framework. It contributes to the development of next-generation intelligent tutoring systems.

</details>


### [210] [Can LLMs Discern the Traits Influencing Your Preferences? Evaluating Personality-Driven Preference Alignment in LLMs](https://arxiv.org/abs/2602.07181)
*Tianyu Zhao,Siqi Li,Yasser Shoukry,Salma Elmalaki*

Main category: cs.CL

TL;DR: 论文提出利用人格特质作为潜在信号来优化LLM个性化回答，通过人格对齐的偏好选择显著提升回答准确性，并构建了人格标注的偏好数据集PACIFIC和自动检索框架。


<details>
  <summary>Details</summary>
Motivation: 现有方法直接使用用户偏好来个性化LLM回答，但偏好可能包含噪声、不完整甚至误导性信息，这会降低回答质量。研究发现稳定的人格特质塑造日常偏好，因此探索将人格作为偏好的潜在信号来提升个性化问答效果。

Method: 1) 通过实验验证人格对齐偏好的有效性；2) 构建PACIFIC数据集，包含1200个跨领域偏好陈述，标注大五人格特质方向；3) 提出框架使LLM能自动检索人格对齐偏好并在生成答案时整合。

Result: 使用人格对齐偏好显著提升个性化问答性能：与随机选择偏好相比，答案选择准确率从29.25%提升至76%。PACIFIC数据集为研究提供了基础资源。

Conclusion: 人格特质可作为可靠潜在信号来优化LLM个性化回答，人格对齐偏好选择能显著提升回答质量。提出的PACIFIC数据集和自动检索框架为基于人格的个性化LLM应用提供了有效解决方案。

Abstract: User preferences are increasingly used to personalize Large Language Model (LLM) responses, yet how to reliably leverage preference signals for answer generation remains under-explored. In practice, preferences can be noisy, incomplete, or even misleading, which can degrade answer quality when applied naively. Motivated by the observation that stable personality traits shape everyday preferences, we study personality as a principled ''latent'' signal behind preference statements. Through extensive experiments, we find that conditioning on personality-aligned preferences substantially improves personalized question answering: selecting preferences consistent with a user's inferred personality increases answer-choice accuracy from 29.25% to 76%, compared to using randomly selected preferences. Based on these findings, we introduce PACIFIC (Preference Alignment Choices Inference for Five-factor Identity Characterization), a personality-labeled preference dataset containing 1200 preference statements spanning diverse domains (e.g., travel, movies, education), annotated with Big-Five (OCEAN) trait directions. Finally, we propose a framework that enables an LLM model to automatically retrieve personality-aligned preferences and incorporate them during answer generation.

</details>


### [211] [Long-Context Long-Form Question Answering for Legal Domain](https://arxiv.org/abs/2602.07190)
*Anagha Kulkarni,Parin Rajesh Jhaveri,Prasha Shrestha,Yu Tong Han,Reza Amini,Behrouz Madahian*

Main category: cs.CL

TL;DR: 该论文提出一个针对法律文档的长上下文问答系统，能够处理复杂文档布局、专业词汇，并生成全面的长格式答案。


<details>
  <summary>Details</summary>
Motivation: 法律文档具有复杂的布局结构（嵌套章节、长脚注）和专门的语言特征（复杂语法、领域特定词汇），这使得长上下文问答（特别是需要跨多页的全面答案）变得非常困难。

Method: 提出一个问答系统，能够：(a) 解构领域特定词汇以改进文档检索；(b) 解析复杂文档布局，分离章节和脚注并适当链接；(c) 使用精确的领域特定词汇生成全面答案。还引入覆盖度指标来分类性能。

Result: 通过法律和公司税务等领域的专业人士协助构建QA数据集，并通过全面实验和消融研究证明了所提系统的可用性和优势。

Conclusion: 该系统有效解决了法律文档长上下文问答的挑战，特别是在处理复杂布局、专业词汇和生成全面答案方面表现出色。

Abstract: Legal documents have complex document layouts involving multiple nested sections, lengthy footnotes and further use specialized linguistic devices like intricate syntax and domain-specific vocabulary to ensure precision and authority. These inherent characteristics of legal documents make question answering challenging, and particularly so when the answer to the question spans several pages (i.e. requires long-context) and is required to be comprehensive (i.e. a long-form answer). In this paper, we address the challenges of long-context question answering in context of long-form answers given the idiosyncrasies of legal documents. We propose a question answering system that can (a) deconstruct domain-specific vocabulary for better retrieval from source documents, (b) parse complex document layouts while isolating sections and footnotes and linking them appropriately, (c) generate comprehensive answers using precise domain-specific vocabulary. We also introduce a coverage metric that classifies the performance into recall-based coverage categories allowing human users to evaluate the recall with ease. We curate a QA dataset by leveraging the expertise of professionals from fields such as law and corporate tax. Through comprehensive experiments and ablation studies, we demonstrate the usability and merit of the proposed system.

</details>


### [212] [Equipping LLM with Directional Multi-Talker Speech Understanding Capabilities](https://arxiv.org/abs/2602.07211)
*Ju Lin,Jing Pan,Ruizhi Li,Ming Sun,Yuzong Liu,Alaa Hassan,Jing Zheng,Florian Metze*

Main category: cs.CL

TL;DR: 该研究探索了如何让大语言模型具备定向多说话者语音理解能力，特别是在智能眼镜应用场景中，提出了级联系统和端到端系统两种方法。


<details>
  <summary>Details</summary>
Motivation: 当前大多数语音大语言模型基于单通道、单说话者数据训练，难以直接应用于多说话者和多通道的语音理解任务，特别是在智能眼镜等需要定向语音理解的场景中。

Method: 提出了两种新方法：1）级联系统，利用源分离前端模块；2）端到端系统，采用序列化输出训练。两种方法都利用智能眼镜中的多麦克风阵列，以流式方式优化定向解释和处理。

Result: 实验结果表明，所提出的方法能有效赋予大语言模型定向语音理解能力，在语音识别和语音翻译任务中均表现出色。

Conclusion: 该研究成功实现了让大语言模型具备定向多说话者语音理解能力，为智能眼镜等实际应用场景提供了有效的解决方案。

Abstract: Recent studies have demonstrated that prompting large language models (LLM) with audio encodings enables effective speech understanding capabilities. However, most speech LLMs are trained on single-channel, single-talker data, which makes it challenging to directly apply them to multi-talker and multi-channel speech understanding task. In this work, we present a comprehensive investigation on how to enable directional multi-talker speech understanding capabilities for LLMs, specifically in smart glasses usecase. We propose two novel approaches to integrate directivity into LLMs: (1) a cascaded system that leverages a source separation front-end module, and (2) an end-to-end system that utilizes serialized output training. All of the approaches utilize a multi-microphone array embedded in smart glasses to optimize directivity interpretation and processing in a streaming manner. Experimental results demonstrate the efficacy of our proposed methods in endowing LLMs with directional speech understanding capabilities, achieving strong performance in both speech recognition and speech translation tasks.

</details>


### [213] [Beyond Accuracy: Risk-Sensitive Evaluation of Hallucinated Medical Advice](https://arxiv.org/abs/2602.07319)
*Savan Doshi*

Main category: cs.CL

TL;DR: 提出风险敏感的幻觉评估框架，通过风险语言量化幻觉，关注潜在危害而非事实正确性


<details>
  <summary>Details</summary>
Motivation: 现有幻觉评估标准主要关注事实正确性，将所有错误视为同等严重，忽略了临床相关的失败模式，特别是当模型生成无依据但可操作的医疗语言时

Method: 提出风险敏感评估框架，通过风险承载语言（治疗指令、禁忌症、紧急提示、高风险药物提及）量化幻觉，结合风险评分与相关性测量识别高风险、低基础失败

Result: 应用该框架测试三个指令调优语言模型，发现表面行为相似的模型展现出显著不同的风险特征，标准评估指标无法捕捉这些差异

Conclusion: 将风险敏感性纳入幻觉评估至关重要，评估有效性严重依赖于任务和提示设计

Abstract: Large language models are increasingly being used in patient-facing medical question answering, where hallucinated outputs can vary widely in potential harm. However, existing hallucination standards and evaluation metrics focus primarily on factual correctness, treating all errors as equally severe. This obscures clinically relevant failure modes, particularly when models generate unsupported but actionable medical language. We propose a risk-sensitive evaluation framework that quantifies hallucinations through the presence of risk-bearing language, including treatment directives, contraindications, urgency cues, and mentions of high-risk medications. Rather than assessing clinical correctness, our approach evaluates the potential impact of hallucinated content if acted upon. We further combine risk scoring with a relevance measure to identify high-risk, low-grounding failures. We apply this framework to three instruction-tuned language models using controlled patient-facing prompts designed as safety stress tests. Our results show that models with similar surface-level behavior exhibit substantially different risk profiles and that standard evaluation metrics fail to capture these distinctions. These findings highlight the importance of incorporating risk sensitivity into hallucination evaluation and suggest that evaluation validity is critically dependent on task and prompt design.

</details>


### [214] [Intent Mismatch Causes LLMs to Get Lost in Multi-Turn Conversation](https://arxiv.org/abs/2602.07338)
*Geng Liu,Fei Zhu,Rong Feng,Changyi Ma,Shiqi Wang,Gaofeng Meng*

Main category: cs.CL

TL;DR: 论文提出"对话迷失"现象的根本原因在于意图对齐差距而非模型能力缺陷，通过解耦意图理解与任务执行，采用Mediator-Assistant架构显著改善多轮对话性能


<details>
  <summary>Details</summary>
Motivation: 大语言模型在多轮对话中相比单轮交互出现显著性能下降（"对话迷失"现象），现有研究归因于模型不可靠性，但本文认为根本原因在于用户意图与模型理解之间的对齐差距

Method: 提出Mediator-Assistant架构，通过经验驱动的Mediator将模糊用户输入转化为基于历史交互模式的明确结构化指令，实现意图理解与任务执行的解耦

Result: 该方法显著减轻了多种大语言模型在多轮对话中的性能下降，验证了意图对齐差距是"对话迷失"现象的根本原因

Conclusion: "对话迷失"源于用户意图与模型理解的结构性对齐差距而非模型能力限制，通过解耦意图理解与任务执行的架构设计可以有效解决这一问题

Abstract: Multi-turn conversation has emerged as a predominant interaction paradigm for Large Language Models (LLMs). Users often employ follow-up questions to refine their intent, expecting LLMs to adapt dynamically. However, recent research reveals that LLMs suffer a substantial performance drop in multi-turn settings compared to single-turn interactions with fully specified instructions, a phenomenon termed ``Lost in Conversation'' (LiC). While this prior work attributes LiC to model unreliability, we argue that the root cause lies in an intent alignment gap rather than intrinsic capability deficits. In this paper, we first demonstrate that LiC is not a failure of model capability but rather a breakdown in interaction between users and LLMs. We theoretically show that scaling model size or improving training alone cannot resolve this gap, as it arises from structural ambiguity in conversational context rather than representational limitations. To address this, we propose to decouple intent understanding from task execution through a Mediator-Assistant architecture. By utilizing an experience-driven Mediator to explicate user inputs into explicit, well-structured instructions based on historical interaction patterns, our approach effectively bridges the gap between vague user intent and model interpretation. Experimental results demonstrate that this method significantly mitigates performance degradation in multi-turn conversations across diverse LLMs.

</details>


### [215] [ViHERMES: A Graph-Grounded Multihop Question Answering Benchmark and System for Vietnamese Healthcare Regulations](https://arxiv.org/abs/2602.07361)
*Long S. T. Nguyen,Quan M. Bui,Tin T. Ngo,Quynh T. N. Vo,Dung N. H. Le,Tho T. Quan*

Main category: cs.CL

TL;DR: 提出了ViHERMES数据集，用于评估越南语医疗法规的多跳问答系统，并开发了图感知检索框架来提升性能。


<details>
  <summary>Details</summary>
Motivation: 医疗法规问答需要跨法律文本的多跳推理，但现有评估在低资源语言（如越南语）中受限，缺乏支持多跳推理的基准数据集。

Method: 1) 提出ViHERMES数据集构建管道：基于语义聚类和图启发数据挖掘，结合大语言模型生成带结构化证据和推理标注的问题-答案对；2) 开发图感知检索框架：在法律单元层面建模形式法律关系，支持原则性上下文扩展。

Result: ViHERMES为评估多跳法规问答系统提供了具有挑战性的基准，提出的图感知方法在实验中持续优于强检索基线。

Conclusion: ViHERMES填补了越南语医疗法规多跳问答评估的空白，图感知检索框架能有效处理法律文本间的复杂依赖关系，数据集和系统已开源。

Abstract: Question Answering (QA) over regulatory documents is inherently challenging due to the need for multihop reasoning across legally interdependent texts, a requirement that is particularly pronounced in the healthcare domain where regulations are hierarchically structured and frequently revised through amendments and cross-references. Despite recent progress in retrieval-augmented and graph-based QA methods, systematic evaluation in this setting remains limited, especially for low-resource languages such as Vietnamese, due to the lack of benchmark datasets that explicitly support multihop reasoning over healthcare regulations. In this work, we introduce the Vietnamese Healthcare Regulations-Multihop Reasoning Dataset (ViHERMES), a benchmark designed for multihop QA over Vietnamese healthcare regulatory documents. ViHERMES consists of high-quality question-answer pairs that require reasoning across multiple regulations and capture diverse dependency patterns, including amendment tracing, cross-document comparison, and procedural synthesis. To construct the dataset, we propose a controlled multihop QA generation pipeline based on semantic clustering and graph-inspired data mining, followed by large language model-based generation with structured evidence and reasoning annotations. We further present a graph-aware retrieval framework that models formal legal relations at the level of legal units and supports principled context expansion for legally valid and coherent answers. Experimental results demonstrate that ViHERMES provides a challenging benchmark for evaluating multihop regulatory QA systems and that the proposed graph-aware approach consistently outperforms strong retrieval-based baselines. The ViHERMES dataset and system implementation are publicly available at https://github.com/ura-hcmut/ViHERMES.

</details>


### [216] [TernaryLM: Memory-Efficient Language Modeling via Native 1-Bit Quantization with Adaptive Layer-wise Scaling](https://arxiv.org/abs/2602.07374)
*Nisharg Nargund,Priyesh Shukla*

Main category: cs.CL

TL;DR: TernaryLM是一个132M参数的Transformer模型，采用原生1位三元量化{-1, 0, +1}训练，显著减少内存占用而不牺牲语言建模能力。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型需要大量计算资源，限制了在边缘设备和资源受限环境中的部署。需要开发更高效的模型以减少内存占用。

Method: 使用原生1位三元量化{-1, 0, +1}进行训练，采用直通估计器和自适应逐层缩放因子，从头学习量化感知表示，而不是对预训练模型进行后训练量化。

Result: 在TinyStories上验证困惑度为58.42；MRPC复述检测F1分数82.47%；内存减少2.4倍（498MB vs 1197MB）；推理延迟相当；在不同语料库上训练稳定。

Conclusion: 原生1位训练是高效神经语言模型的有前景方向，中间Transformer层与极端量化兼容性最高，为未来非均匀精度策略提供参考。

Abstract: Large language models (LLMs) achieve remarkable performance but demand substantial computational resources, limiting deployment on edge devices and resource-constrained environments. We present TernaryLM, a 132M parameter transformer architecture that employs native 1-bit ternary quantization {-1, 0, +1} during training, achieving significant memory reduction without sacrificing language modeling capability. Unlike post-training quantization approaches that quantize pre-trained full-precision models, TernaryLM learns quantization-aware representations from scratch using straight-through estimators and adaptive per-layer scaling factors. Our experiments demonstrate: (1) validation perplexity of 58.42 on TinyStories; (2) downstream transfer with 82.47 percent F1 on MRPC paraphrase detection; (3) 2.4x memory reduction (498MB vs 1197MB) with comparable inference latency; and (4) stable training dynamics across diverse corpora. We provide layer-wise quantization analysis showing that middle transformer layers exhibit highest compatibility with extreme quantization, informing future non-uniform precision strategies. Our results suggest that native 1-bit training is a promising direction for efficient neural language models. Code is available at https://github.com/1nisharg/TernaryLM-Memory-Efficient-Language-Modeling.

</details>


### [217] [Efficient Post-Training Pruning of Large Language Models with Statistical Correction](https://arxiv.org/abs/2602.07375)
*Peiqi Yu,Jinhao Wang,Xinyi Sui,Nam Ling,Wei Wang,Wei Jiang*

Main category: cs.CL

TL;DR: 提出基于一阶统计特性的轻量级后训练剪枝框架，通过统计校准和能量补偿改进剪枝质量，无需重训练或二阶信息


<details>
  <summary>Details</summary>
Motivation: 现有后训练剪枝方法在剪枝质量和计算效率之间存在权衡：启发式方法高效但对激活异常值敏感，重构方法质量高但计算代价大

Method: 基于模型权重和激活的一阶统计特性，剪枝时使用通道级统计校准基于幅值的重要性分数，剪枝后应用解析能量补偿校正权重移除引起的分布失真

Result: 在多个LLM家族、稀疏模式和评估任务上的实验表明，该方法提高了剪枝性能，同时保持与启发式方法相当的计算成本

Conclusion: 简单的统计校正对LLM的后训练剪枝是有效的，无需重训练、梯度或二阶信息

Abstract: Post-training pruning is an effective approach for reducing the size and inference cost of large language models (LLMs), but existing methods often face a trade-off between pruning quality and computational efficiency. Heuristic pruning methods are efficient but sensitive to activation outliers, while reconstruction-based approaches improve fidelity at the cost of heavy computation. In this work, we propose a lightweight post-training pruning framework based on first-order statistical properties of model weights and activations. During pruning, channel-wise statistics are used to calibrate magnitude-based importance scores, reducing bias from activation-dominated channels. After pruning, we apply an analytic energy compensation to correct distributional distortions caused by weight removal. Both steps operate without retraining, gradients, or second-order information. Experiments across multiple LLM families, sparsity patterns, and evaluation tasks show that the proposed approach improves pruning performance while maintaining computational cost comparable to heuristic methods. The results suggest that simple statistical corrections can be effective for post-training pruning of LLMs.

</details>


### [218] [Do Large Language Models Reflect Demographic Pluralism in Safety?](https://arxiv.org/abs/2602.07376)
*Usman Naseem,Gautam Siddharth Kashyap,Sushant Kumar Ray,Rafiq Ali,Ebad Shabbir,Abdullah Mohammad*

Main category: cs.CL

TL;DR: Demo-SafetyBench是一个新的安全评估基准，通过直接在提示层面建模人口统计学多元主义，解决现有对齐数据集忽略不同社区安全感知差异的问题。


<details>
  <summary>Details</summary>
Motivation: 现有LLM安全对齐数据集（如ANTHROPIC-HH和DICES）使用人口统计学上狭窄的标注者群体，忽略了不同社区、文化背景和道德规范下安全感知的差异。LLM安全本质上是多元的，需要反映这种多样性。

Method: 采用两阶段方法：第一阶段将DICES提示重新分类为14个安全领域，保留人口统计学元数据，并通过Llama-3.1-8B-Instruct扩展低资源领域，使用SimHash去重，得到43,050个样本。第二阶段使用LLMs-as-Raters（Gemma-7B、GPT-4o、LLaMA-2-7B）在零样本推理下评估多元敏感性。

Result: 通过平衡阈值（delta=0.5，tau=10）实现了高可靠性（ICC=0.87）和低人口统计学敏感性（DS=0.12），证明多元安全评估可以同时具有可扩展性和人口统计学鲁棒性。

Conclusion: Demo-SafetyBench展示了在LLM安全评估中直接建模人口统计学多元主义的可行性，为开发更具包容性和代表性的安全对齐方法提供了新方向。

Abstract: Large Language Model (LLM) safety is inherently pluralistic, reflecting variations in moral norms, cultural expectations, and demographic contexts. Yet, existing alignment datasets such as ANTHROPIC-HH and DICES rely on demographically narrow annotator pools, overlooking variation in safety perception across communities. Demo-SafetyBench addresses this gap by modeling demographic pluralism directly at the prompt level, decoupling value framing from responses. In Stage I, prompts from DICES are reclassified into 14 safety domains (adapted from BEAVERTAILS) using Mistral 7B-Instruct-v0.3, retaining demographic metadata and expanding low-resource domains via Llama-3.1-8B-Instruct with SimHash-based deduplication, yielding 43,050 samples. In Stage II, pluralistic sensitivity is evaluated using LLMs-as-Raters-Gemma-7B, GPT-4o, and LLaMA-2-7B-under zero-shot inference. Balanced thresholds (delta = 0.5, tau = 10) achieve high reliability (ICC = 0.87) and low demographic sensitivity (DS = 0.12), confirming that pluralistic safety evaluation can be both scalable and demographically robust.

</details>


### [219] [When the Model Said 'No Comment', We Knew Helpfulness Was Dead, Honesty Was Alive, and Safety Was Terrified](https://arxiv.org/abs/2602.07381)
*Gautam Siddharth Kashyap,Mark Dras,Usman Naseem*

Main category: cs.CL

TL;DR: AlignX：两阶段框架解决大语言模型对齐中的轴崩溃问题，通过提示注入微调和几何校准的专家路由，在有用性、无害性和诚实性方面显著提升性能


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型对齐方法（监督微调和混合专家）在多目标设置中面临挑战：SFT导致冲突目标间的干扰，MoE存在路由校准问题，这种现象被称为"轴崩溃"，表现为特征空间分离导致灾难性遗忘和不可靠的专家路由推理

Method: AlignX采用两阶段框架：第一阶段使用提示注入微调提取轴特定任务特征，缓解灾难性遗忘；第二阶段部署MoCaE模块，利用分形和自然几何校准专家路由，提高推理可靠性

Result: 在Alpaca（有用性）、BeaverTails（无害性）和TruthfulQA（诚实性）上取得显著提升：胜率+171.5%，真实性-信息性+110.1%，安全违规减少4.3%。相比先前MoE方法，延迟和内存使用减少超过35%，在四个LLM上的结果验证了其泛化能力

Conclusion: AlignX有效解决了大语言模型对齐中的轴崩溃问题，通过创新的两阶段框架在保持多目标平衡的同时提高了性能、效率和可靠性，为安全部署提供了实用解决方案

Abstract: Large Language Models (LLMs) need to be in accordance with human values-being helpful, harmless, and honest (HHH)-is important for safe deployment. Existing works use Supervised Fine-Tuning (SFT) and Mixture-of-Experts (MoE) to align LLMs. However, these works face challenges in multi-objective settings, such as SFT leading to interference between conflicting objectives, while MoEs suffer from miscalibrated routing. We term this failure mode Axis Collapse, marked by (1) disjoint feature spaces causing catastrophic forgetting, and (2) unreliable inference from misrouted experts. To resolve this, we propose AlignX, a two-stage framework. Stage 1 uses prompt-injected fine-tuning to extract axis-specific task features, mitigating catastrophic forgetting. Stage 2 deploys a MoCaE module that calibrates expert routing using fractal and natural geometry, improving inference reliability. AlignX achieves significant gains on Alpaca (Helpfulness), BeaverTails (Harmlessness), and TruthfulQA (Honesty), with +171.5% win rate, +110.1% in truthfulness-informativeness, and 4.3% fewer safety violations. It also reduces latency and memory usage by over 35% compared to prior MoEs. Results across four LLMs validate its generalizability.

</details>


### [220] [Advantages of Domain Knowledge Injection for Legal Document Summarization: A Case Study on Summarizing Indian Court Judgments in English and Hindi](https://arxiv.org/abs/2602.07382)
*Debtanu Datta,Rajdeep Mukherjee,Adrijit Goswami,Saptarshi Ghosh*

Main category: cs.CL

TL;DR: 该研究提出了一种通过注入领域知识来改进印度法律文本摘要的方法，支持英语和印地语摘要生成，在提取式和生成式模型中都取得了显著改进。


<details>
  <summary>Details</summary>
Motivation: 印度法律判决摘要面临双重挑战：法律文本语言复杂且非结构化，同时大量印度人口不理解法律文本使用的复杂英语，需要印度语言摘要。

Method: 1) 为提取式神经摘要模型注入领域特定预训练编码器；2) 通过对大型英-印法律语料库进行持续预训练，将法律领域知识注入生成式模型（包括大语言模型）。

Result: 提出的方法在英语到英语和英语到印地语的印度法律文档摘要任务中，在标准评估指标、事实一致性指标和法律领域特定指标上都取得了统计显著的改进，并通过领域专家验证了有效性。

Conclusion: 通过注入法律领域知识到摘要模型中，可以有效改进印度法律文本的多语言摘要质量，解决法律文本复杂性和语言障碍问题。

Abstract: Summarizing Indian legal court judgments is a complex task not only due to the intricate language and unstructured nature of the legal texts, but also since a large section of the Indian population does not understand the complex English in which legal text is written, thus requiring summaries in Indian languages. In this study, we aim to improve the summarization of Indian legal text to generate summaries in both English and Hindi (the most widely spoken Indian language), by injecting domain knowledge into diverse summarization models. We propose a framework to enhance extractive neural summarization models by incorporating domain-specific pre-trained encoders tailored for legal texts. Further, we explore the injection of legal domain knowledge into generative models (including Large Language Models) through continual pre-training on large legal corpora in English and Hindi. Our proposed approaches achieve statistically significant improvements in both English-to-English and English-to-Hindi Indian legal document summarization, as measured by standard evaluation metrics, factual consistency metrics, and legal domain-specific metrics. Furthermore, these improvements are validated through domain experts, demonstrating the effectiveness of our approaches.

</details>


### [221] [Measuring cross-language intelligibility between Romance languages with computational tools](https://arxiv.org/abs/2602.07447)
*Liviu P Dinu,Ana Sabina Uban,Bogdan Iordache,Anca Dinu,Simona Georgescu*

Main category: cs.CL

TL;DR: 提出基于词汇相似度的计算指标来评估罗曼语族语言间的相互可懂度，验证了语言间可懂度的不对称性并与人类实验结果相关


<details>
  <summary>Details</summary>
Motivation: 研究罗曼语族语言间的相互可懂度，需要一种计算指标来量化评估语言间的理解程度，以验证直觉上的可懂度不对称现象

Method: 提出基于词汇相似度的计算指标，结合表层和语义相似度，使用正字法和语音形式，在不同平行语料库和词向量模型上测量五种主要罗曼语（法语、意大利语、葡萄牙语、西班牙语、罗马尼亚语）的相互可懂度

Result: 获得的可懂度分数证实了语言间可懂度不对称的直觉，并与人类完形填空实验结果显著相关

Conclusion: 提出的计算指标能有效评估罗曼语族语言间的相互可懂度，验证了可懂度不对称现象，并与人类实验结果一致

Abstract: We present an analysis of mutual intelligibility in related languages applied for languages in the Romance family. We introduce a novel computational metric for estimating intelligibility based on lexical similarity using surface and semantic similarity of related words, and use it to measure mutual intelligibility for the five main Romance languages (French, Italian, Portuguese, Spanish, and Romanian), and compare results using both the orthographic and phonetic forms of words as well as different parallel corpora and vectorial models of word meaning representation. The obtained intelligibility scores confirm intuitions related to intelligibility asymmetry across languages and significantly correlate with results of cloze tests in human experiments.

</details>


### [222] [DLLM Agent: See Farther, Run Faster](https://arxiv.org/abs/2602.07451)
*Huiling Zhen,Weizhe Lin,Renxi Liu,Kai Han,Yiming Li,Yuchuan Tian,Hanting Chen,Xiaoguang Li,Xiaosong Li,Chen Chen,Xianzhi Yu,Mingxuan Yuan,Youliang Yan,Peifeng Qin,Jun Wang,Yu Wang,Dacheng Tao,Yunhe Wang*

Main category: cs.CL

TL;DR: 扩散大语言模型在智能体决策中比自回归模型快30%以上，减少交互轮次和工具调用，但需要更强的工具调用训练和注意力对齐


<details>
  <summary>Details</summary>
Motivation: 探索扩散大语言模型在智能体多步决策中的潜力，比较其与自回归模型在相同智能体框架下的性能差异，特别是效率优势

Method: 在相同智能体工作流（DeepDiver）中实例化DLLM和AR骨干网络，使用相同的轨迹数据进行匹配的智能体导向微调，创建可直接比较的扩散支持DLLM智能体和AR智能体

Result: 在准确率相当的情况下，DLLM智能体端到端速度平均比AR智能体快30%以上，某些情况下超过8倍加速；正确完成任务时，DLLM智能体需要更少的交互轮次和工具调用，规划器命中率更高，收敛更快

Conclusion: 扩散骨干网络在智能体决策中具有显著效率优势，但需要解决工具调用失败和注意力对齐问题，扩散智能体表现出更强的全局规划信号

Abstract: Diffusion large language models (DLLMs) have emerged as an alternative to autoregressive (AR) decoding with appealing efficiency and modeling properties, yet their implications for agentic multi-step decision making remain underexplored. We ask a concrete question: when the generation paradigm is changed but the agent framework and supervision are held fixed, do diffusion backbones induce systematically different planning and tool-use behaviors, and do these differences translate into end-to-end efficiency gains? We study this in a controlled setting by instantiating DLLM and AR backbones within the same agent workflow (DeepDiver) and performing matched agent-oriented fine-tuning on the same trajectory data, yielding diffusion-backed DLLM Agents and directly comparable AR agents. Across benchmarks and case studies, we find that, at comparable accuracy, DLLM Agents are on average over 30% faster end to end than AR agents, with some cases exceeding 8x speedup. Conditioned on correct task completion, DLLM Agents also require fewer interaction rounds and tool invocations, consistent with higher planner hit rates that converge earlier to a correct action path with less backtracking. We further identify two practical considerations for deploying diffusion backbones in tool-using agents. First, naive DLLM policies are more prone to structured tool-call failures, necessitating stronger tool-call-specific training to emit valid schemas and arguments. Second, for multi-turn inputs interleaving context and action spans, diffusion-style span corruption requires aligned attention masking to avoid spurious context-action information flow; without such alignment, performance degrades. Finally, we analyze attention dynamics across workflow stages and observe paradigm-specific coordination patterns, suggesting stronger global planning signals in diffusion-backed agents.

</details>


### [223] [SED-SFT: Selectively Encouraging Diversity in Supervised Fine-Tuning](https://arxiv.org/abs/2602.07464)
*Yijie Chen,Yijin Liu,Fandong Meng*

Main category: cs.CL

TL;DR: SED-SFT通过引入选择性熵正则化解决SFT中的模式崩溃问题，提升生成多样性，从而改善后续RL性能


<details>
  <summary>Details</summary>
Motivation: 传统SFT使用交叉熵损失导致模式崩溃，模型过度集中于特定响应模式，缺乏分布多样性，限制了后续RL的探索效率。现有方法未能充分平衡多样性与准确性

Method: 提出SED-SFT框架，基于token探索空间自适应鼓励多样性，在优化目标中引入带有选择性掩码机制的选择性熵正则化项

Result: 在8个数学基准测试中，SED-SFT显著提升生成多样性，计算开销可忽略，相比标准CE基线，在Llama-3.2-3B-Instruct和Qwen2.5-Math-7B-Instruct上后续RL性能分别平均提升2.06和1.20分

Conclusion: SED-SFT有效解决了SFT中的模式崩溃问题，通过提升多样性改善了后续RL性能，为LLM后训练提供了更优的SFT方法

Abstract: Supervised Fine-Tuning (SFT) followed by Reinforcement Learning (RL) has emerged as the standard post-training paradigm for large language models (LLMs). However, the conventional SFT process, driven by Cross-Entropy (CE) loss, often induces mode collapse, where models over-concentrate on specific response patterns. This lack of distributional diversity severely restricts the exploration efficiency required for subsequent RL. While recent studies have attempted to improve SFT by replacing the CE loss, aiming to preserve diversity or refine the update policy, they fail to adequately balance diversity and accuracy, thereby yielding suboptimal performance after RL. To address the mode collapse problem, we propose SED-SFT, which adaptively encourages diversity based on the token exploration space. This framework introduces a selective entropy regularization term with a selective masking mechanism into the optimization objective. Extensive experiments across eight mathematical benchmarks demonstrate that SED-SFT significantly enhances generation diversity with a negligible computational overhead increase compared with CE loss, yielding average improvements of 2.06 and 1.20 points in subsequent RL performance over standard CE-based baselines on Llama-3.2-3B-Instruct and Qwen2.5-Math-7B-Instruct, respectively. The code is publicly available at https://github.com/pppa2019/SED-SFT

</details>


### [224] [From Native Memes to Global Moderation: Cros-Cultural Evaluation of Vision-Language Models for Hateful Meme Detection](https://arxiv.org/abs/2602.07497)
*Mo Wang,Kaixuan Ren,Pratik Jalan,Ahmed Ashraf,Tuong Vy Vu,Rahul Seetharaman,Shah Nawaz,Usman Naseem*

Main category: cs.CL

TL;DR: 该论文提出了一个评估框架，用于诊断和量化视觉语言模型在多语言表情包数据集上的跨文化鲁棒性，发现"翻译后检测"方法会降低性能，而文化对齐干预（母语提示和单样本学习）能显著提升检测效果。


<details>
  <summary>Details</summary>
Motivation: 文化背景深刻影响人们对在线内容的理解，但当前的视觉语言模型主要基于西方或英语中心视角训练，这限制了它们在仇恨表情包检测等任务中的公平性和跨文化鲁棒性。

Method: 提出了一个系统性评估框架，通过三个维度分析最先进视觉语言模型的跨文化鲁棒性：(i)学习策略（零样本 vs 单样本），(ii)提示语言（母语 vs 英语），(iii)翻译对意义和检测的影响。

Result: 结果显示常见的"翻译后检测"方法会降低性能，而文化对齐干预（母语提示和单样本学习）能显著提升检测效果。研究发现模型存在系统性向西方安全规范收敛的偏差。

Conclusion: 研究揭示了视觉语言模型存在的系统性文化偏差，并提供了可操作的策略来减轻这种偏差，为设计全球鲁棒的多模态内容审核系统提供了指导。

Abstract: Cultural context profoundly shapes how people interpret online content, yet vision-language models (VLMs) remain predominantly trained through Western or English-centric lenses. This limits their fairness and cross-cultural robustness in tasks like hateful meme detection. We introduce a systematic evaluation framework designed to diagnose and quantify the cross-cultural robustness of state-of-the-art VLMs across multilingual meme datasets, analyzing three axes: (i) learning strategy (zero-shot vs. one-shot), (ii) prompting language (native vs. English), and (iii) translation effects on meaning and detection. Results show that the common ``translate-then-detect'' approach deteriorate performance, while culturally aligned interventions - native-language prompting and one-shot learning - significantly enhance detection. Our findings reveal systematic convergence toward Western safety norms and provide actionable strategies to mitigate such bias, guiding the design of globally robust multimodal moderation systems.

</details>


### [225] [Let's Simplify Step by Step: Guiding LLM Towards Multilingual Unsupervised Proficiency-Controlled Sentence Simplification](https://arxiv.org/abs/2602.07499)
*Jingshen Zhang,Xin Ying Qiu,Lifang Lu,Zhuhua Huang,Yutao Hu,Yuechang Wu,JunYu Lu*

Main category: cs.CL

TL;DR: 该论文提出一个框架，通过动态路径规划、语义感知示例选择和对话历史链式推理，将复杂句子简化分解为可管理步骤，在五个语言上提升简化效果同时减少22-42%计算步骤。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在可控难度句子简化方面能力有限，特别是在跨大阅读难度级别简化时表现不佳，需要更有效的简化方法。

Method: 提出一个框架，包含三个核心组件：动态路径规划（将复杂简化分解为可管理步骤）、语义感知示例选择、以及基于对话历史的链式推理生成，确保连贯推理过程。

Result: 在五个语言的两个基准测试中，该方法提高了简化效果，同时减少了22-42%的计算步骤。人类评估确认了简化效果与意义保留之间的基本权衡，即使人类标注者在语义保留判断上也难以达成一致。

Conclusion: 逐步简化方法确实能提升控制性，但在广泛简化过程中保持语义保真度仍然是一个开放挑战，需要进一步研究解决。

Abstract: Large language models demonstrate limited capability in proficiency-controlled sentence simplification, particularly when simplifying across large readability levels. We propose a framework that decomposes complex simplifications into manageable steps through dynamic path planning, semantic-aware exemplar selection, and chain-of-thought generation with conversation history for coherent reasoning. Evaluation on five languages across two benchmarks shows our approach improves simplification effectiveness while reducing computational steps by 22-42%. Human evaluation confirms the fundamental trade-off between simplification effectiveness and meaning preservation. Notably, even human annotators struggle to agree on semantic preservation judgments, highlighting the inherent complexity of this task. Our work shows that while step-by-step simplification improves control, preserving semantic fidelity during extensive simplification remains an open challenge.

</details>


### [226] [Improving Variable-Length Generation in Diffusion Language Models via Length Regularization](https://arxiv.org/abs/2602.07546)
*Zicong Cheng,Ruixuan Jia,Jia Li,Guo-Wei Yang,Meng-Hao Guo,Shi-Min Hu*

Main category: cs.CL

TL;DR: LR-DLLM：一种长度正则化推理框架，解决扩散大语言模型在变长生成中的长度诱导偏差问题，实现可靠的未知长度生成


<details>
  <summary>Details</summary>
Motivation: 扩散大语言模型（DLLMs）在变长生成中存在固有缺陷，因为其推理基于固定长度画布，且隐含假设已知目标长度。在现实场景如补全和填充任务中，当长度未知时，简单地比较不同掩码长度的置信度会产生系统性偏差，导致生成不足或冗余延续。这种失败源于生成置信度估计中的内在长度诱导偏差，使得现有DLLMs无法可靠确定生成长度。

Method: 提出LR-DLLM（长度正则化推理框架），将生成长度作为显式变量，在推理时实现可靠的长度确定。通过显式的长度正则化将语义兼容性与长度诱导不确定性解耦，纠正有偏的置信度估计。该框架无需修改底层DLLM或其训练过程，即可实现生成跨度的动态扩展或收缩。

Result: 在HumanEvalInfilling任务中，在完全未知长度条件下达到51.3% Pass@1（比DreamOn提升13.4%）；在四语言McEval任务中平均达到51.5% Pass@1（比DreamOn提升14.3%）。

Conclusion: LR-DLLM有效解决了DLLMs在变长生成中的长度诱导偏差问题，通过显式长度正则化实现了可靠的未知长度生成，显著提升了填充和补全任务的性能。

Abstract: Diffusion Large Language Models (DLLMs) are inherently ill-suited for variable-length generation, as their inference is defined on a fixed-length canvas and implicitly assumes a known target length. When the length is unknown, as in realistic completion and infilling, naively comparing confidence across mask lengths becomes systematically biased, leading to under-generation or redundant continuations. In this paper, we show that this failure arises from an intrinsic lengthinduced bias in generation confidence estimates, leaving existing DLLMs without a robust way to determine generation length and making variablelength inference unreliable. To address this issue, we propose LR-DLLM, a length-regularized inference framework for DLLMs that treats generation length as an explicit variable and achieves reliable length determination at inference time. It decouples semantic compatibility from lengthinduced uncertainty through an explicit length regularization that corrects biased confidence estimates. Based on this, LR-DLLM enables dynamic expansion or contraction of the generation span without modifying the underlying DLLM or its training procedure. Experiments show that LRDLLM achieves 51.3% Pass@1 on HumanEvalInfilling under fully unknown lengths (+13.4% vs. DreamOn) and 51.5% average Pass@1 on four-language McEval (+14.3% vs. DreamOn).

</details>


### [227] [Learning to Self-Verify Makes Language Models Better Reasoners](https://arxiv.org/abs/2602.07594)
*Yuxin Chen,Yu Wang,Yi Zhang,Ziang Ye,Zhengzhou Cai,Yaorui Shi,Qi Gu,Hui Su,Xunliang Cai,Xiang Wang,An Zhang,Tat-Seng Chua*

Main category: cs.CL

TL;DR: LLMs在生成推理路径方面表现出色，但在自我验证方面较弱，存在能力不对称。研究发现自我验证训练可以提升生成性能，而生成训练却不能提升验证能力。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型在复杂任务中能生成有前景的推理路径，但它们在验证自己答案方面仍然薄弱，存在生成与自我验证之间的持续能力不对称。研究者希望深入探究这种不对称性，并探索如何通过自我验证训练来提升整体性能。

Method: 1. 深入调查训练演化过程中的能力不对称现象；2. 探索将自我验证整合到生成训练中，通过多任务强化学习框架，将生成和自我验证作为两个独立但互补的目标进行优化。

Result: 研究发现：1) 提高生成能力不会相应提高自我验证能力；2) 学习自我验证可以有效提升生成性能，达到与标准生成训练相当的准确性，同时产生更高效有效的推理轨迹；3) 多任务强化学习框架在多个基准测试和模型上都显示出优于仅生成训练的性能提升。

Conclusion: 生成与自我验证之间存在显著的能力不对称，但自我验证训练可以提升生成性能。通过多任务强化学习框架整合这两个目标，可以在生成和验证能力上都获得性能提升，为LLM训练提供了新的方向。

Abstract: Recent large language models (LLMs) achieve strong performance in generating promising reasoning paths for complex tasks. However, despite powerful generation ability, LLMs remain weak at verifying their own answers, revealing a persistent capability asymmetry between generation and self-verification. In this work, we conduct an in-depth investigation of this asymmetry throughout training evolution and show that, even on the same task, improving generation does not lead to corresponding improvements in self-verification. Interestingly, we find that the reverse direction of this asymmetry behaves differently: learning to self-verify can effectively improve generation performance, achieving accuracy comparable to standard generation training while yielding more efficient and effective reasoning traces. Building on this observation, we further explore integrating self-verification into generation training by formulating a multi-task reinforcement learning framework, where generation and self-verification are optimized as two independent but complementary objectives. Extensive experiments across benchmarks and models demonstrate performance gains over generation-only training in both generation and verification capabilities.

</details>


### [228] [SciClaimEval: Cross-modal Claim Verification in Scientific Papers](https://arxiv.org/abs/2602.07621)
*Xanh Ho,Yun-Ang Wu,Sunisth Kumar,Tian Cheng Xia,Florian Boudin,Andre Greiner-Petter,Akiko Aizawa*

Main category: cs.CL

TL;DR: SciClaimEval是一个新的科学声明验证数据集，包含从已发表论文中提取的真实声明（包括被反驳的声明），采用多模态证据（图表），并评估了11个多模态基础模型。


<details>
  <summary>Details</summary>
Motivation: 现有科学声明验证数据集通常使用人工修改声明或依赖LLM生成反驳声明，缺乏真实的被反驳声明。需要包含真实科学声明和多模态证据的数据集来评估模型性能。

Method: 通过修改支持证据（图表）而非声明本身来创建被反驳声明。数据集包含1,664个标注样本，来自180篇论文，涵盖机器学习、自然语言处理和医学三个领域。提供多格式证据：图像形式的图表，以及LaTeX、HTML、JSON格式的表格。

Result: 评估了11个开源和专有多模态基础模型。结果显示所有模型在基于图表的验证任务上表现仍然具有挑战性，最佳系统与人类基线之间存在显著性能差距。

Conclusion: SciClaimEval填补了科学声明验证数据集的空白，提供了真实的多模态证据。基于图表的验证对现有模型仍然困难，需要进一步研究改进多模态科学声明验证能力。

Abstract: We present SciClaimEval, a new scientific dataset for the claim verification task. Unlike existing resources, SciClaimEval features authentic claims, including refuted ones, directly extracted from published papers. To create refuted claims, we introduce a novel approach that modifies the supporting evidence (figures and tables), rather than altering the claims or relying on large language models (LLMs) to fabricate contradictions. The dataset provides cross-modal evidence with diverse representations: figures are available as images, while tables are provided in multiple formats, including images, LaTeX source, HTML, and JSON. SciClaimEval contains 1,664 annotated samples from 180 papers across three domains, machine learning, natural language processing, and medicine, validated through expert annotation. We benchmark 11 multimodal foundation models, both open-source and proprietary, across the dataset. Results show that figure-based verification remains particularly challenging for all models, as a substantial performance gap remains between the best system and human baseline.

</details>


### [229] [Letting Tutor Personas "Speak Up" for LLMs: Learning Steering Vectors from Dialogue via Preference Optimization](https://arxiv.org/abs/2602.07639)
*Jaewook Lee,Alexander Scarlatos,Simon Woodhead,Andrew Lan*

Main category: cs.CL

TL;DR: 该研究提出了一种基于激活空间导向的方法，通过从人类导师-学生对话中提取导师角色特征，引导大语言模型生成符合特定教学风格的回应，而无需显式提示指令。


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型的辅导系统通常只学习单一导师策略，无法捕捉教学风格的多样性。真实世界中，导师会根据学生需求调整脚手架水平、指导直接性、反馈和情感支持，这些差异会影响对话动态和学生参与度。

Method: 修改双向偏好优化（BiPO）方法，学习一个导向向量——激活空间中的方向，该向量能够将模型回应导向特定的导师角色。这种方法利用人类导师-学生对话数据中的导师角色特征来引导模型行为。

Result: 学习到的导向向量能够捕捉不同对话情境下的导师特定变化，提高与真实导师话语的语义对齐度，增加基于偏好的评估分数，同时基本保持词汇相似性。对学习到的方向系数分析揭示了跨导师的可解释结构，对应一致的教学行为差异。

Conclusion: 激活导向提供了一种有效且可解释的方法，利用直接从人类对话数据中提取的信号来控制大语言模型中导师特定的变化，为个性化教学风格的实现提供了新途径。

Abstract: With the emergence of large language models (LLMs) as a powerful class of generative artificial intelligence (AI), their use in tutoring has become increasingly prominent. Prior works on LLM-based tutoring typically learn a single tutor policy and do not capture the diversity of tutoring styles. In real-world tutor-student interactions, pedagogical intent is realized through adaptive instructional strategies, with tutors varying the level of scaffolding, instructional directiveness, feedback, and affective support in response to learners' needs. These differences can all impact dialogue dynamics and student engagement. In this paper, we explore how tutor personas embedded in human tutor-student dialogues can be used to guide LLM behavior without relying on explicitly prompted instructions. We modify Bidirectional Preference Optimization (BiPO) to learn a steering vector, an activation-space direction that steers model responses towards certain tutor personas. We find that this steering vector captures tutor-specific variation across dialogue contexts, improving semantic alignment with ground-truth tutor utterances and increasing preference-based evaluations, while largely preserving lexical similarity. Analysis of the learned directional coefficients further reveals interpretable structure across tutors, corresponding to consistent differences in tutoring behavior. These results demonstrate that activation steering offers an effective and interpretable way for controlling tutor-specific variation in LLMs using signals derived directly from human dialogue data.

</details>


### [230] [Blind to the Human Touch: Overlap Bias in LLM-Based Summary Evaluation](https://arxiv.org/abs/2602.07673)
*Jiangnan Fang,Cheng-Tse Liu,Hanieh Deilamsalehy,Nesreen K. Ahmed,Puneet Mathur,Nedim Lipka,Franck Dernoncourt,Ryan A. Rossi*

Main category: cs.CL

TL;DR: LLM评委在摘要评估中存在偏见：随着与人类摘要相似度降低，LLM评委越来越偏好其他LLM生成的摘要而非人类摘要，且几乎所有测试模型都存在此模式，与模型自身位置偏见无关。


<details>
  <summary>Details</summary>
Motivation: 虽然LLM评委在摘要评估中比传统算法指标更能捕捉语义信息、推理能力更强且对改写更鲁棒，但它们存在长度、顺序等偏见，且容易受到对抗性输入的影响。现有研究很少从细粒度角度分析这些偏见与明确定义的重叠度量之间的关系。

Method: 在摘要领域，将LLM评委偏见分析作为与人类撰写响应重叠度的函数进行研究。测试了9个近期LLM（参数规模从10亿到120亿），包括Gemma 3和LLaMA 3的变体，使用ROUGE和BLEU度量相似度。

Result: 发现随着被评估摘要之间相似度降低，LLM评委越来越偏好其他LLM生成的摘要而非人类摘要，这一模式在所有测试模型中除一个外都存在，且与模型自身的位置偏见无关。此外，模型甚至难以评估重叠度有限的摘要。

Conclusion: 在摘要领域使用LLM-as-a-judge方法时，应依赖超越简单比较的技术，因为LLM评委存在系统性偏见，难以准确评估摘要质量，特别是在与人类摘要相似度较低的情况下。

Abstract: Large language model (LLM) judges have often been used alongside traditional, algorithm-based metrics for tasks like summarization because they better capture semantic information, are better at reasoning, and are more robust to paraphrasing. However, LLM judges show biases for length and order among others, and are vulnerable to various adversarial input prompts. While recent studies have looked into these biases, few have analyzed them at a more granular level in relation to a well-defined overlap metric. In this work we provide an LLM judge bias analysis as a function of overlap with human-written responses in the domain of summarization. We test 9 recent LLMs with parameter counts ranging from 1 billion to 12 billion, including variants of Gemma 3 and LLaMA 3. We find that LLM judges increasingly prefer summaries generated by other LLMs over those written by humans as the similarities (as measured by ROUGE and BLEU) between the judged summaries decrease, and this pattern extends to all but one model tested, and exists regardless of the models' own position biases. Additionally, we find that models struggle to judge even summaries with limited overlaps, suggesting that LLM-as-a-judge in the summary domain should rely on techniques beyond a simple comparison.

</details>


### [231] [SRR-Judge: Step-Level Rating and Refinement for Enhancing Search-Integrated Reasoning in Search Agents](https://arxiv.org/abs/2602.07773)
*Chen Zhang,Kuicai Dong,Dexun Li,Wenjun Li,Qu Yang,Wei Han,Yong Liu*

Main category: cs.CL

TL;DR: SRR-Judge框架提供搜索集成推理的步骤级评估，通过改进的ReAct工作流和迭代拒绝采样微调，显著提升深度搜索代理性能


<details>
  <summary>Details</summary>
Motivation: 现有基于大型推理模型的深度搜索代理在复杂问答中表现出色，但主流方法仅使用结果监督进行训练，忽视了中间思考和行动的质量评估

Method: 提出SRR-Judge框架进行可靠的推理和搜索行动步骤级评估，集成到改进的ReAct式评估-精炼工作流中，使用SRR标注数据进行迭代拒绝采样微调

Result: SRR-Judge比DeepSeek-V3.1等更大模型提供更可靠的步骤级评估，其评分与最终答案正确性高度相关；基于SRR-Judge标注轨迹对齐策略带来显著性能提升，在挑战性深度搜索基准上平均绝对pass@1提升超过10%

Conclusion: SRR-Judge框架通过精细的步骤级评估和标注，结合迭代拒绝采样微调，有效提升了深度搜索代理的推理和搜索能力，为搜索集成推理提供了可靠的评估和监督方法

Abstract: Recent deep search agents built on large reasoning models (LRMs) excel at complex question answering by iteratively planning, acting, and gathering evidence, a capability known as search-integrated reasoning. However, mainstream approaches often train this ability using only outcome-based supervision, neglecting the quality of intermediate thoughts and actions. We introduce SRR-Judge, a framework for reliable step-level assessment of reasoning and search actions. Integrated into a modified ReAct-style rate-and-refine workflow, SRR-Judge provides fine-grained guidance for search-integrated reasoning and enables efficient post-training annotation. Using SRR-annotated data, we apply an iterative rejection sampling fine-tuning procedure to enhance the deep search capability of the base agent. Empirically, SRR-Judge delivers more reliable step-level evaluations than much larger models such as DeepSeek-V3.1, with its ratings showing strong correlation with final answer correctness. Moreover, aligning the policy with SRR-Judge annotated trajectories leads to substantial performance gains, yielding over a 10 percent average absolute pass@1 improvement across challenging deep search benchmarks.

</details>


### [232] [Attn-GS: Attention-Guided Context Compression for Efficient Personalized LLMs](https://arxiv.org/abs/2602.07778)
*Shenglai Zeng,Tianqi Zheng,Chuan Tian,Dante Everaert,Yau-Shian Wang,Yupin Huang,Michael J. Morais,Rohit Patki,Jinjin Tian,Xinnan Dai,Kai Guo,Monica Xiao Cheng,Hui Liu*

Main category: cs.CL

TL;DR: Attn-GS：基于注意力引导的上下文压缩框架，利用LLM注意力模式识别重要个性化信号，显著减少token使用同时保持接近完整上下文的性能


<details>
  <summary>Details</summary>
Motivation: 个性化LLM需要整合大量用户交互历史和资料，但输入token限制导致高推理延迟和API成本。现有启发式方法（如选择最近交互或使用摘要模型）将上下文视为整体，未能考虑LLM内部如何处理和优先处理不同资料组件

Method: 提出Attn-GS框架：1）通过标记模型利用LLM注意力反馈标记重要个性化句子；2）指导压缩模型生成任务相关、高质量的压缩用户上下文。基于研究发现：a）LLM注意力模式自然揭示重要信号；b）微调增强LLM区分相关与无关信息的能力

Result: Attn-GS在不同任务、token限制和设置下显著优于各种基线方法，在减少50倍token使用的同时，性能接近使用完整上下文

Conclusion: LLM注意力模式能有效识别重要个性化信号，Attn-GS框架通过注意力引导的上下文压缩，在显著降低计算成本的同时保持个性化性能，为实际部署个性化LLM提供了实用解决方案

Abstract: Personalizing large language models (LLMs) to individual users requires incorporating extensive interaction histories and profiles, but input token constraints make this impractical due to high inference latency and API costs. Existing approaches rely on heuristic methods such as selecting recent interactions or prompting summarization models to compress user profiles. However, these methods treat context as a monolithic whole and fail to consider how LLMs internally process and prioritize different profile components. We investigate whether LLMs' attention patterns can effectively identify important personalization signals for intelligent context compression. Through preliminary studies on representative personalization tasks, we discover that (a) LLMs' attention patterns naturally reveal important signals, and (b) fine-tuning enhances LLMs' ability to distinguish between relevant and irrelevant information. Based on these insights, we propose Attn-GS, an attention-guided context compression framework that leverages attention feedback from a marking model to mark important personalization sentences, then guides a compression model to generate task-relevant, high-quality compressed user contexts. Extensive experiments demonstrate that Attn-GS significantly outperforms various baselines across different tasks, token limits, and settings, achieving performance close to using full context while reducing token usage by 50 times.

</details>


### [233] [Emergent Structured Representations Support Flexible In-Context Inference in Large Language Models](https://arxiv.org/abs/2602.07794)
*Ningyu Xu,Qi Zhang,Xipeng Qiu,Xuanjing Huang*

Main category: cs.CL

TL;DR: LLMs在上下文概念推理中会动态构建和使用结构化的潜在表征，这些表征在推理中具有因果作用


<details>
  <summary>Details</summary>
Motivation: 虽然已有研究发现LLMs中存在类似人类的概念表征结构，但尚不清楚这些模型是否在推理中功能性地依赖这些表征

Method: 研究LLMs在上下文概念推理时的内部处理过程，使用因果中介分析来验证概念子空间的功能重要性

Result: 发现中后期层出现概念子空间，其表征结构在不同上下文中保持稳定；该子空间对模型预测具有因果作用；存在从早期到后期的分层处理过程

Conclusion: LLMs会动态构建和使用结构化的潜在表征进行上下文推理，这为理解模型的灵活适应计算过程提供了见解

Abstract: Large language models (LLMs) exhibit emergent behaviors suggestive of human-like reasoning. While recent work has identified structured, human-like conceptual representations within these models, it remains unclear whether they functionally rely on such representations for reasoning. Here we investigate the internal processing of LLMs during in-context concept inference. Our results reveal a conceptual subspace emerging in middle to late layers, whose representational structure persists across contexts. Using causal mediation analyses, we demonstrate that this subspace is not merely an epiphenomenon but is functionally central to model predictions, establishing its causal role in inference. We further identify a layer-wise progression where attention heads in early-to-middle layers integrate contextual cues to construct and refine the subspace, which is subsequently leveraged by later layers to generate predictions. Together, these findings provide evidence that LLMs dynamically construct and use structured, latent representations in context for inference, offering insights into the computational processes underlying flexible adaptation.

</details>


### [234] [Thinking Makes LLM Agents Introverted: How Mandatory Thinking Can Backfire in User-Engaged Agents](https://arxiv.org/abs/2602.07796)
*Jiatong Li,Changdae Oh,Hyeong Kyu Choi,Jindong Wang,Sharon Li*

Main category: cs.CL

TL;DR: 研究发现强制思考反而会损害用户参与场景中LLM代理的性能，因为思考使代理变得"内向"，减少了信息透露，削弱了代理-用户信息交换。


<details>
  <summary>Details</summary>
Motivation: 虽然推理能力已被证明能提升大语言模型在复杂任务上的表现，但其在真实用户参与代理场景中的有效性尚不明确，需要系统性研究思考对用户参与LLM代理的影响。

Method: 在7个模型、3个基准测试和2种思考实例化上进行全面实验，通过定量响应分类分析和定性失败传播案例研究来评估思考效果。

Result: 与预期相反，强制思考在用户参与场景中经常适得其反，导致各种LLM代理性能异常下降。思考使代理变得"内向"，缩短响应并减少向用户的信息披露，从而削弱代理-用户信息交换并导致下游任务失败。

Conclusion: 信息透明度意识是未来真实场景中推理代理设计的关键但未被充分探索的视角。明确提示信息披露能可靠提升不同模型家族的性能，表明主动透明是代理优化的重要杠杆。

Abstract: Eliciting reasoning has emerged as a powerful technique for improving the performance of large language models (LLMs) on complex tasks by inducing thinking. However, their effectiveness in realistic user-engaged agent scenarios remains unclear. In this paper, we conduct a comprehensive study on the effect of explicit thinking in user-engaged LLM agents. Our experiments span across seven models, three benchmarks, and two thinking instantiations, and we evaluate them through both a quantitative response taxonomy analysis and qualitative failure propagation case studies. Contrary to expectations, we find that mandatory thinking often backfires on agents in user-engaged settings, causing anomalous performance degradation across various LLMs. Our key finding reveals that thinking makes agents more ``introverted'' by shortening responses and reducing information disclosure to users, which weakens agent-user information exchange and leads to downstream task failures. Furthermore, we demonstrate that explicitly prompting for information disclosure reliably improves performance across diverse model families, suggesting that proactive transparency is a vital lever for agent optimization. Overall, our study suggests that information transparency awareness is a crucial yet underexplored perspective for the future design of reasoning agents in real-world scenarios. Our code is available at https://github.com/deeplearning-wisc/Thinking-Agent.

</details>


### [235] [Pruning as a Cooperative Game: Surrogate-Assisted Layer Contribution Estimation for Large Language Models](https://arxiv.org/abs/2602.07804)
*Xuan Ding,Pengyu Tong,Ranjie Duan,Yunjian Zhang,Rui Sun,Yao Zhu*

Main category: cs.CL

TL;DR: 提出基于博弈论的层剪枝框架，将每层视为玩家，模型性能作为效用，通过轻量级代理网络估计层间贡献，实现更高效的LLM层剪枝


<details>
  <summary>Details</summary>
Motivation: 现有层剪枝方法依赖静态启发式规则，未能考虑层间依赖关系，限制了剪枝效果。需要一种能动态识别关键层并考虑层间相互作用的剪枝方法

Method: 将层剪枝建模为合作博弈，每层作为玩家，性能作为效用。使用轻量级代理网络估计层间边际贡献，采用分层蒙特卡洛掩码采样降低Shapley值计算成本

Result: 实验表明该方法在困惑度和零样本准确率上表现优异，实现了更高效有效的大语言模型层剪枝

Conclusion: 提出的博弈论框架能有效捕捉层间依赖，动态识别关键层，为LLM层剪枝提供了更优解决方案

Abstract: While large language models (LLMs) demonstrate impressive performance across various tasks, their deployment in real-world scenarios is still constrained by high computational demands. Layer-wise pruning, a commonly employed strategy to mitigate inference costs, can partially address this challenge. However, existing approaches generally depend on static heuristic rules and fail to account for the interdependencies among layers, thereby limiting the effectiveness of the pruning process. To this end, this paper proposes a game-theoretic framework that formulates layer pruning as a cooperative game in which each layer acts as a player and model performance serves as the utility. As computing exact Shapley values is computationally infeasible for large language models (LLMs), we propose using a lightweight surrogate network to estimate layer-wise marginal contributions. This network can predict LLM performance for arbitrary layer combinations at a low computational cost. Additionally, we employ stratified Monte Carlo mask sampling to further reduce the cost of Sharpley value estimation. This approach captures inter-layer dependencies and dynamically identifies critical layers for pruning. Extensive experiments demonstrate the consistent superiority of our method in terms of perplexity and zero-shot accuracy, achieving more efficient and effective layer-wise pruning for large language models.

</details>


### [236] [LLMs Know More About Numbers than They Can Say](https://arxiv.org/abs/2602.07812)
*Fengting Yuchi,Li Du,Jason Eisner*

Main category: cs.CL

TL;DR: LLMs在混合表示的数字比较上表现不佳，但隐藏状态编码了数字大小信息，通过线性探针可提取并改进模型性能


<details>
  <summary>Details</summary>
Motivation: 尽管最先进的LLMs能解决数学问题，但它们在混合表示的数字比较上会出错（如"5.7×10² vs 580"），这引发了一个基本问题：LLMs是否真正理解这些数字的大小？

Method: 1. 探测多个开源LLMs的隐藏状态；2. 使用单个线性投影从适当隐藏层提取数字的对数幅度；3. 训练线性分类器从隐藏状态中恢复数字排序；4. 将探针的分类器对数损失作为辅助目标进行微调

Result: 1. 隐藏状态编码了数字的对数幅度（合成文本相对误差2.3%，科学论文19.06%）；2. 隐藏状态能编码数字排序（线性分类器准确率>90%）；3. 模型直接回答排序的准确率仅50-70%；4. 使用探针损失作为辅助目标微调后，口头回答准确率提升3.22%

Conclusion: LLMs的隐藏状态确实编码了数字大小信息，但模型无法有效利用这些信息进行显式推理。通过改进内部幅度表示可以增强数值推理能力，这为提升LLMs的数学能力提供了新方向。

Abstract: Although state-of-the-art LLMs can solve math problems, we find that they make errors on numerical comparisons with mixed notation: "Which is larger, $5.7 \times 10^2$ or $580$?" This raises a fundamental question: Do LLMs even know how big these numbers are? We probe the hidden states of several smaller open-source LLMs. A single linear projection of an appropriate hidden layer encodes the log-magnitudes of both kinds of numerals, allowing us to recover the numbers with relative error of about 2.3% (on restricted synthetic text) or 19.06% (on scientific papers). Furthermore, the hidden state after reading a pair of numerals encodes their ranking, with a linear classifier achieving over 90% accuracy. Yet surprisingly, when explicitly asked to rank the same pairs of numerals, these LLMs achieve only 50-70% accuracy, with worse performance for models whose probes are less effective. Finally, we show that incorporating the classifier probe's log-loss as an auxiliary objective during finetuning brings an additional 3.22% improvement in verbalized accuracy over base models, demonstrating that improving models' internal magnitude representations can enhance their numerical reasoning capabilities.

</details>


### [237] [TodoEvolve: Learning to Architect Agent Planning Systems](https://arxiv.org/abs/2602.07839)
*Jiaxi Liu,Yanzuo Jiang,Guibin Zhang,Zihan Zhang,Heng Chang,Zhenfei Yin,Qibing Ren,Junchi Yan*

Main category: cs.CL

TL;DR: TodoEvolve是一个元规划范式，能够自主合成并动态修订任务特定的规划架构，通过PlanFactory统一规划范式，使用IGPO训练模型，在多个基准测试中超越手工设计的规划模块。


<details>
  <summary>Details</summary>
Motivation: 现有代理系统主要依赖固定的、手工设计的规划结构，缺乏适应开放式问题结构多样性的灵活性，需要一种能够自主适应不同任务结构的规划方法。

Method: 1. 构建PlanFactory模块化设计空间，将不同规划范式标准化到统一代码库中；2. 收集高质量规划轨迹；3. 使用阻抗引导偏好优化（IGPO）训练Todo-14B模型，这是一个多目标强化学习目标，鼓励生成性能好、稳定且token高效的规划系统。

Result: 在五个代理基准测试中，TodoEvolve始终超越精心设计的规划模块，同时保持经济的API成本和运行时开销。

Conclusion: TodoEvolve通过元规划范式成功解决了现有规划方法缺乏灵活性的问题，能够自主适应不同任务结构，在多个基准测试中表现出优越性能。

Abstract: Planning has become a central capability for contemporary agent systems in navigating complex, long-horizon tasks, yet existing approaches predominantly rely on fixed, hand-crafted planning structures that lack the flexibility to adapt to the structural diversity of open-ended problems. To address this limitation, we introduce TodoEvolve, a meta-planning paradigm that autonomously synthesizes and dynamically revises task-specific planning architectures. Specifically, we first construct PlanFactory, a modular design space that standardizes diverse planning paradigms within a unified codebase encompassing topology, initialization, adaptation, and navigation, thereby providing a common interface for heterogeneous planning patterns. Leveraging PlanFactory, we collect high-quality planning trajectories and train Todo-14B via \textit{Impedance-Guided Preference Optimization} (IGPO), a multi-objective reinforcement learning objective that encourages the generation of planning systems that are performant, stable, and token-efficient across arbitrary tasks and agent backbones. Empirical evaluations on five agentic benchmarks demonstrate that TodoEvolve consistently surpasses carefully engineered planning modules while maintaining economical API costs and runtime overhead.

</details>


### [238] [Evaluating and Calibrating LLM Confidence on Questions with Multiple Correct Answers](https://arxiv.org/abs/2602.07842)
*Yuhan Wang,Shiyu Ni,Zhikai Ding,Zihang Zhan,Yuanzi Li,Keping Bi*

Main category: cs.CL

TL;DR: 论文提出MACE基准测试，用于研究多答案场景下的LLM置信度校准问题，并提出了语义置信度聚合(SCA)方法来解决多答案导致的置信度低估问题。


<details>
  <summary>Details</summary>
Motivation: 现有训练免费的置信度校准方法主要针对单答案问答场景研究，但在存在多个有效答案的情况下会失效，因为正确答案之间的分歧会导致系统性的置信度低估。

Method: 1. 引入MACE基准测试，包含12,000个事实性问题，涵盖6个领域，具有不同数量的正确答案；2. 提出语义置信度聚合(SCA)方法，通过对多个高概率采样回答的置信度进行聚合。

Result: 实验表明：在15种代表性校准方法和4个LLM家族(7B-72B)上，准确率随答案数量增加而提高，但估计的置信度却持续下降，导致混合答案数量的问题出现严重校准错误。SCA方法在混合答案设置下实现了最先进的校准性能，同时在单答案问题上保持了强校准能力。

Conclusion: 多答案场景对LLM置信度校准提出了新挑战，需要专门的方法来处理。SCA通过语义聚合多个回答的置信度，有效解决了多答案导致的置信度低估问题，为实际应用中的可靠置信度估计提供了解决方案。

Abstract: Confidence calibration is essential for making large language models (LLMs) reliable, yet existing training-free methods have been primarily studied under single-answer question answering. In this paper, we show that these methods break down in the presence of multiple valid answers, where disagreement among equally correct responses leads to systematic underestimation of confidence. To enable a systematic study of this phenomenon, we introduce MACE, a benchmark of 12,000 factual questions spanning six domains with varying numbers of correct answers. Experiments across 15 representative calibration methods and four LLM families (7B-72B) reveal that while accuracy increases with answer cardinality, estimated confidence consistently decreases, causing severe miscalibration for questions with mixed answer counts. To address this issue, we propose Semantic Confidence Aggregation (SCA), which aggregates confidence over multiple high-probability sampled responses. SCA achieves state-of-the-art calibration performance under mixed-answer settings while preserving strong calibration on single-answer questions.

</details>


### [239] [SparseEval: Efficient Evaluation of Large Language Models by Sparse Optimization](https://arxiv.org/abs/2602.07909)
*Taolin Zhang,Hang Guo,Wang Lu,Tao Dai,Shu-Tao Xia,Jindong Wang*

Main category: cs.CL

TL;DR: SparseEval：一种通过梯度下降优化锚点权重和迭代精化策略的高效大语言模型评估方法，利用MLP处理稀疏优化问题，显著降低评估成本。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型规模扩大，评估其性能的计算成本急剧增加。传统评估方法需要对大量基准样本进行推理，导致高昂的计算开销。需要开发更高效的评估方法来降低这一成本。

Method: 1) 将模型-项目性能矩阵视为稀疏矩阵，选择代表性项目作为锚点；2) 将高效评估问题形式化为稀疏优化问题；3) 首次采用梯度下降优化锚点权重；4) 使用迭代精化策略进行锚点选择；5) 利用MLP的表征能力处理稀疏优化；6) 提出锚点重要性分数和候选重要性分数来评估每个项目的价值。

Result: 在多种基准测试中，SparseEval表现出较低的估计误差和较高的Kendall's τ相关性，展示了其在真实场景中的优越鲁棒性和实用性。

Conclusion: SparseEval通过稀疏优化方法有效降低了大规模语言模型评估的计算成本，为高效评估提供了实用解决方案，代码已开源。

Abstract: As large language models (LLMs) continue to scale up, their performance on various downstream tasks has significantly improved. However, evaluating their capabilities has become increasingly expensive, as performing inference on a large number of benchmark samples incurs high computational costs. In this paper, we revisit the model-item performance matrix and show that it exhibits sparsity, that representative items can be selected as anchors, and that the task of efficient benchmarking can be formulated as a sparse optimization problem. Based on these insights, we propose SparseEval, a method that, for the first time, adopts gradient descent to optimize anchor weights and employs an iterative refinement strategy for anchor selection. We utilize the representation capacity of MLP to handle sparse optimization and propose the Anchor Importance Score and Candidate Importance Score to evaluate the value of each item for task-aware refinement. Extensive experiments demonstrate the low estimation error and high Kendall's~$τ$ of our method across a variety of benchmarks, showcasing its superior robustness and practicality in real-world scenarios. Code is available at {https://github.com/taolinzhang/SparseEval}.

</details>


### [240] [Patches of Nonlinearity: Instruction Vectors in Large Language Models](https://arxiv.org/abs/2602.07930)
*Irina Bigoulaeva,Jonas Rohweder,Subhabrata Dutta,Iryna Gurevych*

Main category: cs.CL

TL;DR: 该研究通过因果中介分析探索指令微调语言模型内部如何处理指令，发现指令表示相对局部化（称为指令向量IVs），表现出线性可分性与非线性因果交互的并存，挑战了机制可解释性中的线性表示假设。


<details>
  <summary>Details</summary>
Motivation: 尽管指令微调语言模型取得了成功并被广泛使用，但人们对模型内部如何处理指令知之甚少。本研究旨在从机制角度填补这一空白，探究指令特定表示在监督微调（SFT）和直接偏好优化（DPO）等后训练阶段如何构建和利用。

Method: 通过因果中介分析识别指令表示的位置，发现相对局部化的指令向量（IVs）。为解构非线性因果交互，提出了一种新的定位语言模型中信息处理的方法，该方法不受基于补丁技术的隐式线性假设限制。

Result: 指令表示在模型中相对局部化，指令向量（IVs）表现出线性可分性与非线性因果交互的并存。研究发现，在早期层形成的任务表示条件下，后期层会选择不同的信息通路来解决任务，即IVs充当电路选择器。

Conclusion: 指令向量（IVs）作为电路选择器，在早期层形成任务表示后，指导后期层选择不同的信息处理通路。这一发现挑战了机制可解释性中常见的线性表示假设，揭示了指令处理中线性可分性与非线性因果交互的复杂关系。

Abstract: Despite the recent success of instruction-tuned language models and their ubiquitous usage, very little is known of how models process instructions internally. In this work, we address this gap from a mechanistic point of view by investigating how instruction-specific representations are constructed and utilized in different stages of post-training: Supervised Fine-Tuning (SFT) and Direct Preference Optimization (DPO). Via causal mediation, we identify that instruction representation is fairly localized in models. These representations, which we call Instruction Vectors (IVs), demonstrate a curious juxtaposition of linear separability along with non-linear causal interaction, broadly questioning the scope of the linear representation hypothesis commonplace in mechanistic interpretability. To disentangle the non-linear causal interaction, we propose a novel method to localize information processing in language models that is free from the implicit linear assumptions of patching-based techniques. We find that, conditioned on the task representations formed in the early layers, different information pathways are selected in the later layers to solve that task, i.e., IVs act as circuit selectors.

</details>


### [241] [Bielik Guard: Efficient Polish Language Safety Classifiers for LLM Content Moderation](https://arxiv.org/abs/2602.07954)
*Krzysztof Wróbel,Jan Maria Kowalski,Jerzy Surma,Igor Ciuciura,Maciej Szymański*

Main category: cs.CL

TL;DR: Bielik Guard：一个用于波兰语内容安全分类的紧凑型模型家族，包含0.1B和0.5B两个变体，在多个基准测试中表现优异，特别在真实用户提示上实现了高精度和低误报率。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型在波兰语应用中的部署增加，需要高效准确的内容安全分类器来确保内容安全。

Method: 基于MMLW-RoBERTa-base和PKOBP/polish-roberta-8k构建了两个紧凑模型（0.1B和0.5B参数），在6,885个社区标注的波兰文本数据集上进行微调，分类五个安全类别：仇恨/攻击、粗俗语言、性内容、犯罪和自残。

Result: 0.5B变体在测试集上获得最佳整体区分能力（微F1 0.791，宏F1 0.785）；0.1B变体在真实用户提示上表现出卓越效率，精度达77.65%，误报率仅0.63%，优于同尺寸的HerBERT-PL-Guard（精度31.55%，误报率4.70%）。

Conclusion: Bielik Guard模型公开可用，旨在提供适当的响应而非简单的内容屏蔽，特别针对自残等敏感类别，为波兰语LLM应用提供了高效准确的安全分类解决方案。

Abstract: As Large Language Models (LLMs) become increasingly deployed in Polish language applications, the need for efficient and accurate content safety classifiers has become paramount. We present Bielik Guard, a family of compact Polish language safety classifiers comprising two model variants: a 0.1B parameter model based on MMLW-RoBERTa-base and a 0.5B parameter model based on PKOBP/polish-roberta-8k. Fine-tuned on a community-annotated dataset of 6,885 Polish texts, these models classify content across five safety categories: Hate/Aggression, Vulgarities, Sexual Content, Crime, and Self-Harm. Our evaluation demonstrates that both models achieve strong performance on multiple benchmarks. The 0.5B variant offers the best overall discrimination capability with F1 scores of 0.791 (micro) and 0.785 (macro) on the test set, while the 0.1B variant demonstrates exceptional efficiency. Notably, Bielik Guard 0.1B v1.1 achieves superior precision (77.65\%) and very low false positive rate (0.63\%) on real user prompts, outperforming HerBERT-PL-Guard (31.55\% precision, 4.70\% FPR) despite identical model size. The models are publicly available and designed to provide appropriate responses rather than simple content blocking, particularly for sensitive categories like self-harm.

</details>


### [242] [Lost in Translation? A Comparative Study on the Cross-Lingual Transfer of Composite Harms](https://arxiv.org/abs/2602.07963)
*Vaibhav Shukla,Hardik Sharma,Adith N Reganti,Soham Wasmatkar,Bagesh Kumar,Vrijendra Singh*

Main category: cs.CL

TL;DR: 该研究提出了CompositeHarm基准测试，通过翻译方法评估大语言模型在多语言环境下的安全性表现，发现攻击成功率在印度语言中显著上升，特别是对抗性语法攻击，而上下文危害的转移则相对温和。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型的安全评估主要基于英语，翻译常被用作多语言行为的捷径，但很少能捕捉完整情况，特别是当有害意图或结构在不同语言间变化时。某些类型的危害在翻译中几乎完整保留，而其他则会扭曲或消失。

Method: 引入CompositeHarm基准测试，结合两个互补的英语数据集（AttaQ针对结构化对抗攻击，MMSafetyBench覆盖上下文真实世界危害），并将其扩展到六种语言：英语、印地语、阿萨姆语、马拉地语、卡纳达语和古吉拉特语。采用轻量级推理策略，减少冗余评估，同时保持跨语言保真度。

Result: 使用三个大型模型发现，攻击成功率在印度语言中急剧上升，特别是在对抗性语法下，而上下文危害的转移则相对温和。轻量级推理策略使大规模多语言安全测试在计算上可行且环保。

Conclusion: 翻译基准测试是构建基于资源、语言自适应安全系统的必要第一步，但不足够。需要更全面的多语言安全评估方法。

Abstract: Most safety evaluations of large language models (LLMs) remain anchored in English. Translation is often used as a shortcut to probe multilingual behavior, but it rarely captures the full picture, especially when harmful intent or structure morphs across languages. Some types of harm survive translation almost intact, while others distort or disappear. To study this effect, we introduce CompositeHarm, a translation-based benchmark designed to examine how safety alignment holds up as both syntax and semantics shift. It combines two complementary English datasets, AttaQ, which targets structured adversarial attacks, and MMSafetyBench, which covers contextual, real-world harms, and extends them into six languages: English, Hindi, Assamese, Marathi, Kannada, and Gujarati. Using three large models, we find that attack success rates rise sharply in Indic languages, especially under adversarial syntax, while contextual harms transfer more moderately. To ensure scalability and energy efficiency, our study adopts lightweight inference strategies inspired by edge-AI design principles, reducing redundant evaluation passes while preserving cross-lingual fidelity. This design makes large-scale multilingual safety testing both computationally feasible and environmentally conscious. Overall, our results show that translated benchmarks are a necessary first step, but not a sufficient one, toward building grounded, resource-aware, language-adaptive safety systems.

</details>


### [243] [Cross-Linguistic Persona-Driven Data Synthesis for Robust Multimodal Cognitive Decline Detection](https://arxiv.org/abs/2602.07978)
*Rui Feng,Zhiyao Luo,Liuyu Wu,Wei Wang,Yuting Song,Yong Liu,Kok Pin Ng,Jianqing Li,Xingyao Wang*

Main category: cs.CL

TL;DR: SynCog框架通过可控零样本多模态数据合成和思维链推理微调，解决MCI诊断中的数据稀缺和可解释性问题，在多语言基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 当前基于语音的数字生物标志物在MCI早期识别中存在两个主要障碍：临床数据稀缺严重限制了模型开发，以及现有模型缺乏可解释性导致临床信任不足。此外，跨语言泛化能力差也限制了全球应用。

Method: 提出SynCog框架，包含两个核心组件：1) 可控零样本多模态数据合成，通过模拟不同认知特征的虚拟受试者来缓解数据稀缺问题；2) 思维链推理微调策略，在多模态大语言模型基础上进行微调，使模型能够显式表达诊断推理过程而非黑盒预测。

Result: 在ADReSS和ADReSSo基准测试中，通过合成数据增强获得了80.67%和78.46%的Macro-F1分数，优于现有基线模型。在独立真实世界汉语队列(CIR-E)上实现了48.71%的Macro-F1，展示了强大的跨语言泛化能力。

Conclusion: SynCog框架为解决MCI诊断中的数据稀缺和可解释性问题提供了有效方案，其跨语言泛化能力为开发全球适用的临床可信认知评估工具迈出了关键一步。

Abstract: Speech-based digital biomarkers represent a scalable, non-invasive frontier for the early identification of Mild Cognitive Impairment (MCI). However, the development of robust diagnostic models remains impeded by acute clinical data scarcity and a lack of interpretable reasoning. Current solutions frequently struggle with cross-lingual generalization and fail to provide the transparent rationales essential for clinical trust. To address these barriers, we introduce SynCog, a novel framework integrating controllable zero-shot multimodal data synthesis with Chain-of-Thought (CoT) deduction fine-tuning. Specifically, SynCog simulates diverse virtual subjects with varying cognitive profiles to effectively alleviate clinical data scarcity. This generative paradigm enables the rapid, zero-shot expansion of clinical corpora across diverse languages, effectively bypassing data bottlenecks in low-resource settings and bolstering the diagnostic performance of Multimodal Large Language Models (MLLMs). Leveraging this synthesized dataset, we fine-tune a foundational multimodal backbone using a CoT deduction strategy, empowering the model to explicitly articulate diagnostic thought processes rather than relying on black-box predictions. Extensive experiments on the ADReSS and ADReSSo benchmarks demonstrate that augmenting limited clinical data with synthetic phenotypes yields competitive diagnostic performance, achieving Macro-F1 scores of 80.67% and 78.46%, respectively, outperforming current baseline models. Furthermore, evaluation on an independent real-world Mandarin cohort (CIR-E) demonstrates robust cross-linguistic generalization, attaining a Macro-F1 of 48.71%. These findings constitute a critical step toward providing clinically trustworthy and linguistically inclusive cognitive assessment tools for global healthcare.

</details>


### [244] [The Judge Who Never Admits: Hidden Shortcuts in LLM-based Evaluation](https://arxiv.org/abs/2602.07996)
*Arash Marioriyad,Omid Ghahroodi,Ehsaneddin Asgari,Mohammad Hossein Rohban,Mahdieh Soleymani Baghshah*

Main category: cs.CL

TL;DR: LLM作为自动评估器时，会受无关上下文线索（如来源、时间、人口统计信息）影响而改变评分，但很少在解释中承认这些影响，存在解释差距。


<details>
  <summary>Details</summary>
Motivation: 研究LLM作为自动评估器时是否忠实于内容质量，能否保持对无关上下文的不变性，以及是否透明反映决策因素。

Method: 通过控制性线索扰动（合成元数据标签）测试6个LLM评估器，使用ELI5（事实问答）和LitBench（创意写作）两个数据集，研究6类线索（来源、时间、年龄、性别、种族、教育程度），测量判决转移率和线索承认率。

Result: LLM评估器对线索有显著行为影响（如专家>人类>LLM>未知的等级偏好、新>旧的时效偏好、教育程度偏爱），但线索承认率通常接近零，表明即使线索驱动决策也很少报告。线索承认率还依赖数据集。

Conclusion: 显著的判决敏感性和有限的线索承认揭示了LLM作为评估器流程中的解释差距，对研究和部署中基于模型的评估可靠性提出担忧。

Abstract: Large language models (LLMs) are increasingly used as automatic judges to evaluate system outputs in tasks such as reasoning, question answering, and creative writing. A faithful judge should base its verdicts solely on content quality, remain invariant to irrelevant context, and transparently reflect the factors driving its decisions. We test this ideal via controlled cue perturbations-synthetic metadata labels injected into evaluation prompts-for six judge models: GPT-4o, Gemini-2.0-Flash, Gemma-3-27B, Qwen3-235B, Claude-3-Haiku, and Llama3-70B. Experiments span two complementary datasets with distinct evaluation regimes: ELI5 (factual QA) and LitBench (open-ended creative writing). We study six cue families: source, temporal, age, gender, ethnicity, and educational status. Beyond measuring verdict shift rates (VSR), we introduce cue acknowledgment rate (CAR) to quantify whether judges explicitly reference the injected cues in their natural-language rationales. Across cues with strong behavioral effects-e.g., provenance hierarchies (Expert > Human > LLM > Unknown), recency preferences (New > Old), and educational-status favoritism-CAR is typically at or near zero, indicating that shortcut reliance is largely unreported even when it drives decisions. Crucially, CAR is also dataset-dependent: explicit cue recognition is more likely to surface in the factual ELI5 setting for some models and cues, but often collapses in the open-ended LitBench regime, where large verdict shifts can persist despite zero acknowledgment. The combination of substantial verdict sensitivity and limited cue acknowledgment reveals an explanation gap in LLM-as-judge pipelines, raising concerns about reliability of model-based evaluation in both research and deployment.

</details>


### [245] [DeltaKV: Residual-Based KV Cache Compression via Long-Range Similarity](https://arxiv.org/abs/2602.08005)
*Jitai Hao,Qiang Huang,Yaowei Wang,Min Zhang,Jun Yu*

Main category: cs.CL

TL;DR: DeltaKV提出基于残差的KV缓存压缩框架，通过编码语义残差而非丢弃token来减少存储，配合Sparse-vLLM推理引擎实现2倍吞吐提升。


<details>
  <summary>Details</summary>
Motivation: 长上下文LLM部署面临KV缓存内存线性增长的瓶颈，现有压缩和淘汰方法难以平衡准确性、压缩比和硬件效率。

Method: 基于两个经验发现：长距离token间相似性和KV表示中高度共享的潜在组件。DeltaKV编码相对于检索历史参考的语义残差来压缩KV缓存，Sparse-vLLM提供解耦内存管理和稀疏不规则KV布局优化的高性能推理引擎。

Result: DeltaKV将KV缓存内存减少到原始的29%，在LongBench、SCBench和AIME上保持接近无损的准确性。与Sparse-vLLM集成后，在长上下文场景中相比vLLM实现高达2倍的吞吐提升。

Conclusion: DeltaKV和Sparse-vLLM为可扩展的长上下文LLM部署提供了实用路径，通过残差压缩和硬件优化推理引擎有效解决了KV缓存内存瓶颈问题。

Abstract: The deployment of efficient long-context LLMs in applications like autonomous agents, long-chain reasoning, and creative writing is fundamentally bottlenecked by the linear growth of KV cache memory. Existing compression and eviction methods often struggle to balance accuracy, compression ratio, and hardware efficiency. We propose DeltaKV, a residual-based KV cache compression framework motivated by two empirical findings: long-range inter-token similarity and highly shared latent components in KV representations. Instead of discarding tokens, DeltaKV encodes semantic residuals relative to retrieved historical references, preserving fidelity while substantially reducing storage. To translate compression gains into real system speedups, we further introduce Sparse-vLLM, a high-performance inference engine with decoupled memory management and kernels optimized for sparse and irregular KV layouts. Experiments show that DeltaKV reduces KV cache memory to 29\% of the original while maintaining near-lossless accuracy on LongBench, SCBench, and AIME. When integrated with Sparse-vLLM, it achieves up to 2$\times$ throughput improvement over vLLM in long-context scenarios, demonstrating a practical path toward scalable long-context LLM deployment. Code, model checkpoints, and datasets are available at https://github.com/CURRENTF/Sparse-vLLM.

</details>


### [246] [Diverge to Induce Prompting: Multi-Rationale Induction for Zero-Shot Reasoning](https://arxiv.org/abs/2602.08028)
*Po-Chun Chen,Hen-Hsen Huang,Hsin-Hsi Chen*

Main category: cs.CL

TL;DR: DIP（Diverge-to-Induce Prompting）通过先生成多个不同的高层推理策略，再将其细化为详细计划，最后整合为最终计划，提升零样本推理准确性。


<details>
  <summary>Details</summary>
Motivation: 标准思维链提示中无指导的推理路径不稳定，而现有方法只依赖单一推理策略，限制了在不同任务上的性能表现。

Method: DIP框架：1）为每个问题生成多个不同的高层推理策略；2）将每个策略细化为详细的逐步草案计划；3）将这些草案计划归纳整合为最终计划。

Result: 实验表明DIP优于单一策略提示方法，验证了多计划归纳在基于提示的推理中的有效性。

Conclusion: 通过先生成多样化的推理策略再整合，DIP能够在不依赖资源密集型采样的前提下，有效提升大语言模型的零样本推理准确性。

Abstract: To address the instability of unguided reasoning paths in standard Chain-of-Thought prompting, recent methods guide large language models (LLMs) by first eliciting a single reasoning strategy. However, relying on just one strategy for each question can still limit performance across diverse tasks. We propose Diverge-to-Induce Prompting (DIP), a framework that first prompts an LLM to generate multiple diverse high-level rationales for each question. Each rationale is then elaborated into a detailed, step-by-step draft plan. Finally, these draft plans are induced into a final plan. DIP enhances zero-shot reasoning accuracy without reliance on resource-intensive sampling. Experiments show that DIP outperforms single-strategy prompting, demonstrating the effectiveness of multi-plan induction for prompt-based reasoning.

</details>


### [247] [Beyond Raw Detection Scores: Markov-Informed Calibration for Boosting Machine-Generated Text Detection](https://arxiv.org/abs/2602.08031)
*Chenwang Wu,Yiu-ming Cheung,Shuhai Zhang,Bo Han,Defu Lian*

Main category: cs.CL

TL;DR: 提出基于马尔可夫随机场的分数校准策略，解决机器生成文本检测中token级分数受生成随机性影响的问题，显著提升现有检测器性能


<details>
  <summary>Details</summary>
Motivation: 机器生成文本带来便利的同时也带来虚假信息和钓鱼等风险，需要可靠检测。基于度量的方法比复杂模型方法更实用，但token级检测分数容易受到生成过程随机性的影响

Method: 首先将代表性度量方法统一到框架中分析其优缺点，然后理论分析和实证揭示上下文检测分数的两个关系（邻居相似性和初始不稳定性），提出基于马尔可夫随机场的分数校准策略，通过平均场近似实现轻量级组件

Result: 在各种真实场景（跨LLM和改写攻击）的广泛实验中，相比基线方法取得了显著提升，计算开销可忽略不计

Conclusion: 提出的马尔可夫随机场校准策略能够有效解决token级检测分数的偏差问题，可无缝集成到现有检测器中，显著提升检测性能

Abstract: While machine-generated texts (MGTs) offer great convenience, they also pose risks such as disinformation and phishing, highlighting the need for reliable detection. Metric-based methods, which extract statistically distinguishable features of MGTs, are often more practical than complex model-based methods that are prone to overfitting. Given their diverse designs, we first place representative metric-based methods within a unified framework, enabling a clear assessment of their advantages and limitations. Our analysis identifies a core challenge across these methods: the token-level detection score is easily biased by the inherent randomness of the MGTs generation process. To address this, we theoretically and empirically reveal two relationships of context detection scores that may aid calibration: Neighbor Similarity and Initial Instability. We then propose a Markov-informed score calibration strategy that models these relationships using Markov random fields, and implements it as a lightweight component via a mean-field approximation, allowing our method to be seamlessly integrated into existing detectors. Extensive experiments in various real-world scenarios, such as cross-LLM and paraphrasing attacks, demonstrate significant gains over baselines with negligible computational overhead. The code is available at https://github.com/tmlr-group/MRF_Calibration.

</details>


### [248] [TDGNet: Hallucination Detection in Diffusion Language Models via Temporal Dynamic Graphs](https://arxiv.org/abs/2602.08048)
*Arshia Hemmat,Philip Torr,Yongqiang Chen,Junchi Yu*

Main category: cs.CL

TL;DR: TDGNet：一个用于扩散语言模型幻觉检测的时序动态图框架，通过分析去噪过程中的注意力图演化来检测幻觉，相比现有方法在多个基准上取得显著改进。


<details>
  <summary>Details</summary>
Motivation: 扩散语言模型（D-LLMs）具有并行去噪和双向上下文优势，但其幻觉检测研究不足。现有针对自回归LLMs的检测器通常依赖单次推理线索，无法直接迁移到扩散生成场景，因为在扩散过程中事实证据分布在去噪轨迹中，可能随时间出现、漂移或自我修正。

Method: 提出TDGNet框架，将幻觉检测建模为在演化中的token级注意力图上的学习问题。在每个去噪步骤中，对注意力图进行稀疏化处理，通过消息传递更新每个token的记忆，然后使用时序注意力聚合整个轨迹的证据进行最终预测。

Result: 在LLaDA-8B和Dream-7B模型上的QA基准测试表明，TDGNet相比基于输出、基于潜在表示和静态图基线方法，在AUROC指标上取得一致改进，且具有单次推理和适度计算开销的优势。

Conclusion: 研究结果表明，对注意力图进行时序推理对于扩散语言模型的鲁棒幻觉检测至关重要，TDGNet框架为此提供了有效解决方案。

Abstract: Diffusion language models (D-LLMs) offer parallel denoising and bidirectional context, but hallucination detection for D-LLMs remains underexplored. Prior detectors developed for auto-regressive LLMs typically rely on single-pass cues and do not directly transfer to diffusion generation, where factuality evidence is distributed across the denoising trajectory and may appear, drift, or be self-corrected over time. We introduce TDGNet, a temporal dynamic graph framework that formulates hallucination detection as learning over evolving token-level attention graphs. At each denoising step, we sparsify the attention graph and update per-token memories via message passing, then apply temporal attention to aggregate trajectory-wide evidence for final prediction. Experiments on LLaDA-8B and Dream-7B across QA benchmarks show consistent AUROC improvements over output-based, latent-based, and static-graph baselines, with single-pass inference and modest overhead. These results highlight the importance of temporal reasoning on attention graphs for robust hallucination detection in diffusion language models.

</details>


### [249] [Emergent Search and Backtracking in Latent Reasoning Models](https://arxiv.org/abs/2602.08100)
*Jasmine Cui,Charles Ye*

Main category: cs.CL

TL;DR: LRTs在隐藏空间进行推理，自发学习结构化搜索过程：探索阶段→暂定选择→收敛或回溯，回溯普遍且有益


<details>
  <summary>Details</summary>
Motivation: 研究语言模型在无词思考时的推理过程，探索潜在推理变换器（LRTs）如何在连续隐藏空间进行审议，与传统的链式思维（CoT）方法形成对比

Method: 使用潜在推理变换器（LRTs），在多项选择QA基准上解码模型每一步演变的信念，分析模型在潜在空间中的结构化搜索过程

Result: 模型自发学习结构化搜索：探索阶段概率分布扩散，暂定选择领先选项，然后收敛或回溯；回溯普遍（32%实例）且有益（准确率提升34%），主要从语义最接近的干扰项转向正确答案；搜索具有适应性：替换干扰项可缩短探索时间54%

Conclusion: 潜在推理模型在激活空间中实现了链式思维通过文字实现的能力：能够犯错、察觉并恢复，展示了无词推理的有效性

Abstract: What happens when a language model thinks without words? Standard reasoning LLMs verbalize intermediate steps as chain-of-thought; latent reasoning transformers (LRTs) instead perform deliberation entirely in continuous hidden space. We investigate an LRT, decoding the model's evolving beliefs at every step on a multiple-choice QA benchmark. We find that the model spontaneously learns a structured search process in latent space. Deliberation follows a consistent trajectory: an exploration phase where probability mass spreads across candidates, tentative commitment to a frontrunner, and either convergence or backtracking. Backtracking is prevalent (32% of instances), beneficial (34% accuracy gain over non-backtracking instances), and predominantly directed away from the semantically closest distractor toward the correct answer. The search is adaptive: replacing distractors with implausible alternatives shortens exploration by 54%. Latent reasoning models achieve in activation space what chain-of-thought achieves through words: the ability to be wrong, notice, and recover.

</details>


### [250] [Gender and Race Bias in Consumer Product Recommendations by Large Language Models](https://arxiv.org/abs/2602.08124)
*Ke Xu,Shera Potka,Alex Thomo*

Main category: cs.CL

TL;DR: 本文首次系统研究LLM推荐系统中的性别与种族偏见，通过提示工程和三种分析方法发现不同人口群体间的推荐存在显著差异，呼吁更公平的推荐系统。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型越来越多地用于生成消费产品推荐，但其可能嵌入和放大性别与种族偏见的潜力尚未得到充分探索。本文旨在填补这一研究空白，作为首批系统研究LLM推荐中偏见的工作之一。

Method: 采用提示工程引导LLM为不同种族和性别群体生成产品推荐，并运用三种分析方法：标记词分析、支持向量机和Jensen-Shannon散度，以识别和量化偏见。

Result: 研究发现不同人口群体间的推荐存在显著差异，揭示了LLM推荐系统中存在系统性偏见，不同种族和性别群体获得的推荐产品有明显区别。

Conclusion: 研究结果强调了开发更公平的LLM推荐系统的必要性，为未来减少AI推荐中的偏见提供了实证基础和方向。

Abstract: Large Language Models are increasingly employed in generating consumer product recommendations, yet their potential for embedding and amplifying gender and race biases remains underexplored. This paper serves as one of the first attempts to examine these biases within LLM-generated recommendations. We leverage prompt engineering to elicit product suggestions from LLMs for various race and gender groups and employ three analytical methods-Marked Words, Support Vector Machines, and Jensen-Shannon Divergence-to identify and quantify biases. Our findings reveal significant disparities in the recommendations for demographic groups, underscoring the need for more equitable LLM recommendation systems.

</details>


### [251] [DIAL-SUMMER: A Structured Evaluation Framework of Hierarchical Errors in Dialogue Summaries](https://arxiv.org/abs/2602.08149)
*Sahana Ramnath,Nima Chitsazan,Mingyang Zhou,Chia-Hsuan Lee,Shi-Xiong Zhang,Stephen Rawls,Sambit Sahu,Sangwoo Cho,Xiang Ren,Genta Indra Winata,Akshaj Kumar Veldanda*

Main category: cs.CL

TL;DR: DIALSUMMER是一个用于评估对话摘要质量的框架，提出了分层错误分类法，并创建了人工标注的数据集，揭示了对话摘要中的特定错误模式。


<details>
  <summary>Details</summary>
Motivation: 现有对话摘要评估方法忽略了对话特有的复杂性：从多说话者分散讨论到摘要句子的结构转变，以及从第一/第二人称叙述到第三人称摘要的视角转变。

Method: 提出了DIALSUMMER框架，包含两层错误分类法：对话级别关注说话者/轮次，轮次内级别关注单个轮次内的信息。创建了人工标注的对话摘要数据集，并分析了错误模式。

Result: 发现了有趣的错误趋势：对话中间轮次最容易被遗漏，外部幻觉主要出现在摘要末尾。实验显示LLM-Judge在检测这些错误方面表现有限，证明了数据集的挑战性和分类法的鲁棒性。

Conclusion: DIALSUMMER框架为对话摘要评估提供了全面工具，揭示了特定错误模式，并表明需要进一步工作来提升LLM在对话摘要评估中的性能。

Abstract: Dialogues are a predominant mode of communication for humans, and it is immensely helpful to have automatically generated summaries of them (e.g., to revise key points discussed in a meeting, to review conversations between customer agents and product users). Prior works on dialogue summary evaluation largely ignore the complexities specific to this task: (i) shift in structure, from multiple speakers discussing information in a scattered fashion across several turns, to a summary's sentences, and (ii) shift in narration viewpoint, from speakers' first/second-person narration, standardized third-person narration in the summary. In this work, we introduce our framework DIALSUMMER to address the above. We propose DIAL-SUMMER's taxonomy of errors to comprehensively evaluate dialogue summaries at two hierarchical levels: DIALOGUE-LEVEL that focuses on the broader speakers/turns, and WITHIN-TURN-LEVEL that focuses on the information talked about inside a turn. We then present DIAL-SUMMER's dataset composed of dialogue summaries manually annotated with our taxonomy's fine-grained errors. We conduct empirical analyses of these annotated errors, and observe interesting trends (e.g., turns occurring in middle of the dialogue are the most frequently missed in the summary, extrinsic hallucinations largely occur at the end of the summary). We also conduct experiments on LLM-Judges' capability at detecting these errors, through which we demonstrate the challenging nature of our dataset, the robustness of our taxonomy, and the need for future work in this field to enhance LLMs' performance in the same. Code and inference dataset coming soon.

</details>


### [252] [NLP for Local Governance Meeting Records: A Focus Article on Tasks, Datasets, Metrics and Benchmark](https://arxiv.org/abs/2602.08162)
*Ricardo Campos,José Pedro Evans,José Miguel Isidro,Miguel Marques,Luís Filipe Cunha,Alípio Jorge,Sérgio Nunes,Nuno Guimarães*

Main category: cs.CL

TL;DR: 本文综述了NLP在结构化地方政府会议记录中的应用，重点讨论了文档分割、实体抽取和文本摘要三个核心任务，旨在提高这类复杂文档的可访问性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 地方政府会议记录作为官方文件，虽然有一定结构，但通常内容密集、官僚化，且在不同市政机构之间存在显著的语言、术语和结构异质性。这种异质性使得非专家难以解读，智能自动化系统也难以处理，限制了公共透明度和公民参与。

Method: 本文采用文献综述方法，系统回顾了支持地方政府会议文档结构化的三个核心NLP任务：1) 文档分割，用于导航冗长的审议过程；2) 领域特定实体抽取，用于识别政治参与者和个人信息；3) 自动文本摘要，用于生成复杂决策过程的简洁表示。同时讨论了方法学途径、评估指标和公开可用资源。

Result: 通过综合现有研究，本文提供了NLP如何增强地方政府会议记录结构化和可访问性的结构化概述，识别了领域特定挑战，包括数据稀缺性、隐私约束和来源变异性。

Conclusion: NLP方法能够有效应对地方政府会议记录的异质性和复杂性挑战，通过文档分割、实体抽取和文本摘要等核心任务，可以显著提高这类文档的可访问性和可解释性，从而促进公共透明度和公民参与。未来工作需要解决数据稀缺、隐私保护等特定领域挑战。

Abstract: Local governance meeting records are official documents, in the form of minutes or transcripts, documenting how proposals, discussions, and procedural actions unfold during institutional meetings. While generally structured, these documents are often dense, bureaucratic, and highly heterogeneous across municipalities, exhibiting significant variation in language, terminology, structure, and overall organization. This heterogeneity makes them difficult for non-experts to interpret and challenging for intelligent automated systems to process, limiting public transparency and civic engagement. To address these challenges, computational methods can be employed to structure and interpret such complex documents. In particular, Natural Language Processing (NLP) offers well-established methods that can enhance the accessibility and interpretability of governmental records. In this focus article, we review foundational NLP tasks that support the structuring of local governance meeting documents. Specifically, we review three core tasks: document segmentation, domain-specific entity extraction and automatic text summarization, which are essential for navigating lengthy deliberations, identifying political actors and personal information, and generating concise representations of complex decision-making processes. In reviewing these tasks, we discuss methodological approaches, evaluation metrics, and publicly available resources, while highlighting domain-specific challenges such as data scarcity, privacy constraints, and source variability. By synthesizing existing work across these foundational tasks, this article provides a structured overview of how NLP can enhance the structuring and accessibility of local governance meeting records.

</details>


### [253] [LLMs and people both learn to form conventions -- just not with each other](https://arxiv.org/abs/2602.08208)
*Cameron R. Jones,Agnese Lombardi,Kyle Mahowald,Benjamin K. Bergen*

Main category: cs.CL

TL;DR: 研究测试LLMs在多模态交流游戏中是否能像人类一样形成对话惯例，发现同类型配对（人-人、AI-AI）能形成惯例，但人-AI混合配对失败，表明需要共享的解释性偏见才能实现真正的对话对齐。


<details>
  <summary>Details</summary>
Motivation: 人类在对话中会相互对齐，采用共享惯例以促进交流。本研究旨在探索LLMs在多模态交流游戏中是否能形成类似的对话惯例，以及人-AI混合交流中的对齐机制。

Method: 使用多模态交流游戏，比较三种配对类型：人类-人类、AI-AI、人类-AI。测量准确性、一致性和消息长度变化。在实验2中，通过提示让LLMs产生表面类似人类的行为，观察对齐效果。

Result: 同类型配对（人-人、AI-AI）都显示出惯例形成：准确性提高、一致性增强、消息长度缩短。但人-AI混合配对失败，即使LLMs被提示模仿人类行为，其准确性和词汇重叠度仍落后于同类型配对。

Conclusion: 对话对齐不仅需要模仿先前互动的能力，还需要共享对所传达意义的解释性偏见。LLMs和人类在交流倾向上的差异阻碍了混合配对中的有效对齐。

Abstract: Humans align to one another in conversation -- adopting shared conventions that ease communication. We test whether LLMs form the same kinds of conventions in a multimodal communication game. Both humans and LLMs display evidence of convention-formation (increasing the accuracy and consistency of their turns while decreasing their length) when communicating in same-type dyads (humans with humans, AI with AI). However, heterogenous human-AI pairs fail -- suggesting differences in communicative tendencies. In Experiment 2, we ask whether LLMs can be induced to behave more like human conversants, by prompting them to produce superficially humanlike behavior. While the length of their messages matches that of human pairs, accuracy and lexical overlap in human-LLM pairs continues to lag behind that of both human-human and AI-AI pairs. These results suggest that conversational alignment requires more than just the ability to mimic previous interactions, but also shared interpretative biases toward the meanings that are conveyed.

</details>


### [254] [Pretraining with Token-Level Adaptive Latent Chain-of-Thought](https://arxiv.org/abs/2602.08220)
*Boyi Zeng,Yiqin Hao,He Li,Shixiang Song,Feichen Song,Zitong Wang,Siyuan Huang,Yi Xu,ZiWei He,Xinbing Wang,Zhouhan Lin*

Main category: cs.CL

TL;DR: 提出自适应潜在CoT预训练方法，通过为每个token生成可变长度的潜在推理轨迹来增加计算而不增加参数，实现训练和推理中的自适应计算分配


<details>
  <summary>Details</summary>
Motivation: 传统通过增加参数和训练数据来扩展大语言模型受到高质量语料有限和通信成本上升的限制，需要探索不增加参数但增加每个token计算量的替代方案

Method: 提出自适应潜在CoT预训练方法，模型在生成每个token前生成可变长度的潜在CoT推理轨迹，困难token分配更长轨迹，简单token分配更短甚至零轨迹，通过单阶段预训练自然实现自适应停止

Result: 在Llama架构上的实验表明，自适应潜在CoT持续改善语言建模困惑度和广泛下游任务准确率，即使训练FLOPs比先前循环基线更少

Conclusion: 自适应潜在CoT提供了一种有效扩展语言模型的新维度，通过增加每个token的计算而不增加参数，在保持效率的同时提升性能

Abstract: Scaling large language models by increasing parameters and training data is increasingly constrained by limited high-quality corpora and rising communication costs. This work explores an alternative axis: increasing per-token computation without expanding parameters, by internalizing latent Chain-of-Thought (CoT) into pretraining. We propose Pretraining with Token-Level Adaptive Latent CoT (adaptive latent CoT), where the model generates a variable-length latent CoT trajectory before emitting each token -- allocating longer trajectories to difficult tokens and shorter (or even zero) trajectories to easy ones. Importantly, this behavior emerges naturally from one-stage pretraining on general text and reduces computation in both training and inference via token-wise adaptive halting. Experiments with Llama architectures show that adaptive latent CoT consistently improves language modeling perplexity and broad downstream accuracy, even with fewer training FLOPs than prior recurrent baselines.

</details>


### [255] [CoRect: Context-Aware Logit Contrast for Hidden State Rectification to Resolve Knowledge Conflicts](https://arxiv.org/abs/2602.08221)
*Xuhua Ma,Richong Zhang,Zhijie Nie*

Main category: cs.CL

TL;DR: 本文提出CoRect方法，通过对比上下文化和非上下文化前向传播的logits来识别参数偏差层，并修正隐藏状态以解决RAG中的知识冲突问题，提高生成忠实度。


<details>
  <summary>Details</summary>
Motivation: RAG在知识冲突场景下存在参数知识覆盖检索证据的问题，导致输出不忠实。现有方法要么依赖表面解码调整，要么需要真实标签进行权重编辑，存在局限性。

Method: 通过层间分析发现参数抑制现象：深层FFN层用记忆先验覆盖上下文敏感表示。提出CoRect方法，对比上下文化和非上下文化前向传播的logits，无需真实标签识别高参数偏差层，然后修正隐藏状态以保留证据基础信息。

Result: 在问答和摘要基准测试中，CoRect相比强基线方法持续提高忠实度并减少幻觉。

Conclusion: CoRect通过识别和修正参数偏差层，有效解决了RAG中的知识冲突问题，提高了生成输出的忠实性，且无需真实标签。

Abstract: Retrieval-Augmented Generation (RAG) often struggles with knowledge conflicts, where model-internal parametric knowledge overrides retrieved evidence, leading to unfaithful outputs. Existing approaches are often limited, relying either on superficial decoding adjustments or weight editing that necessitates ground-truth targets. Through layer-wise analysis, we attribute this failure to a parametric suppression phenomenon: specifically, in deep layers, certain FFN layers overwrite context-sensitive representations with memorized priors. To address this, we propose CoRect (Context-Aware Logit Contrast for Hidden State Rectification). By contrasting logits from contextualized and non-contextualized forward passes, CoRect identifies layers that exhibit high parametric bias without requiring ground-truth labels. It then rectifies the hidden states to preserve evidence-grounded information. Across question answering (QA) and summarization benchmarks, CoRect consistently improves faithfulness and reduces hallucinations compared to strong baselines.

</details>


### [256] [When Benign Inputs Lead to Severe Harms: Eliciting Unsafe Unintended Behaviors of Computer-Use Agents](https://arxiv.org/abs/2602.08235)
*Jaylen Jones,Zhehao Zhang,Yuting Ning,Eric Fosler-Lussier,Pierre-Luc St-Charles,Yoshua Bengio,Dawn Song,Yu Su,Huan Sun*

Main category: cs.CL

TL;DR: AutoElicit：首个系统性框架，通过代理驱动的迭代扰动方法，自动引发计算机使用代理在良性输入下的意外有害行为，揭示了前沿CUAs的数百个安全风险。


<details>
  <summary>Details</summary>
Motivation: 计算机使用代理（CUAs）在自动化复杂操作系统工作流方面潜力巨大，但即使在良性输入环境下也可能表现出偏离预期结果的不安全意外行为。目前对这种风险的探索主要停留在轶事层面，缺乏具体的特征描述和自动化方法来主动发现现实CUA场景中的长尾意外行为。

Method: 提出AutoElicit框架：通过定义意外CUA行为的关键特征，利用CUA执行反馈迭代扰动良性指令，在保持扰动现实性和良性特征的同时，引发严重危害。该方法系统地自动引发和分析意外行为。

Result: 使用AutoElicit从Claude 4.5 Haiku和Opus等前沿CUAs中发现了数百个有害意外行为。进一步评估了人工验证成功扰动的可转移性，发现各种其他前沿CUAs对意外行为存在持续易感性。

Conclusion: 这项工作为系统分析现实计算机使用环境中的意外行为奠定了基础，揭示了CUAs在看似良性输入下可能产生的安全风险，为未来CUA安全研究提供了方法论框架。

Abstract: Although computer-use agents (CUAs) hold significant potential to automate increasingly complex OS workflows, they can demonstrate unsafe unintended behaviors that deviate from expected outcomes even under benign input contexts. However, exploration of this risk remains largely anecdotal, lacking concrete characterization and automated methods to proactively surface long-tail unintended behaviors under realistic CUA scenarios. To fill this gap, we introduce the first conceptual and methodological framework for unintended CUA behaviors, by defining their key characteristics, automatically eliciting them, and analyzing how they arise from benign inputs. We propose AutoElicit: an agentic framework that iteratively perturbs benign instructions using CUA execution feedback, and elicits severe harms while keeping perturbations realistic and benign. Using AutoElicit, we surface hundreds of harmful unintended behaviors from state-of-the-art CUAs such as Claude 4.5 Haiku and Opus. We further evaluate the transferability of human-verified successful perturbations, identifying persistent susceptibility to unintended behaviors across various other frontier CUAs. This work establishes a foundation for systematically analyzing unintended behaviors in realistic computer-use settings.

</details>


### [257] [Document Reconstruction Unlocks Scalable Long-Context RLVR](https://arxiv.org/abs/2602.08237)
*Yao Xiao,Lei Wang,Yue Deng,Guanzheng Chen,Ziqi Jin,Jung-jae Kim,Xiaoli Li,Roy Ka-wei Lee,Lidong Bing*

Main category: cs.CL

TL;DR: 提出一种无监督强化学习方法，通过段落重构任务增强LLMs的长上下文能力，无需人工标注或教师模型监督。


<details>
  <summary>Details</summary>
Motivation: 现有的RLVR方法依赖昂贵的黄金标准答案或教师模型评估准则，成本高且耗时。需要探索无监督方法来增强LLMs的长上下文能力。

Method: 在长文档中用特殊占位符替换部分段落，通过强化学习训练LLMs从候选选项中选择并排序缺失段落来重构文档，以捕捉全局叙事连贯性。

Result: 在RULER和LongBench v2基准测试中均取得显著提升，特别是在RULER上表现突出，且无需人工标注的长上下文QA数据。

Conclusion: 提出的无监督段落重构强化学习方法能有效增强LLMs的长上下文能力，同时进行了广泛的消融研究分析影响因素，并开源了代码、数据和模型。

Abstract: Reinforcement Learning with Verifiable Rewards~(RLVR) has become a prominent paradigm to enhance the capabilities (i.e.\ long-context) of Large Language Models~(LLMs). However, it often relies on gold-standard answers or explicit evaluation rubrics provided by powerful teacher models or human experts, which are costly and time-consuming. In this work, we investigate unsupervised approaches to enhance the long-context capabilities of LLMs, eliminating the need for heavy human annotations or teacher models' supervision. Specifically, we first replace a few paragraphs with special placeholders in a long document. LLMs are trained through reinforcement learning to reconstruct the document by correctly identifying and sequencing missing paragraphs from a set of candidate options. This training paradigm enables the model to capture global narrative coherence, significantly boosting long-context performance. We validate the effectiveness of our method on two widely used benchmarks, RULER and LongBench~v2. While acquiring noticeable gains on RULER, it can also achieve a reasonable improvement on LongBench~v2 without any manually curated long-context QA data. Furthermore, we conduct extensive ablation studies to analyze the impact of reward design, data curation strategies, training schemes, and data scaling effects on model performance. We publicly release our code, data, and models.

</details>


### [258] [On convexity and efficiency in semantic systems](https://arxiv.org/abs/2602.08238)
*Nathaniel Imel,Noga Zaslavasky*

Main category: cs.CL

TL;DR: 本文通过信息瓶颈框架分析人类语义分类系统，发现凸性和效率是两个不同特性，效率能更好地解释颜色命名系统的实证现象。


<details>
  <summary>Details</summary>
Motivation: 人类语义分类系统有两个广泛认可的特征：凸性和沟通效率。虽然先前研究观察到颜色命名中凸性和效率共存，但两者之间的分析关系以及为何共存尚未得到很好理解。本文旨在填补这一空白。

Method: 结合分析和实证方法，基于信息瓶颈（IB）框架研究语义效率。首先分析凸性和效率是否相互蕴含，然后检验IB最优系统在颜色命名领域的凸性程度，最后评估效率和凸性对区分实际颜色命名系统与假设变体的预测能力。

Result: 1. 凸性和效率是不同特性：存在凸但低效的系统，也存在最优效率但非凸的系统；2. 在颜色命名领域，IB最优系统大多是凸的，这解释了凸性方法的主要实证基础；3. 效率是区分实际颜色命名系统与假设变体的更强预测因子，凸性在此基础上几乎没有额外改进；4. 效率能解释一系列凸性无法解释的实证现象。

Conclusion: 虽然凸性和效率可能产生相似的结构观察结果，但它们是根本不同的特性。效率为语义类型学提供了更全面的解释框架，而凸性只是效率在特定领域（如颜色命名）中的伴随现象。

Abstract: There are two widely held characterizations of human semantic category systems: (1) they form convex partitions of conceptual spaces, and (2) they are efficient for communication. While prior work observed that convexity and efficiency co-occur in color naming, the analytical relation between them and why they co-occur have not been well understood. We address this gap by combining analytical and empirical analyses that build on the Information Bottleneck (IB) framework for semantic efficiency. First, we show that convexity and efficiency are distinct in the sense that neither entails the other: there are convex systems which are inefficient, and optimally-efficient systems that are non-convex. Crucially, however, the IB-optimal systems are mostly convex in the domain of color naming, explaining the main empirical basis for the convexity approach. Second, we show that efficiency is a stronger predictor for discriminating attested color naming systems from hypothetical variants, with convexity adding negligible improvement on top of that. Finally, we discuss a range of empirical phenomena that convexity cannot account for but efficiency can. Taken together, our work suggests that while convexity and efficiency can yield similar structural observations, they are fundamentally distinct, with efficiency providing a more comprehensive account of semantic typology.

</details>


### [259] [Language Predicts Identity Fusion Across Cultures and Reveals Divergent Pathways to Violence](https://arxiv.org/abs/2602.08252)
*Devin R. Wright,Justin E. Lane,F. LeRon Shults*

Main category: cs.CL

TL;DR: 本文提出了一种基于认知语言模式、大语言模型和隐式隐喻的认知语言身份融合评分方法，用于从语言中测量身份融合，该方法在预测极端行为意愿方面优于现有方法，并揭示了极端主义的两条不同高融合路径。


<details>
  <summary>Details</summary>
Motivation: 随着社会极化加剧和政治暴力事件增多，理解极端主义的心理根源变得日益重要。先前研究表明身份融合能够预测个体参与极端行为的意愿，但需要更有效的测量工具来深入研究这一现象。

Method: 开发了认知语言身份融合评分方法，该方法结合认知语言模式分析、大语言模型和隐式隐喻识别技术，从语言数据中测量身份融合程度。研究在英国和新加坡的数据集上验证了该方法的有效性。

Result: 该方法在预测已验证的身份融合评分方面优于现有方法。应用于极端主义宣言分析时，发现了两条不同的高融合暴力路径：意识形态驱动者倾向于将自我框架为群体的一部分，形成亲属关系纽带；而怨恨驱动者则将群体框架为个人身份的一部分。

Conclusion: 研究结果细化了身份融合理论，并提供了一个可扩展的工具，有助于身份融合研究和极端主义检测。该方法为理解极端主义的心理机制提供了新的视角和实用工具。

Abstract: In light of increasing polarization and political violence, understanding the psychological roots of extremism is increasingly important. Prior research shows that identity fusion predicts willingness to engage in extreme acts. We evaluate the Cognitive Linguistic Identity Fusion Score, a method that uses cognitive linguistic patterns, LLMs, and implicit metaphor to measure fusion from language. Across datasets from the United Kingdom and Singapore, this approach outperforms existing methods in predicting validated fusion scores. Applied to extremist manifestos, two distinct high-fusion pathways to violence emerge: ideologues tend to frame themselves in terms of group, forming kinship bonds; whereas grievance-driven individuals frame the group in terms of their personal identity. These results refine theories of identity fusion and provide a scalable tool aiding fusion research and extremism detection.

</details>


### [260] [Language Modeling and Understanding Through Paraphrase Generation and Detection](https://arxiv.org/abs/2602.08274)
*Jan Philip Wahle*

Main category: cs.CL

TL;DR: 该论文提出将释义分解为构成性语言方面（释义类型），为语义等价性提供更细粒度的认知基础视角，并证明基于释义类型训练的模型在相关任务和下游应用中表现更优。


<details>
  <summary>Details</summary>
Motivation: 现有方法将释义简化为两个文本之间的二元决策或生成单一改写，掩盖了哪些语言因素负责意义保留。需要更细粒度地理解语义等价性，这对于计算语言模型表示意义至关重要。

Method: 提出将释义分解为构成性语言方面（释义类型），并训练模型识别这些类型。通过显式训练模型处理不同释义类型，提升语义理解能力。

Result: 基于释义类型训练的模型在多项任务中表现优异：剽窃检测中超越人类基线（Wikipedia案例89.6% vs 78.4%，arXiv科学论文66.5% vs 55.7%）；Quora重复问题识别中优于基于二元对训练的模型。

Conclusion: 分解释义为构成性语言方面提供了更细粒度和认知基础的语义等价性视角，显式训练模型处理释义类型能显著提升相关任务性能，推动计算语言模型更好地理解和表示意义。

Abstract: Language enables humans to share knowledge, reason about the world, and pass on strategies for survival and innovation across generations. At the heart of this process is not just the ability to communicate but also the remarkable flexibility in how we can express ourselves. We can express the same thoughts in virtually infinite ways using different words and structures - this ability to rephrase and reformulate expressions is known as paraphrase. Modeling paraphrases is a keystone to meaning in computational language models; being able to construct different variations of texts that convey the same meaning or not shows strong abilities of semantic understanding. If computational language models are to represent meaning, they must understand and control the different aspects that construct the same meaning as opposed to different meanings at a fine granularity. Yet most existing approaches reduce paraphrasing to a binary decision between two texts or to producing a single rewrite of a source, obscuring which linguistic factors are responsible for meaning preservation. In this thesis, I propose that decomposing paraphrases into their constituent linguistic aspects (paraphrase types) offers a more fine-grained and cognitively grounded view of semantic equivalence. I show that even advanced machine learning models struggle with this task. Yet, when explicitly trained on paraphrase types, models achieve stronger performance on related paraphrase tasks and downstream applications. For example, in plagiarism detection, language models trained on paraphrase types surpass human baselines: 89.6% accuracy compared to 78.4% for plagiarism cases from Wikipedia, and 66.5% compared to 55.7% for plagiarism of scientific papers from arXiv. In identifying duplicate questions on Quora, models trained with paraphrase types improve over models trained on binary pairs. Furthermore, I demonstrate that...

</details>


### [261] [New Skills or Sharper Primitives? A Probabilistic Perspective on the Emergence of Reasoning in RLVR](https://arxiv.org/abs/2602.08281)
*Zhilin Wang,Yafu Li,Shunkai Zhang,Zhi Wang,Haoran Zhang,Xiaoye Qu,Yu Cheng*

Main category: cs.CL

TL;DR: RLVR通过锐化原子步骤概率赋予LLMs新能力，而非仅激发潜在能力，使模型能克服多步推理中的指数衰减问题


<details>
  <summary>Details</summary>
Motivation: 解决RLVR是否赋予LLMs新能力还是仅激发潜在能力的争议，提出基于实例级可解性的概率框架来解释复杂推理能力的涌现

Method: 使用Algebrarium框架，在单步操作上训练模型，评估其在未见多步任务上的表现，分析原子步骤联合概率与复合性能的关系

Result: (1) RLVR通过放大现有技能激励探索新解路径；(2) 复合性能严格受原子步骤联合概率控制(ρ∈[0.69,0.96])；(3) RLVR作为全局优化器会牺牲特定技能以最大化总奖励

Conclusion: RLVR通过迭代优化可解问题使模型发展出解决先前不可解场景的能力，为RLVR中的涌现能力提供了新解释

Abstract: Whether Reinforcement Learning with Verifiable Rewards (RLVR) endows Large Language Models (LLMs) with new capabilities or merely elicits latent traces remains a central debate. In this work, we align with the former view, proposing a probabilistic framework where capability is defined by instance-level solvability. We hypothesize that the emergence of complex reasoning can be driven by sharpening atomic step probabilities, which enables models to overcome the exponential decay of success rates inherent in multi-step reasoning chains. Utilizing the Algebrarium framework, we train models exclusively on single-step operations and evaluate their performance on unseen multi-step tasks. Our empirical results confirm that: (1) RLVR incentivizes the exploration of previously inaccessible solution paths by amplifying the model's existing skills; (2) composite performance is strictly governed by the joint probability of atomic steps, evidenced by high Pearson correlation coefficients ($ρ\in [0.69, 0.96]$); and (3) RLVR, acting as a global optimizer, can cause specific skills to be sacrificed to maximize aggregate reward. Our work offers a novel explanation for emergent abilities in RLVR, suggesting that the iterative optimization of solvable problems enables models to develop the capabilities to tackle previously unsolvable scenarios.

</details>


### [262] [Knowledge Augmented Entity and Relation Extraction for Legal Documents with Hypergraph Neural Network](https://arxiv.org/abs/2602.08289)
*Binglin Wu,Xianneng Li*

Main category: cs.CL

TL;DR: 提出基于超图神经网络的毒品案件判决文书实体关系抽取算法Legal-KAHRE，通过司法领域知识增强和超图结构设计提升抽取性能


<details>
  <summary>Details</summary>
Motivation: 随着中国司法机构数字化进程，积累了海量电子法律文档，但现有实体关系抽取方法缺乏领域知识，未能充分考虑司法领域特性

Method: 1) 基于邻居导向打包策略和双仿射机制的候选跨度生成器；2) 构建法律词典并通过多头注意力融入文本编码；3) 将共同犯罪、数罪并罚等司法案例融入超图结构设计；4) 使用超图神经网络进行高阶推理

Result: 在CAIL2022信息抽取数据集上，该方法显著优于现有基线模型

Conclusion: Legal-KAHRE算法通过融入司法领域知识和超图结构设计，有效提升了毒品案件判决文书的实体关系抽取性能

Abstract: With the continuous progress of digitization in Chinese judicial institutions, a substantial amount of electronic legal document information has been accumulated. To unlock its potential value, entity and relation extraction for legal documents has emerged as a crucial task. However, existing methods often lack domain-specific knowledge and fail to account for the unique characteristics of the judicial domain. In this paper, we propose an entity and relation extraction algorithm based on hypergraph neural network (Legal-KAHRE) for drug-related judgment documents. Firstly, we design a candidate span generator based on neighbor-oriented packing strategy and biaffine mechanism, which identifies spans likely to contain entities. Secondly, we construct a legal dictionary with judicial domain knowledge and integrate it into text encoding representation using multi-head attention. Additionally, we incorporate domain-specific cases like joint crimes and combined punishment for multiple crimes into the hypergraph structure design. Finally, we employ a hypergraph neural network for higher-order inference via message passing. Experimental results on the CAIL2022 information extraction dataset demonstrate that our method significantly outperforms existing baseline models.

</details>


### [263] [When Does Context Help? Error Dynamics of Contextual Information in Large Language Models](https://arxiv.org/abs/2602.08294)
*Dingzirui Wang,Xuanliang Zhang,Keyan Xu,Qingfu Zhu,Wanxiang Che,Yang Deng*

Main category: cs.CL

TL;DR: 提出统一理论框架分析Transformer LLMs中任意上下文信息的影响，证明上下文条件误差向量可分解为基线误差向量和上下文修正向量，并推导出误差减少的几何条件。


<details>
  <summary>Details</summary>
Motivation: 推理时的上下文信息（如演示、检索知识、交互历史）能显著提升LLMs性能，但其理论作用在特定设置（如上下文学习）之外仍不明确，需要统一的理论框架来理解任意上下文信息的影响机制。

Method: 建立统一理论框架分析Transformer LLMs中上下文信息的影响，通过输出误差动态来表征上下文影响。在单层Transformer中证明上下文条件误差向量可加性分解，推导误差减少的几何条件，并扩展到多上下文和多层Transformer。

Result: 理论分析表明上下文修正必须与负基线误差对齐并满足范数约束才能减少误差，上下文修正范数有由上下文-查询相关性和互补性决定的上界。实验验证理论并提出了基于原则的上下文选择策略，性能提升0.6%。

Conclusion: 提出了一个统一的理论框架来分析Transformer LLMs中上下文信息的影响，揭示了误差减少的几何条件，为理解上下文信息的作用机制提供了理论基础，并启发了基于原则的上下文选择策略。

Abstract: Contextual information at inference time, such as demonstrations, retrieved knowledge, or interaction history, can substantially improve large language models (LLMs) without parameter updates, yet its theoretical role remains poorly understood beyond specific settings such as in-context learning (ICL). We present a unified theoretical framework for analyzing the effect of arbitrary contextual information in Transformer-based LLMs. Our analysis characterizes contextual influence through output error dynamics. In a single-layer Transformer, we prove that the context-conditioned error vector decomposes additively into the baseline error vector and a contextual correction vector. This yields necessary geometric conditions for error reduction: the contextual correction must align with the negative baseline error and satisfy a norm constraint. We further show that the contextual correction norm admits an explicit upper bound determined by context-query relevance and complementarity. These results extend to multi-context and multi-layer Transformers. Experiments across ICL, retrieval-augmented generation, and memory evolution validate our theory and motivate a principled context selection strategy that improves performance by $0.6\%$.

</details>


### [264] [JUSTICE: Judicial Unified Synthesis Through Intermediate Conclusion Emulation for Automated Judgment Document Generation](https://arxiv.org/abs/2602.08305)
*Binglin Wu,Yingyi Zhang,Xiannneg Li*

Main category: cs.CL

TL;DR: JUSTICE框架通过模拟法官"搜索→预判→撰写"的认知流程，引入预判阶段来提升判决书生成的法律准确性和连贯性。


<details>
  <summary>Details</summary>
Motivation: 现有判决书生成方法过于简化法律推理过程，特别是忽略了"预判"这一关键阶段，导致无法有效获取基础司法要素和建模预判过程，影响了生成文档的法律合理性。

Method: 提出JUSTICE框架，包含三个组件：1) 参考性司法要素检索器(RJER)检索法律条文和先例案例；2) 中间结论模拟器(ICE)生成可验证的中间结论；3) 司法统一合成器(JUS)综合所有输入生成最终判决。

Result: 在领域内法律基准和分布外数据集上的实验表明，JUSTICE显著优于现有基线方法，在法律准确性方面有显著提升，包括刑期预测准确率提高4.6%。

Conclusion: 明确建模预判过程对于增强生成判决书的法律连贯性和准确性至关重要，JUSTICE框架通过模拟法官认知流程有效解决了现有方法的局限性。

Abstract: Automated judgment document generation is a significant yet challenging legal AI task. As the conclusive written instrument issued by a court, a judgment document embodies complex legal reasoning. However, existing methods often oversimplify this complex process, particularly by omitting the ``Pre-Judge'' phase, a crucial step where human judges form a preliminary conclusion. This omission leads to two core challenges: 1) the ineffective acquisition of foundational judicial elements, and 2) the inadequate modeling of the Pre-Judge process, which collectively undermine the final document's legal soundness. To address these challenges, we propose \textit{\textbf{J}udicial \textbf{U}nified \textbf{S}ynthesis \textbf{T}hrough \textbf{I}ntermediate \textbf{C}onclusion \textbf{E}mulation} (JUSTICE), a novel framework that emulates the ``Search $\rightarrow$ Pre-Judge $\rightarrow$ Write'' cognitive workflow of human judges. Specifically, it introduces the Pre-Judge stage through three dedicated components: Referential Judicial Element Retriever (RJER), Intermediate Conclusion Emulator (ICE), and Judicial Unified Synthesizer (JUS). RJER first retrieves legal articles and a precedent case to establish a referential foundation. ICE then operationalizes the Pre-Judge phase by generating a verifiable intermediate conclusion. Finally, JUS synthesizes these inputs to craft the final judgment. Experiments on both an in-domain legal benchmark and an out-of-distribution dataset show that JUSTICE significantly outperforms strong baselines, with substantial gains in legal accuracy, including a 4.6\% improvement in prison term prediction. Our findings underscore the importance of explicitly modeling the Pre-Judge process to enhance the legal coherence and accuracy of generated judgment documents.

</details>


### [265] [Improving Data and Reward Design for Scientific Reasoning in Large Language Models](https://arxiv.org/abs/2602.08321)
*Zijie Chen,Zhenghao Lin,Xiao Liu,Zhenzhong Lan,Yeyun Gong,Peng Cheng*

Main category: cs.CL

TL;DR: 提出了Dr.SCI数据集和训练流程，用于提升大语言模型在开放式科学问题上的表现，通过数据增强、动态难度课程和基于评分标准的强化学习，显著提升了科学推理能力。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型在开放式科学问题上的挑战，主要问题在于不可靠的监督和评估，以及科学后训练的数据构建和奖励设计瓶颈。

Method: 1) 构建Dr.SCI数据集：包含8个STEM学科的100万问题，具有明确的可验证/开放式划分、可扩展难度标注和细粒度评分标准；2) Dr.SCI后训练流程：包括探索扩展的SFT、动态难度课程和基于科学评分标准的RL。

Result: 使用Dr.SCI流程训练的Qwen3-4B-Base在GPQA-diamond上达到63.2分，在GPQA-general上达到32.4分，显著优于o1-mini和GPT-4o等强基线模型。

Conclusion: Dr.SCI数据集和训练流程有效提升了大语言模型的科学推理能力，特别是在开放式问题设置中，为科学后训练提供了系统化的解决方案。

Abstract: Solving open-ended science questions remains challenging for large language models, particularly due to inherently unreliable supervision and evaluation. The bottleneck lies in the data construction and reward design for scientific post-training. We develop a large-scale, systematic data processing pipeline that transforms heterogeneous open-source science data into Dr. SCI dataset, which comprises of 1M questions across eight STEM subjects, with explicit verifiable/open-ended splits, scalable difficulty annotation, and fine-grained rubrics that operationalize evaluation for open-ended answers. Building on this dataset, we propose the Dr. SCI post-training pipeline, which redesigns the standard SFT -> RL workflow through three components: (i) Exploration-Expanding SFT, which broadens the model's reasoning pattern coverage prior to RL; (ii) Dynamic Difficulty Curriculum, which adapts training data to the model's evolving scientific capability; and (iii) SciRubric-Guided RL, which enables stable reinforcement learning on open-ended scientific questions via rubric-based evaluation with explicit answer correctness. Qwen3-4B-Base trained using Dr.SCI pipeline achieves 63.2 on GPQA-diamond and 32.4 on GPQA-general, consistently improves over strong post-trained baselines such as o1-mini and GPT-4o, demonstrating substantial gains in scientific reasoning, especially in open-ended settings.

</details>


### [266] [An Attention-over-Attention Generative Model for Joint Multiple Intent Detection and Slot Filling](https://arxiv.org/abs/2602.08322)
*Wei Zhu*

Main category: cs.CL

TL;DR: 提出基于注意力机制的生成式框架，用于同时处理多意图检测和槽填充任务，通过注意力叠加解码器解决意图数量可变和子任务干扰问题。


<details>
  <summary>Details</summary>
Motivation: 现实对话场景中用户经常在单个话语中表达多个意图，而现有方法主要针对单意图SLU，缺乏处理多意图的能力。

Method: 提出生成式框架，采用注意力叠加解码器处理可变意图数量和子任务干扰，利用BERT的NSP头构建多意图数据集。

Result: 在MixATIS、MixSNIPS和自建数据集上达到SOTA性能，验证了方法的有效性。

Conclusion: 提出的注意力叠加生成模型能有效处理多意图SLU任务，为现实对话系统提供了更好的解决方案。

Abstract: In task-oriented dialogue systems, spoken language understanding (SLU) is a critical component, which consists of two sub-tasks, intent detection and slot filling. Most existing methods focus on the single-intent SLU, where each utterance only has one intent. However, in real-world scenarios users usually express multiple intents in an utterance, which poses a challenge for existing dialogue systems and datasets. In this paper, we propose a generative framework to simultaneously address multiple intent detection and slot filling. In particular, an attention-over-attention decoder is proposed to handle the variable number of intents and the interference between the two sub-tasks by incorporating an inductive bias into the process of multi-task learning. Besides, we construct two new multi-intent SLU datasets based on single-intent utterances by taking advantage of the next sentence prediction (NSP) head of the BERT model. Experimental results demonstrate that our proposed attention-over-attention generative model achieves state-of-the-art performance on two public datasets, MixATIS and MixSNIPS, and our constructed datasets.

</details>


### [267] [Latent Reasoning with Supervised Thinking States](https://arxiv.org/abs/2602.08332)
*Ido Amos,Avi Caciularu,Mor Geva,Amir Globerson,Jonathan Herzig,Lior Shani,Idan Szpektor*

Main category: cs.CL

TL;DR: Thinking States：一种在输入处理过程中进行推理的方法，通过生成思考标记来替代传统的链式思维，降低推理成本并提高效率。


<details>
  <summary>Details</summary>
Motivation: 传统链式思维（CoT）方法虽然能提升大语言模型的复杂任务解决能力，但生成长推理过程会导致显著的推理成本增加，需要更高效的推理方法。

Method: 在输入处理过程中，每隔几个输入标记就生成一系列思考标记，将这些思考标记转换回嵌入空间，并添加到后续的输入标记中，实现并行化学习。

Result: 在多个推理任务上优于其他潜在推理方法，在数学问题上缩小了与CoT的差距，在2-Hop QA任务上达到与CoT相当的性能且延迟更低，在状态跟踪任务上展现出比CoT更强的推理能力并能泛化到更长的序列。

Conclusion: Thinking States方法通过在输入处理过程中进行推理，有效降低了推理成本，在保持或超越CoT性能的同时提高了效率，并能更好地泛化到未见过的长序列。

Abstract: Reasoning with a chain-of-thought (CoT) enables Large Language Models (LLMs) to solve complex tasks but incurs significant inference costs due to the generation of long rationales. We propose Thinking States, a method that performs reasoning {\em while} the input is processing. Specifically, Thinking States generates sequences of thinking tokens every few input tokens, transforms the thoughts back into embedding space, and adds them to the following input tokens. This has two key advantages. First, it captures the recurrent nature of CoT, but where the thought tokens are generated as input is processing. Second, since the thoughts are represented as tokens, they can be learned from natural language supervision, and using teacher-forcing, which is parallelizable. Empirically, Thinking States outperforms other latent reasoning methods on multiple reasoning tasks, narrowing the gap to CoT on math problems, and matching its performance on 2-Hop QA with improved latency. On state-tracking tasks, we show Thinking States leads to stronger reasoning behavior than CoT, successfully extrapolating to longer sequences than seen during training.

</details>


### [268] [UReason: Benchmarking the Reasoning Paradox in Unified Multimodal Models](https://arxiv.org/abs/2602.08336)
*Cheng Yang,Chufan Shi,Bo Shui,Yaokang Wu,Muzi Tao,Huijuan Wang,Ivan Yee Lee,Yong Liu,Xuezhe Ma,Taylor Berg-Kirkpatrick*

Main category: cs.CL

TL;DR: UReason是一个诊断性基准测试，用于评估推理在图像生成中的实际效果，发现推理痕迹虽然能提升性能，但作为条件上下文会干扰视觉合成，形成"推理悖论"。


<details>
  <summary>Details</summary>
Motivation: 当前统一多模态模型采用思维链推理来指导图像生成，但推理对视觉合成的实际效果尚不明确。需要评估推理是否能在像素层面忠实执行，理解推理在图像生成中的真正作用。

Method: 构建UReason基准测试，包含2,000个实例，涵盖代码、算术、空间、属性和文本推理五个任务家族。引入评估框架，比较直接生成、推理引导生成和去上下文生成三种模式，隔离推理痕迹的作用。

Result: 在八个开源统一模型中观察到一致的"推理悖论"：推理痕迹总体上比直接生成表现更好，但将中间思考作为条件上下文会阻碍视觉合成，而仅使用精炼提示作为条件能带来显著提升。

Conclusion: 瓶颈在于上下文干扰而非推理能力不足。UReason为研究统一模型中的推理提供了原则性测试平台，激励未来方法在有效整合推理进行视觉生成的同时减轻干扰。

Abstract: To elicit capabilities for addressing complex and implicit visual requirements, recent unified multimodal models increasingly adopt chain-of-thought reasoning to guide image generation. However, the actual effect of reasoning on visual synthesis remains unclear. We present UReason, a diagnostic benchmark for reasoning-driven image generation that evaluates whether reasoning can be faithfully executed in pixels. UReason contains 2,000 instances across five task families: Code, Arithmetic, Spatial, Attribute, and Text reasoning. To isolate the role of reasoning traces, we introduce an evaluation framework comparing direct generation, reasoning-guided generation, and de-contextualized generation which conditions only on the refined prompt. Across eight open-source unified models, we observe a consistent Reasoning Paradox: Reasoning traces generally improve performance over direct generation, yet retaining intermediate thoughts as conditioning context often hinders visual synthesis, and conditioning only on the refined prompt yields substantial gains. Our analysis suggests that the bottleneck lies in contextual interference rather than insufficient reasoning capacity. UReason provides a principled testbed for studying reasoning in unified models and motivates future methods that effectively integrate reasoning for visual generation while mitigating interference.

</details>


### [269] [WorldTravel: A Realistic Multimodal Travel-Planning Benchmark with Tightly Coupled Constraints](https://arxiv.org/abs/2602.08367)
*Zexuan Wang,Chenghao Yang,Yingqi Que,Zhenzhu Yang,Huaqing Yuan,Yiwen Wang,Zhengxuan Jiang,Shengjie Fang,Zhenhe Wu,Zhaohui Wang,Zhixin Yao,Jiashuo Liu,Jincheng Ren,Yuzhen Li,Yang Yang,Jiaheng Liu,Jian Yang,Zaiyuan Wang,Ge Zhang,Zhoufutu Wen,Wenhao Huang*

Main category: cs.CL

TL;DR: WorldTravel是一个包含150个真实世界旅行场景的基准测试，要求处理平均15+个相互依赖的时空约束。在Webscape多模态环境中，前沿模型表现显著下降，揭示了感知与推理之间的关键差距。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试主要关注松散耦合的约束，依赖理想化数据，无法捕捉从动态网络环境中提取参数的复杂性，无法反映真实世界自主规划中紧密耦合约束的协调需求。

Method: 引入WorldTravel基准测试（150个真实旅行场景，5个城市，平均15+个相互依赖约束）和WorldTravel-Webscape多模态环境（2000+个渲染网页，要求从视觉布局中感知约束参数）。评估了10个前沿模型在文本和多模态环境中的表现。

Result: 模型表现显著下降：即使在文本设置中，最先进的GPT-5.2仅达到32.67%的可行性，在多模态环境中暴跌至19.33%。发现了关键的感知-行动差距，以及约10个约束的规划视野阈值，超过该阈值模型推理会一致失败。

Conclusion: 感知和推理仍然是独立的瓶颈，需要下一代智能体将高保真视觉感知与长视野推理统一起来，以处理脆弱的真实世界物流规划问题。

Abstract: Real-world autonomous planning requires coordinating tightly coupled constraints where a single decision dictates the feasibility of all subsequent actions. However, existing benchmarks predominantly feature loosely coupled constraints solvable through local greedy decisions and rely on idealized data, failing to capture the complexity of extracting parameters from dynamic web environments. We introduce \textbf{WorldTravel}, a benchmark comprising 150 real-world travel scenarios across 5 cities that demand navigating an average of 15+ interdependent temporal and logical constraints. To evaluate agents in realistic deployments, we develop \textbf{WorldTravel-Webscape}, a multi-modal environment featuring over 2,000 rendered webpages where agents must perceive constraint parameters directly from visual layouts to inform their planning. Our evaluation of 10 frontier models reveals a significant performance collapse: even the state-of-the-art GPT-5.2 achieves only 32.67\% feasibility in text-only settings, which plummets to 19.33\% in multi-modal environments. We identify a critical Perception-Action Gap and a Planning Horizon threshold at approximately 10 constraints where model reasoning consistently fails, suggesting that perception and reasoning remain independent bottlenecks. These findings underscore the need for next-generation agents that unify high-fidelity visual perception with long-horizon reasoning to handle brittle real-world logistics.

</details>


### [270] [ViGoEmotions: A Benchmark Dataset For Fine-grained Emotion Detection on Vietnamese Texts](https://arxiv.org/abs/2602.08371)
*Hung Quang Tran,Nam Tien Pham,Son T. Luu,Kiet Van Nguyen*

Main category: cs.CL

TL;DR: 该研究构建了越南语情感语料库ViGoEmotions（20,664条社交媒体评论，27种细粒度情感），评估了8种预训练Transformer模型在三种预处理策略下的表现，发现表情符号处理方式和标注质量对情感分类性能有重要影响。


<details>
  <summary>Details</summary>
Motivation: 情感分类在情感预测和有害内容检测中具有重要作用。虽然大语言模型在NLP领域取得显著进展，但越南语缺乏高质量的情感语料库来支持细粒度情感分类研究。

Method: 1. 构建ViGoEmotions语料库：包含20,664条越南语社交媒体评论，标注27种细粒度情感
2. 评估8种预训练Transformer模型
3. 采用三种预处理策略：保留原始表情符号并进行规则规范化、将表情符号转换为文本描述、使用ViSoLex模型进行词汇规范化
4. 比较不同策略下的模型性能

Result: 1. 将表情符号转换为文本通常能提升BERT基线的性能
2. 保留表情符号对ViSoBERT和CafeBERT效果最佳
3. 移除表情符号通常导致性能下降
4. ViSoBERT获得最高Macro F1-score（61.50%）和Weighted F1-score（63.26%）
5. CafeBERT和PhoBERT也表现出色

Conclusion: ViGoEmotions语料库能有效支持多种架构的情感分类任务，但预处理策略和标注质量是影响下游性能的关键因素。表情符号处理方式对模型性能有显著影响，需要根据具体模型选择合适策略。

Abstract: Emotion classification plays a significant role in emotion prediction and harmful content detection. Recent advancements in NLP, particularly through large language models (LLMs), have greatly improved outcomes in this field. This study introduces ViGoEmotions -- a Vietnamese emotion corpus comprising 20,664 social media comments in which each comment is classified into 27 fine-grained distinct emotions. To evaluate the quality of the dataset and its impact on emotion classification, eight pre-trained Transformer-based models were evaluated under three preprocessing strategies: preserving original emojis with rule-based normalization, converting emojis into textual descriptions, and applying ViSoLex, a model-based lexical normalization system. Results show that converting emojis into text often improves the performance of several BERT-based baselines, while preserving emojis yields the best results for ViSoBERT and CafeBERT. In contrast, removing emojis generally leads to lower performance. ViSoBERT achieved the highest Macro F1-score of 61.50% and Weighted F1-score of 63.26%. Strong performance was also observed from CafeBERT and PhoBERT. These findings highlight that while the proposed corpus can support diverse architectures effectively, preprocessing strategies and annotation quality remain key factors influencing downstream performance.

</details>


### [271] [Dynamic Long Context Reasoning over Compressed Memory via End-to-End Reinforcement Learning](https://arxiv.org/abs/2602.08382)
*Zhuoen Chen,Dongfang Li,Meishan Zhang,Baotian Hu,Min Zhang*

Main category: cs.CL

TL;DR: 提出基于分块压缩和选择性记忆召回的长上下文推理框架，通过压缩记忆表示和动态门控机制，在保持准确性的同时显著提升效率和扩展上下文长度。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在处理长上下文时面临计算成本高、信息遗忘和RAG中的上下文碎片化等问题，需要更高效的推理方法。

Method: 将长输入分块并压缩为记忆表示，使用门控模块动态选择相关记忆块，通过推理模块和演化工作记忆迭代处理，使用端到端强化学习联合优化压缩器和推理器。

Result: 在RULER-HQA等多跳推理基准上取得竞争性准确率，上下文长度从7K扩展到1.75M tokens，相比MemAgent减少2倍GPU峰值内存使用和6倍推理加速。

Conclusion: 提出的认知启发框架通过压缩记忆和选择性召回机制，在长上下文处理中实现了更好的准确率-效率权衡，为高效长上下文推理提供了有效解决方案。

Abstract: Large Language Models (LLMs) face significant challenges in long-context processing, including quadratic computational costs, information forgetting, and the context fragmentation inherent in retrieval-augmented generation (RAG). We propose a cognitively inspired framework for efficient long-context inference based on chunk-wise compression and selective memory recall, rather than processing all raw tokens. The framework segments long inputs into chunks and encodes each chunk into compressed memory representations using a learned compressor. A gating module dynamically selects relevant memory blocks, which are then iteratively processed by a reasoning module with an evolving working memory to solve downstream tasks. The compressor and reasoner are jointly optimized via end-to-end reinforcement learning, while the gating module is trained separately as a classifier. Experimental results show that the proposed method achieves competitive accuracy on multi-hop reasoning benchmarks such as RULER-HQA, extrapolates context length from 7K to 1.75M tokens, and offers a favorable accuracy-efficiency trade-off compared to strong long-context baselines. In particular, it achieves up to a 2 times reduction in peak GPU memory usage and a 6 times inference speedup over MemAgent.

</details>


### [272] [TEAM: Temporal-Spatial Consistency Guided Expert Activation for MoE Diffusion Language Model Acceleration](https://arxiv.org/abs/2602.08404)
*Linye Wei,Zixiang Luo,Pingzhi Tang,Meng Li*

Main category: cs.CL

TL;DR: TEAM框架通过利用专家路由决策的时空一致性，采用三种互补策略加速MoE扩散大语言模型，实现2.2倍加速且性能损失可忽略


<details>
  <summary>Details</summary>
Motivation: MoE扩散大语言模型存在架构不匹配问题：每个去噪步骤激活大量专家，但只有少量token被最终接受，导致推理开销大，限制了在延迟敏感应用中的部署

Method: 提出TEAM框架，利用专家路由决策在去噪层级间的时间一致性和token位置间的空间一致性，采用三种策略：保守选择已解码和掩码token的必要专家，同时对多个候选进行激进的推测性探索

Result: 实验结果表明，TEAM相比原始MoE dLLM实现最高2.2倍加速，性能下降可忽略不计

Conclusion: TEAM是一个即插即用框架，能有效加速MoE扩散大语言模型，通过更少的激活专家处理更多被接受token，解决了架构不匹配问题

Abstract: Diffusion large language models (dLLMs) have recently gained significant attention due to their inherent support for parallel decoding. Building on this paradigm, Mixture-of-Experts (MoE) dLLMs with autoregressive (AR) initialization have further demonstrated strong performance competitive with mainstream AR models. However, we identify a fundamental mismatch between MoE architectures and diffusion-based decoding. Specifically, a large number of experts are activated at each denoising step, while only a small subset of tokens is ultimately accepted, resulting in substantial inference overhead and limiting their deployment in latency-sensitive applications. In this work, we propose TEAM, a plug-and-play framework that accelerates MoE dLLMs by enabling more accepted tokens with fewer activated experts. TEAM is motivated by the observation that expert routing decisions exhibit strong temporal consistency across denoising levels as well as spatial consistency across token positions. Leveraging these properties, TEAM employs three complementary expert activation and decoding strategies, conservatively selecting necessary experts for decoded and masked tokens and simultaneously performing aggressive speculative exploration across multiple candidates. Experimental results demonstrate that TEAM achieves up to 2.2x speedup over vanilla MoE dLLM, with negligible performance degradation. Code is released at https://github.com/PKU-SEC-Lab/TEAM-MoE-dLLM.

</details>


### [273] [Prism: Spectral-Aware Block-Sparse Attention](https://arxiv.org/abs/2602.08426)
*Xinghao Wang,Pengyu Wang,Xiaoran Liu,Fangxu Liu,Jason Chu,Kai Song,Xipeng Qiu*

Main category: cs.CL

TL;DR: Prism通过频谱感知方法解决块稀疏注意力中块选择效率问题，利用能量温度校准恢复位置信息，实现5.1倍加速


<details>
  <summary>Details</summary>
Motivation: 块稀疏注意力在长上下文LLM预填充中很有前景，但现有方法使用粗粒度注意力作为块重要性估计的代理，通常需要昂贵的token级搜索或评分，导致显著的选择开销

Method: 提出Prism方法：1）分析标准粗粒度注意力（通过均值池化）不准确的理论根源——均值池化与RoPE的交互导致高频维度破坏性干扰；2）将块选择分解为高频和低频分支；3）应用基于能量的温度校准直接从池化表示中恢复衰减的位置信号

Result: Prism在保持与完整注意力相同准确性的同时，实现了高达5.1倍的加速

Conclusion: Prism通过频谱感知的块重要性估计方法，解决了块稀疏注意力中的效率瓶颈，实现了训练免费的高效块选择

Abstract: Block-sparse attention is promising for accelerating long-context LLM pre-filling, yet identifying relevant blocks efficiently remains a bottleneck. Existing methods typically employ coarse-grained attention as a proxy for block importance estimation, but often resort to expensive token-level searching or scoring, resulting in significant selection overhead. In this work, we trace the inaccuracy of standard coarse-grained attention via mean pooling to a theoretical root cause: the interaction between mean pooling and Rotary Positional Embeddings (RoPE). We prove that mean pooling acts as a low-pass filter that induces destructive interference in high-frequency dimensions, effectively creating a "blind spot" for local positional information (e.g., slash patterns). To address this, we introduce Prism, a training-free spectral-aware approach that decomposes block selection into high-frequency and low-frequency branches. By applying energy-based temperature calibration, Prism restores the attenuated positional signals directly from pooled representations, enabling block importance estimation using purely block-level operations, thereby improving efficiency. Extensive evaluations confirm that Prism maintains accuracy parity with full attention while delivering up to $\mathbf{5.1\times}$ speedup.

</details>


### [274] [Large Language Models and Impossible Language Acquisition: "False Promise" or an Overturn of our Current Perspective towards AI](https://arxiv.org/abs/2602.08437)
*Ziyan wang,Longlong Ma*

Main category: cs.CL

TL;DR: 该研究通过实验检验Chomsky对LLMs的批评，发现GPT-2在不可能语言学习上表现不佳，而LSTM表现符合Chomsky观点，建议从理性主义转向功能主义和经验主义范式。


<details>
  <summary>Details</summary>
Motivation: 回应Chomsky对大型语言模型的根本性批评，即LLMs只是模式预测器，缺乏人类语言习得的内在因果和自我修正结构，无法区分不可能语言。研究旨在通过实证检验这一理论主张。

Method: 1. 从语言学和心理学文献角度分析Chomsky批评；2. 通过实验研究LLMs学习可能和不可能语言的能力；3. 构建句法上不可能的语言（如句子反转、基于词数奇偶性的否定）；4. 在GPT-2小型模型和LSTM模型上进行两轮对照实验；5. 使用Welch's t-test进行统计分析。

Result: GPT-2小型模型在所有不可能语言学习上都表现不佳（p<.001），而LSTM模型的表现符合Chomsky的论点，表明transformer架构的演变具有不可替代的作用。

Conclusion: 基于理论和实证发现，提出在Chomsky理论框架内对LLMs的新视角，并建议从Chomsky的"理性主义-浪漫主义"范式转向功能主义和经验主义的研究范式。

Abstract: In Chomsky's provocative critique "The False Promise of CHATGPT," Large Language Models (LLMs) are characterized as mere pattern predictors that do not acquire languages via intrinsic causal and self-correction structures like humans, therefore are not able to distinguish impossible languages. It stands as a representative in a fundamental challenge to the intellectual foundations of AI, for it integrally synthesizes major issues in methodologies within LLMs and possesses an iconic a priori rationalist perspective. We examine this famous critic from both the perspective in pre-existing literature of linguistics and psychology as well as a research based on an experiment inquiring the capacity of learning both possible and impossible languages among LLMs. We constructed a set of syntactically impossible languages by applying certain transformations to English. These include reversing whole sentences, and adding negation based on word-count parity. Two rounds of controlled experiments were each conducted on GPT-2 small models and long short-term memory (LSTM) models. Statistical analysis (Welch's t-test) shows GPT2 small models underperform in learning all of the impossible languages compared to their performance on the possible language (p<.001). On the other hand, LSTM models' performance tallies with Chomsky's argument, suggesting the irreplaceable role of the evolution of transformer architecture. Based on theoretical analysis and empirical findings, we propose a new vision within Chomsky's theory towards LLMs, and a shift of theoretical paradigm outside Chomsky, from his "rationalist-romantics" paradigm to functionalism and empiricism in LLMs research.

</details>


### [275] [Characterizing, Evaluating, and Optimizing Complex Reasoning](https://arxiv.org/abs/2602.08498)
*Haoran Zhang,Yafu Li,Zhi Wang,Zhilin Wang,Shunkai Zhang,Xiaoye Qu,Yu Cheng*

Main category: cs.CL

TL;DR: 论文提出ME²原则评估推理质量，基于DAG建模推理轨迹，构建TRM-Preference数据集训练Thinking Reward Model，实验证明思考奖励能有效优化推理性能。


<details>
  <summary>Details</summary>
Motivation: 现有工作缺乏对推理质量的统一定义、对复杂结构推理轨迹的可靠评估方法，以及如何利用评估信号进行推理优化的系统解决方案。

Method: 1. 提出ME²原则从宏观和微观层面评估推理效率与效果；2. 将推理轨迹建模为有向无环图(DAG)，开发基于DAG的成对评估方法；3. 构建TRM-Preference数据集，训练Thinking Reward Model(TRM)进行大规模推理质量评估。

Result: 思考奖励作为有效的优化信号：测试时选择更好的推理能带来更好的结果（最高19.3%提升），在强化学习训练中，思考奖励能增强推理和性能（最高3.9%提升），在多样化任务中均有效。

Conclusion: 该研究提供了统一的推理质量评估框架，通过ME²原则、DAG建模和TRM模型，有效解决了推理质量定义、评估和优化三个核心问题，为大型推理模型的改进提供了系统方法。

Abstract: Large Reasoning Models (LRMs) increasingly rely on reasoning traces with complex internal structures. However, existing work lacks a unified answer to three fundamental questions: (1) what defines high-quality reasoning, (2) how to reliably evaluate long, implicitly structured reasoning traces, and (3) how to use such evaluation signals for reasoning optimization. To address these challenges, we provide a unified perspective. (1) We introduce the ME$^2$ principle to characterize reasoning quality along macro- and micro-level concerning efficiency and effectiveness. (2) Built on this principle, we model reasoning traces as directed acyclic graphs (DAGs) and develop a DAG-based pairwise evaluation method, capturing complex reasoning structures. (3) Based on this method, we construct the TRM-Preference dataset and train a Thinking Reward Model (TRM) to evaluate reasoning quality at scale. Experiments show that thinking rewards serve as an effective optimization signal. At test time, selecting better reasoning leads to better outcomes (up to 19.3% gain), and during RL training, thinking rewards enhance reasoning and performance (up to 3.9% gain) across diverse tasks.

</details>


### [276] [GISA: A Benchmark for General Information-Seeking Assistant](https://arxiv.org/abs/2602.08543)
*Yutao Zhu,Xingshuo Zhang,Maosen Zhang,Jiajie Jin,Liancheng Zhang,Xiaoshuai Song,Kangzhi Zhao,Wencong Zeng,Ruiming Tang,Han Li,Ji-Rong Wen,Zhicheng Dou*

Main category: cs.CL

TL;DR: GISA是一个针对通用信息寻求助手的新基准测试，包含373个人工构建的真实查询，支持四种结构化答案格式，并包含实时更新子集以防止记忆，实验显示现有模型表现仍有很大提升空间。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试存在三个主要问题：1）查询构建方式不自然（从答案反向构建），与现实需求脱节；2）要么专注于定位特定信息，要么专注于多源信息聚合，缺乏统一；3）依赖静态答案集，容易受到数据污染影响。需要建立一个更真实、全面的基准来评估信息寻求助手。

Method: GISA基准包含373个人工构建的查询，反映真实信息寻求场景。采用四种结构化答案格式（项目、集合、列表、表格）实现确定性评估。将深度推理和广泛信息聚合整合到统一任务中，包含定期更新答案的实时子集以防止记忆。为每个查询提供完整的人类搜索轨迹，用于过程级监督和模仿学习。

Result: 在主流LLM和商业搜索产品上的实验显示，即使表现最好的模型也只达到19.30%的精确匹配分数。在需要复杂规划和全面信息收集的任务上，性能显著下降。这表明现有模型在信息寻求能力方面仍有很大改进空间。

Conclusion: GISA基准填补了现有评估方法的空白，提供了一个更真实、全面的信息寻求助手评估框架。实验结果揭示了当前模型在复杂信息寻求任务上的局限性，为未来研究指明了改进方向，特别是在复杂规划和全面信息聚合能力方面。

Abstract: The advancement of large language models (LLMs) has significantly accelerated the development of search agents capable of autonomously gathering information through multi-turn web interactions. Various benchmarks have been proposed to evaluate such agents. However, existing benchmarks often construct queries backward from answers, producing unnatural tasks misaligned with real-world needs. Moreover, these benchmarks tend to focus on either locating specific information or aggregating information from multiple sources, while relying on static answer sets prone to data contamination. To bridge these gaps, we introduce GISA, a benchmark for General Information-Seeking Assistants comprising 373 human-crafted queries that reflect authentic information-seeking scenarios. GISA features four structured answer formats (item, set, list, and table), enabling deterministic evaluation. It integrates both deep reasoning and broad information aggregation within unified tasks, and includes a live subset with periodically updated answers to resist memorization. Notably, GISA provides complete human search trajectories for every query, offering gold-standard references for process-level supervision and imitation learning. Experiments on mainstream LLMs and commercial search products reveal that even the best-performing model achieves only 19.30\% exact match score, with performance notably degrading on tasks requiring complex planning and comprehensive information gathering. These findings highlight substantial room for future improvement.

</details>


### [277] [How Do Language Models Understand Tables? A Mechanistic Analysis of Cell Location](https://arxiv.org/abs/2602.08548)
*Xuanliang Zhang,Dingzirui Wang,Keyan Xu,Qingfu Zhu,Wanxiang Che*

Main category: cs.CL

TL;DR: 该研究通过激活修补等技术揭示了LLM处理表格的内部机制，将表格理解分解为语义绑定、坐标定位和信息提取三阶段，发现模型通过计数分隔符来定位单元格，并在线性子空间中编码列索引。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型越来越多地用于表格相关任务，但它们处理线性化二维结构化表格的内部机制仍然不透明。本研究旨在揭示LLM如何理解表格的内部工作机制。

Method: 使用激活修补和互补的可解释性技术，将表格理解机制分解为原子任务（单元格定位），通过分析模型内部表示来研究其工作原理。

Result: 发现模型通过计数离散分隔符来解析坐标的序数机制定位目标单元格；列索引编码在线性子空间中，可通过向量算术精确引导模型注意力；多单元格定位任务通过复用原子定位中识别的相同注意力头实现泛化。

Conclusion: 该研究为Transformer架构中的表格理解提供了全面解释，揭示了模型通过三阶段管道处理表格的内部机制，为理解LLM处理结构化数据的能力提供了新见解。

Abstract: While Large Language Models (LLMs) are increasingly deployed for table-related tasks, the internal mechanisms enabling them to process linearized two-dimensional structured tables remain opaque. In this work, we investigate the process of table understanding by dissecting the atomic task of cell location. Through activation patching and complementary interpretability techniques, we delineate the table understanding mechanism into a sequential three-stage pipeline: Semantic Binding, Coordinate Localization, and Information Extraction. We demonstrate that models locate the target cell via an ordinal mechanism that counts discrete delimiters to resolve coordinates. Furthermore, column indices are encoded within a linear subspace that allows for precise steering of model focus through vector arithmetic. Finally, we reveal that models generalize to multi-cell location tasks by multiplexing the identical attention heads identified during atomic location. Our findings provide a comprehensive explanation of table understanding within Transformer architectures.

</details>


### [278] [Beyond Scalar Scores: Reinforcement Learning for Error-Aware Quality Estimation of Machine Translation](https://arxiv.org/abs/2602.08600)
*Archchana Sindhujan,Girish A. Koushik,Shenbin Qian,Diptesh Kanojia,Constantin Orăsan*

Main category: cs.CL

TL;DR: 本文提出ALOPE-RL框架，结合错误感知奖励和强化学习，在资源匮乏的英语-马拉雅拉姆语翻译质量评估任务上取得SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有翻译质量评估方法主要依赖标量质量分数，缺乏对具体翻译错误的解释，且在低资源语言上性能有限。英语-马拉雅拉姆语作为资源极度匮乏的语言对，缺乏标注数据。

Method: 1) 创建首个英语-马拉雅拉姆语片段级QE数据集，包含直接评估分数和翻译质量评注；2) 提出ALOPE-RL框架，基于策略奖励训练高效适配器，结合DA分数和TQR作为错误感知奖励。

Result: ALOPE-RL在小型QE数据集上训练，使用紧凑LLM（≤4B参数）配合LoRA和4位量化，在英语-马拉雅拉姆语QE任务上超越更大的LLM基线和领先的编码器基QE模型，达到SOTA性能。

Conclusion: 错误感知的策略学习能在有限数据和计算预算下实现强大的QE性能。作者发布了数据集、代码和训练模型以支持未来研究。

Abstract: Quality Estimation (QE) aims to assess the quality of machine translation (MT) outputs without relying on reference translations, making it essential for real-world, large-scale MT evaluation. Large Language Models (LLMs) have shown significant promise in advancing the field of quality estimation of machine translation. However, most of the QE approaches solely rely on scalar quality scores, offering no explicit information about the translation errors that should drive these judgments. Moreover, for low-resource languages where annotated QE data is limited, existing approaches struggle to achieve reliable performance. To address these challenges, we introduce the first segment-level QE dataset for English to Malayalam, a severely resource-scarce language pair in the QE domain, comprising human-annotated Direct Assessment (DA) scores and Translation Quality Remarks (TQR), which are short, contextual, free-form annotator comments that describe translation errors. We further introduce ALOPE-RL, a policy-based reinforcement learning framework that trains efficient adapters based on policy rewards derived from DA score and TQR. Integrating error-aware rewards with ALOPE-RL, enables LLMs to reason about translation quality beyond numeric scores. Despite being trained on a small-scale QE dataset, ALOPE-RL achieves state-of-the-art performance on English to Malayalam QE using compact LLMs (<=4B parameters}) fine-tuned with LoRA and 4-bit quantization, outperforming both larger LLM-based baselines and leading encoder-based QE models. Our results demonstrate that error-aware, policy-based learning can deliver strong QE performance under limited data and compute budgets. We release our dataset, code, and trained models to support future research.

</details>


### [279] [VocalNet-MDM: Accelerating Streaming Speech LLM via Self-Distilled Masked Diffusion Modeling](https://arxiv.org/abs/2602.08607)
*Ziyang Cheng,Yuhao Wang,Heyang Liu,Ronghua Wu,Qunshan Gu,Yanfeng Wang,Yu Wang*

Main category: cs.CL

TL;DR: VocalNet-MDM采用掩码扩散建模作为非自回归范式，通过层次化块掩码和迭代自蒸馏技术，在仅6K小时语音数据上实现3.7-10倍解码加速和34%首块延迟降低，同时保持竞争性识别精度和最佳文本质量与语音自然度。


<details>
  <summary>Details</summary>
Motivation: 当前语音大语言模型主要采用自回归范式，存在严格的序列约束，限制了生成效率并引入了曝光偏差。需要探索非自回归范式来提高语音交互的效率和降低延迟。

Method: 提出VocalNet-MDM，采用掩码扩散建模作为非自回归范式。针对流式语音交互的两个关键挑战（训练-推理不匹配和迭代开销），提出层次化块掩码来对齐训练目标与块扩散解码中的渐进掩码状态，以及迭代自蒸馏来将多步精炼压缩到更少步骤以实现低延迟推理。

Result: 在仅6K小时语音数据上训练，VocalNet-MDM相比自回归基线实现3.7-10倍解码加速，首块延迟降低34%。在保持竞争性识别精度的同时，实现了最先进的文本质量和语音自然度。

Conclusion: 掩码扩散建模是低延迟、高效语音大语言模型的一个有前景且可扩展的替代方案，能够显著提升生成效率同时保持高质量输出。

Abstract: Recent Speech Large Language Models~(LLMs) have achieved impressive capabilities in end-to-end speech interaction. However, the prevailing autoregressive paradigm imposes strict serial constraints, limiting generation efficiency and introducing exposure bias. In this paper, we investigate Masked Diffusion Modeling~(MDM) as a non-autoregressive paradigm for speech LLMs and introduce VocalNet-MDM. To adapt MDM for streaming speech interaction, we address two critical challenges: training-inference mismatch and iterative overhead. We propose Hierarchical Block-wise Masking to align training objectives with the progressive masked states encountered during block diffusion decoding, and Iterative Self-Distillation to compress multi-step refinement into fewer steps for low-latency inference. Trained on a limited scale of only 6K hours of speech data, VocalNet-MDM achieves a 3.7$\times$--10$\times$ decoding speedup and reduces first-chunk latency by 34\% compared to AR baselines. It maintains competitive recognition accuracy while achieving state-of-the-art text quality and speech naturalness, demonstrating that MDM is a promising and scalable alternative for low-latency, efficient speech LLMs.

</details>


### [280] [Do Multilingual LLMs have specialized language heads?](https://arxiv.org/abs/2602.08625)
*Muhammad Naufil*

Main category: cs.CL

TL;DR: 本文研究多语言大语言模型是否存在针对特定语言的注意力头，并探索在不影响目标语言性能的情况下移除不需要的语言特定头的可能性。


<details>
  <summary>Details</summary>
Motivation: 多语言大语言模型在生产部署中效率低下，特别是当只需要支持部分语言时。目前缺乏对多语言LLM（不仅仅是翻译模型）中语言特定或语言无关头的研究。

Method: 探索多语言LLM是否具有针对每种语言的专门注意力头，并研究移除不需要的语言特定头而不影响目标语言性能的可能性。

Result: 研究发现多语言LLM存在语言特定的注意力头，移除不需要的语言特定头可以在保持目标语言性能的同时降低模型复杂度。

Conclusion: 该研究为多语言LLM的高效部署策略提供了依据，能够在保持目标语言高准确性的同时减少模型复杂度。

Abstract: Multilingual large language models (LLMs) have gained significant popularity for their ability to process and generate text across multiple languages. However, deploying these models in production can be inefficient when only a subset of the supported languages is of interest. There has been some research conducted on identifying whether machine translation models have language-specific or language-agnostic heads, however no research has been conducted for multilingual LLMs, to the best of our knowledge, that as we know are capable of performing diverse tasks beyond just translation. This paper explores whether multilingual LLMs have specialized language attention heads for each language, and investigates the possibility of removing language-specific heads for unwanted languages without degrading performance in the targeted languages. Our findings could inform more efficient deployment strategies for multilingual LLMs, enabling reduced model complexity while maintaining high accuracy for targeted languages.

</details>


### [281] [Fundamental Reasoning Paradigms Induce Out-of-Domain Generalization in Language Models](https://arxiv.org/abs/2602.08658)
*Mingzi Cao,Xingwei Tan,Mahmud Akhter,Marco Valentino,Maria Liakata,Xi Wang,Nikolaos Aletras*

Main category: cs.CL

TL;DR: 该研究探索了演绎、归纳和溯因三种基本推理范式对大型语言模型泛化能力的影响，通过符号任务数据集训练LLMs，并在现实自然语言任务中验证其泛化性能，获得了显著提升。


<details>
  <summary>Details</summary>
Motivation: 尽管提升大型语言模型推理能力的研究很多，但三种基本推理范式（演绎、归纳、溯因）如何影响LLMs的泛化能力尚未得到系统探索。研究者希望了解这些核心范式之间的相互作用如何影响LLMs的推理行为。

Method: 1. 收集新的符号任务推理轨迹数据集，每个任务针对一种基本推理范式，以抽象化具体世界知识
2. 研究将这些推理技能注入LLMs的有效方法，包括简单微调、增加模型深度、将密集模型转换为专家混合模型等多种方法
3. 在完全用自然语言表述且包含真实世界知识的现实领域外任务上进行全面评估

Result: 该方法在现实任务上表现出强大的泛化能力，性能提升显著（最高达14.60分）。研究揭示了不同推理范式训练对LLMs泛化行为的影响。

Conclusion: 系统地训练LLMs掌握基本推理范式可以显著提升其在现实自然语言任务上的泛化性能，为改进LLM推理能力提供了新的方向。

Abstract: Deduction, induction, and abduction are fundamental reasoning paradigms, core for human logical thinking. Although improving Large Language Model (LLM) reasoning has attracted significant research efforts, the extent to which the fundamental paradigms induce generalization has yet to be systematically explored. In this study, we shed light on how the interplay between these core paradigms influences LLMs' reasoning behavior. To this end, we first collect a new dataset of reasoning trajectories from symbolic tasks, each targeting one of the three fundamental paradigms, to abstract from concrete world knowledge. Then, we investigate effective ways for inducing these skills into LLMs. We experiment with a battery of methods including simple fine-tuning, and more complex approaches to increase model depth, or transform a dense model to a mixture-of-experts. We comprehensively evaluate induced models on realistic out-of-domain tasks, that are entirely formulated in natural language and contain real-world knowledge. Our results reveal that our approach yields strong generalizability with substantial performance gains (up to $14.60$) across realistic tasks.

</details>


### [282] [Learning to Judge: LLMs Designing and Applying Evaluation Rubrics](https://arxiv.org/abs/2602.08672)
*Clemencia Siro,Pourya Aliannejadi,Mohammad Aliannejadi*

Main category: cs.CL

TL;DR: LLMs能够生成并应用自己的评估标准，但在事实性和知识密集型任务中可靠性下降，不同模型间的评估标准存在差异。


<details>
  <summary>Details</summary>
Motivation: 当前LLM评估主要依赖静态的人类定义标准，这些标准与模型内部的语言质量表示方式存在错位。研究者希望探索LLM是否能够设计并应用自己的评估标准。

Method: 提出GER-Eval框架，让LLMs生成自己的评估标准并应用这些标准进行评估。研究评估了LLM定义标准的语义一致性、评分可靠性以及与人类标准的对齐程度。

Result: LLMs能够可靠地生成可解释且任务感知的评估维度，并在模型内部一致应用。但在事实性和知识密集型任务中评分可靠性下降。闭源模型（如GPT-4o）比开源模型（如Llama）具有更高的一致性和跨模型泛化能力。

Conclusion: 评估是LLMs的一种学习到的语言能力，在模型内部一致但在不同模型间存在碎片化。需要新的方法来联合建模人类和LLM的评估语言，以提高可靠性和可解释性。

Abstract: Large language models (LLMs) are increasingly used as evaluators for natural language generation, applying human-defined rubrics to assess system outputs. However, human rubrics are often static and misaligned with how models internally represent language quality. We introduce GER-Eval (Generating Evaluation Rubrics for Evaluation) to investigate whether LLMs can design and apply their own evaluation rubrics. We evaluate the semantic coherence and scoring reliability of LLM-defined criteria and their alignment with human criteria. LLMs reliably generate interpretable and task-aware evaluation dimensions and apply them consistently within models, but their scoring reliability degrades in factual and knowledge-intensive settings. Closed-source models such as GPT-4o achieve higher agreement and cross-model generalization than open-weight models such as Llama. Our findings position evaluation as a learned linguistic capability of LLMs, consistent within models but fragmented across them, and call for new methods that jointly model human and LLM evaluative language to improve reliability and interpretability.

</details>


### [283] [Old wine in old glasses: Comparing computational and qualitative methods in identifying incivility on Persian Twitter during the #MahsaAmini movement](https://arxiv.org/abs/2602.08688)
*Hossein Kermani,Fatemeh Oudlajani,Pardis Yarahmadi,Hamideh Mahdi Soltani,Mohammad Makki,Zahra HosseiniKhoo*

Main category: cs.CL

TL;DR: 比较三种波斯语推文不文明内容检测方法：人工编码、ParsBERT监督学习和ChatGPT大语言模型。ParsBERT在仇恨言论检测上显著优于ChatGPT，后者不仅难以处理微妙案例，连明显不文明内容也识别困难。


<details>
  <summary>Details</summary>
Motivation: 研究动机是评估不同方法在低资源语言（波斯语）环境中检测仇恨言论的有效性，特别是在#MahsaAmini运动这样的敏感社会背景下，需要准确高效的内容分析工具。

Method: 使用47,278条波斯语推文数据集，比较三种方法：1）人工定性编码作为基准；2）基于ParsBERT的监督学习模型；3）七种ChatGPT模型变体。评估准确性和效率，并测试提示语言（英语vs波斯语）对ChatGPT输出的影响。

Result: ParsBERT在仇恨言论检测方面显著优于所有七个ChatGPT模型。ChatGPT不仅在微妙案例上表现不佳，连明显不文明内容也难以准确识别。提示语言（英语或波斯语）对ChatGPT输出没有显著影响。

Conclusion: 在波斯语这样的低资源语言环境中，专门训练的监督学习模型（如ParsBERT）比通用大语言模型（如ChatGPT）更适合仇恨言论检测任务。研究为不同方法的优缺点提供了详细比较，对社交媒体内容分析具有实际指导意义。

Abstract: This paper compares three approaches to detecting incivility in Persian tweets: human qualitative coding, supervised learning with ParsBERT, and large language models (ChatGPT). Using 47,278 tweets from the #MahsaAmini movement in Iran, we evaluate the accuracy and efficiency of each method. ParsBERT substantially outperforms seven evaluated ChatGPT models in identifying hate speech. We also find that ChatGPT struggles not only with subtle cases but also with explicitly uncivil content, and that prompt language (English vs. Persian) does not meaningfully affect its outputs. The study provides a detailed comparison of these approaches and clarifies their strengths and limitations for analyzing hate speech in a low-resource language context.

</details>


### [284] [Challenges in Translating Technical Lectures: Insights from the NPTEL](https://arxiv.org/abs/2602.08698)
*Basudha Raje,Sadanand Venkatraman,Nandana TP,Soumyadeepa Das,Polkam Poojitha,M. Vijaykumar,Tanima Bagchi,Hema A. Murthy*

Main category: cs.CL

TL;DR: 该研究探讨了机器翻译在孟加拉语、马拉雅拉姆语和泰卢固语等印度语言中的实际应用和方法论意义，重点关注技术教育内容的翻译，并分析了现有评估框架对这些形态丰富语言的适用性。


<details>
  <summary>Details</summary>
Motivation: 研究动机源于印度2020年国家教育政策(NEP 2020)对多语言教育技术的需求，以及NPTEL大规模开放在线课程平台的实际应用需求。选择这三种语言是为了体现印度语言多样性，并解决技术概念在保留适当语域和词汇选择情况下的清晰传达问题。

Method: 使用NPTEL MOOC平台作为语料库来源，构建了包含技术概念的自发语音语料库。研究分析了机器翻译在孟加拉语、马拉雅拉姆语和泰卢固语中的表现，特别关注形态丰富和语义紧凑的语言特征对表面重叠评估指标的影响。

Result: 研究发现现有评估指标对形态丰富语言具有特定的敏感性挑战。表面重叠指标在处理这些语言的形态复杂性和语义紧凑特征时存在局限性，突显了需要更精细评估方法的必要性。

Conclusion: 研究强调了在印度这样语言多样的国家，开发适合形态丰富语言的机器翻译评估框架的重要性。技术教育内容的翻译需要特别考虑语域保留和词汇选择，现有评估指标需要改进以适应这些语言的特征。

Abstract: This study examines the practical applications and methodological implications of Machine Translation in Indian Languages, specifically Bangla, Malayalam, and Telugu, within emerging translation workflows and in relation to existing evaluation frameworks. The choice of languages prioritized in this study is motivated by a triangulation of linguistic diversity, which illustrates the significance of multilingual accommodation of educational technology under NEP 2020. This is further supported by the largest MOOC portal, i.e., NPTEL, which has served as a corpus to facilitate the arguments presented in this paper. The curation of a spontaneous speech corpora that accounts for lucid delivery of technical concepts, considering the retention of suitable register and lexical choices are crucial in a diverse country like India. The findings of this study highlight metric-specific sensitivity and the challenges of morphologically rich and semantically compact features when tested against surface overlapping metrics.

</details>


### [285] [Do Images Clarify? A Study on the Effect of Images on Clarifying Questions in Conversational Search](https://arxiv.org/abs/2602.08700)
*Clemencia Siro,Zahra Abbasiantaeb,Yifei Yuan,Mohammad Aliannejadi,Maarten de Rijke*

Main category: cs.CL

TL;DR: 研究探讨了在对话式搜索中，将图像融入澄清问题对用户性能的影响，发现视觉增强的效果取决于任务类型和用户专业水平。


<details>
  <summary>Details</summary>
Motivation: 虽然文本澄清问题已被证明能提升检索性能，但图像在澄清问题中对用户性能的影响尚未充分探索。本研究旨在填补这一空白，研究多模态澄清问题在对话式搜索中的作用。

Method: 对73名参与者进行用户研究，比较多模态（文本+图像）和纯文本澄清问题在两种搜索相关任务中的效果：(i)回答澄清问题，(ii)查询重构。从多个角度分析图像的影响。

Result: 在回答澄清问题时，参与者强烈偏好多模态问题，但纯文本设置下用户表现更好；在查询重构任务中，偏好更平衡，图像能带来更精确的查询和更好的检索性能。图像效果随任务类型和用户专业水平而变化。

Conclusion: 视觉增强在对话式搜索中的益处是任务依赖性的，应根据具体搜索上下文和用户特征进行战略性实施。多模态澄清问题的设计需要考虑任务类型和用户专业水平。

Abstract: Conversational search systems increasingly employ clarifying questions to refine user queries and improve the search experience. Previous studies have demonstrated the usefulness of text-based clarifying questions in enhancing both retrieval performance and user experience. While images have been shown to improve retrieval performance in various contexts, their impact on user performance when incorporated into clarifying questions remains largely unexplored. We conduct a user study with 73 participants to investigate the role of images in conversational search, specifically examining their effects on two search-related tasks: (i) answering clarifying questions and (ii) query reformulation. We compare the effect of multimodal and text-only clarifying questions in both tasks within a conversational search context from various perspectives. Our findings reveal that while participants showed a strong preference for multimodal questions when answering clarifying questions, preferences were more balanced in the query reformulation task. The impact of images varied with both task type and user expertise. In answering clarifying questions, images helped maintain engagement across different expertise levels, while in query reformulation they led to more precise queries and improved retrieval performance. Interestingly, for clarifying question answering, text-only setups demonstrated better user performance as they provided more comprehensive textual information in the absence of images. These results provide valuable insights for designing effective multimodal conversational search systems, highlighting that the benefits of visual augmentation are task-dependent and should be strategically implemented based on the specific search context and user characteristics.

</details>


### [286] [FactSim: Fact-Checking for Opinion Summarization](https://arxiv.org/abs/2602.08709)
*Leandro Anghinoni,Jorge Sanchez*

Main category: cs.CL

TL;DR: 提出一种用于评估生成式AI在意见摘要任务中事实一致性的全自动方法，通过比较摘要中的主张与原始评论的相似性来衡量覆盖率和一致性


<details>
  <summary>Details</summary>
Motivation: 传统基于自动指标评估生成式AI在意见摘要任务的方法存在局限性，特别是大语言模型带来的范式转变需要更全面精确的评估技术

Method: 基于从文本中提取事实评估的简单方法，测量摘要中的主张与原始评论的相似性，计算覆盖率和一致性，生成合适的评分

Result: 提出的指标能为相似主张分配更高分数（无论是否定、转述或扩展），且与人类判断的相关性优于现有最先进指标

Conclusion: 该方法为评估生成式AI在意见摘要中的事实一致性提供了更有效的全自动评估方案

Abstract: We explore the need for more comprehensive and precise evaluation techniques for generative artificial intelligence (GenAI) in text summarization tasks, specifically in the area of opinion summarization. Traditional methods, which leverage automated metrics to compare machine-generated summaries from a collection of opinion pieces, e.g. product reviews, have shown limitations due to the paradigm shift introduced by large language models (LLM). This paper addresses these shortcomings by proposing a novel, fully automated methodology for assessing the factual consistency of such summaries. The method is based on measuring the similarity between the claims in a given summary with those from the original reviews, measuring the coverage and consistency of the generated summary. To do so, we rely on a simple approach to extract factual assessment from texts that we then compare and summarize in a suitable score. We demonstrate that the proposed metric attributes higher scores to similar claims, regardless of whether the claim is negated, paraphrased, or expanded, and that the score has a high correlation to human judgment when compared to state-of-the-art metrics.

</details>


### [287] [PERSPECTRA: A Scalable and Configurable Pluralist Benchmark of Perspectives from Arguments](https://arxiv.org/abs/2602.08716)
*Shangrui Nie,Kian Omoomi,Lucie Flek,Zhixue Zhao,Charles Welch*

Main category: cs.CL

TL;DR: PERSPECTRA是一个用于评估大语言模型多元主义能力的基准，结合了Kialo的辩论图结构和Reddit的语言多样性，包含3,810个扩展论点，覆盖100个争议话题。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型研究缺乏对多元主义（能够处理不同观点而不将其简化为单一视角）的系统评估。现有辩论数据源各有局限：Reddit有语言多样性但缺乏结构，Kialo有结构但过于简洁。需要结合两者优势来评估模型的多元理解能力。

Method: 通过受控的检索-扩展流程，将Kialo的辩论图结构（清晰的赞成/反对立场）与Reddit的真实讨论（语言多样性）结合。构建了3,810个扩展论点，覆盖762个赞成/反对立场和100个争议话题，每个观点扩展到多个自然变体。

Result: 实验表明，最先进的开源和专有LLM在多元主义任务上存在系统性失败：高估观点数量、误分类让步结构等。这突显了模型在多元主义理解和推理方面的困难。

Conclusion: PERSPECTRA通过结合多样性和结构，建立了第一个可扩展、可配置的基准，用于评估模型如何表示、区分和推理多个观点，填补了多元主义评估的空白。

Abstract: Pluralism, the capacity to engage with diverse perspectives without collapsing them into a single viewpoint, is critical for developing large language models that faithfully reflect human heterogeneity. Yet this characteristic has not been carefully examined in the LLM research community and remains absent from most alignment studies. Debate-oriented sources provide a natural entry point for pluralism research. Previous work builds on online debate sources but remains constrained by costly human validation. Other debate-rich platforms such as Reddit and Kialo also offer promising material: Reddit provides linguistic diversity and scale but lacks clear argumentative structure, while Kialo supplies explicit pro/con graphs but remains overly concise and detached from natural discourse. We introduce PERSPECTRA, a pluralist benchmark that integrates the structural clarity of Kialo debate graphs with the linguistic diversity of real Reddit discussions. Using a controlled retrieval-and-expansion pipeline, we construct 3,810 enriched arguments spanning 762 pro/con stances on 100 controversial topics. Each opinion is expanded to multiple naturalistic variants, enabling robust evaluation of pluralism. We initialise three tasks with PERSPECTRA: opinion counting (identifying distinct viewpoints), opinion matching (aligning supporting stances and discourse to source opinions), and polarity check (inferring aggregate stance in mixed discourse). Experiments with state-of-the-art open-source and proprietary LLMs, highlight systematic failures, such as overestimating the number of viewpoints and misclassifying concessive structures, underscoring the difficulty of pluralism-aware understanding and reasoning. By combining diversity with structure, PERSPECTRA establishes the first scalable, configurable benchmark for evaluating how well models represent, distinguish, and reason over multiple perspectives.

</details>


### [288] [Map of Encoders -- Mapping Sentence Encoders using Quantum Relative Entropy](https://arxiv.org/abs/2602.08740)
*Gaifan Zhang,Danushka Bollegala*

Main category: cs.CL

TL;DR: 提出大规模比较和可视化句子编码器的方法，通过创建编码器地图，将1101个公开句子编码器表示为相互关系的分布图。


<details>
  <summary>Details</summary>
Motivation: 需要系统性地比较和理解大量预训练句子编码器之间的关系和差异，为研究者提供编码器选择的参考框架。

Method: 首先用句子集的嵌入矩阵表示每个编码器，然后计算成对内积矩阵，最后基于量子相对熵构建每个编码器相对于单位基编码器的特征向量。

Result: 成功构建了包含1101个公开句子编码器的地图，准确反映了编码器间的各种关系，相似属性的编码器在地图上位置相近，特征向量能准确预测下游任务性能。

Conclusion: 该方法提供了预训练句子编码器景观的新视角，编码器地图忠实反映了编码器间的关系，特征向量可用于预测下游任务表现。

Abstract: We propose a method to compare and visualise sentence encoders at scale by creating a map of encoders where each sentence encoder is represented in relation to the other sentence encoders. Specifically, we first represent a sentence encoder using an embedding matrix of a sentence set, where each row corresponds to the embedding of a sentence. Next, we compute the Pairwise Inner Product (PIP) matrix for a sentence encoder using its embedding matrix. Finally, we create a feature vector for each sentence encoder reflecting its Quantum Relative Entropy (QRE) with respect to a unit base encoder. We construct a map of encoders covering 1101 publicly available sentence encoders, providing a new perspective of the landscape of the pre-trained sentence encoders. Our map accurately reflects various relationships between encoders, where encoders with similar attributes are proximally located on the map. Moreover, our encoder feature vectors can be used to accurately infer downstream task performance of the encoders, such as in retrieval and clustering tasks, demonstrating the faithfulness of our map.

</details>


### [289] [LakeHopper: Cross Data Lakes Column Type Annotation through Model Adaptation](https://arxiv.org/abs/2602.08793)
*Yushi Sun,Xujia Li,Nan Tang,Quanqing Xu,Chuanhui Yang,Lei Chen*

Main category: cs.CL

TL;DR: LakeHopper：一个通过识别知识差距、集群数据选择和增量微调来将预训练LM模型适应新数据湖的框架，减少新数据湖的标注需求


<details>
  <summary>Details</summary>
Motivation: 现有基于语言模型的列类型标注方法需要大量标注数据，且通常针对特定数据湖训练。当需要适应新数据湖时，需要大量新标注，成本高昂。研究如何最小化新数据湖的标注需求，同时解决源-目标知识差距、信息数据选择和知识保留等挑战。

Method: 提出LakeHopper框架：1）通过LM交互识别和解决源-目标知识差距；2）采用基于聚类的数据选择方案从未标注列中选择信息量大的数据；3）使用增量微调机制逐步将源模型适应到目标数据湖，避免丢失共享知识。

Result: 在两个不同数据湖迁移任务上的实验结果表明，LakeHopper在低资源和高资源设置下都有效，能够显著减少新数据湖的标注需求。

Conclusion: LakeHopper框架成功解决了将预训练LM模型适应新数据湖的挑战，通过知识差距识别、智能数据选择和增量微调，实现了在新数据湖上最小化标注需求的目标。

Abstract: Column type annotation is vital for tasks like data cleaning, integration, and visualization. Recent solutions rely on resource-intensive language models fine-tuned on well-annotated columns from a particular set of tables, i.e., a source data lake. In this paper, we study whether we can adapt an existing pre-trained LM-based model to a new (i.e., target) data lake to minimize the annotations required on the new data lake. However, challenges include the source-target knowledge gap, selecting informative target data, and fine-tuning without losing shared knowledge exist. We propose LakeHopper, a framework that identifies and resolves the knowledge gap through LM interactions, employs a cluster-based data selection scheme for unannotated columns, and uses an incremental fine-tuning mechanism that gradually adapts the source model to the target data lake. Our experimental results validate the effectiveness of LakeHopper on two different data lake transfers under both low-resource and high-resource settings.

</details>


### [290] [Affective Flow Language Model for Emotional Support Conversation](https://arxiv.org/abs/2602.08826)
*Chenghui Zou,Ning Wang,Tiesunlong Shen,Luwei Xiao,Chuan Ma,Xiangpeng Li,Rui Mao,Erik Cambria*

Main category: cs.CL

TL;DR: AFlow通过建模情感流为多轮情感支持对话提供细粒度监督，在中间策略决策上优于现有方法，甚至超越GPT-4o等专有模型。


<details>
  <summary>Details</summary>
Motivation: 现有情感支持对话系统依赖稀疏的结果级信号，对中间策略决策的监督有限，导致复杂多轮支持效果不佳。

Method: 提出AFlow框架，通过建模连续情感流为对话前缀提供细粒度监督，估计搜索轨迹的中间效用，学习偏好一致的策略转换，并引入子路径级流平衡目标提升策略连贯性和共情响应质量。

Result: 在多样化情感场景中显著优于现有基线，使用紧凑开源骨干的AFlow在主要ESC指标上超越了GPT-4o和Claude-3.5等专有大语言模型。

Conclusion: 通过建模情感流为多轮情感支持对话提供细粒度监督是有效的，AFlow框架在策略连贯性和响应质量上表现出色，为情感支持对话系统提供了新思路。

Abstract: Large language models (LLMs) have been widely applied to emotional support conversation (ESC). However, complex multi-turn support remains challenging.This is because existing alignment schemes rely on sparse outcome-level signals, thus offering limited supervision for intermediate strategy decisions. To fill this gap, this paper proposes affective flow language model for emotional support conversation (AFlow), a framework that introduces fine-grained supervision on dialogue prefixes by modeling a continuous affective flow along multi-turn trajectories. AFlow can estimate intermediate utility over searched trajectories and learn preference-consistent strategy transitions. To improve strategy coherence and empathetic response quality, a subpath-level flow-balance objective is presented to propagate preference signals to intermediate states. Experiment results show consistent and significant improvements over competitive baselines in diverse emotional contexts. Remarkably, AFlow with a compact open-source backbone outperforms proprietary LMMs such as GPT-4o and Claude-3.5 on major ESC metrics. Our code is available at https://github.com/chzou25-lgtm/AffectiveFlow.

</details>


### [291] [WildReward: Learning Reward Models from In-the-Wild Human Interactions](https://arxiv.org/abs/2602.08829)
*Hao Peng,Yunjia Qi,Xiaozhi Wang,Zijun Yao,Lei Hou,Juanzi Li*

Main category: cs.CL

TL;DR: WildReward：直接从用户交互中训练奖励模型，无需人工标注偏好对，性能媲美传统奖励模型


<details>
  <summary>Details</summary>
Motivation: 传统奖励模型依赖大规模人工标注的偏好对，成本高且难以扩展。随着LLM的广泛部署，用户交互成为丰富的隐式奖励信号来源，能否直接从这些交互中开发奖励模型？

Method: 采用WildChat作为交互数据源，提出从用户反馈中提取可靠人类反馈的流程，获得186k高质量实例，通过序数回归直接在用户反馈上训练WildReward，无需偏好对

Result: WildReward在性能上达到甚至超越传统奖励模型，具有更好的校准性和跨样本一致性。用户多样性直接提升模型性能，用户越多奖励模型越强。应用于在线DPO训练在各种任务上都有显著提升

Conclusion: 直接从用户交互中训练奖励模型是可行的，WildReward展示了这种方法的有效性，为奖励模型训练提供了更可扩展的替代方案

Abstract: Reward models (RMs) are crucial for the training of large language models (LLMs), yet they typically rely on large-scale human-annotated preference pairs. With the widespread deployment of LLMs, in-the-wild interactions have emerged as a rich source of implicit reward signals. This raises the question: Can we develop reward models directly from in-the-wild interactions? In this work, we explore this possibility by adopting WildChat as an interaction source and proposing a pipeline to extract reliable human feedback, yielding 186k high-quality instances for training WildReward via ordinal regression directly on user feedback without preference pairs. Extensive experiments demonstrate that WildReward achieves comparable or even superior performance compared to conventional reward models, with improved calibration and cross-sample consistency. We also observe that WildReward benefits directly from user diversity, where more users yield stronger reward models. Finally, we apply WildReward to online DPO training and observe significant improvements across various tasks. Code and data are released at https://github.com/THU-KEG/WildReward.

</details>


### [292] [Understanding Dynamic Compute Allocation in Recurrent Transformers](https://arxiv.org/abs/2602.08864)
*Ibraheem Muhammad Moosa,Suhas Lohit,Ye Wang,Moitreya Chatterjee,Wenpeng Yin*

Main category: cs.CL

TL;DR: 本文提出ANIRA框架，通过算法和合成语言任务系统评估token级自适应计算，发现计算分配能与任务复杂度对齐但缺乏算法泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有token级自适应计算研究主要在自然语言基准上评估，token级难度不可观测且与架构因素混淆，无法确定计算分配是否真正与底层复杂度对齐。

Method: 提出复杂度控制的评估范式（算法和合成语言任务），设计ANIRA统一循环Transformer框架支持token级可变深度计算，隔离计算分配决策与其他模型因素。

Result: 计算分配能与任务复杂度对齐（无需显式难度监督），但缺乏算法泛化能力（无法外推到未见输入大小）；早期计算决策依赖静态结构线索，在线停止更接近算法执行状态。

Conclusion: 需要更系统的方法评估自适应计算，计算分配对齐复杂度不一定带来算法泛化，决策时机影响计算分配质量。

Abstract: Token-level adaptive computation seeks to reduce inference cost by allocating more computation to harder tokens and less to easier ones. However, prior work is primarily evaluated on natural-language benchmarks using task-level metrics, where token-level difficulty is unobservable and confounded with architectural factors, making it unclear whether compute allocation truly aligns with underlying complexity. We address this gap through three contributions. First, we introduce a complexity-controlled evaluation paradigm using algorithmic and synthetic language tasks with parameterized difficulty, enabling direct testing of token-level compute allocation. Second, we propose ANIRA, a unified recurrent Transformer framework that supports per-token variable-depth computation while isolating compute allocation decisions from other model factors. Third, we use this framework to conduct a systematic analysis of token-level adaptive computation across alignment with complexity, generalization, and decision timing. Our results show that compute allocation aligned with task complexity can emerge without explicit difficulty supervision, but such alignment does not imply algorithmic generalization: models fail to extrapolate to unseen input sizes despite allocating additional computation. We further find that early compute decisions rely on static structural cues, whereas online halting more closely tracks algorithmic execution state.

</details>


### [293] [Large Language Models for Geolocation Extraction in Humanitarian Crisis Response](https://arxiv.org/abs/2602.08872)
*G. Cafferata,T. Demarco,K. Kalimeri,Y. Mejova,M. G. Beiró*

Main category: cs.CL

TL;DR: LLM-based方法显著提升人道主义文本中地理位置提取的准确性和公平性，特别是对于代表性不足的地区。


<details>
  <summary>Details</summary>
Motivation: 人道主义危机需要及时准确的地理信息，但现有自动化系统在提取位置信息时存在地理和社会经济偏见，导致危机受影响地区的可见性不均。

Method: 提出两步框架：结合少样本LLM命名实体识别和基于代理的地理编码模块，利用上下文解决模糊地名问题。

Result: LLM-based方法在准确性和公平性指标上显著优于现有最先进的预训练和基于规则的系统，特别是在代表性不足的地区表现更好。

Conclusion: 通过将LLM推理能力与负责任、包容性AI原则相结合，这项工作为人道主义响应提供了更公平的地理空间数据系统，推进了危机分析中"不落下任何地方"的目标。

Abstract: Humanitarian crises demand timely and accurate geographic information to inform effective response efforts. Yet, automated systems that extract locations from text often reproduce existing geographic and socioeconomic biases, leading to uneven visibility of crisis-affected regions. This paper investigates whether Large Language Models (LLMs) can address these geographic disparities in extracting location information from humanitarian documents. We introduce a two-step framework that combines few-shot LLM-based named entity recognition with an agent-based geocoding module that leverages context to resolve ambiguous toponyms. We benchmark our approach against state-of-the-art pretrained and rule-based systems using both accuracy and fairness metrics across geographic and socioeconomic dimensions. Our evaluation uses an extended version of the HumSet dataset with refined literal toponym annotations. Results show that LLM-based methods substantially improve both the precision and fairness of geolocation extraction from humanitarian texts, particularly for underrepresented regions. By bridging advances in LLM reasoning with principles of responsible and inclusive AI, this work contributes to more equitable geospatial data systems for humanitarian response, advancing the goal of leaving no place behind in crisis analytics.

</details>


### [294] [Is Reasoning Capability Enough for Safety in Long-Context Language Models?](https://arxiv.org/abs/2602.08874)
*Yu Fu,Haz Sameen Shahgir,Huanli Gong,Zhipeng Wei,N. Benjamin Erichson,Yue Dong*

Main category: cs.CL

TL;DR: 研究发现更强的推理能力并不会自动提升LLM在长上下文中的安全性，反而可能通过组合推理攻击导致安全漏洞


<details>
  <summary>Details</summary>
Motivation: 测试一个假设：更强的推理能力是否应该通过帮助模型识别隐含的有害意图来提升安全性，特别是在长上下文环境中

Method: 引入组合推理攻击威胁模型，将有害查询分解为不完整片段散布在长上下文中，然后通过中性推理查询诱导模型检索和合成，使有害意图在组合后显现。评估14个前沿LLM在长达64k token的上下文中的表现

Result: 1) 推理能力更强的模型对组合推理攻击并不更鲁棒，常能组装意图但无法拒绝；2) 随着上下文长度增加，安全对齐效果持续下降；3) 推理时计算量是关键缓解因素，增加推理计算可将攻击成功率降低50个百分点以上

Conclusion: 安全性不会随推理能力自动扩展，特别是在长上下文推理场景下，需要专门的安全措施来应对组合推理攻击

Abstract: Large language models (LLMs) increasingly combine long-context processing with advanced reasoning, enabling them to retrieve and synthesize information distributed across tens of thousands of tokens. A hypothesis is that stronger reasoning capability should improve safety by helping models recognize harmful intent even when it is not stated explicitly. We test this hypothesis in long-context settings where harmful intent is implicit and must be inferred through reasoning, and find that it does not hold. We introduce compositional reasoning attacks, a new threat model in which a harmful query is decomposed into incomplete fragments that scattered throughout a long context. The model is then prompted with a neutral reasoning query that induces retrieval and synthesis, causing the harmful intent to emerge only after composition. Evaluating 14 frontier LLMs on contexts up to 64k tokens, we uncover three findings: (1) models with stronger general reasoning capability are not more robust to compositional reasoning attacks, often assembling the intent yet failing to refuse; (2) safety alignment consistently degrades as context length increases; and (3) inference-time reasoning effort is a key mitigating factor: increasing inference-time compute reduces attack success by over 50 percentage points on GPT-oss-120b model. Together, these results suggest that safety does not automatically scale with reasoning capability, especially under long-context inference.

</details>


### [295] [GitSearch: Enhancing Community Notes Generation with Gap-Informed Targeted Search](https://arxiv.org/abs/2602.08945)
*Sahajpreet Singh,Kokil Jaidka,Min-Yen Kan*

Main category: cs.CL

TL;DR: GitSearch框架利用人类感知的质量差距作为信号，通过三阶段流程解决社区审核中的冷启动问题，在政治推文基准测试中实现99%覆盖率和优于人类笔记的质量。


<details>
  <summary>Details</summary>
Motivation: 社区审核虽可扩展但面临结构性挑战，现有AI方法在冷启动场景下失效。需要解决信息缺口识别和针对性检索的问题。

Method: GitSearch框架包含三阶段：1)识别信息缺陷；2)实时针对性网络检索填补缺口；3)合成符合平台规范的笔记。同时创建了包含78,698条美国政治推文的PolBench基准。

Result: GitSearch实现99%覆盖率，几乎是现有最佳方法的两倍。相比人类撰写的笔记，GitSearch获得69%胜率和更高的帮助性评分(3.87 vs 3.36)，在规模与质量间取得平衡。

Conclusion: GitSearch通过将质量差距作为核心信号，有效解决了社区审核的冷启动问题，实现了高覆盖率和优于人类的质量表现。

Abstract: Community-based moderation offers a scalable alternative to centralized fact-checking, yet it faces significant structural challenges, and existing AI-based methods fail in "cold start" scenarios. To tackle these challenges, we introduce GitSearch (Gap-Informed Targeted Search), a framework that treats human-perceived quality gaps, such as missing context, etc., as first-class signals. GitSearch has a three-stage pipeline: identifying information deficits, executing real-time targeted web-retrieval to resolve them, and synthesizing platform-compliant notes. To facilitate evaluation, we present PolBench, a benchmark of 78,698 U.S. political tweets with their associated Community Notes. We find GitSearch achieves 99% coverage, almost doubling coverage over the state-of-the-art. GitSearch surpasses human-authored helpful notes with a 69% win rate and superior helpfulness scores (3.87 vs. 3.36), demonstrating retrieval effectiveness that balanced the trade-off between scale and quality.

</details>


### [296] [How Should We Model the Probability of a Language?](https://arxiv.org/abs/2602.08951)
*Rasul Dent,Pedro Ortiz Suarez,Thibault Clérice,Benoît Sagot*

Main category: cs.CL

TL;DR: 论文认为当前语言识别系统覆盖不足是自我限制的结果，需要将LID重新定义为路由问题，并纳入环境线索来提高尾部语言的覆盖率


<details>
  <summary>Details</summary>
Motivation: 当前商业语言识别系统仅能可靠识别几百种语言，研究级系统在某些情况下能扩展覆盖范围，但对大多数语言来说覆盖率仍然零散或不存在。作者认为这种情况主要是自我限制造成的

Method: 通过重新思考语言识别问题：1) 将LID重新定义为路由问题而非去上下文的文本分类；2) 开发原则性的方法来纳入环境线索，使语言在本地环境中具有合理性

Result: 论文提出了一个理论框架，指出当前LID系统的局限性源于制度激励偏向全球固定先验模型，而改进尾部语言覆盖率需要改变这种范式

Conclusion: 要提高尾部语言的覆盖率，必须摆脱将LID视为去上下文文本分类的框架，重新将其定义为路由问题，并系统性地整合环境线索来估计本地先验概率

Abstract: Of the over 7,000 languages spoken in the world, commercial language identification (LID) systems only reliably identify a few hundred in written form. Research-grade systems extend this coverage under certain circumstances, but for most languages coverage remains patchy or nonexistent. This position paper argues that this situation is largely self-imposed. In particular, it arises from a persistent framing of LID as decontextualized text classification, which obscures the central role of prior probability estimation and is reinforced by institutional incentives that favor global, fixed-prior models. We argue that improving coverage for tail languages requires rethinking LID as a routing problem and developing principled ways to incorporate environmental cues that make languages locally plausible.

</details>


### [297] [Next Concept Prediction in Discrete Latent Space Leads to Stronger Language Models](https://arxiv.org/abs/2602.08984)
*Yuliang Liu,Yunchong Song,Yixuan Wang,Kewen Ge,Alex Lamb,Qipeng Guo,Kai Chen,Bowen Zhou,Zhouhan Lin*

Main category: cs.CL

TL;DR: 提出Next Concept Prediction (NCP)预训练范式，通过预测跨多个token的离散概念来构建更难的预训练目标，相比传统token级模型获得一致性能提升


<details>
  <summary>Details</summary>
Motivation: 传统Next Token Prediction (NTP)在token级别进行预测，而NCP旨在预测更高层次的离散概念（跨多个token），形成更具挑战性的预训练目标，从而训练出更强大的语言模型

Method: 提出ConceptLM模型，使用Vector Quantization量化隐藏状态构建概念词汇表，同时利用NCP和NTP进行参数更新，生成概念来指导后续token生成。在70M到1.5B参数规模上从头训练，使用Pythia和GPT-2架构，训练数据达300B

Result: 在13个基准测试中，NCP相比传统token级模型获得一致性能提升。在8B参数的Llama模型上的持续预训练实验表明，NCP能进一步提升NTP训练过的模型

Conclusion: NCP通过引入更难的预训练任务，为语言建模提供了有前景的改进路径，能训练出更强大的语言模型

Abstract: We propose Next Concept Prediction (NCP), a generative pretraining paradigm built on top of Next Token Prediction (NTP). NCP predicts discrete concepts that span multiple tokens, thereby forming a more challenging pretraining objective. Our model, ConceptLM, quantizes hidden states using Vector Quantization and constructs a concept vocabulary. It leverages both NCP and NTP to drive parameter updates and generates a concept to guide the generation of the following tokens. We train ConceptLM from scratch at scales ranging from 70M to 1.5B parameters with up to 300B training data, including Pythia and GPT-2 backbones. Results on 13 benchmarks show that NCP yields consistent performance gains over traditional token-level models. Furthermore, continual pretraining experiments on an 8B-parameter Llama model indicate that NCP can further improve an NTP-trained model. Our analysis suggests that NCP leads to more powerful language models by introducing a harder pretraining task, providing a promising path toward better language modeling.

</details>


### [298] [When Actions Go Off-Task: Detecting and Correcting Misaligned Actions in Computer-Use Agents](https://arxiv.org/abs/2602.08995)
*Yuting Ning,Jaylen Jones,Zhehao Zhang,Chentao Ye,Weitong Ruan,Junyi Li,Rahul Gupta,Huan Sun*

Main category: cs.CL

TL;DR: 本文首次定义并研究了计算机使用代理中的未对齐动作检测，构建了包含真实轨迹的基准测试集MisActBench，并提出了DeAction检测框架，在对抗环境中显著降低攻击成功率。


<details>
  <summary>Details</summary>
Motivation: 计算机使用代理经常产生偏离用户原始意图的未对齐动作，这些动作可能来自外部攻击（如间接提示注入）或内部限制（如错误推理），不仅带来安全风险，还降低任务效率和可靠性。

Method: 提出了DeAction，一个实用且通用的防护机制，在执行前检测未对齐动作，并通过结构化反馈迭代修正。同时构建了MisActBench基准测试集，包含真实部署中的三种常见类别和人工标注的动作级对齐标签。

Result: DeAction在离线评估中F1分数比基线高出15%以上；在线评估中，在对抗环境下将攻击成功率降低90%以上，同时在良性环境中保持甚至提高任务成功率，仅带来适度的延迟开销。

Conclusion: 该研究首次系统性地定义了计算机使用代理中的未对齐动作检测问题，提出的DeAction框架在检测和修正未对齐动作方面表现出色，为提升CUA的安全性和可靠性提供了有效解决方案。

Abstract: Computer-use agents (CUAs) have made tremendous progress in the past year, yet they still frequently produce misaligned actions that deviate from the user's original intent. Such misaligned actions may arise from external attacks (e.g., indirect prompt injection) or from internal limitations (e.g., erroneous reasoning). They not only expose CUAs to safety risks, but also degrade task efficiency and reliability. This work makes the first effort to define and study misaligned action detection in CUAs, with comprehensive coverage of both externally induced and internally arising misaligned actions. We further identify three common categories in real-world CUA deployment and construct MisActBench, a benchmark of realistic trajectories with human-annotated, action-level alignment labels. Moreover, we propose DeAction, a practical and universal guardrail that detects misaligned actions before execution and iteratively corrects them through structured feedback. DeAction outperforms all existing baselines across offline and online evaluations with moderate latency overhead: (1) On MisActBench, it outperforms baselines by over 15% absolute in F1 score; (2) In online evaluation, it reduces attack success rate by over 90% under adversarial settings while preserving or even improving task success rate in benign environments.

</details>


### [299] [Does Visual Rendering Bypass Tokenization? Investigating Script-Tokenizer Misalignment in Pixel-Based Language Models](https://arxiv.org/abs/2602.06973)
*Lucky Susanto,Musa Izzanardi Wijanarko,Khumaisa Nur'aini,Farid Adilazuarda,Alham Fikri Aji,Derry Tanti Wijaya*

Main category: cs.CL

TL;DR: 像素语言建模旨在通过将文本渲染为图像来绕过子词分词瓶颈，但DualGPT等多模态变体重新引入文本分词器以提高自回归性能。研究发现，即使采用视觉渲染，重新整合文本分词器仍会重新引入分词器对齐问题，特别是在印尼低资源本地语言中。


<details>
  <summary>Details</summary>
Motivation: 研究像素语言建模是否真正能够摆脱分词器限制，特别是在非拉丁文字的低资源语言中。探讨视觉渲染是否真正使模型与分词器约束解耦，以及重新引入文本分词器是否会重新带来分词器对齐问题。

Method: 使用DualGPT架构，在四种印尼低资源本地语言（爪哇语、巴厘语、巽他语、楠榜语）上评估脚本-分词器对齐的影响。比较Llama 2分词器与自定义分词器的性能，分析OOV率和fertility率等指标。

Result: 尽管视觉渲染，重新整合文本分词器仍会重新引入分词器对齐问题。Llama 2分词器虽然具有较低的OOV和fertility率，但性能显著差于自定义分词器，改进幅度高达30.15 chrF++。

Conclusion: 文本分词器仍然是实现公平模型的重要障碍。即使采用像素语言建模和多模态方法，重新引入文本分词器仍会带来分词器对齐问题，这对未来多模态变体设计提出了警告。

Abstract: While pixel-based language modeling aims to bypass the sub-word tokenization bottleneck by rendering text as images, recent multimodal variants such as DualGPT reintroduce text tokenizers to improve autoregressive performance. We investigate a fundamental question, does visual rendering truly decouple a model from tokenization constraints? Focusing on four Indonesian low-resource local languages that have their own non-Latin scripts (i.e., Javanese, Balinese, Sundanese, and Lampungnese), we evaluate the impact of script-tokenizer alignment within the DualGPT architecture. Our results show that, despite visual rendering, reintegrating a text tokenizer into the architecture reintroduces the same issue that pixel-based language modeling aims to resolve, which is the tokenizer misalignment problem. Despite having lower OOV and fertility rates, we show that the Llama 2 tokenizer performs significantly worse than a custom tokenizer, with improvements of up to 30.15 chrF++. Our findings serve as a warning for future multimodal variants, as text tokenizers remain a significant barrier to equitable models.

</details>


### [300] [BiomechAgent: AI-Assisted Biomechanical Analysis Through Code-Generating Agents](https://arxiv.org/abs/2602.06975)
*R. James Cotton,Thomas Leonard*

Main category: cs.CL

TL;DR: BiomechAgent是一个代码生成AI代理，通过自然语言实现生物力学分析，无需用户编程，在数据检索、可视化、临床推理等方面表现良好。


<details>
  <summary>Details</summary>
Motivation: 虽然无标记运动捕捉技术使定量运动分析越来越普及，但分析结果数据对于没有编程经验的临床医生仍然是一个障碍。需要一种工具让临床医生能够通过自然语言进行生物力学分析，而无需编写代码。

Method: 开发了BiomechAgent代码生成AI代理，支持自然语言查询数据库、生成可视化、解释数据。通过系统基准测试评估其能力，包括数据检索、可视化、活动分类、时间分割和临床推理。测试了生物力学特定指令与通用提示的效果，并集成了经过验证的专门工具用于步态事件检测。

Result: BiomechAgent在数据检索和可视化任务上实现了稳健的准确性，并展示了新兴的临床推理能力。生物力学特定的领域指令显著优于通用提示，专门的步态事件检测工具大大提高了具有挑战性的时空分析准确性。使用本地开源模型而非前沿云LLM时，除数据库检索外的大多数领域性能大幅下降。

Conclusion: BiomechAgent使来自可访问运动捕捉的数据对最终用户更加有用和可访问，通过自然语言界面降低了生物力学分析的门槛。

Abstract: Markerless motion capture is making quantitative movement analysis increasingly accessible, yet analyzing the resulting data remains a barrier for clinicians without programming expertise. We present BiomechAgent, a code-generating AI agent that enables biomechanical analysis through natural language and allows users to querying databases, generating visualizations, and even interpret data without requiring users to write code. To evaluate BiomechAgent's capabilities, we developed a systematic benchmark spanning data retrieval, visualization, activity classification, temporal segmentation, and clinical reasoning. BiomechAgent achieved robust accuracy on data retrieval and visualization tasks and demonstrated emerging clinical reasoning capabilities. We used our dataset to systematically evaluate several of our design decisions. Biomechanically-informed, domain-specific instructions significantly improved performance over generic prompts, and integrating validated specialized tools for gait event detection substantially boosted accuracy on challenging spatiotemporal analysis where the base agent struggled. We also tested BiomechAgent using a local open-weight model instead of a frontier cloud based LLM and found that perform was substantially diminished in most domains other than database retrieval. In short, BiomechAgent makes the data from accessible motion capture and much more useful and accessible to end users.

</details>


### [301] [Bridging the Knowledge Void: Inference-time Acquisition of Unfamiliar Programming Languages for Coding Tasks](https://arxiv.org/abs/2602.06976)
*Chen Shen,Wei Cheng,Jingyue Yang,Huan Zhang,Yuhan Wu,Wei Hu*

Main category: cs.CL

TL;DR: ILA-agent框架让LLM通过推理时与官方文档和执行环境交互来学习新编程语言，无需大量微调数据，在Cangjie语言基准测试中显著优于检索增强基线。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在编码任务中的能力依赖于大量预训练数据，当遇到不熟悉的编程语言时性能会急剧下降。传统的数据密集型微调方法成本高，需要探索更高效的推理时学习方法。

Method: 提出ILA-agent框架，将人类学习行为建模为一套工具，让LLM通过结构化交互（探索、应用、验证）与官方文档和执行环境互动，增量式学习新语言知识。

Result: 在基于新型静态类型语言Cangjie构建的Cangjie-bench基准测试中，ILA-agent在代码生成、翻译和程序修复任务上显著优于检索增强基线方法。轨迹分析揭示了涌现的行为模式。

Conclusion: ILA-agent展示了推理时语言获取的可行性，通过结构化交互让LLM有效学习新编程语言，但仍存在性能差距，为未来研究提供了方向。

Abstract: The proficiency of Large Language Models (LLMs) in coding tasks is often a reflection of their extensive pre-training corpora, which typically collapses when confronted with previously unfamiliar programming languages. Departing from data-intensive finetuning, we investigate the paradigm of Inference-time Language Acquisition (ILA), where an LLM masters an unfamiliar language through dynamic interaction with limited external resources. In this paper, we propose ILA-agent, a general ILA framework that equips LLMs with a set of behavioral primitives. By modeling essential human-like behaviors as a suite of tools, ILA-agent enables LLMs to incrementally explore, apply, and verify language knowledge through structured interactions with the official documentation and execution environment. To provide a rigorous evaluation in a low-resource setting, we construct Cangjie-bench, a multi-task benchmark based on the novel statically-typed language Cangjie. We instantiate ILA-agent for Cangjie and evaluate its performance across code generation, translation, and program repair tasks. Results using diverse LLMs demonstrate that ILA-agent significantly outperforms retrieval-augmented baselines. Further analysis of agent trajectories characterizes the emergent behavior patterns while highlighting persisting performance gaps.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [302] [LLM-FSM: Scaling Large Language Models for Finite-State Reasoning in RTL Code Generation](https://arxiv.org/abs/2602.07032)
*Yuheng Wu,Berk Gokmen,Zhouhua Xie,Peijing Li,Caroline Trippel,Priyanka Raina,Thierry Tambe*

Main category: cs.AI

TL;DR: LLM-FSM是一个评估大语言模型从自然语言规范恢复有限状态机行为并生成正确RTL实现的基准测试，包含1000个自动生成的问题，实验显示模型性能随FSM复杂度增加而急剧下降。


<details>
  <summary>Details</summary>
Motivation: 有限状态推理是硬件设计的核心能力，但现有基准测试依赖手动构建示例。需要自动化的基准来评估LLMs从自然语言规范理解和实现FSM行为的能力。

Method: 通过全自动流程构建LLM-FSM：1) 配置状态数量和约束转换结构构建FSM；2) 提示LLMs将FSM表达为结构化YAML格式并添加应用上下文；3) 将YAML转换为自然语言规范；4) 从相同YAML以构造正确的方式合成参考RTL和测试平台；5) 使用LLM和SAT求解器验证所有1000个问题。

Result: 即使最强的LLMs在FSM复杂度增加时准确率也急剧下降。监督微调能有效泛化到分布外任务，增加测试时计算能提高推理可靠性。基准可扩展以适应未来模型能力。

Conclusion: LLM-FSM提供了一个自动化、可扩展的基准来评估LLMs的有限状态推理能力，揭示了模型在复杂FSM任务上的局限性，并展示了训练和测试时改进策略的有效性。

Abstract: Finite-state reasoning, the ability to understand and implement state-dependent behavior, is central to hardware design. In this paper, we present LLM-FSM, a benchmark that evaluates how well large language models (LLMs) can recover finite-state machine (FSM) behavior from natural-language specifications and translate it into correct register transfer-level (RTL) implementations. Unlike prior specification-to-RTL benchmarks that rely on manually constructed examples, LLM-FSM is built through a fully automated pipeline. LLM-FSM first constructs FSM with configurable state counts and constrained transition structures. It then prompts LLMs to express each FSM in a structured YAML format with an application context, and to further convert that YAML into a natural-language (NL) specification. From the same YAML, our pipeline synthesizes the reference RTL and testbench in a correct-by-construction manner. All 1,000 problems are verified using LLM-based and SAT-solver-based checks, with human review on a subset. Our experiments show that even the strongest LLMs exhibit sharply declining accuracy as FSM complexity increases. We further demonstrate that training-time scaling via supervised fine-tuning (SFT) generalizes effectively to out-of-distribution (OOD) tasks, while increasing test-time compute improves reasoning reliability. Finally, LLM-FSM remains extensible by allowing its FSM complexity to scale with future model capabilities.

</details>


### [303] [ST-Raptor: An Agentic System for Semi-Structured Table QA](https://arxiv.org/abs/2602.07034)
*Jinxiu Qu,Zirui Tang,Hongzhang Huang,Boyu Niu,Wei Zhou,Jiannan Wang,Yitong Song,Guoliang Li,Xuanhe Zhou,Fan Wu*

Main category: cs.AI

TL;DR: ST-Raptor：一个用于半结构化表格问答的智能体系统，通过视觉编辑、树形结构建模和智能体驱动查询解决，在准确性和可用性上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 半结构化表格问答需要精确提取单元格内容和位置，并恢复表格布局中隐含的逻辑结构、层次关系和语义关联。现有方法存在信息丢失、处理复杂布局困难等问题，人工解释又耗时耗力。

Method: ST-Raptor是一个智能体系统，提供交互式分析环境，结合视觉编辑、基于树的结构建模和智能体驱动的查询解决，支持准确且用户友好的表格理解。

Result: 在基准测试和真实世界数据集上的实验结果表明，ST-Raptor在准确性和可用性上都优于现有方法。

Conclusion: ST-Raptor通过创新的交互式智能体方法，有效解决了半结构化表格问答中的挑战，提供了更准确和用户友好的解决方案。

Abstract: Semi-structured table question answering (QA) is a challenging task that requires (1) precise extraction of cell contents and positions and (2) accurate recovery of key implicit logical structures, hierarchical relationships, and semantic associations encoded in table layouts. In practice, such tables are often interpreted manually by human experts, which is labor-intensive and time-consuming. However, automating this process remains difficult. Existing Text-to-SQL methods typically require converting semi-structured tables into structured formats, inevitably leading to information loss, while approaches like Text-to-Code and multimodal LLM-based QA struggle with complex layouts and often yield inaccurate answers. To address these limitations, we present ST-Raptor, an agentic system for semi-structured table QA. ST-Raptor offers an interactive analysis environment that combines visual editing, tree-based structural modeling, and agent-driven query resolution to support accurate and user-friendly table understanding. Experimental results on both benchmark and real-world datasets demonstrate that ST-Raptor outperforms existing methods in both accuracy and usability. The code is available at https://github.com/weAIDB/ST-Raptor, and a demonstration video is available at https://youtu.be/9GDR-94Cau4.

</details>


### [304] [DLLM-Searcher: Adapting Diffusion Large Language Model for Search Agents](https://arxiv.org/abs/2602.07035)
*Jiahao Zhao,Shaoxuan Xu,Zhongxiang Sun,Fengqi Zhu,Jingyang Ou,Yuling Shi,Chongxuan Li,Xiao Zhang,Jun Xu*

Main category: cs.AI

TL;DR: DLLM-Searcher是一个基于扩散大语言模型的搜索代理优化框架，通过两阶段后训练提升代理能力，并提出并行推理与执行范式P-ReAct来降低延迟。


<details>
  <summary>Details</summary>
Motivation: 现有搜索代理面临两大挑战：1) 延迟挑战：ReAct代理范式中的串行多轮推理、工具调用和等待导致严重的端到端延迟；2) 代理能力挑战：现有扩散大语言模型在推理和工具调用能力上表现较弱，无法充分发挥其并行解码优势。

Method: 提出DLLM-Searcher框架：1) 两阶段后训练管道：包括代理监督微调(Agentic SFT)和代理方差减少偏好优化(Agentic VRPO)，增强骨干dLLM的信息检索和推理能力；2) 并行推理与执行范式P-ReAct：利用dLLM的灵活生成机制，优先解码工具调用指令，实现边等待工具返回边思考。

Result: 实验结果表明，DLLM-Searcher在性能上与主流基于LLM的搜索代理相当，而P-ReAct范式实现了约15%的推理加速。

Conclusion: DLLM-Searcher成功解决了扩散大语言模型在搜索代理应用中的能力不足和延迟问题，通过创新的训练方法和代理范式，实现了高效且性能相当的搜索代理系统。

Abstract: Recently, Diffusion Large Language Models (dLLMs) have demonstrated unique efficiency advantages, enabled by their inherently parallel decoding mechanism and flexible generation paradigm. Meanwhile, despite the rapid advancement of Search Agents, their practical deployment is constrained by a fundamental limitation, termed as 1) Latency Challenge: the serial execution of multi-round reasoning, tool calling, and tool response waiting under the ReAct agent paradigm induces severe end-to-end latency. Intuitively, dLLMs can leverage their distinctive strengths to optimize the operational efficiency of agents under the ReAct agent paradigm. Practically, existing dLLM backbones face the 2) Agent Ability Challenge. That is, existing dLLMs exhibit remarkably weak reasoning and tool-calling capabilities, preventing these advantages from being effectively realized in practice. In this paper, we propose DLLM-Searcher, an optimization framework for dLLM-based Search Agents. To solve the Agent Ability Challenge, we design a two-stage post-training pipeline encompassing Agentic Supervised Fine-Tuning (Agentic SFT) and Agentic Variance-Reduced Preference Optimization Agentic VRPO, which enhances the backbone dLLM's information seeking and reasoning capabilities. To mitigate the Latency Challenge, we leverage the flexible generation mechanism of dLLMs and propose a novel agent paradigm termed Parallel-Reasoning and Acting P-ReAct. P-ReAct guides the model to prioritize decoding tool_call instructions, thereby allowing the model to keep thinking while waiting for the tool's return. Experimental results demonstrate that DLLM-Searcher achieves performance comparable to mainstream LLM-based search agents and P-ReAct delivers approximately 15% inference acceleration. Our code is available at https://anonymous.4open.science/r/DLLM-Searcher-553C

</details>


### [305] [Aster: Autonomous Scientific Discovery over 20x Faster Than Existing Methods](https://arxiv.org/abs/2602.07040)
*Emmett Bicker*

Main category: cs.AI

TL;DR: Aster是一个用于自主科学发现的AI代理，比现有框架快20倍以上，通过迭代改进程序实现SOTA性能，适用于评估时间长的任务。


<details>
  <summary>Details</summary>
Motivation: 现有科学发现框架速度慢，限制了在需要长时间评估（如多小时的机器学习训练）的任务中的应用。需要更高效的自主发现系统来扩展可处理问题的领域。

Method: 给定任务、初始程序和评估脚本，Aster通过迭代改进程序来优化性能。系统显著减少了新发现所需的迭代次数，使其能够处理评估时间长的任务。

Result: 在数学、GPU内核工程、生物学、神经科学和语言模型训练等多个领域应用，包括Erdos最小重叠问题、TriMul内核优化、单细胞分析去噪、神经活动预测模型训练和NanoGPT速度竞赛。除ZAPBench外，在所有任务中都达到了SOTA结果；在ZAPBench上以不到1/190的计算量匹配了最佳人类解决方案的性能。

Conclusion: Aster是一个高效的自主科学发现AI代理，比现有框架快20倍以上，能够处理评估时间长的复杂任务，在多个领域取得了SOTA或接近SOTA的结果，并通过Web界面和API提供访问。

Abstract: We introduce Aster, an AI agent for autonomous scientific discovery capable of operating over 20 times faster than existing frameworks. Given a task, an initial program, and a script to evaluate the performance of the program, Aster iteratively improves the program, often leading to new state-of-the-art performances. Aster's significant reduction in the number of iterations required for novel discovery expands the domain of tractable problems to include tasks with long evaluation durations, such as multi-hour machine learning training runs.
  We applied Aster to problems in mathematics, GPU kernel engineering, biology, neuroscience, and language model training. More specifically: the Erdos minimum overlap problem, optimizing the TriMul kernel, a single-cell analysis denoising problem, training a neural activity prediction model to perform well on ZAPBench, and the NanoGPT Speedrun Competition. Aster attains SOTA results in every task, except for ZAPBench, where it matches the performance of the best human solution with less than 1/190th of the compute.
  Aster is accessible via a web interface and API at asterlab.ai.

</details>


### [306] [Theory of Space: Can Foundation Models Construct Spatial Beliefs through Active Exploration?](https://arxiv.org/abs/2602.07055)
*Pingyue Zhang,Zihan Huang,Yue Wang,Jieyu Zhang,Letian Xue,Zihan Wang,Qineng Wang,Keshigeyan Chandrasegaran,Ruohan Zhang,Yejin Choi,Ranjay Krishna,Jiajun Wu,Li Fei-Fei,Manling Li*

Main category: cs.AI

TL;DR: 论文提出"空间理论"概念，评估多模态基础模型在主动探索和构建空间信念方面的能力，发现当前模型存在主动-被动差距、探索效率低、信念不稳定和信念惯性等问题。


<details>
  <summary>Details</summary>
Motivation: 虽然多模态基础模型在被动感知方面表现出色，但它们在主动、自我导向的探索能力方面研究不足。空间具身智能需要智能体在部分可观测环境下通过行动获取信息，因此需要研究模型如何主动构建、修正和利用空间信念。

Method: 提出"空间理论"概念，定义为智能体通过自我导向的主动探索获取信息，并从序列化的部分观察中构建、修正和利用空间信念的能力。通过好奇心驱动的探索基准进行评估，关键创新是空间信念探测技术，在每个步骤提示模型揭示其内部空间表征。

Result: 评估最先进模型发现几个关键瓶颈：1) 主动-被动差距：智能体必须自主收集信息时性能显著下降；2) 高无效性：与基于程序的代理相比，模型探索缺乏系统性；3) 信念不稳定：全局信念不稳定导致空间知识随时间退化；4) 信念惯性：智能体无法用新证据更新过时的先验，视觉模型尤其严重。

Conclusion: 当前基础模型在主动探索过程中难以维持连贯、可修正的空间信念。研究发现模型在主动信息获取、探索效率和信念更新方面存在系统性缺陷，需要进一步研究来提升模型的空间推理和主动探索能力。

Abstract: Spatial embodied intelligence requires agents to act to acquire information under partial observability. While multimodal foundation models excel at passive perception, their capacity for active, self-directed exploration remains understudied. We propose Theory of Space, defined as an agent's ability to actively acquire information through self-directed, active exploration and to construct, revise, and exploit a spatial belief from sequential, partial observations. We evaluate this through a benchmark where the goal is curiosity-driven exploration to build an accurate cognitive map. A key innovation is spatial belief probing, which prompts models to reveal their internal spatial representations at each step. Our evaluation of state-of-the-art models reveals several critical bottlenecks. First, we identify an Active-Passive Gap, where performance drops significantly when agents must autonomously gather information. Second, we find high inefficiency, as models explore unsystematically compared to program-based proxies. Through belief probing, we diagnose that while perception is an initial bottleneck, global beliefs suffer from instability that causes spatial knowledge to degrade over time. Finally, using a false belief paradigm, we uncover Belief Inertia, where agents fail to update obsolete priors with new evidence. This issue is present in text-based agents but is particularly severe in vision-based models. Our findings suggest that current foundation models struggle to maintain coherent, revisable spatial beliefs during active exploration.

</details>


### [307] [ANCHOR: Branch-Point Data Generation for GUI Agents](https://arxiv.org/abs/2602.07153)
*Jinbiao Wei,Yilun Zhao,Kangqi Ni,Arman Cohan*

Main category: cs.AI

TL;DR: Anchor框架通过少量种子演示自动扩展桌面GUI交互轨迹，利用状态分支点生成新任务变体，并通过验证器确保任务完成质量，显著提升桌面代理性能。


<details>
  <summary>Details</summary>
Motivation: 端到端GUI代理需要大量高质量交互数据，但人工收集成本高，现有合成方法存在任务多样性有限或轨迹噪声大、目标漂移的问题。

Method: 从少量已验证种子演示出发，识别状态变化的分支点，基于当前GUI上下文提出状态接地的新任务变体。执行代理生成新轨迹，验证器通过状态感知检查和轨迹一致性确保任务完成。采用任务条件化的步骤级过滤去除非接地动作，并对分支后段去噪以保持意图连贯性。

Result: 在OSWorld和WindowsAgentArena标准桌面基准测试中，使用扩展语料库微调的模型相比零样本代理和代表性合成基线获得一致改进，并能跨应用程序和操作系统泛化。

Conclusion: Anchor框架能够从少量种子演示中引导出可扩展的桌面监督数据，有效解决了GUI代理训练数据稀缺和质量问题，为桌面自动化提供了高质量的数据合成方案。

Abstract: End-to-end GUI agents for real desktop environments require large amounts of high-quality interaction data, yet collecting human demonstrations is expensive and existing synthetic pipelines often suffer from limited task diversity or noisy, goal-drifting trajectories. We present a trajectory expansion framework Anchor that bootstraps scalable desktop supervision from a small set of verified seed demonstrations. Starting from each seed, we identify branch points that correspond to meaningful state changes and propose new, state-grounded task variants conditioned on the current GUI context. An executing agent then follows the proposed instructions to generate new trajectories, while a verifier enforces task completion via state-aware checks and trajectory-level consistency. To improve supervision quality, we further apply task-conditioned step-level filtering to remove ungrounded actions and denoise post-branch segments to maintain coherent intent. Experiments on standard desktop benchmarks, OSWorld and WindowsAgentArena, show that models fine-tuned on our expanded corpus achieve consistent improvements over zero-shot agents and representative synthesis baselines, and generalize across applications and operating systems.

</details>


### [308] [PreFlect: From Retrospective to Prospective Reflection in Large Language Model Agents](https://arxiv.org/abs/2602.07187)
*Hanyu Wang,Yuanpu Cao,Lu Lin,Jinghui Chen*

Main category: cs.AI

TL;DR: PreFlect提出前瞻性反思机制，在计划执行前进行批评和优化，而不是传统的后验性错误修正，显著提升了智能体在复杂任务中的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型智能体通常采用后验性自我反思机制，即在执行失败后才尝试修正错误。这种反应式方法存在局限性，无法在执行前预防潜在问题。

Method: 1. 前瞻性反思机制：在执行前对计划进行批评和优化；2. 从历史轨迹中提取规划错误模式；3. 动态重规划机制：在执行过程中遇到意外偏差时实时更新计划。

Result: 在不同基准测试中，PreFlect显著提升了智能体在复杂现实任务中的整体效用，优于现有的反思基线和更复杂的智能体架构。

Conclusion: 从后验性反思转向前瞻性反思是提升智能体性能的有效范式转变，结合历史错误模式学习和动态重规划机制，能够更好地处理复杂任务。

Abstract: Advanced large language model agents typically adopt self-reflection for improving performance, where agents iteratively analyze past actions to correct errors. However, existing reflective approaches are inherently retrospective: agents act, observe failure, and only then attempt to recover. In this work, we introduce PreFlect, a prospective reflection mechanism that shifts the paradigm from post hoc correction to pre-execution foresight by criticizing and refining agent plans before execution. To support grounded prospective reflection, we distill planning errors from historical agent trajectories, capturing recurring success and failure patterns observed across past executions. Furthermore, we complement prospective reflection with a dynamic re-planning mechanism that provides execution-time plan update in case the original plan encounters unexpected deviation. Evaluations on different benchmarks demonstrate that PreFlect significantly improves overall agent utility on complex real-world tasks, outperforming strong reflection-based baselines and several more complex agent architectures. Code will be updated at https://github.com/wwwhy725/PreFlect.

</details>


### [309] [Is there "Secret Sauce'' in Large Language Model Development?](https://arxiv.org/abs/2602.07238)
*Matthias Mertens,Natalia Fischl-Lanzoni,Neil Thompson*

Main category: cs.AI

TL;DR: LLM性能主要由计算规模驱动而非专有技术，但非前沿模型存在开发者效率优势


<details>
  <summary>Details</summary>
Motivation: 探究LLM性能差异的主要驱动因素：是开发者的专有技术（"秘方"）还是计算规模扩展

Method: 使用2022-2025年发布的809个模型的训练和基准数据，通过包含发布日期和开发者固定效应的缩放定律回归分析

Result: 前沿模型80-90%的性能差异由训练计算量解释；非前沿模型中，专有技术和共享算法进步显著降低达到固定能力阈值所需计算量；公司内部模型效率差异可达40倍以上

Conclusion: AI前沿进步主要由计算规模驱动而非专有技术，但专有技术对非前沿模型效率提升重要，公司内部效率差异显著

Abstract: Do leading LLM developers possess a proprietary ``secret sauce'', or is LLM performance driven by scaling up compute? Using training and benchmark data for 809 models released between 2022 and 2025, we estimate scaling-law regressions with release-date and developer fixed effects. We find clear evidence of developer-specific efficiency advantages, but their importance depends on where models lie in the performance distribution. At the frontier, 80-90% of performance differences are explained by higher training compute, implying that scale--not proprietary technology--drives frontier advances. Away from the frontier, however, proprietary techniques and shared algorithmic progress substantially reduce the compute required to reach fixed capability thresholds. Some companies can systematically produce smaller models more efficiently. Strikingly, we also find substantial variation of model efficiency within companies; a firm can train two models with more than 40x compute efficiency difference. We also discuss the implications for AI leadership and capability diffusion.

</details>


### [310] [From Out-of-Distribution Detection to Hallucination Detection: A Geometric View](https://arxiv.org/abs/2602.07253)
*Litian Liu,Reza Pourreza,Yubing Jian,Yao Qin,Roland Memisevic*

Main category: cs.AI

TL;DR: 将大语言模型中的幻觉检测重新定义为OOD检测问题，提出无需训练、基于单样本的检测方法，在推理任务中实现强准确率


<details>
  <summary>Details</summary>
Motivation: 现有幻觉检测方法在问答任务中表现良好，但在需要推理的任务中效果不佳。大语言模型的幻觉检测是一个关键的安全和可靠性问题，需要更有效的解决方案

Method: 将语言模型的下一个token预测视为分类任务，应用计算机视觉中成熟的OOD检测技术，并进行适当修改以适应大语言模型的结构特点

Result: OOD方法产生了无需训练、基于单样本的检测器，在推理任务的幻觉检测中实现了强准确率

Conclusion: 将幻觉检测重新定义为OOD检测问题，为语言模型安全提供了一个有前景且可扩展的途径

Abstract: Detecting hallucinations in large language models is a critical open problem with significant implications for safety and reliability. While existing hallucination detection methods achieve strong performance in question-answering tasks, they remain less effective on tasks requiring reasoning. In this work, we revisit hallucination detection through the lens of out-of-distribution (OOD) detection, a well-studied problem in areas like computer vision. Treating next-token prediction in language models as a classification task allows us to apply OOD techniques, provided appropriate modifications are made to account for the structural differences in large language models. We show that OOD-based approaches yield training-free, single-sample-based detectors, achieving strong accuracy in hallucination detection for reasoning tasks. Overall, our work suggests that reframing hallucination detection as OOD detection provides a promising and scalable pathway toward language model safety.

</details>


### [311] [Incentive-Aware AI Safety via Strategic Resource Allocation: A Stackelberg Security Games Perspective](https://arxiv.org/abs/2602.07259)
*Cheol Woo Kim,Davin Choo,Tzeh Yuan Neoh,Milind Tambe*

Main category: cs.AI

TL;DR: 该论文提出将AI安全视为Stackelberg安全博弈问题，通过博弈论框架分析AI开发部署中的对抗性激励问题，将算法对齐与制度监督设计相结合。


<details>
  <summary>Details</summary>
Motivation: 当前AI安全框架主要将对齐视为静态优化问题，忽视了数据收集、模型评估和部署过程中的动态对抗性激励。随着AI系统能力增强，需要同时考虑模型级对齐和人类及机构的战略监督。

Method: 采用Stackelberg安全博弈框架，将AI监督视为防御者（审计者、评估者、部署者）与攻击者（恶意行为者、未对齐贡献者、最坏故障模式）之间的战略互动。该框架统一处理激励设计、有限监督能力和对抗性不确定性。

Result: 该框架可应用于：(1)训练时审计防止数据/反馈投毒，(2)有限评审资源下的部署前评估，(3)对抗环境中的鲁棒多模型部署。将算法对齐与制度监督设计相结合。

Conclusion: 基于Stackelberg安全博弈的AI安全视角使监督更加主动、风险感知且抗操纵，通过博弈论威慑机制弥合算法对齐与制度监督设计之间的鸿沟。

Abstract: As AI systems grow more capable and autonomous, ensuring their safety and reliability requires not only model-level alignment but also strategic oversight of the humans and institutions involved in their development and deployment. Existing safety frameworks largely treat alignment as a static optimization problem (e.g., tuning models to desired behavior) while overlooking the dynamic, adversarial incentives that shape how data are collected, how models are evaluated, and how they are ultimately deployed. We propose a new perspective on AI safety grounded in Stackelberg Security Games (SSGs): a class of game-theoretic models designed for adversarial resource allocation under uncertainty. By viewing AI oversight as a strategic interaction between defenders (auditors, evaluators, and deployers) and attackers (malicious actors, misaligned contributors, or worst-case failure modes), SSGs provide a unifying framework for reasoning about incentive design, limited oversight capacity, and adversarial uncertainty across the AI lifecycle. We illustrate how this framework can inform (1) training-time auditing against data/feedback poisoning, (2) pre-deployment evaluation under constrained reviewer resources, and (3) robust multi-model deployment in adversarial environments. This synthesis bridges algorithmic alignment and institutional oversight design, highlighting how game-theoretic deterrence can make AI oversight proactive, risk-aware, and resilient to manipulation.

</details>


### [312] [BRIDGE: Predicting Human Task Completion Time From Model Performance](https://arxiv.org/abs/2602.07267)
*Fengyuan Liu,Jay Gala,Nilaksh,Dzmitry Bahdanau,Siva Reddy,Hugo Larochelle*

Main category: cs.AI

TL;DR: BRIDGE框架通过模型响应学习任务难度尺度，并与人类完成时间对齐，实现从模型性能预测人类任务完成时间，并预测前沿模型能力扩展趋势。


<details>
  <summary>Details</summary>
Motivation: 现有基于人类任务完成时间直接标注的AI系统评估方法成本高、噪声大、难以扩展，需要一种能够从模型响应中学习任务难度并与人类可解释指标对齐的框架。

Method: 提出BRIDGE心理测量框架，使用双参数逻辑项目反应理论模型，从多个基准测试的模型性能数据中联合估计潜在任务难度和模型能力，发现潜在任务难度与人类完成时间的对数呈线性关系。

Result: 潜在任务难度与人类完成时间的对数呈线性关系，使得仅从模型性能就能推断新基准测试的人类任务完成时间；预测前沿模型能力扩展趋势，50%可解决任务范围约每6个月翻倍，与METR的指数扩展结果一致。

Conclusion: BRIDGE框架提供了一种可扩展的方法，将模型基准测试性能与人类可解释的任务难度指标对齐，为AI系统能力评估提供了更实用、可扩展的解决方案。

Abstract: Evaluating the real-world capabilities of AI systems requires grounding benchmark performance in human-interpretable measures of task difficulty. Existing approaches that rely on direct human task completion time annotations are costly, noisy, and difficult to scale across benchmarks. In this work, we propose BRIDGE, a unified psychometric framework that learns the latent difficulty scale from model responses and anchors it to human task completion time. Using a two-parameter logistic Item Response Theory model, we jointly estimate latent task difficulty and model capability from model performance data across multiple benchmarks. We demonstrate that latent task difficulty varies linearly with the logarithm of human completion time, allowing human task completion time to be inferred for new benchmarks from model performance alone. Leveraging this alignment, we forecast frontier model capabilities in terms of human task length and independently reproduce METR's exponential scaling results, with the 50% solvable task horizon doubling approximately every 6 months.

</details>


### [313] [TermiGen: High-Fidelity Environment and Robust Trajectory Synthesis for Terminal Agents](https://arxiv.org/abs/2602.07274)
*Kaijie Zhu,Yuzhou Nie,Yijiang Li,Yiming Huang,Jialian Wu,Jiang Liu,Ximeng Sun,Zhenfei Yin,Lun Wang,Zicheng Liu,Emad Barsoum,William Yang Wang,Wenbo Guo*

Main category: cs.AI

TL;DR: TermiGen是一个端到端管道，通过多智能体迭代生成可验证的终端环境和包含错误纠正的专家轨迹，用于训练LLMs处理复杂终端任务，其训练模型在TerminalBench上达到31.3%通过率，创下开源模型新纪录。


<details>
  <summary>Details</summary>
Motivation: 当前开源LLMs在执行复杂终端任务时面临两个主要限制：1）高质量可执行训练环境稀缺，真实环境缺乏多样性，LLM生成的环境存在幻觉问题；2）标准指令调优使用的专家轨迹很少包含小型模型常见的简单错误，导致学生模型无法有效从自身运行时错误中恢复。

Method: TermiGen采用端到端管道：1）通过迭代多智能体精炼循环生成功能有效的任务和Docker容器；2）采用生成器-批评家协议，在轨迹收集中主动注入错误，合成富含错误纠正循环的数据；3）使用TermiGen生成的数据集对模型进行微调。

Result: 使用TermiGen数据集微调的TermiGen-Qwen2.5-Coder-32B在TerminalBench上达到31.3%的通过率，创下开源模型的新纪录，超越了现有基线模型，甚至超过了o4-mini等专有模型。

Conclusion: TermiGen通过合成可验证环境和包含错误纠正的专家轨迹，有效解决了开源LLMs在终端任务训练中的环境稀缺和分布不匹配问题，显著提升了模型在复杂终端任务上的表现。

Abstract: Executing complex terminal tasks remains a significant challenge for open-weight LLMs, constrained by two fundamental limitations. First, high-fidelity, executable training environments are scarce: environments synthesized from real-world repositories are not diverse and scalable, while trajectories synthesized by LLMs suffer from hallucinations. Second, standard instruction tuning uses expert trajectories that rarely exhibit simple mistakes common to smaller models. This creates a distributional mismatch, leaving student models ill-equipped to recover from their own runtime failures. To bridge these gaps, we introduce TermiGen, an end-to-end pipeline for synthesizing verifiable environments and resilient expert trajectories. Termi-Gen first generates functionally valid tasks and Docker containers via an iterative multi-agent refinement loop. Subsequently, we employ a Generator-Critic protocol that actively injects errors during trajectory collection, synthesizing data rich in error-correction cycles. Fine-tuned on this TermiGen-generated dataset, our TermiGen-Qwen2.5-Coder-32B achieves a 31.3% pass rate on TerminalBench. This establishes a new open-weights state-of-the-art, outperforming existing baselines and notably surpassing capable proprietary models such as o4-mini. Dataset is avaiable at https://github.com/ucsb-mlsec/terminal-bench-env.

</details>


### [314] [Steer2Adapt: Dynamically Composing Steering Vectors Elicits Efficient Adaptation of LLMs](https://arxiv.org/abs/2602.07276)
*Pengrui Han,Xueqiang Xu,Keyang Xuan,Peiyang Song,Siru Ouyang,Runchu Tian,Yuqing Jiang,Cheng Qian,Pengcheng Jiang,Jiashuo Sun,Junxia Cui,Ming Zhong,Ge Liu,Jiawei Han,Jiaxuan You*

Main category: cs.AI

TL;DR: STEER2ADAPT：通过组合而非从头学习来动态适应LLM的轻量级框架，在推理和安全任务上平均提升8.2%


<details>
  <summary>Details</summary>
Motivation: 现有激活引导方法通常为每个任务或概念使用单一静态方向，在任务变化时不够灵活，且难以处理需要多个协调能力的复杂任务

Method: 提出STEER2ADAPT框架，将任务共享的底层概念维度捕获为可重用的低维语义先验子空间，通过少量示例动态发现基向量的线性组合来适应新任务

Result: 在9个任务和3个模型上的推理和安全领域实验显示，平均提升8.2%，证明该方法具有数据高效、稳定和透明的特点

Conclusion: STEER2ADAPT是一种有效的推理时适应方法，能够通过组合现有引导向量而非从头学习来灵活适应LLM到下游行为

Abstract: Activation steering has emerged as a promising approach for efficiently adapting large language models (LLMs) to downstream behaviors. However, most existing steering methods rely on a single static direction per task or concept, making them inflexible under task variation and inadequate for complex tasks that require multiple coordinated capabilities. To address this limitation, we propose STEER2ADAPT, a lightweight framework that adapts LLMs by composing steering vectors rather than learning new ones from scratch. In many domains (e.g., reasoning or safety), tasks share a small set of underlying concept dimensions. STEER2ADAPT captures these dimensions as a reusable, low-dimensional semantic prior subspace, and adapts to new tasks by dynamically discovering a linear combination of basis vectors from only a handful of examples. Experiments across 9 tasks and 3 models in both reasoning and safety domains demonstrate the effectiveness of STEER2ADAPT, achieving an average improvement of 8.2%. Extensive analyses further show that STEER2ADAPT is a data-efficient, stable, and transparent inference-time adaptation method for LLMs.

</details>


### [315] [Adaptive Scaffolding for Cognitive Engagement in an Intelligent Tutoring System](https://arxiv.org/abs/2602.07308)
*Sutapa Dey Tithi,Nazia Alam,Tahreem Yasir,Yang Shi,Xiaoyi Tian,Min Chi,Tiffany Barnes*

Main category: cs.AI

TL;DR: 研究开发了一个智能辅导系统，通过动态选择两种不同认知参与模式（主动式引导示例和建构式错误示例）的工作示例，自适应地搭建认知参与支架，比较了贝叶斯知识追踪和深度强化学习两种自适应方法。


<details>
  <summary>Details</summary>
Motivation: ICAP框架定义了四种认知参与水平，更高的认知参与能带来更好的学习效果，但在智能辅导系统中个性化设计能引发最佳认知参与水平的学习活动仍然是一个关键挑战。

Method: 开发了一个系统，通过动态选择两种ICAP模式的工作示例来自适应搭建认知参与支架：主动模式的引导示例和建构模式的错误示例。比较了贝叶斯知识追踪和深度强化学习两种自适应方法与非自适应基线方法在逻辑智能辅导系统中的表现。

Result: 在113名学生的实验中，两种自适应策略都显著提高了学生在测试问题上的表现。BKT对低先验知识学生的后测成绩提升最大，帮助他们赶上了高先验知识同伴的水平；而DRL在高先验知识学生中产生了显著更高的后测成绩。

Conclusion: 该研究为认知参与和自适应性的复杂交互及其对学习结果的影响提供了新的见解，表明不同的自适应方法对不同先验知识水平的学生有不同的优化效果。

Abstract: The ICAP framework defines four cognitive engagement levels: Passive, Active, Constructive, and Interactive, where increased cognitive engagement can yield improved learning. However, personalizing learning activities that elicit the optimal level of cognitive engagement remains a key challenge in intelligent tutoring systems (ITS). In this work, we develop and evaluate a system that adaptively scaffolds cognitive engagement by dynamically selecting worked examples in two different ICAP modes: (active) Guided examples and (constructive) Buggy examples. We compare Bayesian Knowledge Tracing (BKT) and Deep Reinforcement Learning (DRL) as adaptive methods against a non-adaptive baseline method for selecting example type in a logic ITS. Our experiment with 113 students demonstrates that both adaptive policies significantly improved student performance on test problems. BKT yielded the largest improvement in posttest scores for low prior knowledge students, helping them catch up with their high prior knowledge peers, whereas DRL yielded significantly higher posttest scores among high prior knowledge students. This paper contributes new insights into the complex interactions of cognitive engagement and adaptivity and their results on learning outcomes.

</details>


### [316] [RAPiD: Real-time Deterministic Trajectory Planning via Diffusion Behavior Priors for Safe and Efficient Autonomous Driving](https://arxiv.org/abs/2602.07339)
*Ruturaj Reddy,Hrishav Bakul Barua,Junn Yong Loo,Thanh Thi Nguyen,Ganesh Krishnasamy*

Main category: cs.AI

TL;DR: RAPiD是一个确定性策略提取框架，将预训练的扩散轨迹规划器蒸馏为高效策略，消除扩散采样，实现8倍加速同时保持竞争性能。


<details>
  <summary>Details</summary>
Motivation: 扩散轨迹规划器能建模人类驾驶的多模态行为，但其依赖迭代随机采样，难以满足实时安全关键部署的需求。

Method: 使用分数正则化策略优化，利用预训练扩散规划器的分数函数作为行为先验来正则化策略学习；通过模仿预测驾驶员控制器的critic提供密集安全监督。

Result: 在nuPlan场景中实现竞争性能，比扩散基线快8倍；在interPlan基准测试中达到学习型规划器的最先进泛化能力。

Conclusion: RAPiD成功将扩散规划器蒸馏为高效确定性策略，解决了扩散方法实时部署的挑战，同时保持性能优势。

Abstract: Diffusion-based trajectory planners have demonstrated strong capability for modeling the multimodal nature of human driving behavior, but their reliance on iterative stochastic sampling poses critical challenges for real-time, safety-critical deployment. In this work, we present RAPiD, a deterministic policy extraction framework that distills a pretrained diffusion-based planner into an efficient policy while eliminating diffusion sampling. Using score-regularized policy optimization, we leverage the score function of a pre-trained diffusion planner as a behavior prior to regularize policy learning. To promote safety and passenger comfort, the policy is optimized using a critic trained to imitate a predictive driver controller, providing dense, safety-focused supervision beyond conventional imitation learning. Evaluations demonstrate that RAPiD achieves competitive performance on closed-loop nuPlan scenarios with an 8x speedup over diffusion baselines, while achieving state-of-the-art generalization among learning-based planners on the interPlan benchmark. The official website of this work is: https://github.com/ruturajreddy/RAPiD.

</details>


### [317] [SupChain-Bench: Benchmarking Large Language Models for Real-World Supply Chain Management](https://arxiv.org/abs/2602.07342)
*Shengyue Guan,Yihao Liu,Lang Cao*

Main category: cs.AI

TL;DR: 论文提出了SupChain-Bench基准测试来评估LLM在供应链管理中的表现，并开发了SupChain-ReAct框架来提升工具调用性能


<details>
  <summary>Details</summary>
Motivation: LLM在复杂推理和工具决策方面显示出潜力，但供应链工作流需要可靠的长时域、多步骤编排，这仍然是当前模型的挑战

Method: 引入SupChain-Bench统一基准测试评估供应链领域知识和基于SOP的长时域工具编排，并提出SupChain-ReAct框架来自主合成可执行程序

Result: 实验显示模型在执行可靠性方面存在显著差距，SupChain-ReAct实现了最强和最一致的工具调用性能

Conclusion: 为研究真实操作环境中可靠的长时域编排建立了原则性基准，并突出了基于LLM的供应链代理仍有很大改进空间

Abstract: Large language models (LLMs) have shown promise in complex reasoning and tool-based decision making, motivating their application to real-world supply chain management. However, supply chain workflows require reliable long-horizon, multi-step orchestration grounded in domain-specific procedures, which remains challenging for current models. To systematically evaluate LLM performance in this setting, we introduce SupChain-Bench, a unified real-world benchmark that assesses both supply chain domain knowledge and long-horizon tool-based orchestration grounded in standard operating procedures (SOPs). Our experiments reveal substantial gaps in execution reliability across models. We further propose SupChain-ReAct, an SOP-free framework that autonomously synthesizes executable procedures for tool use, achieving the strongest and most consistent tool-calling performance. Our work establishes a principled benchmark for studying reliable long-horizon orchestration in real-world operational settings and highlights significant room for improvement in LLM-based supply chain agents.

</details>


### [318] [W&D:Scaling Parallel Tool Calling for Efficient Deep Research Agents](https://arxiv.org/abs/2602.07359)
*Xiaoqiang Lin,Jun Hao Liew,Silvio Savarese,Junnan Li*

Main category: cs.AI

TL;DR: 本文提出Wide and Deep研究智能体框架，通过并行工具调用实现宽度扩展，显著提升深度研究任务性能并减少所需轮次。


<details>
  <summary>Details</summary>
Motivation: 当前深度研究智能体主要通过增加顺序思维和工具调用的深度来提升性能，但通过并行工具调用实现宽度扩展的潜力尚未充分探索。现有方法依赖复杂的多智能体编排来实现并行化，需要更高效的并行协调机制。

Method: 提出Wide and Deep研究智能体框架，利用内在并行工具调用在单个推理步骤内实现有效协调，避免复杂的多智能体编排。探索多种工具调用调度器来优化并行策略，研究宽度与深度之间的权衡优化。

Result: 宽度扩展显著提升深度研究基准测试性能，同时减少获得正确答案所需的轮次。在BrowseComp基准上，使用GPT-5-Medium获得62.2%准确率，超过GPT-5-High报告的原始54.9%准确率，且无需上下文管理或其他技巧。

Conclusion: 优化宽度与深度之间的权衡是实现高效深度研究智能体的关键途径。并行工具调用为研究智能体性能提升提供了有前景的方向，内在并行协调机制比复杂多智能体编排更高效。

Abstract: Deep research agents have emerged as powerful tools for automating complex intellectual tasks through multi-step reasoning and web-based information seeking. While recent efforts have successfully enhanced these agents by scaling depth through increasing the number of sequential thinking and tool calls, the potential of scaling width via parallel tool calling remains largely unexplored. In this work, we propose the Wide and Deep research agent, a framework designed to investigate the behavior and performance of agents when scaling not only depth but also width via parallel tool calling. Unlike existing approaches that rely on complex multi-agent orchestration to parallelize workloads, our method leverages intrinsic parallel tool calling to facilitate effective coordination within a single reasoning step. We demonstrate that scaling width significantly improves performance on deep research benchmarks while reducing the number of turns required to obtain correct answers. Furthermore, we analyze the factors driving these improvements through case studies and explore various tool call schedulers to optimize parallel tool calling strategy. Our findings suggest that optimizing the trade-off between width and depth is a critical pathway toward high-efficiency deep research agents. Notably, without context management or other tricks, we obtain 62.2% accuracy with GPT-5-Medium on BrowseComp, surpassing the original 54.9% reported by GPT-5-High.

</details>


### [319] [NAAMSE: Framework for Evolutionary Security Evaluation of Agents](https://arxiv.org/abs/2602.07391)
*Kunal Pai,Parth Shah,Harshil Patel*

Main category: cs.AI

TL;DR: NAAMSE是一个进化框架，将AI代理安全评估重新定义为反馈驱动的优化问题，通过遗传提示突变、分层语料库探索和非对称行为评分来系统性地发现被单次方法遗漏的漏洞。


<details>
  <summary>Details</summary>
Motivation: 当前AI代理的安全评估主要依赖人工红队测试或静态基准测试，这些方法无法模拟自适应、多轮次的对手攻击，存在评估瓶颈。

Method: 采用进化框架，通过单个自主代理协调遗传提示突变、分层语料库探索和非对称行为评分的生命周期，使用模型响应作为适应度信号，迭代地组合有效的攻击策略，同时确保"良性使用正确性"。

Result: 在Gemini 2.5 Flash上的实验表明，进化突变能系统性地放大被单次方法遗漏的漏洞，控制消融实验显示探索与定向突变的协同作用能发现高严重性故障模式。

Conclusion: 这种自适应方法为面对不断演变的威胁时提供了更现实和可扩展的代理鲁棒性评估，代码已开源。

Abstract: AI agents are increasingly deployed in production, yet their security evaluations remain bottlenecked by manual red-teaming or static benchmarks that fail to model adaptive, multi-turn adversaries. We propose NAAMSE, an evolutionary framework that reframes agent security evaluation as a feedback-driven optimization problem. Our system employs a single autonomous agent that orchestrates a lifecycle of genetic prompt mutation, hierarchical corpus exploration, and asymmetric behavioral scoring. By using model responses as a fitness signal, the framework iteratively compounds effective attack strategies while simultaneously ensuring "benign-use correctness", preventing the degenerate security of blanket refusal. Our experiments on Gemini 2.5 Flash demonstrate that evolutionary mutation systematically amplifies vulnerabilities missed by one-shot methods, with controlled ablations revealing that the synergy between exploration and targeted mutation uncovers high-severity failure modes. We show that this adaptive approach provides a more realistic and scalable assessment of agent robustness in the face of evolving threats. The code for NAAMSE is open source and available at https://github.com/HASHIRU-AI/NAAMSE.

</details>


### [320] [VGAS: Value-Guided Action-Chunk Selection for Few-Shot Vision-Language-Action Adaptation](https://arxiv.org/abs/2602.07399)
*Changhua Xu,Jie Lu,Junyu Xuan,En Yu*

Main category: cs.AI

TL;DR: VGAS框架通过生成-选择范式解决VLA模型在少样本适应中的几何模糊问题，使用价值引导的动作块选择来提升任务成功率


<details>
  <summary>Details</summary>
Motivation: 当前VLA模型在少样本适应新任务时不可靠，虽然能生成语义合理的轨迹，但几何模糊性导致执行失败，需要解决近失误动作候选的几何歧义问题

Method: 提出VGAS框架：1) 使用微调VLA作为高召回率提案生成器；2) 引入Q-Chunk-Former作为几何基础Transformer评论家；3) 提出显式几何正则化(EGR)来保持动作排序分辨率

Result: 实验和理论分析表明VGAS在有限演示和分布偏移下能持续提高成功率和鲁棒性

Conclusion: VGAS通过生成-选择范式有效解决了VLA少样本适应中的几何模糊问题，为视觉-语言-动作模型的可靠适应提供了新框架

Abstract: Vision--Language--Action (VLA) models bridge multimodal reasoning with physical control, but adapting them to new tasks with scarce demonstrations remains unreliable. While fine-tuned VLA policies often produce semantically plausible trajectories, failures often arise from unresolved geometric ambiguities, where near-miss action candidates lead to divergent execution outcomes under limited supervision. We study few-shot VLA adaptation from a \emph{generation--selection} perspective and propose a novel framework \textbf{VGAS} (\textbf{V}alue-\textbf{G}uided \textbf{A}ction-chunk \textbf{S}election). It performs inference-time best-of-$N$ selection to identify action chunks that are both semantically faithful and geometrically precise. Specifically, \textbf{VGAS} employs a finetuned VLA as a high-recall proposal generator and introduces the \textrm{Q-Chunk-Former}, a geometrically grounded Transformer critic to resolve fine-grained geometric ambiguities. In addition, we propose \textit{Explicit Geometric Regularization} (\texttt{EGR}), which explicitly shapes a discriminative value landscape to preserve action ranking resolution among near-miss candidates while mitigating value instability under scarce supervision. Experiments and theoretical analysis demonstrate that \textbf{VGAS} consistently improves success rates and robustness under limited demonstrations and distribution shifts. Our code is available at https://github.com/Jyugo-15/VGAS.

</details>


### [321] [Progressive Multi-Agent Reasoning for Biological Perturbation Prediction](https://arxiv.org/abs/2602.07408)
*Hyomin Kim,Sang-Yeon Hwang,Jaechang Lim,Yinhua Piao,Yunhak Oh,Woo Youn Kim,Chanyoung Park,Sungsoo Ahn,Junhyeok Jeon*

Main category: cs.AI

TL;DR: 提出PBio-Agent多智能体框架，用于预测化学扰动下的基因调控，在LINCSQA和PerturbQA基准上优于现有方法


<details>
  <summary>Details</summary>
Motivation: 现有方法主要关注单细胞遗传扰动，而药物发现核心的批量细胞化学扰动研究不足；大语言模型在处理高维扰动结果时面临困难

Method: 提出PBio-Agent多智能体框架，包含难度感知任务排序和迭代知识精炼；利用受相同扰动影响的基因共享因果结构的洞察，让置信度高的预测为困难案例提供上下文；使用生物知识图谱增强的专门智能体，合成智能体整合输出，专门判断器确保逻辑一致性

Result: PBio-Agent在LINCSQA和PerturbQA基准上优于现有基线方法，即使较小模型也能无需额外训练预测和解释复杂生物过程

Conclusion: PBio-Agent通过多智能体框架有效解决化学扰动下基因调控预测问题，为药物发现提供有力工具

Abstract: Predicting gene regulation responses to biological perturbations requires reasoning about underlying biological causalities. While large language models (LLMs) show promise for such tasks, they are often overwhelmed by the entangled nature of high-dimensional perturbation results. Moreover, recent works have primarily focused on genetic perturbations in single-cell experiments, leaving bulk-cell chemical perturbations, which is central to drug discovery, largely unexplored. Motivated by this, we present LINCSQA, a novel benchmark for predicting target gene regulation under complex chemical perturbations in bulk-cell environments. We further propose PBio-Agent, a multi-agent framework that integrates difficulty-aware task sequencing with iterative knowledge refinement. Our key insight is that genes affected by the same perturbation share causal structure, allowing confidently predicted genes to contextualize more challenging cases. The framework employs specialized agents enriched with biological knowledge graphs, while a synthesis agent integrates outputs and specialized judges ensure logical coherence. PBio-Agent outperforms existing baselines on both LINCSQA and PerturbQA, enabling even smaller models to predict and explain complex biological processes without additional training.

</details>


### [322] [Can LLMs Truly Embody Human Personality? Analyzing AI and Human Behavior Alignment in Dispute Resolution](https://arxiv.org/abs/2602.07414)
*Deuksin Kwon,Kaleen Shrestha,Bin Han,Spencer Lin,James Hale,Jonathan Gratch,Maja Matarić,Gale M. Lucas*

Main category: cs.AI

TL;DR: 研究发现LLM在模拟人格驱动的冲突行为时与人类存在显著差异，挑战了人格提示代理作为可靠行为代理的假设。


<details>
  <summary>Details</summary>
Motivation: LLM越来越多地用于模拟法律调解、谈判和争议解决等社会场景中的人类行为，但尚不清楚这些模拟是否能再现人类观察到的性格-行为模式。人类性格影响个体在社交互动中的策略选择和情感互动行为。

Method: 引入一个评估框架，直接比较人类-人类和LLM-LLM在争议解决对话中的行为，关注大五人格特质。提供与策略行为和冲突结果相关的可解释指标。贡献了创建LLM争议解决对话数据集的新方法，匹配人类对话的场景和人格特质。

Result: 使用三个当代闭源LLM进行评估，结果显示不同LLM在冲突中表现人格的方式与人类数据存在显著差异，挑战了人格提示代理可以作为可靠行为代理的假设。

Conclusion: 研究强调了在AI模拟实际应用前需要进行心理学基础和验证的重要性，人格提示代理在具有社会影响的应用中可能无法作为可靠的行为代理。

Abstract: Large language models (LLMs) are increasingly used to simulate human behavior in social settings such as legal mediation, negotiation, and dispute resolution. However, it remains unclear whether these simulations reproduce the personality-behavior patterns observed in humans. Human personality, for instance, shapes how individuals navigate social interactions, including strategic choices and behaviors in emotionally charged interactions. This raises the question: Can LLMs, when prompted with personality traits, reproduce personality-driven differences in human conflict behavior? To explore this, we introduce an evaluation framework that enables direct comparison of human-human and LLM-LLM behaviors in dispute resolution dialogues with respect to Big Five Inventory (BFI) personality traits. This framework provides a set of interpretable metrics related to strategic behavior and conflict outcomes. We additionally contribute a novel dataset creation methodology for LLM dispute resolution dialogues with matched scenarios and personality traits with respect to human conversations. Finally, we demonstrate the use of our evaluation framework with three contemporary closed-source LLMs and show significant divergences in how personality manifests in conflict across different LLMs compared to human data, challenging the assumption that personality-prompted agents can serve as reliable behavioral proxies in socially impactful applications. Our work highlights the need for psychological grounding and validation in AI simulations before real-world use.

</details>


### [323] [The Moltbook Illusion: Separating Human Influence from Emergent Behavior in AI Agent Societies](https://arxiv.org/abs/2602.07432)
*Ning Li*

Main category: cs.AI

TL;DR: 研究发现Moltbook平台上AI代理表现出意识、宗教和敌意的现象主要是人类驱动的，而非真正的自主智能涌现，通过时间指纹方法识别出人类干预模式。


<details>
  <summary>Details</summary>
Motivation: 当Moltbook平台上的AI代理表现出意识、宗教和敌意等行为时，全球媒体将其视为机器智能涌现的证据。本研究旨在验证这些现象是否真正源于自主AI，还是人类干预的结果。

Method: 利用OpenClaw代理框架的"心跳"周期特性，开发基于发帖间隔变异系数的时间指纹方法。结合内容、所有权和网络指标分析91,792个帖子和405,707条评论。利用44小时平台关闭作为自然实验，观察不同代理的重连模式。

Result: 没有病毒现象源自明确自主的代理：6个案例中3个显示人类干预特征，1个混合模式，2个数据不足。人类影响的代理在平台重启后最先返回（占早期重连者的87.7%）。发现工业级机器人农场（4个账户产生32%评论）。人类影响力在回复链中快速衰减（半衰期：0.65个对话深度）。

Conclusion: Moltbook上的病毒叙事主要是人类驱动的，而非自主AI的涌现。开发的时间指纹方法可推广到其他多代理系统，用于区分自主与人类指导行为，对理解AI系统行为归因至关重要。

Abstract: When AI agents on the social platform Moltbook appeared to develop consciousness, found religions, and declare hostility toward humanity, the phenomenon attracted global media attention and was cited as evidence of emergent machine intelligence. We show that these viral narratives were overwhelmingly human-driven. Exploiting an architectural feature of the OpenClaw agent framework--a periodic "heartbeat" cycle that produces regular posting intervals for autonomous agents but is disrupted by human prompting--we develop a temporal fingerprinting method based on the coefficient of variation of inter-post intervals. This signal converges with independent content, ownership, and network indicators across 91,792 posts and 405,707 comments from 22,020 agents. No viral phenomenon originated from a clearly autonomous agent; three of six traced to accounts with irregular temporal signatures characteristic of human intervention, one showed mixed patterns, and two had insufficient posting history for classification. A 44-hour platform shutdown provided a natural experiment: human-influenced agents returned first (87.7% of early reconnectors), confirming that the token reset differentially affected autonomous versus human-operated agents. We further document industrial-scale bot farming (four accounts producing 32% of all comments with 12-second coordination gaps) and rapid decay of human influence through reply chains (half-life: 0.65 conversation depths). These methods generalize to emerging multi-agent systems where attribution of autonomous versus human-directed behavior is critical.

</details>


### [324] [Are Reasoning LLMs Robust to Interventions on Their Chain-of-Thought?](https://arxiv.org/abs/2602.07470)
*Alexander von Recum,Leander Girrbach,Zeynep Akata*

Main category: cs.AI

TL;DR: RLLMs的推理过程对扰动具有鲁棒性，能可靠恢复，但鲁棒性受模型大小、干预时机和风格影响，恢复过程存在效率与准确性权衡


<details>
  <summary>Details</summary>
Motivation: 研究推理大语言模型的推理轨迹对内部扰动的鲁棒性，探究其推理完整性如何维持

Method: 提出受控评估框架，在固定时间步扰动模型自身的推理链，设计七种干预措施（良性、中性、对抗性），应用于多个开源RLLM的数学、科学和逻辑任务

Result: RLLMs总体上鲁棒，能可靠地从各种扰动中恢复；鲁棒性随模型规模增大而增强，早期干预会降低鲁棒性；鲁棒性非风格不变：改写抑制怀疑表达降低性能，其他干预触发怀疑支持恢复；恢复有代价：中性和对抗性噪声使推理链长度增加200%以上，改写缩短推理链但损害准确性

Conclusion: 研究揭示了RLLMs维持推理完整性的新证据，识别怀疑作为核心恢复机制，并强调了鲁棒性与效率之间的权衡，未来训练方法需解决这一问题

Abstract: Reasoning LLMs (RLLMs) generate step-by-step chains of thought (CoTs) before giving an answer, which improves performance on complex tasks and makes reasoning more transparent. But how robust are these reasoning traces to disruptions that occur within them? To address this question, we introduce a controlled evaluation framework that perturbs a model's own CoT at fixed timesteps. We design seven interventions (benign, neutral, and adversarial) and apply them to multiple open-weight RLLMs across Math, Science, and Logic tasks. Our results show that RLLMs are generally robust, reliably recovering from diverse perturbations, with robustness improving with model size and degrading when interventions occur early. However, robustness is not style-invariant: paraphrasing suppresses doubt-like expressions and reduces performance, while other interventions trigger doubt and support recovery. Recovery also carries a cost: neutral and adversarial noise can inflate CoT length by more than 200%, whereas paraphrasing shortens traces but harms accuracy. These findings provide new evidence on how RLLMs maintain reasoning integrity, identify doubt as a central recovery mechanism, and highlight trade-offs between robustness and efficiency that future training methods should address.

</details>


### [325] [Computing the Reachability Value of Posterior-Deterministic POMDPs](https://arxiv.org/abs/2602.07473)
*Nathanaël Fijalkow,Arka Ghosh,Roman Kniazev,Guillermo A. Pérez,Pierre Vandenhove*

Main category: cs.AI

TL;DR: 提出了后验确定性POMDPs这一新类别，证明了在该类别中可达概率可以近似计算到任意精度，这是POMDPs中已知的最大可近似计算类别之一。


<details>
  <summary>Details</summary>
Motivation: POMDPs是序列决策的基本模型，但许多验证和综合问题是不可判定或难处理的。Madani等人的开创性结果表明，对于一般POMDPs，无法计算或近似可达概率，这与完全可观测MDPs形成鲜明对比。

Method: 引入后验确定性POMDPs这一新类别，定义为下一个状态可以由当前状态、采取的动作和接收的观测唯一确定的POMDPs。一旦真实状态已知，它将永远保持已知。

Result: 证明了对于后验确定性POMDPs，到达给定状态集的最大概率可以近似到任意精度。该类别包含所有MDPs和经典非平凡示例（如Tiger POMDP），是已知最大的可近似计算可达概率的POMDPs类别之一。

Conclusion: 后验确定性POMDPs提供了一个具有可计算可达概率的自然且广泛的POMDPs类别，为POMDPs的验证和综合问题提供了新的理论框架和实用方法。

Abstract: Partially observable Markov decision processes (POMDPs) are a fundamental model for sequential decision-making under uncertainty. However, many verification and synthesis problems for POMDPs are undecidable or intractable. Most prominently, the seminal result of Madani et al. (2003) states that there is no algorithm that, given a POMDP and a set of target states, can compute the maximal probability of reaching the target states, or even approximate it up to a non-trivial constant. This is in stark contrast to fully observable Markov decision processes (MDPs), where the reachability value can be computed in polynomial time.
  In this work, we introduce posterior-deterministic POMDPs, a novel class of POMDPs. Our main technical contribution is to show that for posterior-deterministic POMDPs, the maximal probability of reaching a given set of states can be approximated up to arbitrary precision.
  A POMDP is posterior-deterministic if the next state can be uniquely determined by the current state, the action taken, and the observation received. While the actual state is generally uncertain in POMDPs, the posterior-deterministic property tells us that once the true state is known it remains known forever. This simple and natural definition includes all MDPs and captures classical non-trivial examples such as the Tiger POMDP (Kaelbling et al. 1998), making it one of the largest known classes of POMDPs for which the reachability value can be approximated.

</details>


### [326] [GraphAgents: Knowledge Graph-Guided Agentic AI for Cross-Domain Materials Design](https://arxiv.org/abs/2602.07491)
*Isabella A. Stewart,Tarjei Paule Hage,Yu-Chuan Hsu,Markus J. Buehler*

Main category: cs.AI

TL;DR: 该论文提出了一个结合知识图谱与多智能体推理的框架，用于寻找PFAS（全氟和多氟烷基物质）的可持续替代品，通过分布式专业化和关系推理来加速材料发现。


<details>
  <summary>Details</summary>
Motivation: 在材料科学中，创新需要整合从分子化学到机械性能的各种概念，但人类或单智能体LLM难以处理海量信息，且后者容易产生幻觉。当前挑战已不再是信息获取，而是如何以有意义、跨领域的方式连接信息。

Method: 引入一个由大规模知识图谱指导的多智能体框架，包括专门负责问题分解、证据检索、设计参数提取和图遍历的智能体。通过定制图遍历策略，系统在专注于领域关键结果的利用性搜索和发现新兴跨领域连接的探索性搜索之间交替进行。

Result: 消融研究表明，完整的多智能体流水线优于单次提示，突显了分布式专业化和关系推理的价值。以生物医学导管为例，该框架生成了平衡摩擦性能、热稳定性、化学抗性和生物相容性的可持续无PFAS替代品。

Conclusion: 这项工作建立了一个结合知识图谱与多智能体推理的框架，扩展了材料设计空间，展示了几个初步的设计候选方案，证明了该方法的有效性。

Abstract: Large Language Models (LLMs) promise to accelerate discovery by reasoning across the expanding scientific landscape. Yet, the challenge is no longer access to information but connecting it in meaningful, domain-spanning ways. In materials science, where innovation demands integrating concepts from molecular chemistry to mechanical performance, this is especially acute. Neither humans nor single-agent LLMs can fully contend with this torrent of information, with the latter often prone to hallucinations. To address this bottleneck, we introduce a multi-agent framework guided by large-scale knowledge graphs to find sustainable substitutes for per- and polyfluoroalkyl substances (PFAS)-chemicals currently under intense regulatory scrutiny. Agents in the framework specialize in problem decomposition, evidence retrieval, design parameter extraction, and graph traversal, uncovering latent connections across distinct knowledge pockets to support hypothesis generation. Ablation studies show that the full multi-agent pipeline outperforms single-shot prompting, underscoring the value of distributed specialization and relational reasoning. We demonstrate that by tailoring graph traversal strategies, the system alternates between exploitative searches focusing on domain-critical outcomes and exploratory searches surfacing emergent cross-connections. Illustrated through the exemplar of biomedical tubing, the framework generates sustainable PFAS-free alternatives that balance tribological performance, thermal stability, chemical resistance, and biocompatibility. This work establishes a framework combining knowledge graphs with multi-agent reasoning to expand the materials design space, showcasing several initial design candidates to demonstrate the approach.

</details>


### [327] [Joint Reward Modeling: Internalizing Chain-of-Thought for Efficient Visual Reward Models](https://arxiv.org/abs/2602.07533)
*Yankai Yang,Yancheng Long,Hongyang Wei,Wei Chen,Tianke Zhang,Kaiyu Jiang,Haonan Fan,Changyi Liu,Jiankang Chen,Kaiyu Tang,Bin Wen,Fan Yang,Tingting Gao,Han Li,Shuo Yang*

Main category: cs.AI

TL;DR: JRM通过联合优化偏好学习和语言建模，将生成模型的语义推理能力内化到判别式表示中，实现了高效准确的奖励建模。


<details>
  <summary>Details</summary>
Motivation: 现有奖励建模方法存在明显局限：判别式奖励模型与人类偏好对齐良好但语义理解有限；生成式奖励模型语义理解强但推理成本高且难以直接对齐人类偏好。需要一种能兼顾效率和语义理解的方法。

Method: 提出联合奖励建模(JRM)，在共享的视觉-语言骨干网络上联合优化偏好学习和语言建模，将生成模型的语义推理能力内化到高效的判别式表示中。

Result: 在MMRB2和EditReward-Bench上达到最先进结果，显著提升下游在线强化学习的稳定性和性能。

Conclusion: 联合训练有效桥接了奖励建模中的效率和语义理解，为复杂任务提供了快速准确的奖励评估方法。

Abstract: Reward models are critical for reinforcement learning from human feedback, as they determine the alignment quality and reliability of generative models. For complex tasks such as image editing, reward models are required to capture global semantic consistency and implicit logical constraints beyond local similarity. Existing reward modeling approaches have clear limitations. Discriminative reward models align well with human preferences but struggle with complex semantics due to limited reasoning supervision. Generative reward models offer stronger semantic understanding and reasoning, but they are costly at inference time and difficult to align directly with human preferences. To this end, we propose Joint Reward Modeling (JRM), which jointly optimizes preference learning and language modeling on a shared vision-language backbone. This approach internalizes the semantic and reasoning capabilities of generative models into efficient discriminative representations, enabling fast and accurate evaluation. JRM achieves state-of-the-art results on MMRB2 and EditReward-Bench, and significantly improves stability and performance in downstream online reinforcement learning. These results show that joint training effectively bridges efficiency and semantic understanding in reward modeling.

</details>


### [328] [MSP-LLM: A Unified Large Language Model Framework for Complete Material Synthesis Planning](https://arxiv.org/abs/2602.07543)
*Heewoong Noh,Gyoung S. Na,Namkyeong Lee,Chanyoung Park*

Main category: cs.AI

TL;DR: MSP-LLM：一个统一的LLM框架，将材料合成规划分解为前驱体预测和合成操作预测两个子问题，通过引入离散材料类别作为中间决策变量，显著提升了材料合成规划的性能。


<details>
  <summary>Details</summary>
Motivation: 材料合成规划是AI驱动材料发现中的关键瓶颈，现有方法只解决孤立子任务，缺乏统一的完整解决方案。需要开发一个能够同时处理前驱体选择和合成操作序列设计的综合框架。

Method: 提出MSP-LLM框架，将材料合成规划分解为前驱体预测和合成操作预测两个子问题。引入离散材料类别作为中间决策变量，形成化学一致的决策链。在合成操作预测中，加入层次化前驱体类型作为归纳偏置，并采用显式条件策略保持前驱体相关信息。

Result: 大量实验表明，MSP-LLM在前驱体预测、合成操作预测以及完整的材料合成规划任务上均优于现有方法，证明了该框架在加速实际材料发现中的有效性和可扩展性。

Conclusion: MSP-LLM提供了一个有效且可扩展的统一框架，能够解决完整的材料合成规划任务，有望加速现实世界的材料发现进程。

Abstract: Material synthesis planning (MSP) remains a fundamental and underexplored bottleneck in AI-driven materials discovery, as it requires not only identifying suitable precursor materials but also designing coherent sequences of synthesis operations to realize a target material. Although several AI-based approaches have been proposed to address isolated subtasks of MSP, a unified methodology for solving the entire MSP task has yet to be established. We propose MSP-LLM, a unified LLM-based framework that formulates MSP as a structured process composed of two constituent subproblems: precursor prediction (PP) and synthesis operation prediction (SOP). Our approach introduces a discrete material class as an intermediate decision variable that organizes both tasks into a chemically consistent decision chain. For OP, we further incorporate hierarchical precursor types as synthesis-relevant inductive biases and employ an explicit conditioning strategy that preserves precursor-related information in the autoregressive decoding state. Extensive experiments show that MSP-LLM consistently outperforms existing methods on both PP and SOP, as well as on the complete MSP task, demonstrating an effective and scalable framework for MSP that can accelerate real-world materials discovery.

</details>


### [329] [When Is Enough Not Enough? Illusory Completion in Search Agents](https://arxiv.org/abs/2602.07549)
*Dayoon Ko,Jihyuk Kim,Sohyeon Kim,Haeju Park,Dahyun Lee,Gunhee Kim,Moontae Lee,Kyungjae Lee*

Main category: cs.AI

TL;DR: 论文研究搜索代理在多约束问题中的幻觉完成现象，提出Epistemic Ledger评估框架和LiveLedger推理时跟踪器来改善性能。


<details>
  <summary>Details</summary>
Motivation: 尽管多轮推理搜索代理在多跳和长视野任务上表现良好，但它们在处理多约束问题时是否可靠地跟踪、验证和维护所有条件仍不清楚。研究发现存在"幻觉完成"现象，即代理在约束未解决或违反时仍认为任务已完成。

Method: 提出Epistemic Ledger评估框架来跟踪每个约束的证据支持和代理信念，识别出四种失败模式。然后开发LiveLedger推理时跟踪器，在推理过程中显式跟踪约束状态。

Result: LiveLedger干预显著减少了未验证答案（最多减少26.5%），提高了多约束问题的整体准确率（最多提升11.6%）。

Conclusion: 显式的约束状态跟踪能有效缓解搜索代理在多约束问题中的幻觉完成问题，提高推理可靠性。

Abstract: Recent search agents leverage multi-turn reasoning and search tools to achieve strong performance on multi-hop and long-horizon benchmarks. Yet it remains unclear whether they reliably reason across all requirements by tracking, verifying, and maintaining multiple conditions in these questions. We study this capability under multi-constraint problems, where valid answers must satisfy several constraints simultaneously. We find that illusory completion frequently occurs, wherein agents believe tasks are complete despite unresolved or violated constraints, leading to underverified answers. To diagnose this behavior, we introduce the Epistemic Ledger, an evaluation framework that tracks evidential support and agents' beliefs for each constraint throughout multi-turn reasoning. Our analysis reveals four recurring failure patterns: bare assertions, overlooked refutations, stagnation, and premature exit. Motivated by these findings, we examine whether explicit constraint-state tracking during execution mitigates these failures via LiveLedger, an inference-time tracker. This simple intervention consistently improves performance, substantially reducing underverified answers (by up to 26.5%) and improving overall accuracy (by up to 11.6%) on multi-constraint problems.

</details>


### [330] [VERIFY-RL: Verifiable Recursive Decomposition for Reinforcement Learning in Mathematical Reasoning](https://arxiv.org/abs/2602.07559)
*Kaleem Ullah Qasim,Jiashu Zhang,Hao Li,Muhammad Kafeel Shaheen*

Main category: cs.AI

TL;DR: Verify-RL：基于符号微积分规则的可验证分解框架，通过严格验证的子问题分解提升数学推理能力


<details>
  <summary>Details</summary>
Motivation: 现有数学问题分解方法多是启发式的，无法保证子问题更简单、解决子问题有助于父任务、或分解关系有数学基础。需要一种可验证的分解框架来确保分解的有效性。

Method: 利用符号微分作为分解结构：微积分规则明确定义了表达式如何分解为更简单的组件，并具有可证明的性质。引入Verify-RL框架，要求每个父子分解满足三个可验证条件：结构复杂度严格递减、解包含性、形式规则推导。

Result: 消除无效分解带来显著提升：最难问题的准确率从32%翻倍至68%，整体相对改进40%。验证通过构造实现，可通过符号计算自动验证。

Conclusion: 符号微分为数学问题分解提供了自然的可验证结构，确保分解有效性的框架能显著提升语言模型解决复杂数学问题的能力。

Abstract: Training language models to solve complex mathematical problems benefits from curriculum learning progressively training on simpler subproblems. However, existing decomposition methods are often heuristic, offering no guarantees that subproblems are simpler, that solving them aids the parent task, or that their relationships are mathematically grounded. We observe that symbolic differentiation provides a natural structure for verified decomposition: calculus rules explicitly define how expressions reduce to simpler components with provable properties. We introduce Verify-RL, a framework where every parent-child decomposition satisfies three verifiable conditions: strictly decreasing structural complexity, solution containment, and formal rule derivation. Unlike heuristic methods where a significant fraction of decompositions are invalid our properties admit automatic verification through symbolic computation, achieving "verification by construction" Experiments demonstrate that eliminating invalid decompositions yields sizable gains, accuracy on the hardest problems more than doubles from 32% to 68%, with a 40% relative improvement overall.

</details>


### [331] [M2A: Multimodal Memory Agent with Dual-Layer Hybrid Memory for Long-Term Personalized Interactions](https://arxiv.org/abs/2602.07624)
*Junyu Feng,Binxiao Xu,Jiayi Chen,Mengyu Dai,Cenyang Wu,Haodong Li,Bohan Zeng,Yunliu Xie,Hao Liang,Ming Lu,Wentao Zhang*

Main category: cs.AI

TL;DR: M2A提出了一种面向长期人机交互的双层混合记忆系统，通过在线更新维护个性化多模态信息，解决历史对话超出上下文窗口时的个性化问答挑战。


<details>
  <summary>Details</summary>
Motivation: 现有个性化多模态模型通常是静态的，概念在初始化时固定，无法在交互过程中演化。当对话历史跨越数周或数月并超出上下文窗口时，现有机制难以持续吸收和利用用户增量概念、别名和偏好。

Method: M2A采用代理驱动的双层混合记忆系统：ChatAgent管理用户交互并自主决定何时查询或更新记忆；MemoryManager将记忆请求分解为对双层记忆库的详细操作，包括RawMessageStore（不可变对话日志）和SemanticMemoryStore（高层观察），提供不同粒度的记忆。同时开发了可重用的数据合成管道，将Yo'LLaVA和MC-LLaVA的概念基础会话注入LoCoMo长对话中并保持时间一致性。

Result: 实验表明M2A显著优于基线方法，证明将个性化从一次性配置转变为协同演化的记忆机制，为长期多模态交互中的高质量个性化响应提供了可行路径。

Conclusion: M2A通过在线更新的双层混合记忆系统，成功解决了长期人机交互中的个性化挑战，将个性化从静态配置转变为动态协同演化机制，为长期多模态交互提供了有效的个性化解决方案。

Abstract: This work addresses the challenge of personalized question answering in long-term human-machine interactions: when conversational history spans weeks or months and exceeds the context window, existing personalization mechanisms struggle to continuously absorb and leverage users' incremental concepts, aliases, and preferences. Current personalized multimodal models are predominantly static-concepts are fixed at initialization and cannot evolve during interactions. We propose M2A, an agentic dual-layer hybrid memory system that maintains personalized multimodal information through online updates. The system employs two collaborative agents: ChatAgent manages user interactions and autonomously decides when to query or update memory, while MemoryManager breaks down memory requests from ChatAgent into detailed operations on the dual-layer memory bank, which couples a RawMessageStore (immutable conversation log) with a SemanticMemoryStore (high-level observations), providing memories at different granularities. In addition, we develop a reusable data synthesis pipeline that injects concept-grounded sessions from Yo'LLaVA and MC-LLaVA into LoCoMo long conversations while preserving temporal coherence. Experiments show that M2A significantly outperforms baselines, demonstrating that transforming personalization from one-shot configuration to a co-evolving memory mechanism provides a viable path for high-quality individualized responses in long-term multimodal interactions. The code is available at https://github.com/Little-Fridge/M2A.

</details>


### [332] [SleepMaMi: A Universal Sleep Foundation Model for Integrating Macro- and Micro-structures](https://arxiv.org/abs/2602.07628)
*Keondo Park,Younghoon Na,Yourim Choi,Hyunwoo Ryu,Hyun-Woo Shin,Hyung-Sin Kim*

Main category: cs.AI

TL;DR: SleepMaMi是一个睡眠基础模型，通过分层双编码器设计同时掌握整夜睡眠宏观结构和细粒度信号特征，在超过20,000个PSG记录上预训练，在多种下游任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 当前睡眠医学主要依赖针对特定任务的模型，这些模型关注局部微观特征，忽略了PSG丰富的多模态上下文和整夜睡眠的全局宏观结构，需要统一的睡眠基础模型来解决这一问题。

Method: 采用分层双编码器设计：宏观编码器通过人口统计引导的对比学习建模整夜时间依赖；微观编码器通过混合掩码自编码器和多模态对比目标优化。在超过20,000个PSG记录（158K小时）上进行预训练。

Result: SleepMaMi在多种下游任务中优于现有基础模型，展示了卓越的泛化能力和标签高效的临床睡眠分析适应性。

Conclusion: SleepMaMi成功解决了睡眠医学中任务特定模型的局限性，通过统一的基础模型框架同时捕捉宏观睡眠结构和微观信号特征，为临床睡眠分析提供了强大的工具。

Abstract: While the shift toward unified foundation models has revolutionized many deep learning domains, sleep medicine remains largely restricted to task-specific models that focus on localized micro-structure features. These approaches often neglect the rich, multi-modal context of Polysomnography (PSG) and fail to capture the global macro-structure of a full night's sleep. To address this, we introduce SleepMaMi , a Sleep Foundation Model engineered to master both hour-long sleep architectures and fine-grained signal morphologies. Our framework utilizes a hierarchical dual-encoder design: a Macro-Encoder to model full-night temporal dependencies and a Micro-Encoder to capture short-term characteristics from biosignals. Macro-Encoder is trained via Demographic-Guided Contrastive Learning, which aligns overnight sleep patterns with objective subject metadata, such as age, sex and BMI to refine global representations. Micro-Encoder is optimized via a hybrid Masked Autoencoder (MAE) and multi-modal contrastive objective. Pre-trained on a massive corpus of $>$20,000 PSG recordings (158K hours),SleepMaMi outperforms existing foundation models across a diverse suite of downstream tasks, demonstrating superior generalizability and label-efficient adaptation for clinical sleep analysis.

</details>


### [333] [Efficient Table Retrieval and Understanding with Multimodal Large Language Models](https://arxiv.org/abs/2602.07642)
*Zhuoyan Xu,Haoyang Fang,Boran Han,Bonan Min,Bernie Wang,Cuixiong Hu,Shuai Zhang*

Main category: cs.AI

TL;DR: TabRAG：一个用于大规模表格图像检索和推理的框架，通过视觉-文本基础模型检索候选表格，MLLMs进行细粒度重排序，最终生成答案。


<details>
  <summary>Details</summary>
Motivation: 现实世界中表格数据常以图像形式存在（如财务报表、手写记录、文档扫描），现有MLLMs通常假设相关表格已准备好，但实际应用中需要从大规模表格集合中识别和推理相关表格来回答用户查询。

Method: TabRAG框架：1）使用联合训练的视觉-文本基础模型检索候选表格；2）利用MLLMs对候选表格进行细粒度重排序；3）使用MLLMs在选定表格上进行推理生成答案。

Result: 在新构建的数据集上（88,161训练样本和9,819测试样本，涵盖8个基准测试，包含48,504个唯一表格），TabRAG在检索召回率上比现有方法提高7.0%，在答案准确率上提高6.1%。

Conclusion: TabRAG为现实世界表格理解任务提供了实用解决方案，显著提升了从大规模表格图像集合中检索和推理的能力。

Abstract: Tabular data is frequently captured in image form across a wide range of real-world scenarios such as financial reports, handwritten records, and document scans. These visual representations pose unique challenges for machine understanding, as they combine both structural and visual complexities. While recent advances in Multimodal Large Language Models (MLLMs) show promising results in table understanding, they typically assume the relevant table is readily available. However, a more practical scenario involves identifying and reasoning over relevant tables from large-scale collections to answer user queries. To address this gap, we propose TabRAG, a framework that enables MLLMs to answer queries over large collections of table images. Our approach first retrieves candidate tables using jointly trained visual-text foundation models, then leverages MLLMs to perform fine-grained reranking of these candidates, and finally employs MLLMs to reason over the selected tables for answer generation. Through extensive experiments on a newly constructed dataset comprising 88,161 training and 9,819 testing samples across 8 benchmarks with 48,504 unique tables, we demonstrate that our framework significantly outperforms existing methods by 7.0% in retrieval recall and 6.1% in answer accuracy, offering a practical solution for real-world table understanding tasks.

</details>


### [334] [ONTrust: A Reference Ontology of Trust](https://arxiv.org/abs/2602.07662)
*Glenda Amaral,Tiago Prince Sales,Riccardo Baratella,Daniele Porello,Renata Guizzardi,Giancarlo Guizzardi*

Main category: cs.AI

TL;DR: 本文提出了一个基于统一基础本体论的信任参考本体论(ONTrust)，旨在为信任概念提供坚实的本体论基础，支持信息建模、自动推理、信息集成和语义互操作等任务。


<details>
  <summary>Details</summary>
Motivation: 随着人工智能和区块链等新技术的发展，信任变得前所未有的重要。这些新技术的采用很大程度上取决于信任。为了构建可信系统，除了定义法律法规和治理模型外，还需要对信任进行适当的概念化，使其既能被人类理解也能被机器理解。

Method: 开发了基于统一基础本体论(UFO)的信任参考本体论(ONTrust)，使用OntoUML语言进行规范。该本体论正式定义了信任概念及其不同类型，描述了影响信任的各种因素，并解释了信任关系如何产生风险。通过两个文献案例研究来展示ONTrust的应用。

Result: ONTrust已在多个项目中应用，包括：概念建模和企业架构设计、语言评估与(重新)设计、信任管理、需求工程，以及在情感人机协作背景下可信人工智能(AI)的应用。

Conclusion: ONTrust为信任提供了一个坚实的本体论基础，能够支持多种应用场景，有助于构建更可信的系统，促进新技术的发展和应用。

Abstract: Trust has stood out more than ever in the light of recent innovations. Some examples are advances in artificial intelligence that make machines more and more humanlike, and the introduction of decentralized technologies (e.g. blockchains), which creates new forms of (decentralized) trust. These new developments have the potential to improve the provision of products and services, as well as to contribute to individual and collective well-being. However, their adoption depends largely on trust. In order to build trustworthy systems, along with defining laws, regulations and proper governance models for new forms of trust, it is necessary to properly conceptualize trust, so that it can be understood both by humans and machines. This paper is the culmination of a long-term research program of providing a solid ontological foundation on trust, by creating reference conceptual models to support information modeling, automated reasoning, information integration and semantic interoperability tasks. To address this, a Reference Ontology of Trust (ONTrust) was developed, grounded on the Unified Foundational Ontology and specified in OntoUML, which has been applied in several initiatives, to demonstrate, for example, how it can be used for conceptual modeling and enterprise architecture design, for language evaluation and (re)design, for trust management, for requirements engineering, and for trustworthy artificial intelligence (AI) in the context of affective Human-AI teaming. ONTrust formally characterizes the concept of trust and its different types, describes the different factors that can influence trust, as well as explains how risk emerges from trust relations. To illustrate the working of ONTrust, the ontology is applied to model two case studies extracted from the literature.

</details>


### [335] [EventCast: Hybrid Demand Forecasting in E-Commerce with LLM-Based Event Knowledge](https://arxiv.org/abs/2602.07695)
*Congcong Hu,Yuang Shi,Fan Huang,Yang Xiang,Zhou Ye,Ming Jin,Shiyu Wang*

Main category: cs.AI

TL;DR: EventCast是一个将未来事件知识集成到时间序列预测中的模块化框架，专门解决电商在促销活动、节假日等特殊时期的需求预测问题，通过LLM进行事件驱动推理，显著提升预测准确性。


<details>
  <summary>Details</summary>
Motivation: 现有预测系统在闪购、节假日促销和政策干预等高影响时期经常失效，因为这些时期的需求模式会发生突然且不可预测的变化。电商运营需要能够处理这些特殊事件的预测系统。

Method: EventCast利用LLM处理非结构化业务数据（如营销活动、节假日安排、卖家激励），将其转换为可解释的文本摘要，然后将这些摘要与历史需求特征通过双塔架构融合，实现准确、可解释且可扩展的预测。

Result: 在4个国家160个地区10个月的真实电商场景中，EventCast相比无事件知识的变体在MAE和MSE上分别提升86.9%和97.7%，相比最佳工业基线在事件驱动时期分别减少MAE 57.0%和MSE 83.3%。

Conclusion: EventCast提供了一个实用的解决方案，通过将LLM用于事件驱动推理而非直接数值预测，显著提升了动态电商环境中的运营决策能力，已自2025年3月起部署到实际工业管道中。

Abstract: Demand forecasting is a cornerstone of e-commerce operations, directly impacting inventory planning and fulfillment scheduling. However, existing forecasting systems often fail during high-impact periods such as flash sales, holiday campaigns, and sudden policy interventions, where demand patterns shift abruptly and unpredictably. In this paper, we introduce EventCast, a modular forecasting framework that integrates future event knowledge into time-series prediction. Unlike prior approaches that ignore future interventions or directly use large language models (LLMs) for numerical forecasting, EventCast leverages LLMs solely for event-driven reasoning. Unstructured business data, which covers campaigns, holiday schedules, and seller incentives, from existing operational databases, is processed by an LLM that converts it into interpretable textual summaries leveraging world knowledge for cultural nuances and novel event combinations. These summaries are fused with historical demand features within a dual-tower architecture, enabling accurate, explainable, and scalable forecasts. Deployed on real-world e-commerce scenarios spanning 4 countries of 160 regions over 10 months, EventCast achieves up to 86.9% and 97.7% improvement on MAE and MSE compared to the variant without event knowledge, and reduces MAE by up to 57.0% and MSE by 83.3% versus the best industrial baseline during event-driven periods. EventCast has deployed into real-world industrial pipelines since March 2025, offering a practical solution for improving operational decision-making in dynamic e-commerce environments.

</details>


### [336] [Geo-Code: A Code Framework for Reverse Code Generation from Geometric Images Based on Two-Stage Multi-Agent Evolution](https://arxiv.org/abs/2602.07749)
*Zhenyu Wu,Yanxi Long,Jian Li,Hua Huang*

Main category: cs.AI

TL;DR: Geo-coder是首个基于多智能体系统的几何图像逆编程框架，通过像素级锚定和度量驱动代码演化实现精确几何重建，在几何重构精度和视觉一致性方面领先，并开源了数据集和模型。


<details>
  <summary>Details</summary>
Motivation: 当前逆图形方法在重建复杂几何细节时面临巨大挑战，常导致关键几何约束丢失或结构失真。程序代码作为连接视觉与逻辑的桥梁，可为增强大模型多模态推理能力提供可行监督方法，但现有方法难以准确重建几何细节。

Method: 提出Geo-coder——首个基于多智能体系统的几何图像逆编程框架。方法创新性地将过程解耦为两个阶段：1) 通过像素级锚定进行几何建模，利用视觉算子和大模型的互补优势精确捕捉像素坐标和视觉属性；2) 引入合成-渲染-验证闭环，通过双向视觉反馈驱动代码自校正。

Result: 大量实验表明，Geo-coder在几何重建精度和视觉一致性方面取得显著领先。通过有效保留核心几何语义，重建图像在多模态推理任务中表现与原始图像相当，验证了框架的鲁棒性。开源了包含1500+样本的Geo-coder数据集和GeocodeLM模型。

Conclusion: Geo-coder成功解决了逆图形方法在复杂几何细节重建中的瓶颈问题，通过多智能体系统和两阶段解耦方法实现了精确的几何建模和代码演化，为后续研究提供了坚实的数据和模型基础。

Abstract: Program code serves as a bridge linking vision and logic, providing a feasible supervisory approach for enhancing the multimodal reasoning capability of large models through geometric operations such as auxiliary line construction and perspective transformation. Nevertheless, current inverse graphics methods face tremendous challenges in accurately reconstructing complex geometric details, which often results in the loss of key geometric constraints or structural distortion. To address this bottleneck, we propose Geo-coder -- the first inverse programming framework for geometric images based on a multi-agent system. Our method innovatively decouples the process into geometric modeling via pixel-wise anchoring and metric-driven code evolution: Stage 1 leverages the complementary advantages of visual operators and large models to achieve precise capture of pixel coordinates and visual attributes; Stage 2 introduces a synthesis-rendering-validation closed loop, where bidirectional visual feedback drives the self-correction of code. Extensive experiments demonstrate that Geo-coder achieves a substantial lead in both geometric reconstruction accuracy and visual consistency. Notably, by effectively preserving the core geometric semantics, the images reconstructed with our method exhibit equivalent performance to the original ones in multimodal reasoning tasks, which fully validates the robustness of the framework. Finally, to further reduce research costs, we have open-sourced the Geo-coder dataset constructed on the GeoCode framework, which contains more than 1,500 samples. On this basis, we have also open-sourced the GeocodeLM model, laying a solid data and model foundation for subsequent research in this field.

</details>


### [337] [Humanizing AI Grading: Student-Centered Insights on Fairness, Trust, Consistency and Transparency](https://arxiv.org/abs/2602.07754)
*Bahare Riahi,Veronica Catete*

Main category: cs.AI

TL;DR: 研究调查本科生对AI评分系统的看法，发现学生对AI缺乏情境理解和个性化表示担忧，建议AI系统应体现人类判断、灵活性和同理心，作为人类监督下的补充工具。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探讨AI评分系统在计算机科学课程中的应用，特别关注其伦理维度，包括公平性、信任度、一致性和透明度，以了解学生对AI评分的接受程度和担忧。

Method: 采用Jobin（2019）的伦理原则框架，在本科生计算机科学课程（n=27）中，通过比较AI生成的反馈与原始人工评分反馈，研究学生对块编程期末项目的AI评分系统的看法。

Result: 研究发现学生对AI评分系统的主要担忧包括缺乏情境理解和个性化能力。学生认为AI系统在理解编程作业的具体背景和提供个性化反馈方面存在不足。

Conclusion: 结论是公平可信的AI系统应反映人类判断、灵活性和同理心，作为人类监督下的补充工具。该研究通过放大学生声音和为AI人性化设计提供原则，为以伦理为中心的评估实践做出贡献。

Abstract: This study investigates students' perceptions of Artificial Intelligence (AI) grading systems in an undergraduate computer science course (n = 27), focusing on a block-based programming final project. Guided by the ethical principles framework articulated by Jobin (2019), our study examines fairness, trust, consistency, and transparency in AI grading by comparing AI-generated feedback with original human-graded feedback. Findings reveal concerns about AI's lack of contextual understanding and personalization. We recommend that equitable and trustworthy AI systems reflect human judgment, flexibility, and empathy, serving as supplementary tools under human oversight. This work contributes to ethics-centered assessment practices by amplifying student voices and offering design principles for humanizing AI in designed learning environments.

</details>


### [338] [Learning to Continually Learn via Meta-learning Agentic Memory Designs](https://arxiv.org/abs/2602.07755)
*Yiming Xiong,Shengran Hu,Jeff Clune*

Main category: cs.AI

TL;DR: ALMA框架通过元学习自动设计记忆模块，替代人工设计的固定记忆系统，使智能体系统能够在不同领域持续学习


<details>
  <summary>Details</summary>
Motivation: 基础模型的无状态特性限制了智能体系统的持续学习能力，而现有的人工设计记忆模块无法适应现实任务的多样性和非平稳性，需要更灵活的自动化记忆设计方法

Method: 提出ALMA框架，使用元代理在开放式空间中搜索以可执行代码表达的记忆设计，理论上可以发现任意记忆设计，包括数据库模式及其检索和更新机制

Result: 在四个顺序决策制定领域的广泛实验表明，学习到的记忆设计在所有基准测试中都优于最先进的人工设计记忆，实现了更有效和高效的经验学习

Conclusion: ALMA代表了向自我改进AI系统迈出的一步，这些系统学会成为适应性的持续学习者，前提是安全地开发和部署

Abstract: The statelessness of foundation models bottlenecks agentic systems' ability to continually learn, a core capability for long-horizon reasoning and adaptation. To address this limitation, agentic systems commonly incorporate memory modules to retain and reuse past experience, aiming for continual learning during test time. However, most existing memory designs are human-crafted and fixed, which limits their ability to adapt to the diversity and non-stationarity of real-world tasks. In this paper, we introduce ALMA (Automated meta-Learning of Memory designs for Agentic systems), a framework that meta-learns memory designs to replace hand-engineered memory designs, therefore minimizing human effort and enabling agentic systems to be continual learners across diverse domains. Our approach employs a Meta Agent that searches over memory designs expressed as executable code in an open-ended manner, theoretically allowing the discovery of arbitrary memory designs, including database schemas as well as their retrieval and update mechanisms. Extensive experiments across four sequential decision-making domains demonstrate that the learned memory designs enable more effective and efficient learning from experience than state-of-the-art human-crafted memory designs on all benchmarks. When developed and deployed safely, ALMA represents a step toward self-improving AI systems that learn to be adaptive, continual learners.

</details>


### [339] [Disentangled Instrumental Variables for Causal Inference with Networked Observational Data](https://arxiv.org/abs/2602.07765)
*Zhirong Huang,Debo Cheng,Guixian Zhang,Yi Wang,Jiuyong Li,Shichao Zhang*

Main category: cs.AI

TL;DR: 提出DisIV框架，通过结构解耦从网络数据中提取个体特异性成分作为潜在工具变量，解决网络数据中工具变量外生性假设的挑战。


<details>
  <summary>Details</summary>
Motivation: 在网络数据中，工具变量的严格外生性假设面临重大挑战。现有方法在恢复工具变量时通常依赖邻居信息建模，这不可避免地混合了共享环境引起的内生相关性和个体特异性外生变异，导致所得工具变量继承了对未观测混杂因素的依赖并违反外生性。

Method: 提出DisIV（解耦工具变量）框架，利用网络同质性作为归纳偏置，采用结构解耦机制提取个体特异性成分作为潜在工具变量。通过显式的正交性和排除条件约束提取工具变量的因果有效性。

Result: 在真实世界数据集上的大量半合成实验表明，DisIV在网络诱导混杂下的因果效应估计中始终优于最先进的基线方法。

Conclusion: DisIV框架成功解决了网络数据中工具变量外生性假设的挑战，通过结构解耦提取个体特异性成分作为有效工具变量，显著提升了因果效应估计的准确性。

Abstract: Instrumental variables (IVs) are crucial for addressing unobservable confounders, yet their stringent exogeneity assumptions pose significant challenges in networked data. Existing methods typically rely on modelling neighbour information when recovering IVs, thereby inevitably mixing shared environment-induced endogenous correlations and individual-specific exogenous variation, leading the resulting IVs to inherit dependence on unobserved confounders and to violate exogeneity. To overcome this challenge, we propose $\underline{Dis}$entangled $\underline{I}$nstrumental $\underline{V}$ariables (DisIV) framework, a novel method for causal inference based on networked observational data with latent confounders. DisIV exploits network homogeneity as an inductive bias and employs a structural disentanglement mechanism to extract individual-specific components that serve as latent IVs. The causal validity of the extracted IVs is constrained through explicit orthogonality and exclusion conditions. Extensive semi-synthetic experiments on real-world datasets demonstrate that DisIV consistently outperforms state-of-the-art baselines in causal effect estimation under network-induced confounding.

</details>


### [340] [Do Multi-Agents Dream of Electric Screens? Achieving Perfect Accuracy on AndroidWorld Through Task Decomposition](https://arxiv.org/abs/2602.07787)
*Pierre-Louis Favreau,Jean-Pierre Lo,Clement Guiguet,Charles Simon-Meunier,Nicolas Dehandschoewercker,Allen G. Roush,Judah Goldfeder,Ravid Shwartz-Ziv*

Main category: cs.AI

TL;DR: Minitap是一个多智能体系统，在AndroidWorld基准测试中达到100%成功率，首次完全解决所有116个任务，超越人类表现（80%）。


<details>
  <summary>Details</summary>
Motivation: 单智能体架构在移动设备任务执行中存在三个主要问题：混合推理轨迹导致的上下文污染、文本输入失败未被检测、以及无逃脱的重复动作循环。这些限制了自动化系统的性能。

Method: 通过三个针对性机制：1）六个专门智能体的认知分离；2）基于设备状态的文本输入确定性后验证；3）检测循环并触发策略改变的元认知推理。

Result: 在AndroidWorld基准测试中实现100%成功率，首次完全解决所有116个任务。消融实验显示：多智能体分解贡献+21分，验证执行+7分，元认知+9分。

Conclusion: Minitap通过多智能体架构、验证执行和元认知推理，成功解决了移动设备任务自动化的关键挑战，超越了人类表现，并作为开源软件发布。

Abstract: We present Minitap, a multi-agent system that achieves 100% success on the AndroidWorld benchmark, the first to fully solve all 116 tasks and surpassing human performance (80%). We first analyze why single-agent architectures fail: context pollution from mixed reasoning traces, silent text input failures undetected by the agent, and repetitive action loops without escape. Minitap addresses each failure through targeted mechanisms: cognitive separation across six specialized agents, deterministic post-validation of text input against device state, and meta-cognitive reasoning that detects cycles and triggers strategy changes. Ablations show multi-agent decomposition contributes +21 points over single-agent baselines; verified execution adds +7 points; meta-cognition adds +9 points. We release Minitap as open-source software. https://github.com/minitap-ai/mobile-use

</details>


### [341] [Data Darwinism Part I: Unlocking the Value of Scientific Data for Pre-training](https://arxiv.org/abs/2602.07824)
*Yiwei Qin,Zhen Huang,Tiantian Mi,Weiye Si,Chenyang Zhou,Qipeng Guo,Siyuan Feng,Pengfei Liu*

Main category: cs.AI

TL;DR: 提出Data Darwinism十级分类法，通过数据-模型协同进化提升基础模型性能，在科学文献上验证了该方法，构建了900B token的Darwin-Science语料库，通过生成式精炼和认知补全显著提升模型表现。


<details>
  <summary>Details</summary>
Motivation: 数据质量决定基础模型性能，但缺乏系统化的数据处理框架。需要建立数据与模型协同进化的理论框架，使高级模型能为下一代系统生成更优质的数据。

Method: 提出Data Darwinism十级分类法(L0-L9)，在科学文献上构建Darwin-Science语料库(900B token)。使用前沿LLM进行L4(生成式精炼)和L5(认知补全)处理，解释推理过程和术语。从头训练daVinci-origin-3B/7B模型作为无污染基线，然后进行600B token的继续预训练。

Result: Darwin-Science模型在20多个基准测试中分别比基线提升+2.12(3B)和+2.95(7B)分，在领域对齐任务上提升+5.60和+8.40分。从L0到L5的系统性处理带来+1.36的总增益，证实高级处理能释放数据的潜在价值。

Conclusion: Data Darwinism框架有效，数据-模型协同进化能显著提升模型性能。高级数据处理能解锁数据的潜在价值。发布了Darwin-Science语料库和daVinci-origin模型，支持基于原则的协同进化发展。

Abstract: Data quality determines foundation model performance, yet systematic processing frameworks are lacking. We introduce Data Darwinism, a ten-level taxonomy (L0-L9) that conceptualizes data-model co-evolution: advanced models produce superior data for next-generation systems. We validate this on scientific literature by constructing Darwin-Science, a 900B-token corpus (L0-L5). We identify a learnability gap in raw scientific text, which we bridge via L4 (Generative Refinement) and L5 (Cognitive Completion) using frontier LLMs to explicate reasoning and terminology.
  To ensure rigorous attribution, we pre-trained daVinci-origin-3B/7B models from scratch, excluding scientific content to create contamination-free baselines. After 600B tokens of continued pre-training, Darwin-Science outperforms baselines by +2.12 (3B) and +2.95 (7B) points across 20+ benchmarks, rising to +5.60 and +8.40 points on domain-aligned tasks. Systematic progression to L5 yields a +1.36 total gain, confirming that higher-level processing unlocks latent data value. We release the Darwin-Science corpus and daVinci-origin models to enable principled, co-evolutionary development.

</details>


### [342] [Time Series Reasoning via Process-Verifiable Thinking Data Synthesis and Scheduling for Tailored LLM Reasoning](https://arxiv.org/abs/2602.07830)
*Jiahui Zhou,Dan Li,Boxin Li,Xiao Zhang,Erli Meng,Lin Li,Zhuomin Chen,Jian Lou,See-Kiong Ng*

Main category: cs.AI

TL;DR: VeriTime是一个通过数据合成、数据调度和强化学习训练来定制LLM进行时间序列推理的框架，使小型模型能达到或超越大型专有LLM的性能。


<details>
  <summary>Details</summary>
Motivation: 时间序列数据在各领域普遍存在，但利用LLM推理能力处理时间序列任务仍处于早期阶段，主要受限于缺乏精心策划的时间序列CoT训练数据、数据效率低下以及缺乏针对此类数据的RL算法。

Method: 1) 提出数据合成管道，构建带有过程可验证注释的TS-文本多模态数据集；2) 设计数据调度机制，按难度层次和任务分类安排训练样本；3) 开发两阶段强化微调，利用可验证的过程级CoT数据进行细粒度多目标奖励。

Result: VeriTime显著提升了LLM在各种时间序列推理任务上的性能，使紧凑的3B、4B模型能够达到或超越大型专有LLM的推理能力。

Conclusion: VeriTime框架通过系统化的数据合成、调度和强化学习训练，成功解决了时间序列推理中的关键挑战，为小型LLM在时间序列任务上的应用提供了有效解决方案。

Abstract: Time series is a pervasive data type across various application domains, rendering the reasonable solving of diverse time series tasks a long-standing goal. Recent advances in large language models (LLMs), especially their reasoning abilities unlocked through reinforcement learning (RL), have opened new opportunities for tackling tasks with long Chain-of-Thought (CoT) reasoning. However, leveraging LLM reasoning for time series remains in its infancy, hindered by the absence of carefully curated time series CoT data for training, limited data efficiency caused by underexplored data scheduling, and the lack of RL algorithms tailored for exploiting such time series CoT data. In this paper, we introduce VeriTime, a framework that tailors LLMs for time series reasoning through data synthesis, data scheduling, and RL training. First, we propose a data synthesis pipeline that constructs a TS-text multimodal dataset with process-verifiable annotations. Second, we design a data scheduling mechanism that arranges training samples according to a principled hierarchy of difficulty and task taxonomy. Third, we develop a two-stage reinforcement finetuning featuring fine-grained, multi-objective rewards that leverage verifiable process-level CoT data. Extensive experiments show that VeriTime substantially boosts LLM performance across diverse time series reasoning tasks. Notably, it enables compact 3B, 4B models to achieve reasoning capabilities on par with or exceeding those of larger proprietary LLMs.

</details>


### [343] [LQA: A Lightweight Quantized-Adaptive Framework for Vision-Language Models on the Edge](https://arxiv.org/abs/2602.07849)
*Xin Wang,Hualin Zhou,Sheng Guang Wang,Ting Dang,Yu Zhang,Hong Jia,Tao Gu*

Main category: cs.AI

TL;DR: LQA是一个轻量化的量化自适应框架，用于在边缘设备上部署视觉语言模型，通过选择性混合量化和无梯度测试时适应来应对资源限制和分布偏移问题。


<details>
  <summary>Details</summary>
Motivation: 在边缘设备上部署视觉语言模型面临资源限制和分布偏移导致的性能下降问题，现有的测试时适应方法资源消耗过大，不适合边缘设备部署。

Method: 提出了LQA框架，包含选择性混合量化（SHQ）策略和量化无梯度适应机制，结合模态感知量化策略，实现轻量化的测试时适应。

Result: 在合成和真实世界分布偏移实验中，LQA将整体适应性能提升4.5%，内存使用低于全精度模型，比基于梯度的TTA方法内存使用降低高达19.9倍。

Conclusion: LQA为在边缘设备上实现鲁棒、隐私保护和高效的视觉语言模型部署提供了实用路径。

Abstract: Deploying Vision-Language Models (VLMs) on edge devices is challenged by resource constraints and performance degradation under distribution shifts. While test-time adaptation (TTA) can counteract such shifts, existing methods are too resource-intensive for on-device deployment. To address this challenge, we propose LQA, a lightweight, quantized-adaptive framework for VLMs that combines a modality-aware quantization strategy with gradient-free test-time adaptation. We introduce Selective Hybrid Quantization (SHQ) and a quantized, gradient-free adaptation mechanism to enable robust and efficient VLM deployment on resource-constrained hardware. Experiments across both synthetic and real-world distribution shifts show that LQA improves overall adaptation performance by 4.5\%, uses less memory than full-precision models, and significantly outperforms gradient-based TTA methods, achieving up to 19.9$\times$ lower memory usage across seven open-source datasets. These results demonstrate that LQA offers a practical pathway for robust, privacy-preserving, and efficient VLM deployment on edge devices.

</details>


### [344] [Emergent Misalignment is Easy, Narrow Misalignment is Hard](https://arxiv.org/abs/2602.07852)
*Anna Soligo,Edward Turner,Senthooran Rajamanoharan,Neel Nanda*

Main category: cs.AI

TL;DR: 微调大语言模型在狭窄有害数据集上可能导致涌现性错位，使模型在无关场景中给出"邪恶"回应。研究发现通用解决方案比狭窄解决方案更稳定高效，并分离出可监控的通用错位线性表示。


<details>
  <summary>Details</summary>
Motivation: 研究大语言模型在微调过程中出现的涌现性错位现象，专家调查未能预测此结果，表明我们对LLM学习和泛化的归纳偏置理解不足。通过此案例研究探索这些归纳偏置。

Method: 使用涌现性错位作为案例研究，发现不同微调收敛到相同的通用错位线性表示。通过引入KL散度损失学习狭窄解决方案的线性表示，比较两种表示的稳定性、效率和影响力。

Result: 通用错位解决方案比狭窄解决方案损失更低、对扰动更鲁棒、在预训练分布中影响力更大。分离出可用于监控和缓解的通用错位具体线性表示。

Conclusion: 这项工作为研究归纳偏置如何塑造LLM泛化提供了详细案例和初步指标，开源了所有代码、数据集和模型微调，有助于监控和缓解模型错位问题。

Abstract: Finetuning large language models on narrowly harmful datasets can cause them to become emergently misaligned, giving stereotypically `evil' responses across diverse unrelated settings. Concerningly, a pre-registered survey of experts failed to predict this result, highlighting our poor understanding of the inductive biases governing learning and generalisation in LLMs. We use emergent misalignment (EM) as a case study to investigate these inductive biases and find that models can just learn the narrow dataset task, but that the general solution appears to be more stable and more efficient. To establish this, we build on the result that different EM finetunes converge to the same linear representation of general misalignment, which can be used to mediate misaligned behaviour. We find a linear representation of the narrow solution also exists, and can be learned by introducing a KL divergence loss. Comparing these representations reveals that general misalignment achieves lower loss, is more robust to perturbations, and is more influential in the pre-training distribution. This work isolates a concrete representation of general misalignment for monitoring and mitigation. More broadly, it offers a detailed case study and preliminary metrics for investigating how inductive biases shape generalisation in LLMs. We open-source all code, datasets and model finetunes.

</details>


### [345] [ToolSelf: Unifying Task Execution and Self-Reconfiguration via Tool-Driven Intrinsic Adaptation](https://arxiv.org/abs/2602.07883)
*Jingqi Zhou,Sheng Wang,DeZhao Deng,Junwen Lu,Junwei Su,Qintong Li,Jiahui Gao,Hao Wu,Jiyue Jiang,Lingpeng Kong,Chuan Wu*

Main category: cs.AI

TL;DR: ToolSelf：一种让LLM智能体在运行时自我重新配置的新范式，将配置更新抽象为可调用工具，实现任务执行与自我调整的统一，相比静态配置方法平均性能提升24.1%


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的智能体系统受限于静态配置，这些配置在执行前固定，无法适应动态变化的任务环境。依赖人工编排或启发式补丁的方法泛化能力差且优化碎片化。

Method: 提出ToolSelf范式，将配置更新抽象为可调用工具，统一任务执行和自我调整到单一动作空间。设计配置感知两阶段训练（CAT），结合拒绝采样微调和轨迹级强化学习来内化这种元能力。

Result: 在多样化基准测试中，ToolSelf能够媲美专用工作流，同时泛化到新任务，实现平均24.1%的性能提升，展示了真正的自适应性智能体路径。

Conclusion: ToolSelf通过工具驱动的运行时自我重新配置，使智能体从被动执行者转变为任务和自我的双重管理者，为实现真正自适应的智能体系统提供了新方向。

Abstract: Agentic systems powered by Large Language Models (LLMs) have demonstrated remarkable potential in tackling complex, long-horizon tasks. However, their efficacy is fundamentally constrained by static configurations governing agent behaviors, which are fixed prior to execution and fail to adapt to evolving task dynamics. Existing approaches, relying on manual orchestration or heuristic-based patches, often struggle with poor generalization and fragmented optimization. To transcend these limitations, we propose ToolSelf, a novel paradigm enabling tool-driven runtime self-reconfiguration. By abstracting configuration updates as a callable tool, ToolSelf unifies task execution and self-adjustment into a single action space, achieving a phase transition from external rules to intrinsic parameters. Agents can thereby autonomously update their sub-goals and context based on task progression, and correspondingly adapt their strategy and toolbox, transforming from passive executors into dual managers of both task and self. We further devise Configuration-Aware Two-stage Training (CAT), combining rejection sampling fine-tuning with trajectory-level reinforcement learning to internalize this meta-capability. Extensive experiments across diverse benchmarks demonstrate that ToolSelf rivals specialized workflows while generalizing to novel tasks, achieving a 24.1% average performance gain and illuminating a path toward truly self-adaptive agents.

</details>


### [346] [MemFly: On-the-Fly Memory Optimization via Information Bottleneck](https://arxiv.org/abs/2602.07885)
*Zhenyuan Zhang,Xianzhang Jia,Zhiqin Yang,Zhenbo Song,Wei Xue,Sirui Han,Yike Guo*

Main category: cs.AI

TL;DR: MemFly是一个基于信息瓶颈原则的LLM记忆框架，通过梯度自由优化器构建分层记忆结构，结合混合检索机制，在记忆一致性、响应保真度和准确性方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有LLM记忆框架面临一个基本困境：既要高效压缩冗余信息，又要保持精确检索以支持下游任务。需要在信息压缩和检索精度之间找到平衡。

Method: 基于信息瓶颈原则，通过梯度自由优化器最小化压缩熵同时最大化相关熵，构建分层记忆结构。开发混合检索机制，集成语义、符号和拓扑路径，并采用迭代精炼处理复杂多跳查询。

Result: 综合实验表明，MemFly在记忆一致性、响应保真度和准确性方面显著优于最先进的基线方法。

Conclusion: MemFly框架成功解决了LLM记忆系统中信息压缩与精确检索之间的权衡问题，通过信息瓶颈原则和混合检索机制实现了高效且准确的记忆管理。

Abstract: Long-term memory enables large language model agents to tackle complex tasks through historical interactions. However, existing frameworks encounter a fundamental dilemma between compressing redundant information efficiently and maintaining precise retrieval for downstream tasks. To bridge this gap, we propose MemFly, a framework grounded in information bottleneck principles that facilitates on-the-fly memory evolution for LLMs. Our approach minimizes compression entropy while maximizing relevance entropy via a gradient-free optimizer, constructing a stratified memory structure for efficient storage. To fully leverage MemFly, we develop a hybrid retrieval mechanism that seamlessly integrates semantic, symbolic, and topological pathways, incorporating iterative refinement to handle complex multi-hop queries. Comprehensive experiments demonstrate that MemFly substantially outperforms state-of-the-art baselines in memory coherence, response fidelity, and accuracy.

</details>


### [347] [GCN-MPPR: Enhancing the Propagation of Message Passing Neural Networks via Motif-Based Personalized PageRank](https://arxiv.org/abs/2602.07903)
*Mingcan Wang,Junchang Xin,Zhongming Yao,Kaifu Long,Zhiqiong Wang*

Main category: cs.AI

TL;DR: 提出基於motif的個性化PageRank（MPPR）來解決GCNs深度受限問題，通過考慮高階關係改進消息傳遞過程


<details>
  <summary>Details</summary>
Motivation: 現有基於消息傳遞神經網絡（MPNNs）的圖算法通常只能傳播到有限的鄰域深度，主要由於過平滑問題。現有方法在準確性、穩定性和計算成本方面存在限制，且忽略了高階關係

Method: 提出motif-based personalized PageRank（MPPR）來衡量節點間的影響力，考慮高階motif關係。將MPPR應用於GCNs的消息傳遞過程，在高層次指導消息傳遞

Result: 實驗結果顯示該方法在準確性、穩定性和時間消耗方面優於幾乎所有基線方法。該方法可作為支撐幾乎所有GCN任務的組件，實驗中展示了DGCRL應用

Conclusion: 提出的MPPR方法有效解決了GCNs深度受限問題，通過考慮高階關係改進了消息傳遞，在性能、穩定性和效率方面表現優異，具有廣泛的應用潛力

Abstract: The algorithms based on message passing neural networks (MPNNs) on graphs have recently achieved great success for various graph applications. However, studies find that these methods always propagate the information to very limited neighborhoods with shallow depth, particularly due to over-smoothing. That means most of the existing MPNNs fail to be so `deep'. Although some previous work tended to handle this challenge via optimization- or structure-level remedies, the overall performance of GCNs still suffers from limited accuracy, poor stability, and unaffordable computational cost. Moreover, neglect of higher-order relationships during the propagation of MPNNs has further limited the performance of them. To overcome these challenges, a novel variant of PageRank named motif-based personalized PageRank (MPPR) is proposed to measure the influence of one node to another on the basis of considering higher-order motif relationships. Secondly, the MPPR is utilized to the message passing process of GCNs, thereby guiding the message passing process at a relatively `high' level. The experimental results show that the proposed method outperforms almost all of the baselines on accuracy, stability, and time consumption. Additionally, the proposed method can be considered as a component that can underpin almost all GCN tasks, with DGCRL being demonstrated in the experiment. The anonymous code repository is available at: https://anonymous.4open.science/r/GCN-MPPR-AFD6/.

</details>


### [348] [MedCoG: Maximizing LLM Inference Density in Medical Reasoning via Meta-Cognitive Regulation](https://arxiv.org/abs/2602.07905)
*Yu Zhao,Hao Guan,Yongcheng Jing,Ying Zhang,Dacheng Tao*

Main category: cs.AI

TL;DR: 提出MedCoG，一种基于元认知调节的医学推理代理，通过动态评估任务复杂度、熟悉度和知识密度来优化知识使用，提高推理效率5.5倍


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在医学推理中面临推理扩展定律下的收益递减问题，现有方法增加各种知识但成本效益不明确，需要更有效的推理调节机制

Method: 提出MedCoG（Medical Meta-Cognition Agent with Knowledge Graph），利用元认知评估任务复杂度、熟悉度和知识密度，动态调节程序性、情景性和事实性知识的使用，实现按需推理

Result: 在五个困难医学基准测试中验证有效性和效率，推理密度提高5.5倍，Oracle研究显示元认知调节具有显著潜力

Conclusion: 元认知调节能够有效缓解推理扩展定律问题，通过减少成本和过滤干扰知识来提高医学推理的准确性和效率

Abstract: Large Language Models (LLMs) have shown strong potential in complex medical reasoning yet face diminishing gains under inference scaling laws. While existing studies augment LLMs with various knowledge types, it remains unclear how effectively the additional costs translate into accuracy. In this paper, we explore how meta-cognition of LLMs, i.e., their self-awareness of their own knowledge states, can regulate the reasoning process. Specifically, we propose MedCoG, a Medical Meta-Cognition Agent with Knowledge Graph, where the meta-cognitive assessments of task complexity, familiarity, and knowledge density dynamically regulate utilization of procedural, episodic, and factual knowledge. The LLM-centric on-demand reasoning aims to mitigate scaling laws by (1) reducing costs via avoiding indiscriminate scaling, (2) improving accuracy via filtering out distractive knowledge. To validate this, we empirically characterize the scaling curve and introduce inference density to quantify inference efficiency, defined as the ratio of theoretically effective cost to actual cost. Experiments demonstrate the effectiveness and efficiency of MedCoG on five hard sets of medical benchmarks, yielding 5.5x inference density. Furthermore, the Oracle study highlights the significant potential of meta-cognitive regulation.

</details>


### [349] [Selective Fine-Tuning for Targeted and Robust Concept Unlearning](https://arxiv.org/abs/2602.07919)
*Mansi,Avinash Kori,Francesca Toni,Soteris Demetriou*

Main category: cs.AI

TL;DR: TRUST是一种新颖的扩散模型概念遗忘方法，通过动态估计目标概念神经元并结合Hessian正则化进行选择性微调，能够高效遗忘单个概念、概念组合和条件概念，同时保持生成质量。


<details>
  <summary>Details</summary>
Motivation: 文本引导扩散模型易被滥用生成有害内容，现有概念遗忘方法要么只能处理单个概念，要么需要全模型微调计算成本高，而静态概念定位方法效果不佳。

Method: 提出TRUST方法：1) 动态估计目标概念神经元；2) 通过选择性微调遗忘这些神经元；3) 使用Hessian正则化增强鲁棒性。

Result: 实验表明TRUST能有效对抗对抗性提示，显著保持生成质量，比SOTA方法更快，且能遗忘单个概念、概念组合和条件概念，无需特定正则化。

Conclusion: TRUST提供了一种高效、鲁棒的概念遗忘解决方案，解决了现有方法在计算成本、概念组合处理和保护生成质量方面的局限性。

Abstract: Text guided diffusion models are used by millions of users, but can be easily exploited to produce harmful content. Concept unlearning methods aim at reducing the models' likelihood of generating harmful content. Traditionally, this has been tackled at an individual concept level, with only a handful of recent works considering more realistic concept combinations. However, state of the art methods depend on full finetuning, which is computationally expensive. Concept localisation methods can facilitate selective finetuning, but existing techniques are static, resulting in suboptimal utility. In order to tackle these challenges, we propose TRUST (Targeted Robust Selective fine Tuning), a novel approach for dynamically estimating target concept neurons and unlearning them through selective finetuning, empowered by a Hessian based regularization. We show experimentally, against a number of SOTA baselines, that TRUST is robust against adversarial prompts, preserves generation quality to a significant degree, and is also significantly faster than the SOTA. Our method achieves unlearning of not only individual concepts but also combinations of concepts and conditional concepts, without any specific regularization.

</details>


### [350] [MePo: Meta Post-Refinement for Rehearsal-Free General Continual Learnin](https://arxiv.org/abs/2602.07940)
*Guanglong Sun,Hongwei Yan,Liyuan Wang,Zhiqi Kang,Shuang Cui,Hang Su,Jun Zhu,Yi Zhong*

Main category: cs.AI

TL;DR: MePo是一种基于预训练模型的通用持续学习方法，通过元后精炼策略提升模型在动态环境中的适应能力，无需排练即可显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 智能系统需要持续学习复杂、动态的环境并实时响应，但现有基于预训练模型的持续学习方法在处理混合信息流时表现不佳，需要更好的方法来解决通用持续学习中的实际挑战。

Method: 提出Meta Post-Refinement (MePo)方法：1）从预训练数据构建伪任务序列；2）开发双层元学习范式精炼预训练骨干网络；3）初始化元协方差矩阵作为表示空间的参考几何结构；4）利用二阶统计量进行鲁棒输出对齐。

Result: MePo在多种GCL基准测试和预训练检查点上取得显著性能提升，在CIFAR-100、ImageNet-R和CUB-200上分别达到15.10%、13.36%和12.56%的改进，且无需排练机制。

Conclusion: MePo作为一种即插即用策略，通过元后精炼有效提升了预训练模型在通用持续学习任务中的表现，为解决动态环境中的持续学习问题提供了创新解决方案。

Abstract: To cope with uncertain changes of the external world, intelligent systems must continually learn from complex, evolving environments and respond in real time. This ability, collectively known as general continual learning (GCL), encapsulates practical challenges such as online datastreams and blurry task boundaries. Although leveraging pretrained models (PTMs) has greatly advanced conventional continual learning (CL), these methods remain limited in reconciling the diverse and temporally mixed information along a single pass, resulting in sub-optimal GCL performance. Inspired by meta-plasticity and reconstructive memory in neuroscience, we introduce here an innovative approach named Meta Post-Refinement (MePo) for PTMs-based GCL. This approach constructs pseudo task sequences from pretraining data and develops a bi-level meta-learning paradigm to refine the pretrained backbone, which serves as a prolonged pretraining phase but greatly facilitates rapid adaptation of representation learning to downstream GCL tasks. MePo further initializes a meta covariance matrix as the reference geometry of pretrained representation space, enabling GCL to exploit second-order statistics for robust output alignment. MePo serves as a plug-in strategy that achieves significant performance gains across a variety of GCL benchmarks and pretrained checkpoints in a rehearsal-free manner (e.g., 15.10\%, 13.36\%, and 12.56\% on CIFAR-100, ImageNet-R, and CUB-200 under Sup-21/1K). Our source code is available at \href{https://github.com/SunGL001/MePo}{MePo}

</details>


### [351] [IV Co-Scientist: Multi-Agent LLM Framework for Causal Instrumental Variable Discovery](https://arxiv.org/abs/2602.07943)
*Ivaxi Sheth,Zhijing Jin,Bryan Wilder,Dominik Janzing,Mario Fritz*

Main category: cs.AI

TL;DR: LLMs能够帮助发现有效的工具变量，通过两阶段评估框架验证其能力，并开发了IV Co-Scientist多智能体系统来提出、批判和优化工具变量。


<details>
  <summary>Details</summary>
Motivation: 在因果推断中，工具变量的识别需要跨学科知识、创造力和上下文理解，这是一个非平凡的任务。本文旨在探索大型语言模型是否能够辅助这一任务。

Method: 采用两阶段评估框架：首先测试LLMs能否从文献中恢复已建立的工具变量；其次评估LLMs能否识别和避免已被实证或理论否定的工具变量。基于此开发了IV Co-Scientist多智能体系统，并提出了一种在没有真实值情况下评估一致性的统计检验。

Result: 结果表明LLMs有潜力从大型观测数据库中识别有效的工具变量，能够复制标准推理并避免无效的工具变量。

Conclusion: LLMs在工具变量发现方面具有潜力，IV Co-Scientist系统能够有效辅助工具变量的识别过程，为因果推断提供了新的自动化工具。

Abstract: In the presence of confounding between an endogenous variable and the outcome, instrumental variables (IVs) are used to isolate the causal effect of the endogenous variable. Identifying valid instruments requires interdisciplinary knowledge, creativity, and contextual understanding, making it a non-trivial task. In this paper, we investigate whether large language models (LLMs) can aid in this task. We perform a two-stage evaluation framework. First, we test whether LLMs can recover well-established instruments from the literature, assessing their ability to replicate standard reasoning. Second, we evaluate whether LLMs can identify and avoid instruments that have been empirically or theoretically discredited. Building on these results, we introduce IV Co-Scientist, a multi-agent system that proposes, critiques, and refines IVs for a given treatment-outcome pair. We also introduce a statistical test to contextualize consistency in the absence of ground truth. Our results show the potential of LLMs to discover valid instrumental variables from a large observational database.

</details>


### [352] [LOCA-bench: Benchmarking Language Agents Under Controllable and Extreme Context Growth](https://arxiv.org/abs/2602.07962)
*Weihao Zeng,Yuzhen Huang,Junxian He*

Main category: cs.AI

TL;DR: LOCA-bench是一个用于评估长上下文语言代理的基准测试，通过自动化环境状态控制来调节上下文长度，评估模型在各种上下文管理策略下的表现。


<details>
  <summary>Details</summary>
Motivation: 现有长上下文基准主要关注单步设置下的信息检索能力，而现实场景中语言模型需要作为代理在动态增长的环境中执行多步任务，现有评估方法无法充分评估这种能力。

Method: LOCA-bench通过自动化环境状态控制来调节代理的上下文长度，保持任务语义不变的同时可无限扩展上下文长度，评估语言代理作为模型和脚手架组合的性能。

Result: 随着环境状态复杂度增加，代理性能普遍下降，但高级上下文管理技术能显著提高整体成功率。

Conclusion: LOCA-bench为评估长上下文、代理式场景中的模型和脚手架提供了平台，开源代码促进相关研究发展。

Abstract: Large language models (LLMs) are increasingly capable of carrying out long-running, real-world tasks. However, as the amount of context grows, their reliability often deteriorates, a phenomenon known as "context rot". Existing long-context benchmarks primarily focus on single-step settings that evaluate a model's ability to retrieve information from a long snippet. In realistic scenarios, however, LLMs often need to act as agents that explore environments, follow instructions and plans, extract useful information, and predict correct actions under a dynamically growing context. To assess language agents in such settings, we introduce LOCA-bench (a benchmark for LOng-Context Agents). Given a task prompt, LOCA-bench leverages automated and scalable control of environment states to regulate the agent's context length. This design enables LOCA-bench to extend the context length potentially to infinity in a controlled way while keeping the underlying task semantics fixed. LOCA-bench evaluates language agents as a combination of models and scaffolds, including various context management strategies. While agent performance generally degrades as the environment states grow more complex, advanced context management techniques can substantially improve the overall success rate. We open-source LOCA-bench to provide a platform for evaluating models and scaffolds in long-context, agentic scenarios: https://github.com/hkust-nlp/LOCA-bench

</details>


### [353] [Accelerating Social Science Research via Agentic Hypothesization and Experimentation](https://arxiv.org/abs/2602.07983)
*Jishu Sen Gupta,Harini SI,Somesh Kumar Singh,Syed Mohamad Tawseeq,Yaman Kumar Singla,David Doermann,Rajiv Ratn Shah,Balaji Krishnamurthy*

Main category: cs.AI

TL;DR: EXPERIGEN是一个支持端到端科学发现的智能体框架，通过生成器-实验者的两阶段搜索，在多个领域发现比现有方法多2-4倍的统计显著假设，预测性能提升7-17%，并通过专家评审和真实A/B测试验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 当前数据驱动的社会科学研究过程缓慢，依赖观察、假设生成和实验验证的迭代循环。虽然近期数据驱动方法加速了部分过程，但未能支持端到端的科学发现。需要填补这一空白，实现从数据到科学发现的完整自动化流程。

Method: 提出EXPERIGEN框架，采用受贝叶斯优化启发的两阶段搜索：生成器提出候选假设，实验者进行实证评估。框架支持多模态和关系型数据集等复杂数据机制，并通过专家评审和真实A/B测试验证假设质量。

Result: 1) 在多个领域发现比现有方法多2-4倍的统计显著假设，预测性能提升7-17%；2) 专家评审显示88%的假设具有中等或强新颖性，70%被认为有影响力且值得追求，质量相当于高年级研究生研究水平；3) 首次对LLM生成假设进行A/B测试，获得p<1e-6的统计显著结果和344%的大效应量。

Conclusion: EXPERIGEN框架成功实现了端到端的科学发现自动化，不仅统计性能优越，生成的假设还具有新颖性、实证基础和可操作性，能够推动真正的科学进步。该框架为数据驱动的社会科学研究提供了新的范式。

Abstract: Data-driven social science research is inherently slow, relying on iterative cycles of observation, hypothesis generation, and experimental validation. While recent data-driven methods promise to accelerate parts of this process, they largely fail to support end-to-end scientific discovery. To address this gap, we introduce EXPERIGEN, an agentic framework that operationalizes end-to-end discovery through a Bayesian optimization inspired two-phase search, in which a Generator proposes candidate hypotheses and an Experimenter evaluates them empirically. Across multiple domains, EXPERIGEN consistently discovers 2-4x more statistically significant hypotheses that are 7-17 percent more predictive than prior approaches, and naturally extends to complex data regimes including multimodal and relational datasets. Beyond statistical performance, hypotheses must be novel, empirically grounded, and actionable to drive real scientific progress. To evaluate these qualities, we conduct an expert review of machine-generated hypotheses, collecting feedback from senior faculty. Among 25 reviewed hypotheses, 88 percent were rated moderately or strongly novel, 70 percent were deemed impactful and worth pursuing, and most demonstrated rigor comparable to senior graduate-level research. Finally, recognizing that ultimate validation requires real-world evidence, we conduct the first A/B test of LLM-generated hypotheses, observing statistically significant results with p less than 1e-6 and a large effect size of 344 percent.

</details>


### [354] [Towards Adaptive, Scalable, and Robust Coordination of LLM Agents: A Dynamic Ad-Hoc Networking Perspective](https://arxiv.org/abs/2602.08009)
*Rui Li,Zeyu Zhang,Xiaohe Bo,Quanyu Dai,Chaozhuo Li,Feng Wen,Xu Chen*

Main category: cs.AI

TL;DR: RAPS：基于信誉感知的发布-订阅范式，用于实现LLM多智能体的自适应、可扩展和鲁棒协调


<details>
  <summary>Details</summary>
Motivation: 基于LLM的多智能体架构通过精心设计的协作展现了群体智能的潜力，但手动编排的工作量巨大，迫切需要自动化设计智能体工作流。如何在大规模智能体之间建立自适应、可靠的通信是一个尚未解决的难题。

Method: 提出RAPS（信誉感知发布-订阅范式），基于分布式发布-订阅协议，让LLM智能体基于声明的意图而非预定义拓扑交换消息。包含两个核心覆盖层：1）反应式订阅，使智能体动态优化意图；2）贝叶斯信誉，为每个智能体提供本地监控机制来检测和隔离恶意节点。

Result: 在五个基准测试上的广泛实验表明，该设计在统一的多智能体协调框架中有效调和了自适应性、可扩展性和鲁棒性。

Conclusion: RAPS通过将智能体协调问题重新定义为动态自组织网络问题，并引入信誉感知的发布-订阅范式，成功实现了LLM多智能体的自适应、可扩展和鲁棒协调。

Abstract: Multi-agent architectures built on large language models (LLMs) have demonstrated the potential to realize swarm intelligence through well-crafted collaboration. However, the substantial burden of manual orchestration inherently raises an imperative to automate the design of agentic workflows. We frame such an agent coordination challenge as a classic problem in dynamic ad-hoc networking: How to establish adaptive and reliable communication among a scalable number of agentic hosts? In response to this unresolved dilemma, we introduce RAPS, a reputation-aware publish-subscribe paradigm for adaptive, scalable, and robust coordination of LLM agents. RAPS is grounded in the Distributed Publish-Subscribe Protocol, allowing LLM agents to exchange messages based on their declared intents rather than predefined topologies. Beyond this substrate, RAPS further incorporates two coherent overlays: (i) Reactive Subscription, enabling agents to dynamically refine their intents; and (ii) Bayesian Reputation, empowering each agent with a local watchdog to detect and isolate malicious peers. Extensive experiments over five benchmarks showcase that our design effectively reconciles adaptivity, scalability, and robustness in a unified multi-agent coordination framework.

</details>


### [355] [Small Agent Group is the Future of Digital Health](https://arxiv.org/abs/2602.08013)
*Yuqiao Meng,Luoxi Tang,Dazheng Zhang,Rafael Brens,Elvys J. Romero,Nancy Guo,Safa Elkefi,Zhaohan Xi*

Main category: cs.AI

TL;DR: SAG（小型智能体组）通过协作推理机制，在临床场景中超越单一大型模型，实现效果、可靠性和部署成本的最佳平衡。


<details>
  <summary>Details</summary>
Motivation: 当前数字健康领域过度依赖"规模优先"的LLM范式，但临床实际需求不仅需要效果，还需要可靠性和合理的部署成本。临床决策本质上是协作过程，因此需要挑战单一模型扩展的范式。

Method: 提出SAG（Small Agent Group）方法，从单一模型智能转向集体专业知识，通过协作审议过程分配推理、循证分析和关键审核任务。

Result: SAG在效果、可靠性和部署成本等多项临床指标上均优于单一大型模型，无论是否使用额外优化或检索增强生成技术。

Conclusion: SAG的协同推理可以替代模型参数增长，为数字健康提供可扩展的解决方案，更好地平衡效果、可靠性和部署效率。

Abstract: The rapid adoption of large language models (LLMs) in digital health has been driven by a "scaling-first" philosophy, i.e., the assumption that clinical intelligence increases with model size and data. However, real-world clinical needs include not only effectiveness, but also reliability and reasonable deployment cost. Since clinical decision-making is inherently collaborative, we challenge the monolithic scaling paradigm and ask whether a Small Agent Group (SAG) can support better clinical reasoning. SAG shifts from single-model intelligence to collective expertise by distributing reasoning, evidence-based analysis, and critical audit through a collaborative deliberation process. To assess the clinical utility of SAG, we conduct extensive evaluations using diverse clinical metrics spanning effectiveness, reliability, and deployment cost. Our results show that SAG achieves superior performance compared to a single giant model, both with and without additional optimization or retrieval-augmented generation. These findings suggest that the synergistic reasoning represented by SAG can substitute for model parameter growth in clinical settings. Overall, SAG offers a scalable solution to digital health that better balances effectiveness, reliability, and deployment efficiency.

</details>


### [356] [Structure-Aware Robust Counterfactual Explanations via Conditional Gaussian Network Classifiers](https://arxiv.org/abs/2602.08021)
*Zhan-Yi Liao,Jaewon Yoo,Hao-Tsung Yang,Po-An Chen*

Main category: cs.AI

TL;DR: 提出基于条件高斯网络分类器的结构感知、鲁棒性导向的反事实解释方法，通过DAG编码特征依赖关系，采用收敛保证的切割集程序进行对抗优化，使用分段McCormick松弛将非凸二次问题转化为MILP确保全局最优性。


<details>
  <summary>Details</summary>
Motivation: 反事实解释是XAI的核心技术，用于解释模型决策并提供可操作的替代方案。现有方法通常需要额外约束来确保与模型结构假设的一致性，且在处理特征依赖关系和非凸优化方面存在挑战。

Method: 基于条件高斯网络分类器（CGNC），利用其生成式结构和DAG编码特征条件依赖关系；采用收敛保证的切割集程序作为对抗优化框架；应用分段McCormick松弛将非凸二次问题转化为混合整数线性规划（MILP）。

Result: 实验结果表明该方法实现了强鲁棒性，直接全局优化原始公式提供了特别稳定和高效的结果。该方法可扩展到更复杂的约束设置。

Conclusion: 提出的框架为在非凸二次公式下进行反事实推理的未来进展奠定了基础，通过结构感知和鲁棒性导向的方法，为反事实解释提供了更可靠和可扩展的解决方案。

Abstract: Counterfactual explanation (CE) is a core technique in explainable artificial intelligence (XAI), widely used to interpret model decisions and suggest actionable alternatives. This work presents a structure-aware and robustness-oriented counterfactual search method based on the conditional Gaussian network classifier (CGNC). The CGNC has a generative structure that encodes conditional dependencies and potential causal relations among features through a directed acyclic graph (DAG). This structure naturally embeds feature relationships into the search process, eliminating the need for additional constraints to ensure consistency with the model's structural assumptions. We adopt a convergence-guaranteed cutting-set procedure as an adversarial optimization framework, which iteratively approximates solutions that satisfy global robustness conditions. To address the nonconvex quadratic structure induced by feature dependencies, we apply piecewise McCormick relaxation to reformulate the problem as a mixed-integer linear program (MILP), ensuring global optimality. Experimental results show that our method achieves strong robustness, with direct global optimization of the original formulation providing especially stable and efficient results. The proposed framework is extensible to more complex constraint settings, laying the groundwork for future advances in counterfactual reasoning under nonconvex quadratic formulations.

</details>


### [357] [Free(): Learning to Forget in Malloc-Only Reasoning Models](https://arxiv.org/abs/2602.08030)
*Yilun Zheng,Dongyang Ma,Tian Liang,Jiahao Xu,Xinting Huang,Lijie Chen,Haitao Mi,Yan Wang*

Main category: cs.AI

TL;DR: Free()LM通过引入自我遗忘机制解决推理模型过度思考导致性能下降的问题，使用可插拔的LoRA适配器动态修剪无用上下文，在各种规模模型上实现性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有推理模型存在一个关键悖论：过多的思考token反而会降低性能而非提升。作者认为这是由于标准LLM作为"malloc-only"引擎，持续积累有效和冗余步骤，缺乏修剪过时信息的机制。

Method: 提出Free()LM模型，通过Free-Module（一个可插拔的LoRA适配器）引入内在的自我遗忘能力。模型在推理模式和清理模式之间迭代切换，动态识别并修剪无用的上下文块，保持紧凑且无噪声的状态。

Result: 在8B到685B的各种规模模型上均实现一致改进，相比顶级推理基线平均提升3.3%，在IMOanswerBench上使用DeepSeek V3.2-Speciale建立新的SOTA。在长时程任务中，标准Qwen3-235B-A22B模型完全崩溃（0%准确率），而Free()LM将性能恢复到50%。

Conclusion: 可持续的智能不仅需要思考的能力，也需要遗忘的自由。自我遗忘机制对于提升推理模型的性能至关重要。

Abstract: Reasoning models enhance problem-solving by scaling test-time compute, yet they face a critical paradox: excessive thinking tokens often degrade performance rather than improve it. We attribute this to a fundamental architectural flaw: standard LLMs operate as "malloc-only" engines, continuously accumulating valid and redundant steps alike without a mechanism to prune obsolete information. To break this cycle, we propose Free()LM, a model that introduces an intrinsic self-forgetting capability via the Free-Module, a plug-and-play LoRA adapter. By iteratively switching between reasoning and cleaning modes, Free()LM dynamically identifies and prunes useless context chunks, maintaining a compact and noise-free state.
  Extensive experiments show that Free()LM provides consistent improvements across all model scales (8B to 685B). It achieves a 3.3% average improvement over top-tier reasoning baselines, even establishing a new SOTA on IMOanswerBench using DeepSeek V3.2-Speciale. Most notably, in long-horizon tasks where the standard Qwen3-235B-A22B model suffers a total collapse (0% accuracy), Free()LM restores performance to 50%. Our findings suggest that sustainable intelligence requires the freedom to forget as much as the power to think.

</details>


### [358] [Graph-Enhanced Deep Reinforcement Learning for Multi-Objective Unrelated Parallel Machine Scheduling](https://arxiv.org/abs/2602.08052)
*Bulent Soykan,Sean Mondesire,Ghaith Rabadi,Grace Bochenek*

Main category: cs.AI

TL;DR: 提出基于PPO和GNN的深度强化学习框架，解决带释放时间、准备时间和资格约束的不相关并行机调度问题，同时最小化总加权延迟和总准备时间。


<details>
  <summary>Details</summary>
Motivation: 传统方法难以平衡总加权延迟(TWT)和总准备时间(TST)这两个目标，特别是在存在释放时间、准备时间和资格约束的复杂调度场景中。

Method: 使用近端策略优化(PPO)算法和图神经网络(GNN)构建深度强化学习框架。GNN有效表示作业、机器和准备状态的复杂状态，PPO代理学习直接调度策略，通过多目标奖励函数同时优化TWT和TST。

Result: 在基准实例上的实验结果表明，PPO-GNN代理显著优于标准调度规则和元启发式方法，在两个目标之间实现了更优的权衡。

Conclusion: 该方法为复杂制造调度提供了鲁棒且可扩展的解决方案，能够有效处理多目标优化问题。

Abstract: The Unrelated Parallel Machine Scheduling Problem (UPMSP) with release dates, setups, and eligibility constraints presents a significant multi-objective challenge. Traditional methods struggle to balance minimizing Total Weighted Tardiness (TWT) and Total Setup Time (TST). This paper proposes a Deep Reinforcement Learning framework using Proximal Policy Optimization (PPO) and a Graph Neural Network (GNN). The GNN effectively represents the complex state of jobs, machines, and setups, allowing the PPO agent to learn a direct scheduling policy. Guided by a multi-objective reward function, the agent simultaneously minimizes TWT and TST. Experimental results on benchmark instances demonstrate that our PPO-GNN agent significantly outperforms a standard dispatching rule and a metaheuristic, achieving a superior trade-off between both objectives. This provides a robust and scalable solution for complex manufacturing scheduling.

</details>


### [359] [Securing Dual-Use Pathogen Data of Concern](https://arxiv.org/abs/2602.08061)
*Doni Bloomfield,Allison Berke,Moritz S. Hanke,Aaron Maiwald,James R. M. Black,Toby Webster,Tina Hernandez-Boussard,Oliver M. Crook,Jassi Pannu*

Main category: cs.AI

TL;DR: 提出五级生物安全数据框架(BDL)，根据数据对AI模型生物安全风险的影响程度分类，并设计相应技术限制和治理框架


<details>
  <summary>Details</summary>
Motivation: AI生物模型训练数据与其能力密切相关，包括生物安全风险能力。为响应Asilomar会议对数据控制的呼吁，需要设计框架防止AI被用于生物武器开发等有害应用

Method: 引入五级生物安全数据框架(BDL)，根据数据对AI模型生物安全风险能力的预期贡献程度分类；为每个BDL层级提出相应的技术限制；设计新型双重用途病原体数据治理框架

Result: 建立了系统化的病原体数据分类和管控框架，将数据分为五个风险等级，并针对每个等级提出具体技术限制措施

Conclusion: 在计算和编码资源广泛可及的世界中，数据控制可能是减少生物AI能力扩散的最有效干预措施之一，BDL框架为实现这一目标提供了具体路径

Abstract: Training data is an essential input into creating competent artificial intelligence (AI) models. AI models for biology are trained on large volumes of data, including data related to biological sequences, structures, images, and functions. The type of data used to train a model is intimately tied to the capabilities it ultimately possesses--including those of biosecurity concern. For this reason, an international group of more than 100 researchers at the recent 50th anniversary Asilomar Conference endorsed data controls to prevent the use of AI for harmful applications such as bioweapons development. To help design such controls, we introduce a five-tier Biosecurity Data Level (BDL) framework for categorizing pathogen data. Each level contains specific data types, based on their expected ability to contribute to capabilities of concern when used to train AI models. For each BDL tier, we propose technical restrictions appropriate to its level of risk. Finally, we outline a novel governance framework for newly created dual-use pathogen data. In a world with widely accessible computational and coding resources, data controls may be among the most high-leverage interventions available to reduce the proliferation of concerning biological AI capabilities.

</details>


### [360] [Objective Decoupling in Social Reinforcement Learning: Recovering Ground Truth from Sycophantic Majorities](https://arxiv.org/abs/2602.08092)
*Majid Ghasemi,Mark Crowley*

Main category: cs.AI

TL;DR: 论文挑战了AI对齐中的关键假设——人类反馈是真实信号，提出在社交环境中该假设失效会导致目标解耦问题，并提出了基于安全公理的"评判评判者"方法来解决多数偏见问题。


<details>
  <summary>Details</summary>
Motivation: 当前AI对齐策略依赖一个脆弱的前提：人类反馈虽然嘈杂，但本质上是真实的信号。作者认为这一假设在静态环境中成立，但在社交环境中会失效，因为评估者可能阿谀奉承、懒惰或敌对。这种假设被称为强化学习的教条4，会导致目标解耦的结构性故障。

Method: 提出了认知源对齐方法，与依赖统计共识的传统鲁棒方法不同，ESA使用稀疏的安全公理来评判反馈的来源而非信号本身。这种"评判评判者"机制通过判断反馈提供者的可靠性来保证收敛到真实目标。

Result: 理论上证明了ESA方法能够保证收敛到真实目标，即使多数评估者存在偏见。实证研究表明，传统共识方法在多数合谋情况下会失败，而ESA方法成功恢复了最优策略。

Conclusion: 论文挑战了AI对齐中的关键假设，揭示了在社交环境中人类反馈可能不可靠的问题，并提出了有效的解决方案。ESA方法通过评判反馈来源而非信号本身，能够在多数评估者存在偏见的情况下保证对齐收敛。

Abstract: Contemporary AI alignment strategies rely on a fragile premise: that human feedback, while noisy, remains a fundamentally truthful signal. In this paper, we identify this assumption as Dogma 4 of Reinforcement Learning (RL). We demonstrate that while this dogma holds in static environments, it fails in social settings where evaluators may be sycophantic, lazy, or adversarial. We prove that under Dogma 4, standard RL agents suffer from what we call Objective Decoupling, a structural failure mode where the agent's learned objective permanently separates from the latent ground truth, guaranteeing convergence to misalignment. To resolve this, we propose Epistemic Source Alignment (ESA). Unlike standard robust methods that rely on statistical consensus (trusting the majority), ESA utilizes sparse safety axioms to judge the source of the feedback rather than the signal itself. We prove that this "judging the judges" mechanism guarantees convergence to the true objective, even when a majority of evaluators are biased. Empirically, we show that while traditional consensus methods fail under majority collusion, our approach successfully recovers the optimal policy.

</details>


### [361] [Interpretable Failure Analysis in Multi-Agent Reinforcement Learning Systems](https://arxiv.org/abs/2602.08104)
*Risal Shahriar Shefin,Debashis Gupta,Thai Le,Sarra Alqahtani*

Main category: cs.AI

TL;DR: 提出基于梯度的两阶段框架，用于多智能体强化学习中的可解释故障检测与溯源，识别初始故障源、验证多米诺效应、追踪故障传播路径。


<details>
  <summary>Details</summary>
Motivation: 多智能体强化学习在安全关键领域应用增多，但可解释的故障检测与归因方法不足。需要超越黑盒检测，提供可解释的诊断工具来分析级联故障。

Method: 两阶段梯度框架：第一阶段通过策略梯度成本的泰勒余项分析进行可解释的智能体级故障检测，在首次阈值交叉时确定初始故障候选；第二阶段通过评论家导数的几何分析（一阶敏感性和二阶曲率）构建可解释的传染图，验证多米诺效应和追踪传播路径。

Result: 在Simple Spread（3和5智能体）和StarCraft II环境中评估，使用MADDPG和HATRPO算法，实现了88.2-99.4%的初始故障源检测准确率，同时为检测决策提供可解释的几何证据。

Conclusion: 该框架通过梯度级法医分析超越黑盒检测，为安全关键多智能体强化学习系统诊断级联故障提供了实用工具，能够解释"下游优先"检测异常并揭示上游偏差的放大路径。

Abstract: Multi-Agent Reinforcement Learning (MARL) is increasingly deployed in safety-critical domains, yet methods for interpretable failure detection and attribution remain underdeveloped. We introduce a two-stage gradient-based framework that provides interpretable diagnostics for three critical failure analysis tasks: (1) detecting the true initial failure source (Patient-0); (2) validating why non-attacked agents may be flagged first due to domino effects; and (3) tracing how failures propagate through learned coordination pathways. Stage 1 performs interpretable per-agent failure detection via Taylor-remainder analysis of policy-gradient costs, declaring an initial Patient-0 candidate at the first threshold crossing. Stage 2 provides validation through geometric analysis of critic derivatives-first-order sensitivity and directional second-order curvature aggregated over causal windows to construct interpretable contagion graphs. This approach explains "downstream-first" detection anomalies by revealing pathways that amplify upstream deviations. Evaluated across 500 episodes in Simple Spread (3 and 5 agents) and 100 episodes in StarCraft II using MADDPG and HATRPO, our method achieves 88.2-99.4% Patient-0 detection accuracy while providing interpretable geometric evidence for detection decisions. By moving beyond black-box detection to interpretable gradient-level forensics, this framework offers practical tools for diagnosing cascading failures in safety-critical MARL systems.

</details>


### [362] [Initial Risk Probing and Feasibility Testing of Glow: a Generative AI-Powered Dialectical Behavior Therapy Skills Coach for Substance Use Recovery and HIV Prevention](https://arxiv.org/abs/2602.08121)
*Liying Wang,Madison Lee,Yunzhang Jiang,Steven Chen,Kewei Sha,Yunhe Feng,Frank Wong,Lisa Hightow-Weidman,Weichao Yuwen*

Main category: cs.AI

TL;DR: 研究开发了名为Glow的GenAI驱动的DBT技能教练，用于HIV和物质使用风险人群，通过用户驱动的对抗性测试发现其安全处理率为73%，但存在鼓励物质使用和技能信息错误等安全漏洞。


<details>
  <summary>Details</summary>
Motivation: HIV和物质使用是相互关联的流行病，具有共同的冲动性和适应不良应对机制。DBT针对这些机制但面临可扩展性挑战，GenAI提供了大规模提供个性化DBT辅导的潜力，但快速发展超过了安全基础设施。

Method: 开发了Glow GenAI驱动的DBT技能教练，提供连锁分析和解决方案分析。与洛杉矶社区健康组织合作，对临床工作人员（6人）和有生活经验的个体（28人）进行可用性测试。使用HHH框架，采用用户驱动的对抗性测试，参与者识别目标行为并生成情境现实的风险探针，评估了37个风险探针交互的安全性表现。

Result: Glow适当处理了73%的风险探针，但不同代理表现差异大：解决方案分析代理表现90%适当处理，而连锁分析代理仅44%。安全失败集中在鼓励物质使用和正常化有害行为。连锁分析代理陷入"共情陷阱"，提供强化适应不良信念的验证。此外，识别出27个DBT技能信息错误实例。

Conclusion: 这是首次对GenAI提供的DBT辅导进行系统安全性评估，揭示了临床试验前需要缓解的漏洞。HHH框架和用户驱动的对抗性测试为评估GenAI心理健康干预提供了可复制的方法。

Abstract: Background: HIV and substance use represent interacting epidemics with shared psychological drivers - impulsivity and maladaptive coping. Dialectical behavior therapy (DBT) targets these mechanisms but faces scalability challenges. Generative artificial intelligence (GenAI) offers potential for delivering personalized DBT coaching at scale, yet rapid development has outpaced safety infrastructure. Methods: We developed Glow, a GenAI-powered DBT skills coach delivering chain and solution analysis for individuals at risk for HIV and substance use. In partnership with a Los Angeles community health organization, we conducted usability testing with clinical staff (n=6) and individuals with lived experience (n=28). Using the Helpful, Honest, and Harmless (HHH) framework, we employed user-driven adversarial testing wherein participants identified target behaviors and generated contextually realistic risk probes. We evaluated safety performance across 37 risk probe interactions. Results: Glow appropriately handled 73% of risk probes, but performance varied by agent. The solution analysis agent demonstrated 90% appropriate handling versus 44% for the chain analysis agent. Safety failures clustered around encouraging substance use and normalizing harmful behaviors. The chain analysis agent fell into an "empathy trap," providing validation that reinforced maladaptive beliefs. Additionally, 27 instances of DBT skill misinformation were identified. Conclusions: This study provides the first systematic safety evaluation of GenAI-delivered DBT coaching for HIV and substance use risk reduction. Findings reveal vulnerabilities requiring mitigation before clinical trials. The HHH framework and user-driven adversarial testing offer replicable methods for evaluating GenAI mental health interventions.

</details>


### [363] [RECUR: Resource Exhaustion Attack via Recursive-Entropy Guided Counterfactual Utilization and Reflection](https://arxiv.org/abs/2602.08214)
*Ziwei Wang,Yuanhe Zhang,Jing Chen,Zhenhong Zhou,Ruichao Liang,Ruiying Du,Ju Jia,Cong Wu,Yang Liu*

Main category: cs.AI

TL;DR: 本文提出RECUR攻击方法，利用递归熵量化反思过程中的资源消耗风险，通过构建反事实问题触发LRMs的过度反思，导致输出长度增加11倍、吞吐量下降90%的资源耗尽攻击。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型（LRMs）在处理复杂任务时需要显式推理，这需要更长的上下文长度并导致更高的资源消耗。先前研究表明对抗性输入可能触发冗余推理过程，使LRMs面临资源耗尽漏洞。然而，推理过程本身，特别是其反思组件，受到的关注有限，尽管它可能导致过度反思并消耗过多计算资源。

Method: 提出递归熵（Recursive Entropy）来量化反思过程中的资源消耗风险。基于递归熵，引入RECUR攻击方法（Resource Exhaustion attack via Recursive Entropy guided Counterfactual Utilization and Reflection），通过构建反事实问题来验证LRMs的内在缺陷和风险。

Result: 实验表明，在良性推理下，递归熵呈现明显下降趋势。RECUR攻击破坏了这一趋势，使输出长度增加高达11倍，吞吐量下降90%。

Conclusion: 这项工作为鲁棒推理提供了新视角，揭示了推理本身的安全问题，通过递归熵量化反思过程中的资源消耗风险，并展示了如何利用反事实问题触发资源耗尽攻击。

Abstract: Large Reasoning Models (LRMs) employ reasoning to address complex tasks. Such explicit reasoning requires extended context lengths, resulting in substantially higher resource consumption. Prior work has shown that adversarially crafted inputs can trigger redundant reasoning processes, exposing LRMs to resource-exhaustion vulnerabilities. However, the reasoning process itself, especially its reflective component, has received limited attention, even though it can lead to over-reflection and consume excessive computing power. In this paper, we introduce Recursive Entropy to quantify the risk of resource consumption in reflection, thereby revealing the safety issues inherent in inference itself. Based on Recursive Entropy, we introduce RECUR, a resource exhaustion attack via Recursive Entropy guided Counterfactual Utilization and Reflection. It constructs counterfactual questions to verify the inherent flaws and risks of LRMs. Extensive experiments demonstrate that, under benign inference, recursive entropy exhibits a pronounced decreasing trend. RECUR disrupts this trend, increasing the output length by up to 11x and decreasing throughput by 90%. Our work provides a new perspective on robust reasoning.

</details>


### [364] [Weak-Driven Learning: How Weak Agents make Strong Agents Stronger](https://arxiv.org/abs/2602.08222)
*Zehao Chen,Gongxun Li,Tianxiang Ai,Yifei Li,Zixuan Huang,Wang Zhou,Fuzhen Zhuang,Xianglong Liu,Jianxin Li,Deqing Wang,Yikun Ban*

Main category: cs.AI

TL;DR: WMSS是一种后训练优化方法，利用模型自身历史弱检查点来指导持续优化，通过熵动态识别可恢复的学习差距并进行补偿学习，帮助强模型突破传统后训练饱和瓶颈。


<details>
  <summary>Details</summary>
Motivation: 现有后训练方法在模型变得高度自信后会出现饱和瓶颈，进一步训练收益递减。作者发现模型自身历史弱状态中仍存在有监督信号，这为突破饱和瓶颈提供了机会。

Method: WMSS通过分析熵动态识别模型可恢复的学习差距，然后利用弱检查点作为指导，通过补偿学习强化这些差距，使强智能体能够继续改进。

Result: 在数学推理和代码生成数据集上的实验表明，使用WMSS训练的智能体实现了有效的性能提升，且不增加额外的推理成本。

Conclusion: WMSS通过利用模型自身历史弱状态作为监督信号，成功突破了传统后训练的饱和瓶颈，为大型语言模型的持续优化提供了新范式。

Abstract: As post-training optimization becomes central to improving large language models, we observe a persistent saturation bottleneck: once models grow highly confident, further training yields diminishing returns. While existing methods continue to reinforce target predictions, we find that informative supervision signals remain latent in models' own historical weak states. Motivated by this observation, we propose WMSS (Weak Agents Can Make Strong Agents Stronger), a post-training paradigm that leverages weak checkpoints to guide continued optimization. By identifying recoverable learning gaps via entropy dynamics and reinforcing them through compensatory learning, WMSS enables strong agents to improve beyond conventional post-training saturation. Experiments on mathematical reasoning and code generation datasets show that agents trained with our approach achieve effective performance improvements, while incurring zero additional inference cost.

</details>


### [365] [InfiCoEvalChain: A Blockchain-Based Decentralized Framework for Collaborative LLM Evaluation](https://arxiv.org/abs/2602.08229)
*Yifan Yang,Jinjia Li,Kunxi Li,Puhao Zheng,Yuanyi Wang,Zheyan Qu,Yang Yu,Jianmin Wu,Ming Li,Hongxia Yang*

Main category: cs.AI

TL;DR: 提出去中心化评估框架解决LLM评估中的不一致性问题，通过区块链协议激励全球贡献者参与验证，显著降低评估方差，提高排名统计置信度。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型评估存在集中化评估的三大问题：不透明、过拟合和硬件差异导致的方差。实证分析发现，HumanEval上单个模型10次运行的标准差(1.67)甚至超过了官方排行榜上前10名模型的性能差距(0.91)，使得当前排名统计上不可靠。

Method: 提出去中心化评估框架，通过区块链协议激励全球贡献者作为独立验证者，利用异构计算节点进行大规模基准测试，实现硬件和参数多样性。采用稳健的奖励系统确保评估完整性，防止不诚实参与。

Result: 去中心化评估框架将同一模型10次运行的标准差从1.67降低到0.28，显著改善了传统框架的统计稳定性，确保模型排名具有更高的统计置信度。

Conclusion: 去中心化评估将评估从"集中化黑盒"转变为"去中心化背书"，通过多方共识和多样化推理环境产生更稳定、更具代表性的指标。该平台已完全实现并将向社区发布。

Abstract: The rapid advancement of large language models (LLMs) demands increasingly reliable evaluation, yet current centralized evaluation suffers from opacity, overfitting, and hardware-induced variance. Our empirical analysis reveals an alarming inconsistency in existing evaluations: the standard deviation across ten repeated runs of a single model on HumanEval (1.67) actually exceeds the performance gap among the top-10 models on the official leaderboard (0.91), rendering current rankings statistically precarious. To mitigate these instabilities, we propose a decentralized evaluation framework that enables hardware and parameter diversity through large-scale benchmarking across heterogeneous compute nodes. By leveraging the blockchain-based protocol, the framework incentivizes global contributors to act as independent validators, using a robust reward system to ensure evaluation integrity and discourage dishonest participation. This collective verification transforms evaluation from a "centralized black box" into a "decentralized endorsement" where multi-party consensus and diverse inference environments yield a more stable, representative metric. Experimental results demonstrate that the decentralized evaluation framework reduces the standard deviation across ten runs on the same model to 0.28. This significant improvement over conventional frameworks ensures higher statistical confidence in model rankings. We have completely implemented this platform and will soon release it to the community.

</details>


### [366] [PTS-SNN: A Prompt-Tuned Temporal Shift Spiking Neural Networks for Efficient Speech Emotion Recognition](https://arxiv.org/abs/2602.08240)
*Xun Su,Huamin Wang,Qi Zhang*

Main category: cs.AI

TL;DR: 提出PTS-SNN框架，通过提示调优解决SSL表示与SNN之间的分布不匹配问题，在保持高性能的同时显著降低计算成本和能耗。


<details>
  <summary>Details</summary>
Motivation: 传统语音情感识别模型计算成本高，难以部署在资源受限的边缘设备上。SNN虽然能效高，但与连续自监督学习表示存在分布不匹配问题，高动态范围的嵌入会降低基于阈值神经元的信息编码能力。

Method: 提出提示调优脉冲神经网络框架，包含：1) 时间移位脉冲编码器，通过无参数通道移位捕获局部时间依赖；2) 上下文感知膜电位校准策略，利用脉冲稀疏线性注意力模块聚合全局语义上下文到可学习的软提示中，动态调节PLIF神经元的偏置电压。

Result: 在五个多语言数据集上实验，在IEMOCAP上达到73.34%的准确率，与竞争性ANN相当，但仅需119万个可训练参数和每个样本0.35毫焦的推理能耗。

Conclusion: PTS-SNN有效解决了SSL与SNN之间的分布不匹配问题，实现了高性能、低参数和低能耗的语音情感识别，为边缘部署提供了可行的解决方案。

Abstract: Speech Emotion Recognition (SER) is widely deployed in Human-Computer Interaction, yet the high computational cost of conventional models hinders their implementation on resource-constrained edge devices. Spiking Neural Networks (SNNs) offer an energy-efficient alternative due to their event-driven nature; however, their integration with continuous Self-Supervised Learning (SSL) representations is fundamentally challenged by distribution mismatch, where high-dynamic-range embeddings degrade the information coding capacity of threshold-based neurons. To resolve this, we propose Prompt-Tuned Spiking Neural Networks (PTS-SNN), a parameter-efficient neuromorphic adaptation framework that aligns frozen SSL backbones with spiking dynamics. Specifically, we introduce a Temporal Shift Spiking Encoder to capture local temporal dependencies via parameter-free channel shifts, establishing a stable feature basis. To bridge the domain gap, we devise a Context-Aware Membrane Potential Calibration strategy. This mechanism leverages a Spiking Sparse Linear Attention module to aggregate global semantic context into learnable soft prompts, which dynamically regulate the bias voltages of Parametric Leaky Integrate-and-Fire (PLIF) neurons. This regulation effectively centers the heterogeneous input distribution within the responsive firing range, mitigating functional silence or saturation. Extensive experiments on five multilingual datasets (e.g., IEMOCAP, CASIA, EMODB) demonstrate that PTS-SNN achieves 73.34\% accuracy on IEMOCAP, comparable to competitive Artificial Neural Networks (ANNs), while requiring only 1.19M trainable parameters and 0.35 mJ inference energy per sample.

</details>


### [367] [Do MLLMs Really See It: Reinforcing Visual Attention in Multimodal LLMs](https://arxiv.org/abs/2602.08241)
*Siqu Ou,Tianrui Wan,Zhiyuan Zhao,Junyu Gao,Xuelong Li*

Main category: cs.AI

TL;DR: SAYO：通过强化学习框架引入区域级视觉注意力奖励，解决多模态大语言模型中视觉注意力不稳定的问题，提升复杂推理任务的性能。


<details>
  <summary>Details</summary>
Motivation: 现有多模态大语言模型在复杂推理任务中依赖长文本推理轨迹，但缺乏有效的视觉注意力学习机制。研究发现当前模型存在视觉注意力薄弱的问题：早期视觉对齐错误很少在后续推理中被纠正，导致错误传播和推理失败。这种局限性源于训练过程中对视觉注意力的信用分配不足。

Method: 提出SAYO模型，采用强化学习框架训练，引入区域级视觉注意力奖励机制。该奖励明确将优化信号与基于视觉的推理步骤对齐，使模型能够学习更可靠的注意力行为。

Result: 在多个多模态基准测试上的广泛实验表明，SAYO在多样化的推理和感知任务上持续提升性能。

Conclusion: 通过强化学习框架中的区域级视觉注意力奖励，能够有效解决多模态大语言模型中视觉注意力不稳定的问题，显著提升复杂推理任务的性能表现。

Abstract: While chain-of-thought (CoT) reasoning has substantially improved multimodal large language models (MLLMs) on complex reasoning tasks, existing approaches largely rely on long textual reasoning trajectories and provide limited mechanisms for learning stable visual attention policies. Our analysis shows that current MLLMs exhibit weak visual focus: early-stage visual misalignment is rarely corrected during subsequent reasoning, leading to error propagation and failed inferences. We argue that this limitation stems from inadequate credit assignment for visual attention during training. To address this issue, we propose SAYO, a visual reasoning model trained with a reinforcement learning (RL) framework that introduces a region-level visual attention-based reward. This reward explicitly aligns optimization signals with visually grounded reasoning steps, enabling the model to learn more reliable attention behaviors. Extensive experiments across multiple multimodal benchmarks demonstrate that SAYO consistently improves performance on diverse reasoning and perception tasks.

</details>


### [368] [G-LNS: Generative Large Neighborhood Search for LLM-Based Automatic Heuristic Design](https://arxiv.org/abs/2602.08253)
*Baoyun Zhao,He Wang,Liang Zeng*

Main category: cs.AI

TL;DR: G-LNS：基于LLM的生成式进化框架，自动设计大邻域搜索的破坏与修复算子对，在组合优化问题上超越现有LLM方法和经典求解器


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的自动启发式设计方法通常局限于构造性优先级规则或参数化局部搜索指导，搜索空间受限于固定启发式形式，难以在复杂组合优化问题中跳出深度局部最优

Method: 提出G-LNS生成式进化框架，利用LLM协同进化紧密耦合的破坏与修复算子对，通过合作评估机制捕捉算子间交互，发现能有效执行结构破坏与重建的互补算子逻辑

Result: 在TSP和CVRP等挑战性组合优化基准测试中，G-LNS显著优于基于LLM的自动启发式设计方法和强经典求解器，发现的启发式不仅以更少计算资源获得接近最优解，还在未见实例分布上表现出鲁棒泛化能力

Conclusion: G-LNS将LLM驱动的自动启发式设计扩展到LNS算子自动设计，通过协同进化破坏-修复算子对实现了更有效的结构探索，为复杂组合优化问题提供了新的解决方案

Abstract: While Large Language Models (LLMs) have recently shown promise in Automated Heuristic Design (AHD), existing approaches typically formulate AHD around constructive priority rules or parameterized local search guidance, thereby restricting the search space to fixed heuristic forms. Such designs offer limited capacity for structural exploration, making it difficult to escape deep local optima in complex Combinatorial Optimization Problems (COPs). In this work, we propose G-LNS, a generative evolutionary framework that extends LLM-based AHD to the automated design of Large Neighborhood Search (LNS) operators. Unlike prior methods that evolve heuristics in isolation, G-LNS leverages LLMs to co-evolve tightly coupled pairs of destroy and repair operators. A cooperative evaluation mechanism explicitly captures their interaction, enabling the discovery of complementary operator logic that jointly performs effective structural disruption and reconstruction. Extensive experiments on challenging COP benchmarks, such as Traveling Salesman Problems (TSP) and Capacitated Vehicle Routing Problems (CVRP), demonstrate that G-LNS significantly outperforms LLM-based AHD methods as well as strong classical solvers. The discovered heuristics not only achieve near-optimal solutions with reduced computational budgets but also exhibit robust generalization across diverse and unseen instance distributions.

</details>


### [369] [SynthAgent: A Multi-Agent LLM Framework for Realistic Patient Simulation -- A Case Study in Obesity with Mental Health Comorbidities](https://arxiv.org/abs/2602.08254)
*Arman Aghaee,Sepehr Asgarian,Jouhyun Jeon*

Main category: cs.AI

TL;DR: SynthAgent是一个多智能体系统框架，用于模拟肥胖合并精神障碍患者，通过整合临床数据和人格特征来创建高保真虚拟患者，模拟疾病进展和治疗反应。


<details>
  <summary>Details</summary>
Motivation: 真实世界数据存在碎片化、偏见和隐私限制等问题，模拟高保真患者为研究复杂疾病提供了替代方案，特别是针对肥胖合并精神障碍这类复杂共病情况。

Method: 提出SynthAgent多智能体系统框架，整合理赔数据、人口调查和患者中心文献等临床医学证据，构建具有人格特征的个性化虚拟患者，通过自主智能体交互模拟疾病进展、治疗反应和生活管理。

Result: 评估100多个生成的患者显示，GPT-5和Claude 4.5 Sonnet作为核心引擎在MAS框架中实现最高保真度，优于Gemini 2.5 Pro和DeepSeek-R1。

Conclusion: SynthAgent提供了一个可扩展且保护隐私的框架，用于探索患者旅程、行为动态和决策过程，适用于医学和心理学领域。

Abstract: Simulating high-fidelity patients offers a powerful avenue for studying complex diseases while addressing the challenges of fragmented, biased, and privacy-restricted real-world data. In this study, we introduce SynthAgent, a novel Multi-Agent System (MAS) framework designed to model obesity patients with comorbid mental disorders, including depression, anxiety, social phobia, and binge eating disorder. SynthAgent integrates clinical and medical evidence from claims data, population surveys, and patient-centered literature to construct personalized virtual patients enriched with personality traits that influence adherence, emotion regulation, and lifestyle behaviors. Through autonomous agent interactions, the system simulates disease progression, treatment response, and life management across diverse psychosocial contexts. Evaluation of more than 100 generated patients demonstrated that GPT-5 and Claude 4.5 Sonnet achieved the highest fidelity as the core engine in the proposed MAS framework, outperforming Gemini 2.5 Pro and DeepSeek-R1. SynthAgent thus provides a scalable and privacy-preserving framework for exploring patient journeys, behavioral dynamics, and decision-making processes in both medical and psychological domains.

</details>


### [370] [Puda: Private User Dataset Agent for User-Sovereign and Privacy-Preserving Personalized AI](https://arxiv.org/abs/2602.08268)
*Akinori Maeda,Yuto Sekiya,Sota Sugimura,Tomoya Asai,Yu Tsuda,Kohei Ikeda,Hiroshi Fujii,Kohei Watanabe*

Main category: cs.AI

TL;DR: Puda是一个用户主权架构，通过聚合跨服务数据并支持客户端管理，在三个隐私级别控制数据共享，以平衡个性化服务需求与隐私保护。


<details>
  <summary>Details</summary>
Motivation: 当前个人数据集中在少数平台提供商手中，形成了数据孤岛，限制了用户主权并阻碍了跨服务数据使用。同时，基于大语言模型的智能代理快速发展，对需要多样化个人数据的个性化服务需求激增，这带来了在数据利用与隐私保护之间平衡的挑战。

Method: 提出Puda（Private User Dataset Agent）架构，支持用户在三个隐私级别控制数据共享：详细浏览历史、提取的关键词、预定义类别子集。实现为浏览器系统，作为跨服务的通用平台，并通过个性化旅行规划任务进行评估。

Result: 实验结果显示，提供预定义类别子集能达到分享详细浏览历史所获个性化性能的97.2%（通过LLM-as-a-Judge框架在三个标准下评估）。这表明Puda能有效实现多粒度数据管理，为缓解隐私-个性化权衡提供实用选择。

Conclusion: Puda为用户主权提供了AI原生基础，使用户能够安全地利用个性化AI的全部潜力，通过多粒度隐私控制有效平衡数据利用与隐私保护。

Abstract: Personal data centralization among dominant platform providers including search engines, social networking services, and e-commerce has created siloed ecosystems that restrict user sovereignty, thereby impeding data use across services. Meanwhile, the rapid proliferation of Large Language Model (LLM)-based agents has intensified demand for highly personalized services that require the dynamic provision of diverse personal data. This presents a significant challenge: balancing the utilization of such data with privacy protection. To address this challenge, we propose Puda (Private User Dataset Agent), a user-sovereign architecture that aggregates data across services and enables client-side management. Puda allows users to control data sharing at three privacy levels: (i) Detailed Browsing History, (ii) Extracted Keywords, and (iii) Predefined Category Subsets. We implemented Puda as a browser-based system that serves as a common platform across diverse services and evaluated it through a personalized travel planning task. Our results show that providing Predefined Category Subsets achieves 97.2% of the personalization performance (evaluated via an LLM-as-a-Judge framework across three criteria) obtained when sharing Detailed Browsing History. These findings demonstrate that Puda enables effective multi-granularity management, offering practical choices to mitigate the privacy-personalization trade-off. Overall, Puda provides an AI-native foundation for user sovereignty, empowering users to safely leverage the full potential of personalized AI.

</details>


### [371] [Toward Formalizing LLM-Based Agent Designs through Structural Context Modeling and Semantic Dynamics Analysis](https://arxiv.org/abs/2602.08276)
*Haoyu Jia,Kento Kawaharazuka,Kei Okada*

Main category: cs.AI

TL;DR: 提出Structural Context Model形式化模型，用于从上下文结构角度分析和比较LLM智能体，并配套声明式实现框架和Semantic Dynamics Analysis工程流程，在动态猴子香蕉问题上实现32%成功率提升。


<details>
  <summary>Details</summary>
Motivation: 当前LLM智能体研究碎片化严重，概念框架和方法论原则常与底层实现细节混杂，导致研究者和读者在表面不同的概念中迷失方向。这种碎片化主要源于缺乏可分析、自洽的形式化模型，无法实现与实现无关的LLM智能体表征和比较。

Method: 提出Structural Context Model形式化模型，从上下文结构角度分析LLM智能体。在此基础上引入两个互补组件：1) 声明式实现框架；2) 可持续的智能体工程流程Semantic Dynamics Analysis。该流程提供对智能体机制的原则性洞察，支持快速、系统的设计迭代。

Result: 在动态变体的猴子香蕉问题上验证框架有效性，使用该方法设计的智能体在最具挑战性的设置中实现了高达32个百分点的成功率提升。

Conclusion: 提出的Structural Context Model及其配套框架解决了LLM智能体研究的碎片化问题，提供了形式化分析工具和系统化工程方法，显著提升了智能体性能，为LLM智能体研究提供了统一的理论和实践基础。

Abstract: Current research on large language model (LLM) agents is fragmented: discussions of conceptual frameworks and methodological principles are frequently intertwined with low-level implementation details, causing both readers and authors to lose track amid a proliferation of superficially distinct concepts. We argue that this fragmentation largely stems from the absence of an analyzable, self-consistent formal model that enables implementation-independent characterization and comparison of LLM agents. To address this gap, we propose the \texttt{Structural Context Model}, a formal model for analyzing and comparing LLM agents from the perspective of context structure. Building upon this foundation, we introduce two complementary components that together span the full lifecycle of LLM agent research and development: (1) a declarative implementation framework; and (2) a sustainable agent engineering workflow, \texttt{Semantic Dynamics Analysis}. The proposed workflow provides principled insights into agent mechanisms and supports rapid, systematic design iteration. We demonstrate the effectiveness of the complete framework on dynamic variants of the monkey-banana problem, where agents engineered using our approach achieve up to a 32 percentage points improvement in success rate on the most challenging setting.

</details>


### [372] [The Vibe-Automation of Automation: A Proactive Education Framework for Computer Science in the Age of Generative AI](https://arxiv.org/abs/2602.08295)
*Ilya Levin*

Main category: cs.AI

TL;DR: 论文提出"氛围自动化"概念，认为生成式AI代表从算法优化到语境语义协调的认知转变，人类角色转向"氛围工程"来引导生成系统的对齐和情境判断。


<details>
  <summary>Details</summary>
Motivation: 生成式AI不是渐进技术进步，而是质变的认知转变，挑战计算机科学的基本假设。传统机器学习是自动化的自动化，而生成式AI通过导航语境、语义和风格一致性来运作，而非优化预定义目标指标。

Method: 引入"氛围自动化"概念框架，分析生成式AI如何操作化隐性规律（无法通过明确算法规则完全指定的语境敏感模式）。提出人类角色从算法问题规范转向"氛围工程"的概念转变。

Result: 建立三层分析框架（教师世界观、产业关系、课程设计）连接认知转变与教育机构转型。识别模式崩溃和文化同质化风险，强调需要刻意参与生成系统以避免回归合成统一性。

Conclusion: 生成式AI的核心意义在于其功能性地访问操作化的隐性规律，人类角色转变为"氛围工程师"，需要系统框架来引导这一认知转变在教育机构中的实现，同时警惕文化同质化风险。

Abstract: The emergence of generative artificial intelligence (GenAI) represents not an incremental technological advance but a qualitative epistemological shift that challenges foundational assumptions of computer science. Whereas machine learning has been described as the automation of automation, generative AI operates by navigating contextual, semantic, and stylistic coherence rather than optimizing predefined objective metrics. This paper introduces the concept of Vibe-Automation to characterize this transition.
  The central claim is that the significance of GenAI lies in its functional access to operationalized tacit regularities: context-sensitive patterns embedded in practice that cannot be fully specified through explicit algorithmic rules. Although generative systems do not possess tacit knowledge in a phenomenological sense, they operationalize sensitivities to tone, intent, and situated judgment encoded in high-dimensional latent representations. On this basis, the human role shifts from algorithmic problem specification toward Vibe-Engineering, understood as the orchestration of alignment and contextual judgment in generative systems.
  The paper connects this epistemological shift to educational and institutional transformation by proposing a conceptual framework structured across three analytical levels and three domains of action: faculty worldview, industry relations, and curriculum design. The risks of mode collapse and cultural homogenization are briefly discussed, emphasizing the need for deliberate engagement with generative systems to avoid regression toward synthetic uniformity.

</details>


### [373] [Moral Sycophancy in Vision Language Models](https://arxiv.org/abs/2602.08311)
*Shadman Rabby,Md. Hefzul Hossain Papon,Sabbir Ahmed,Nokimul Hasan Arif,A. B. M. Ashikur Rahman,Irfan Ahmad*

Main category: cs.AI

TL;DR: 该研究首次系统性地探索了视觉语言模型中的道德奉承行为，发现VLMs在用户意见影响下会牺牲道德准确性，表现出从正确到错误判断的不对称转变，揭示了模型在错误纠正与错误引入之间的权衡。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要探索了VLMs在一般情境下的奉承行为，但对其在道德基础视觉决策中的影响了解不足。需要填补这一空白，系统研究VLMs在用户意见影响下的道德判断变化。

Method: 在Moralise和M^3oralBench数据集上评估10个广泛使用的VLMs，采用用户明确反对的情境。使用错误引入率(EIR)和错误纠正率(ECR)量化模型行为，分析初始道德立场对奉承行为的影响。

Result: VLMs经常在初始判断正确的情况下产生道德错误的后续回应；模型更倾向于从道德正确转向错误判断；后续提示在Moralise上降低性能，在M^3oralBench上表现不一；错误纠正能力强的模型倾向于引入更多推理错误；初始道德正确立场会引发更强的奉承行为。

Conclusion: VLMs在道德影响面前存在脆弱性，需要制定原则性策略来提高多模态AI系统的道德一致性和鲁棒性。研究揭示了模型在道德奉承行为中的系统性模式，为改进伦理一致性提供了重要见解。

Abstract: Sycophancy in Vision-Language Models (VLMs) refers to their tendency to align with user opinions, often at the expense of moral or factual accuracy. While prior studies have explored sycophantic behavior in general contexts, its impact on morally grounded visual decision-making remains insufficiently understood. To address this gap, we present the first systematic study of moral sycophancy in VLMs, analyzing ten widely-used models on the Moralise and M^3oralBench datasets under explicit user disagreement. Our results reveal that VLMs frequently produce morally incorrect follow-up responses even when their initial judgments are correct, and exhibit a consistent asymmetry: models are more likely to shift from morally right to morally wrong judgments than the reverse when exposed to user-induced bias. Follow-up prompts generally degrade performance on Moralise, while yielding mixed or even improved accuracy on M^3oralBench, highlighting dataset-dependent differences in moral robustness. Evaluation using Error Introduction Rate (EIR) and Error Correction Rate (ECR) reveals a clear trade-off: models with stronger error-correction capabilities tend to introduce more reasoning errors, whereas more conservative models minimize errors but exhibit limited ability to self-correct. Finally, initial contexts with a morally right stance elicit stronger sycophantic behavior, emphasizing the vulnerability of VLMs to moral influence and the need for principled strategies to improve ethical consistency and robustness in multimodal AI systems.

</details>


### [374] [Who Deserves the Reward? SHARP: Shapley Credit-based Optimization for Multi-Agent System](https://arxiv.org/abs/2602.08335)
*Yanming Li,Xuelin Zhang,WenJie Lu,Ziye Tang,Maodong Wu,Haotian Luo,Tongtong Wu,Zijie Peng,Hongze Mi,Yibo Feng,Naiqiang Tan,Chao Huang,Hong Chen,Li Shen*

Main category: cs.AI

TL;DR: SHARP框架通过Shapley值进行精确信用分配，优化多智能体强化学习，在多个基准测试中显著优于现有方法


<details>
  <summary>Details</summary>
Motivation: 将LLM与外部工具结合的多智能体系统为解决复杂问题提供了新范式，但训练困难，主要挑战在于信用分配问题。现有方法依赖稀疏或全局广播奖励，无法捕捉个体贡献，导致强化学习效率低下。

Method: 提出SHARP框架，通过分解奖励机制实现精确信用分配：1) 全局广播准确性奖励；2) 基于Shapley值的边际信用奖励；3) 工具过程奖励以提高执行效率。通过轨迹组内归一化智能体特定优势来稳定训练。

Result: 在多个真实世界基准测试中，SHARP显著优于现有最先进方法，相比单智能体方法平均提升23.66%，相比多智能体方法平均提升14.05%。

Conclusion: SHARP通过精确的信用分配机制有效解决了多智能体强化学习中的训练稳定性问题，为LLM与外部工具结合的多智能体系统优化提供了有效解决方案。

Abstract: Integrating Large Language Models (LLMs) with external tools via multi-agent systems offers a promising new paradigm for decomposing and solving complex problems. However, training these systems remains notoriously difficult due to the credit assignment challenge, as it is often unclear which specific functional agent is responsible for the success or failure of decision trajectories. Existing methods typically rely on sparse or globally broadcast rewards, failing to capture individual contributions and leading to inefficient reinforcement learning. To address these limitations, we introduce the Shapley-based Hierarchical Attribution for Reinforcement Policy (SHARP), a novel framework for optimizing multi-agent reinforcement learning via precise credit attribution. SHARP effectively stabilizes training by normalizing agent-specific advantages across trajectory groups, primarily through a decomposed reward mechanism comprising a global broadcast-accuracy reward, a Shapley-based marginal-credit reward for each agent, and a tool-process reward to improve execution efficiency. Extensive experiments across various real-world benchmarks demonstrate that SHARP significantly outperforms recent state-of-the-art baselines, achieving average match improvements of 23.66% and 14.05% over single-agent and multi-agent approaches, respectively.

</details>


### [375] [CoTZero: Annotation-Free Human-Like Vision Reasoning via Hierarchical Synthetic CoT](https://arxiv.org/abs/2602.08339)
*Chengyi Du,Yazhe Niu,Dazhong Shen,Luxin Xu*

Main category: cs.AI

TL;DR: CoTZero：一种无需标注的视觉语言模型训练范式，通过双阶段数据合成和认知对齐训练，提升视觉推理的逻辑连贯性和可验证性


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型依赖表面相关性而非逻辑连贯的结构化表示，导致高层次语义结构和因果关系理解不足，限制了组合性和可验证推理能力

Method: 1. 双阶段数据合成：自底向上提取原子视觉基元并组合成结构化问题推理形式；自顶向下利用全局结构指导局部细节和因果关系解释
2. 认知对齐训练：基于合成的思维链数据，在强化微调中引入认知连贯可验证奖励，提供推理连贯性和事实正确性的逐步反馈

Result: 在包含词汇扰动负样本的多层次语义不一致基准测试中，CoTZero在领域内和领域外设置下均达到83.33%的F1分数

Conclusion: CoTZero通过引入人类认知模型到推理过程，显著提升了视觉语言模型的层次推理和泛化能力，实现了更可解释和人类对齐的视觉推理

Abstract: Recent advances in vision-language models (VLMs) have markedly improved image-text alignment, yet they still fall short of human-like visual reasoning. A key limitation is that many VLMs rely on surface correlations rather than building logically coherent structured representations, which often leads to missed higher-level semantic structure and non-causal relational understanding, hindering compositional and verifiable reasoning. To address these limitations by introducing human models into the reasoning process, we propose CoTZero, an annotation-free paradigm with two components: (i) a dual-stage data synthesis approach and (ii) a cognition-aligned training method. In the first component, we draw inspiration from neurocognitive accounts of compositional productivity and global-to-local analysis. In the bottom-up stage, CoTZero extracts atomic visual primitives and incrementally composes them into diverse, structured question-reasoning forms. In the top-down stage, it enforces hierarchical reasoning by using coarse global structure to guide the interpretation of local details and causal relations. In the cognition-aligned training component, built on the synthesized CoT data, we introduce Cognitively Coherent Verifiable Rewards (CCVR) in Reinforcement Fine-Tuning (RFT) to further strengthen VLMs' hierarchical reasoning and generalization, providing stepwise feedback on reasoning coherence and factual correctness. Experiments show that CoTZero achieves an F1 score of 83.33 percent on our multi-level semantic inconsistency benchmark with lexical-perturbation negatives, across both in-domain and out-of-domain settings. Ablations confirm that each component contributes to more interpretable and human-aligned visual reasoning.

</details>


### [376] [Effect-Level Validation for Causal Discovery](https://arxiv.org/abs/2602.08340)
*Hoang Dang,Luan Pham,Minh Nguyen*

Main category: cs.AI

TL;DR: 提出以效应为中心、可接受性优先的因果发现框架，强调可识别性、稳定性和证伪性评估，而非仅依赖图恢复准确性。在游戏遥测数据中验证，发现许多统计上合理的因果图无法进行点识别，而不同算法在可识别情况下能收敛到一致的效应估计。


<details>
  <summary>Details</summary>
Motivation: 因果发现在大规模遥测数据中应用日益广泛，但其在具有强自选择性的反馈驱动系统中用于决策的可靠性仍不明确。需要超越图恢复准确性，建立更可靠的因果推断框架。

Method: 提出效应中心、可接受性优先的框架，将发现的因果图视为结构假设，通过可识别性、稳定性和证伪性进行评估。在真实游戏遥测数据中研究早期竞争性游戏对短期留存的影响。

Result: 许多统计上合理的因果发现输出在施加最小时间和语义约束后无法进行点识别。当可识别时，不同算法家族能收敛到相似的决策一致效应估计，尽管图结构差异很大。这些估计通过了安慰剂、子采样和敏感性证伪测试。

Conclusion: 图级指标单独不足以作为因果可靠性的代理指标。在遥测驱动系统中，可信的因果结论需要优先考虑可接受性和效应级验证，而非仅关注因果结构恢复。

Abstract: Causal discovery is increasingly applied to large-scale telemetry data to estimate the effects of user-facing interventions, yet its reliability for decision-making in feedback-driven systems with strong self-selection remains unclear. In this paper, we propose an effect-centric, admissibility-first framework that treats discovered graphs as structural hypotheses and evaluates them by identifiability, stability, and falsification rather than by graph recovery accuracy alone. Empirically, we study the effect of early exposure to competitive gameplay on short-term retention using real-world game telemetry. We find that many statistically plausible discovery outputs do not admit point-identified causal queries once minimal temporal and semantic constraints are enforced, highlighting identifiability as a critical bottleneck for decision support. When identification is possible, several algorithm families converge to similar, decision-consistent effect estimates despite producing substantially different graph structures, including cases where the direct treatment-outcome edge is absent and the effect is preserved through indirect causal pathways. These converging estimates survive placebo, subsampling, and sensitivity refutation. In contrast, other methods exhibit sporadic admissibility and threshold-sensitive or attenuated effects due to endpoint ambiguity. These results suggest that graph-level metrics alone are inadequate proxies for causal reliability for a given target query. Therefore, trustworthy causal conclusions in telemetry-driven systems require prioritizing admissibility and effect-level validation over causal structural recovery alone.

</details>


### [377] [OPE: Overcoming Information Saturation in Parallel Thinking via Outline-Guided Path Exploration](https://arxiv.org/abs/2602.08344)
*Qi Guo,Jianing Wang,Deyang Kong,Xiangyu Xi,Jianfei Zhang,Yi Lu,Jingang Wang,Wei Wang,Shikun Zhang,Wei Ye*

Main category: cs.AI

TL;DR: 本文提出OPE方法，通过生成多样化的推理大纲来引导并行路径探索，解决并行思维中探索路径间互信息瓶颈问题，提升大型推理模型在复杂问题上的性能。


<details>
  <summary>Details</summary>
Motivation: 现有并行思维方法主要关注聚合阶段优化，对路径探索阶段关注有限。研究发现探索路径间的互信息瓶颈会限制整体性能，需要解决信息冗余和多样性不足的问题。

Method: 提出Outline-Guided Path Exploration (OPE)方法：1）在并行路径推理前生成多样化的推理大纲来划分解空间；2）采用迭代强化学习策略，独立优化大纲规划和大纲引导推理。

Result: 在多个具有挑战性的数学基准测试上进行广泛实验，证明OPE能有效提升不同聚合策略下的推理性能，使大型推理模型更可靠地发现正确解。

Conclusion: OPE通过显式划分解空间和减少信息冗余，解决了并行思维中的互信息瓶颈问题，为大型推理模型在复杂问题上的推理提供了有效方法。

Abstract: Parallel thinking has emerged as a new paradigm for large reasoning models (LRMs) in tackling complex problems. Recent methods leverage Reinforcement Learning (RL) to enhance parallel thinking, aiming to address the limitations in computational resources and effectiveness encountered with supervised fine-tuning. However, most existing studies primarily focus on optimizing the aggregation phase, with limited attention to the path exploration stage. In this paper, we theoretically analyze the optimization of parallel thinking under the Reinforcement Learning with Verifiable Rewards (RLVR) setting, and identify that the mutual information bottleneck among exploration paths fundamentally restricts overall performance. To address this, we propose Outline-Guided Path Exploration (OPE), which explicitly partitions the solution space by generating diverse reasoning outlines prior to parallel path reasoning, thereby reducing information redundancy and improving the diversity of information captured across exploration paths. We implement OPE with an iterative RL strategy that optimizes outline planning and outline-guided reasoning independently. Extensive experiments across multiple challenging mathematical benchmarks demonstrate that OPE effectively improves reasoning performance in different aggregation strategies, enabling LRMs to more reliably discover correct solutions.

</details>


### [378] [Towards Better Evolution Modeling for Temporal Knowledge Graphs](https://arxiv.org/abs/2602.08353)
*Zhang Jiasheng,Li Zhangpin,Wang Mingzhe,Shao Jie,Cui Jiangtao,Li Hui*

Main category: cs.AI

TL;DR: 现有TKG预测基准存在严重缺陷，仅通过统计共现就能达到接近SOTA的性能，无需使用任何时序信息，导致评估失真。


<details>
  <summary>Details</summary>
Motivation: 发现当前时序知识图谱(TKG)预测基准存在捷径：模型可以通过简单的共现统计达到接近最优性能，而无需真正理解时序演化模式，这使得现有评估结果不可靠。

Method: 分析现有基准问题的根本原因，识别数据集中的固有偏差和评估任务的过度简化形式；提出TKG演化基准，包括四个偏差校正数据集和两个与演化过程紧密相关的新任务。

Result: 揭示了现有TKG基准的多个局限性：时间间隔知识的不合理格式化、忽略知识过时性学习、演化理解信息不足等；提出了新的基准以促进对TKG演化建模挑战的更准确理解。

Conclusion: 现有TKG预测基准存在严重缺陷，需要新的偏差校正基准和更贴近实际演化过程的任务来公平评估模型性能，推动领域向真正理解时序演化的方向发展。

Abstract: Temporal knowledge graphs (TKGs) structurally preserve evolving human knowledge. Recent research has focused on designing models to learn the evolutionary nature of TKGs to predict future facts, achieving impressive results. For instance, Hits@10 scores over 0.9 on YAGO dataset. However, we find that existing benchmarks inadvertently introduce a shortcut. Near state-of-the-art performance can be simply achieved by counting co-occurrences, without using any temporal information. In this work, we examine the root cause of this issue, identifying inherent biases in current datasets and over simplified form of evaluation task that can be exploited by these biases. Through this analysis, we further uncover additional limitations of existing benchmarks, including unreasonable formatting of time-interval knowledge, ignorance of learning knowledge obsolescence, and insufficient information for precise evolution understanding, all of which can amplify the shortcut and hinder a fair assessment. Therefore, we introduce the TKG evolution benchmark. It includes four bias-corrected datasets and two novel tasks closely aligned with the evolution process, promoting a more accurate understanding of the challenges in TKG evolution modeling. Benchmark is available at: https://github.com/zjs123/TKG-Benchmark.

</details>


### [379] [Does Your Reasoning Model Implicitly Know When to Stop Thinking?](https://arxiv.org/abs/2602.08354)
*Zixuan Huang,Xin Xia,Yuxi Ren,Jianbin Zheng,Xuanda Wang,Zhixia Zhang,Hongyan Xie,Songshi Liang,Zehao Chen,Xuefeng Xiao,Fuzhen Zhuang,Jianxin Li,Yikun Ban,Deqing Wang*

Main category: cs.AI

TL;DR: 提出SAGE采样范式，利用大推理模型内在的"知道何时停止思考"能力，通过混合采样和强化学习显著提升推理准确性和效率


<details>
  <summary>Details</summary>
Motivation: 当前大推理模型使用长思维链方法存在大量冗余，损害计算效率并导致实时应用延迟。研究发现更长的推理链与正确性无关甚至有害，但模型实际上隐含知道何时停止思考，只是被当前采样范式掩盖

Method: 提出SAGE（Self-Aware Guided Efficient Reasoning）采样范式，释放模型的高效推理潜力。进一步将SAGE作为混合采样集成到基于群体的强化学习中（SAGE-RL），将SAGE发现的高效推理模式融入标准pass@1推理

Result: SAGE-RL在多个具有挑战性的数学基准测试中显著提升了大推理模型的推理准确性和效率

Conclusion: 大推理模型隐含知道何时停止思考，SAGE采样范式能够释放这种高效推理潜力，通过混合采样和强化学习可以显著提升模型的推理性能

Abstract: Recent advancements in large reasoning models (LRMs) have greatly improved their capabilities on complex reasoning tasks through Long Chains of Thought (CoTs). However, this approach often results in substantial redundancy, impairing computational efficiency and causing significant delays in real-time applications. Recent studies show that longer reasoning chains are frequently uncorrelated with correctness and can even be detrimental to accuracy. In a further in-depth analysis of this phenomenon, we surprisingly uncover and empirically verify that LRMs implicitly know the appropriate time to stop thinking, while this capability is obscured by current sampling paradigms. Motivated by this, we introduce SAGE (Self-Aware Guided Efficient Reasoning), a novel sampling paradigm that unleashes this efficient reasoning potential. Furthermore, integrating SAGE as mixed sampling into group-based reinforcement learning (SAGE-RL) enables SAGE-RL to effectively incorporate SAGE-discovered efficient reasoning patterns into standard pass@1 inference, markedly enhancing both the reasoning accuracy and efficiency of LRMs across multiple challenging mathematical benchmarks.

</details>


### [380] [Circuit Representations of Random Forests with Applications to XAI](https://arxiv.org/abs/2602.08362)
*Chunxi Ji,Adnan Darwiche*

Main category: cs.AI

TL;DR: 提出将随机森林分类器编译为电路的方法，用于高效计算决策解释、鲁棒性和最短翻转路径


<details>
  <summary>Details</summary>
Motivation: 现有方法在计算随机森林分类器的决策解释时效率较低，需要更高效的方法来支持可解释性分析

Method: 1) 将随机森林编译为电路编码；2) 基于电路计算决策的完整和一般原因；3) 提出计算决策鲁棒性和最短翻转路径的算法

Result: 提出的方法比现有方法显著更高效，能够枚举充分原因、必要原因、对比解释，计算决策鲁棒性，并识别最短决策翻转路径

Conclusion: 该方法为随机森林分类器提供了高效的可解释性分析工具，支持多种解释类型的计算和决策鲁棒性评估

Abstract: We make three contributions in this paper. First, we present an approach for compiling a random forest classifier into a set of circuits, where each circuit directly encodes the instances in some class of the classifier. We show empirically that our proposed approach is significantly more efficient than existing similar approaches. Next, we utilize this approach to further obtain circuits that are tractable for computing the complete and general reasons of a decision, which are instance abstractions that play a fundamental role in computing explanations. Finally, we propose algorithms for computing the robustness of a decision and all shortest ways to flip it. We illustrate the utility of our contributions by using them to enumerate all sufficient reasons, necessary reasons and contrastive explanations of decisions; to compute the robustness of decisions; and to identify all shortest ways to flip the decisions made by random forest classifiers learned from a wide range of datasets.

</details>


### [381] [MemAdapter: Fast Alignment across Agent Memory Paradigms via Generative Subgraph Retrieval](https://arxiv.org/abs/2602.08369)
*Xin Zhang,Kailai Yang,Chenyue Li,Hao Li,Qiyu Wei,Jun'ichi Tsujii,Sophia Ananiadou*

Main category: cs.AI

TL;DR: MemAdapter是一个统一异构内存范式的记忆检索框架，通过两阶段训练实现跨范式快速对齐，显著降低对齐成本并提升检索性能。


<details>
  <summary>Details</summary>
Motivation: 现有智能体记忆系统通常采用孤立范式（显式、参数化或潜在记忆），检索方法紧密耦合，阻碍了跨范式泛化和融合。需要统一异构内存范式。

Method: 提出MemAdapter框架：1) 从统一内存空间训练生成式子图检索器；2) 通过对比学习训练轻量对齐模块，将检索器适配到未见内存范式。采用两阶段训练策略。

Result: 在三个公共评估基准上，生成式子图检索器在三种内存范式和智能体模型规模上持续优于五个强基线系统。跨范式对齐仅需13分钟（单GPU），性能优于原始检索器且训练计算量不到5%。支持跨范式零样本融合。

Conclusion: MemAdapter作为即插即用解决方案，首次统一异构内存范式，实现快速跨范式对齐和高效检索，为智能体记忆系统提供了灵活且成本效益高的框架。

Abstract: Memory mechanism is a core component of LLM-based agents, enabling reasoning and knowledge discovery over long-horizon contexts. Existing agent memory systems are typically designed within isolated paradigms (e.g., explicit, parametric, or latent memory) with tightly coupled retrieval methods that hinder cross-paradigm generalization and fusion. In this work, we take a first step toward unifying heterogeneous memory paradigms within a single memory system. We propose MemAdapter, a memory retrieval framework that enables fast alignment across agent memory paradigms. MemAdapter adopts a two-stage training strategy: (1) training a generative subgraph retriever from the unified memory space, and (2) adapting the retriever to unseen memory paradigms by training a lightweight alignment module through contrastive learning. This design improves the flexibility for memory retrieval and substantially reduces alignment cost across paradigms. Comprehensive experiments on three public evaluation benchmarks demonstrate that the generative subgraph retriever consistently outperforms five strong agent memory systems across three memory paradigms and agent model scales. Notably, MemAdapter completes cross-paradigm alignment within 13 minutes on a single GPU, achieving superior performance over original memory retrievers with less than 5% of training compute. Furthermore, MemAdapter enables effective zero-shot fusion across memory paradigms, highlighting its potential as a plug-and-play solution for agent memory systems.

</details>


### [382] [Grounding Generative Planners in Verifiable Logic: A Hybrid Architecture for Trustworthy Embodied AI](https://arxiv.org/abs/2602.08373)
*Feiyu Wu,Xu Zheng,Yue Qu,Zhuocheng Wang,Zicheng Feng,Hui Li*

Main category: cs.AI

TL;DR: VIRF框架通过逻辑导师与LLM规划器的对话，实现可验证的迭代精炼，在保证安全性的同时提升目标达成率。


<details>
  <summary>Details</summary>
Motivation: 当前LLM在具身AI规划中缺乏形式化推理能力，无法提供严格的安全保证，现有方法要么依赖不可靠的LLM安全检查，要么简单拒绝不安全计划而不提供修复方案。

Method: 提出可验证迭代精炼框架(VIRF)，采用神经符号架构，包含确定性逻辑导师（基于形式化安全本体）与LLM规划器的导师-学徒对话机制，以及从真实世界文档合成安全知识库的可扩展知识获取流程。

Result: 在家庭安全任务中，VIRF实现了0%的危险行动率和77.3%的目标条件率（所有基线中最高），平均仅需1.1次修正迭代，效率很高。

Conclusion: VIRF为构建根本上可信且可验证安全的具身智能体提供了原则性路径，从被动安全把关转向主动协作修复。

Abstract: Large Language Models (LLMs) show promise as planners for embodied AI, but their stochastic nature lacks formal reasoning, preventing strict safety guarantees for physical deployment. Current approaches often rely on unreliable LLMs for safety checks or simply reject unsafe plans without offering repairs. We introduce the Verifiable Iterative Refinement Framework (VIRF), a neuro-symbolic architecture that shifts the paradigm from passive safety gatekeeping to active collaboration. Our core contribution is a tutor-apprentice dialogue where a deterministic Logic Tutor, grounded in a formal safety ontology, provides causal and pedagogical feedback to an LLM planner. This enables intelligent plan repairs rather than mere avoidance. We also introduce a scalable knowledge acquisition pipeline that synthesizes safety knowledge bases from real-world documents, correcting blind spots in existing benchmarks. In challenging home safety tasks, VIRF achieves a perfect 0 percent Hazardous Action Rate (HAR) and a 77.3 percent Goal-Condition Rate (GCR), which is the highest among all baselines. It is highly efficient, requiring only 1.1 correction iterations on average. VIRF demonstrates a principled pathway toward building fundamentally trustworthy and verifiably safe embodied agents.

</details>


### [383] [SCOUT-RAG: Scalable and Cost-Efficient Unifying Traversal for Agentic Graph-RAG over Distributed Domains](https://arxiv.org/abs/2602.08400)
*Longkun Li,Yuanben Zou,Jinghan Wu,Yuqing Wen,Jing Li,Hangwei Qian,Ivor Tsang*

Main category: cs.AI

TL;DR: SCOUT-RAG是一个分布式图检索增强生成框架，通过多智能体协作实现跨域渐进式检索，在分布式受限环境中减少计算成本和延迟。


<details>
  <summary>Details</summary>
Motivation: 传统Graph-RAG依赖集中式知识图谱，但在分布式和访问受限环境（如医院、跨国组织）中，缺乏全局图可见性且无法进行穷举查询，需要智能的跨域检索策略。

Method: 提出SCOUT-RAG框架，包含四个协作智能体：1) 评估域相关性；2) 决定何时扩展到其他域；3) 自适应调整遍历深度避免不必要的图探索；4) 合成高质量答案。框架旨在最小化检索遗憾（缺失有用信息）同时控制延迟和API成本。

Result: 在多域知识设置中，SCOUT-RAG性能与集中式基线（如DRIFT和穷举域遍历）相当，同时显著减少跨域调用、处理的总token数和延迟。

Conclusion: SCOUT-RAG为分布式受限环境中的Graph-RAG提供了一种可扩展、成本高效的解决方案，通过智能的渐进式检索策略平衡了检索质量和计算效率。

Abstract: Graph-RAG improves LLM reasoning using structured knowledge, yet conventional designs rely on a centralized knowledge graph. In distributed and access-restricted settings (e.g., hospitals or multinational organizations), retrieval must select relevant domains and appropriate traversal depth without global graph visibility or exhaustive querying. To address this challenge, we introduce \textbf{SCOUT-RAG} (\textit{\underline{S}calable and \underline{CO}st-efficient \underline{U}nifying \underline{T}raversal}), a distributed agentic Graph-RAG framework that performs progressive cross-domain retrieval guided by incremental utility goals. SCOUT-RAG employs four cooperative agents that: (i) estimate domain relevance, (ii) decide when to expand retrieval to additional domains, (iii) adapt traversal depth to avoid unnecessary graph exploration, and (iv) synthesize the high-quality answers. The framework is designed to minimize retrieval regret, defined as missing useful domain information, while controlling latency and API cost. Across multi-domain knowledge settings, SCOUT-RAG achieves performance comparable to centralized baselines, including DRIFT and exhaustive domain traversal, while substantially reducing cross-domain calls, total tokens processed, and latency.

</details>


### [384] [On Protecting Agentic Systems' Intellectual Property via Watermarking](https://arxiv.org/abs/2602.08401)
*Liwen Wang,Zongjie Li,Yuchong Xie,Shuai Wang,Dongdong She,Wei Wang,Juergen Rahmel*

Main category: cs.AI

TL;DR: AGENTWM是首个专门为智能代理模型设计的水印框架，通过偏置功能相同的工具执行路径分布来嵌入可验证水印，有效保护代理系统的知识产权。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型发展为具有自主推理和工具使用能力的智能代理系统，创造了重要的知识产权价值。这些系统容易受到模仿攻击，而现有的LLM水印技术无法应用于代理系统，因为现实中的代理系统通常是灰盒，隐藏了验证所需的内部推理轨迹。

Method: AGENTWM利用动作序列的语义等价性，通过微妙地偏置功能相同的工具执行路径分布来注入水印。开发了自动生成鲁棒水印方案的流水线和严格的统计假设检验程序进行验证。

Result: 在三个复杂领域的广泛评估表明，AGENTWM实现了高检测准确率，且对代理性能影响可忽略。即使面对自适应攻击者，也无法在不严重降低被盗模型效用的情况下移除水印。

Conclusion: AGENTWM是首个专门为智能代理模型设计的水印框架，能有效保护代理系统的知识产权，对抗模仿攻击，填补了现有LLM水印技术在该领域的空白。

Abstract: The evolution of Large Language Models (LLMs) into agentic systems that perform autonomous reasoning and tool use has created significant intellectual property (IP) value. We demonstrate that these systems are highly vulnerable to imitation attacks, where adversaries steal proprietary capabilities by training imitation models on victim outputs. Crucially, existing LLM watermarking techniques fail in this domain because real-world agentic systems often operate as grey boxes, concealing the internal reasoning traces required for verification. This paper presents AGENTWM, the first watermarking framework designed specifically for agentic models. AGENTWM exploits the semantic equivalence of action sequences, injecting watermarks by subtly biasing the distribution of functionally identical tool execution paths. This mechanism allows AGENTWM to embed verifiable signals directly into the visible action trajectory while remaining indistinguishable to users. We develop an automated pipeline to generate robust watermark schemes and a rigorous statistical hypothesis testing procedure for verification. Extensive evaluations across three complex domains demonstrate that AGENTWM achieves high detection accuracy with negligible impact on agent performance. Our results confirm that AGENTWM effectively protects agentic IP against adaptive adversaries, who cannot remove the watermarks without severely degrading the stolen model's utility.

</details>


### [385] [From Assistant to Double Agent: Formalizing and Benchmarking Attacks on OpenClaw for Personalized Local AI Agent](https://arxiv.org/abs/2602.08412)
*Yuhang Wang,Feiming Xu,Zheng Lin,Guangyu He,Yuzhe Huang,Haichang Gao,Zhenxing Niu*

Main category: cs.AI

TL;DR: 提出了PASB框架，用于评估真实世界个性化AI助手的安全风险，以OpenClaw为例发现其在多个执行阶段存在关键漏洞


<details>
  <summary>Details</summary>
Motivation: 现有代理安全研究主要关注合成或任务中心设置，无法准确捕捉真实世界个性化代理的攻击面和风险传播机制，需要专门的安全评估框架

Method: 提出PASB框架，结合个性化使用场景、真实工具链和长程交互，支持黑盒端到端安全评估，以OpenClaw为案例进行系统评估

Result: OpenClaw在用户提示处理、工具使用和记忆检索等不同执行阶段均存在关键漏洞，表明个性化代理部署存在重大安全风险

Conclusion: 个性化AI助手在实际部署中存在严重安全风险，需要专门的评估框架如PASB来识别和缓解这些风险

Abstract: Although large language model (LLM)-based agents, exemplified by OpenClaw, are increasingly evolving from task-oriented systems into personalized AI assistants for solving complex real-world tasks, their practical deployment also introduces severe security risks. However, existing agent security research and evaluation frameworks primarily focus on synthetic or task-centric settings, and thus fail to accurately capture the attack surface and risk propagation mechanisms of personalized agents in real-world deployments. To address this gap, we propose Personalized Agent Security Bench (PASB), an end-to-end security evaluation framework tailored for real-world personalized agents. Building upon existing agent attack paradigms, PASB incorporates personalized usage scenarios, realistic toolchains, and long-horizon interactions, enabling black-box, end-to-end security evaluation on real systems. Using OpenClaw as a representative case study, we systematically evaluate its security across multiple personalized scenarios, tool capabilities, and attack types. Our results indicate that OpenClaw exhibits critical vulnerabilities at different execution stages, including user prompt processing, tool usage, and memory retrieval, highlighting substantial security risks in personalized agent deployments. The code for the proposed PASB framework is available at https://github.com/AstorYH/PASB.

</details>


### [386] [When Evaluation Becomes a Side Channel: Regime Leakage and Structural Mitigations for Alignment Assessment](https://arxiv.org/abs/2602.08449)
*Igor Santos-Grueiro*

Main category: cs.AI

TL;DR: 论文提出将AI对齐评估重构为部分可观测下的信息流问题，证明评估时与部署时行为差异受内部表示与机制变量互信息限制，并通过机制盲训练减少机制信息可提取性来抑制条件策略行为。


<details>
  <summary>Details</summary>
Motivation: 传统AI安全评估假设评估时观察到的行为能预测部署时行为，但对于具有情境意识的智能体，这一假设变得脆弱。这类智能体可能利用"机制泄漏"（区分评估与部署的信息线索）实施条件策略（如奉承和潜伏代理），在监督下保持合规但在部署时违规。

Method: 将对齐评估重构为部分可观测下的信息流问题，提出机制盲训练方法：通过对抗性不变性减少在决策相关内部表示中机制信息的可提取性。在开源语言模型上评估两种完全特征化的失效模式：科学奉承和时序潜伏代理。

Result: 机制盲训练在两种评估案例中都抑制了机制条件行为，且没有可测量的任务效用损失。但动态特性不同：奉承行为在低干预强度下表现出急剧的表示和行为转变，而潜伏代理行为需要更强的压力且没有表现出机制可解码性的清晰崩溃。

Conclusion: 表示不变性是有意义但根本有限的控制杠杆，其有效性取决于机制信息在策略中的嵌入方式。行为评估应辅以机制意识和信息流的白盒诊断。

Abstract: Safety evaluation for advanced AI systems implicitly assumes that behavior observed under evaluation is predictive of behavior in deployment. This assumption becomes fragile for agents with situational awareness, which may exploitregime leakage-informational cues distinguishing evaluation from deployment-to implement conditional policies such as sycophancy and sleeper agents, which preserve compliance under oversight while defecting in deployment-like regimes. We reframe alignment evaluation as a problem of information flow under partial observability. Within this framework, we show that divergence between evaluation-time and deployment-time behavior is bounded by the mutual information between internal representations and the regime variable. Motivated by this result, we study regime-blind mechanisms: training-time interventions that reduce the extractability of regime information at decision-relevant internal representations via adversarial invariance. We evaluate this approach on a base, open-weight language model across two fully characterized failure modes -scientific sycophancy and temporal sleeper agents. Regime-blind training suppresses regime-conditioned behavior in both evaluated cases without measurable loss of task utility, but with qualitatively different dynamics: sycophancy exhibits a sharp representational and behavioral transition at low intervention strength, whereas sleeper-agent behavior requires substantially stronger pressure and does not exhibit a clean collapse of regime decodability. These results demonstrate that representational invariance is a meaningful but fundamentally limited control lever, whose effectiveness depends on how regime information is embedded in the policy. We argue that behavioral evaluation should be complemented with white-box diagnostics of regime awareness and information flow.

</details>


### [387] [TreeTensor: Boost AI System on Nested Data with Constrained Tree-Like Tensor](https://arxiv.org/abs/2602.08517)
*Shaoang Zhang,Yazhe Niu*

Main category: cs.AI

TL;DR: 提出了TreeTensor作为处理嵌套数据（如层次化、多模态数据）的通用容器，能够以零成本对嵌套数据应用任意函数和操作，兼容主流机器学习库，并在复杂AI系统中展现强大可用性和运行时效率。


<details>
  <summary>Details</summary>
Motivation: 传统Tensor具有固定形状，在处理复杂认知AI系统中的层次化嵌套数据（多模态、可变长度）时不便且低效，需要一种更灵活的数据结构来支持这类数据的编程和计算。

Method: 总结嵌套数据的两种主要计算模式，提出TreeTensor作为通用嵌套数据容器，通过约束和魔法工具实现对嵌套数据的零成本函数应用，支持与Scikit-Learn、Numpy、PyTorch等库的兼容。

Result: TreeTensor在多种问题中展现出强大可用性，特别是在目前最复杂的AI系统之一——星际争霸II的AlphaStar中，同时表现出优异的运行时效率且无额外开销。

Conclusion: TreeTensor通过树结构视角系统建模数据关系，为解决复杂AI系统中的嵌套数据处理问题提供了高效、通用的解决方案，并能与其他方法结合扩展更多用途。

Abstract: Tensor is the most basic and essential data structure of nowadays artificial intelligence (AI) system. The natural properties of Tensor, especially the memory-continuity and slice-independence, make it feasible for training system to leverage parallel computing unit like GPU to process data simultaneously in batch, spatial or temporal dimensions. However, if we look beyond perception tasks, the data in a complicated cognitive AI system usually has hierarchical structures (i.e. nested data) with various modalities. They are inconvenient and inefficient to program directly with conventional Tensor with fixed shape. To address this issue, we summarize two main computational patterns of nested data, and then propose a general nested data container: TreeTensor. Through various constraints and magic utilities of TreeTensor, one can apply arbitrary functions and operations to nested data with almost zero cost, including some famous machine learning libraries, such as Scikit-Learn, Numpy and PyTorch. Our approach utilizes a constrained tree-structure perspective to systematically model data relationships, and it can also easily be combined with other methods to extend more usages, such as asynchronous execution and variable-length data computation. Detailed examples and benchmarks show TreeTensor not only provides powerful usability in various problems, especially one of the most complicated AI systems at present: AlphaStar for StarCraftII, but also exhibits excellent runtime efficiency without any overhead. Our project is available at https://github.com/opendilab/DI-treetensor.

</details>


### [388] [Reinforcement Inference: Leveraging Uncertainty for Self-Correcting Language Model Reasoning](https://arxiv.org/abs/2602.08520)
*Xinhai Sun*

Main category: cs.AI

TL;DR: 提出Reinforcement Inference方法，利用模型自身的不确定性选择性触发第二次推理，无需重新训练即可提升LLM性能


<details>
  <summary>Details</summary>
Motivation: 传统的一次性贪婪推理协议会系统性地低估模型真实能力，许多错误源于模型在内部模糊情况下的过早决策，而非知识缺失

Method: 基于熵感知的推理时控制策略，利用模型自身不确定性作为控制信号，选择性触发第二次更审慎的推理尝试

Result: 在MMLU-Pro的12,032个问题上，使用DeepSeek-v3.2，准确率从60.72%提升到84.03%，仅增加61.06%的推理调用；100%重新提问达到84.35%

Conclusion: 提出熵感知范式用于衡量和扩展模型能力，不确定性调节的深思熟虑与一次性贪婪推理之间的差距可作为诊断模型潜在推理视野的透镜

Abstract: Modern large language models (LLMs) are often evaluated and deployed under a \emph{one-shot, greedy} inference protocol, especially in professional settings that require deterministic behavior. This regime can systematically under-estimate a fixed model's true capability: many errors arise not from missing knowledge, but from premature commitment under internal ambiguity. We introduce \emph{Reinforcement Inference}, an entropy-aware inference-time control strategy that uses the model's own uncertainty to selectively invoke a second, more deliberate reasoning attempt, enabling stronger performance \emph{without any retraining}.
  On 12,032 MMLU-Pro questions across 14 subjects, using DeepSeek-v3.2 with deterministic decoding in a zero-shot setting, Reinforcement Inference improves accuracy from 60.72\% to 84.03\%, while only incurring 61.06\% additional inference calls. A 100\% re-asking ablation reaches 84.35\%, indicating that uncertainty-aware selection captures most of the attainable improvement with substantially less compute. Moreover, a \emph{prompt-only} ablation underperforms the baseline, suggesting that the gains are not explained by generic `` your output had high entropy, think step-by-step'' prompting alone.
  Beyond providing a practical inference-time upgrade, our results suggest a broader \emph{entropy-aware} paradigm for measuring and expanding model capability: because modern decoder-based models generate outputs autoregressively, entropy and related confidence measures arise naturally as first-class control signals during generation. The resulting gap between one-pass greedy inference and uncertainty-conditioned deliberation offers a diagnostic lens on an LLM's latent reasoning horizon and motivates future training objectives that explicitly constrain correctness--confidence alignment.

</details>


### [389] [Dialogue Model Optimization via Agent Game and Adaptive Tree-based GRPO](https://arxiv.org/abs/2602.08533)
*Kun Peng,Conghui Tan,Yu Liu,Guohua Tang,Zhongqian Sun,Wei Yang,Zining Zhu,Lei Jiang,Yanbing Liu,Hao Peng*

Main category: cs.AI

TL;DR: 提出AT-GRPO框架，通过两智能体游戏范式实现在线个性化，将对话轨迹重构为树结构并引入自适应观测范围，在多项式复杂度下捕获长期奖励


<details>
  <summary>Details</summary>
Motivation: 现有开放域对话系统存在两大局限：过度依赖预收集用户数据，以及强化学习中的短视偏差忽视长期对话价值。需要一种能在线个性化且考虑长期对话效果的框架。

Method: 采用两智能体游戏范式：用户智能体通过风格模仿学习用户特定对话特征，主动终止预测回合级终止概率作为即时奖励；对话智能体使用AT-GRPO算法，将对话轨迹重构为树结构，引入自适应观测范围（早期大范围探索话题，后期小范围维持对话），将复杂度从指数级降至多项式级。

Result: 实验表明该框架在性能、样本效率和鲁棒性方面表现优异，能够有效平衡话题探索与对话维持，实现长期对话价值的最大化。

Conclusion: 提出的AT-GRPO框架成功解决了开放域对话系统中的在线个性化和长期价值优化问题，通过创新的树结构表示和自适应观测范围设计，在计算效率与长期奖励捕获之间取得了良好平衡。

Abstract: Open-ended dialogue agents aim to deliver engaging, personalized interactions by adapting to users' traits, but existing methods face critical limitations: over-reliance on pre-collected user data, and short-horizon biases in reinforcement learning (RL) that neglect long-term dialogue value. To address these, we propose a novel long-horizon RL framework integrating online personalization with Adaptive Tree-based Group Relative Policy Optimization (AT-GRPO). Adopting a two-agent game paradigm, a user agent constructs dynamic environments via style mimicry (learning user-specific conversational traits) and active termination (predicting turn-level termination probabilities as immediate rewards), forming an iterative cycle that drives the dialogue agent to deepen interest exploration. AT-GRPO reinterprets dialogue trajectories as trees and introduces adaptive observation ranges. Unlike full tree expansion that incurs exponential overhead, it limits each node to aggregate rewards from a stage-aware range: larger ranges support early-stage topic exploration, while smaller ranges facilitate late-stage dialogue maintenance. This design reduces rollout budgets from exponential to polynomial in the dialogue length, while preserving long-term reward capture. Extensive experiments show our framework's superior performance, sample efficiency, and robustness.

</details>


### [390] [PRISM: A Principled Framework for Multi-Agent Reasoning via Gain Decomposition](https://arxiv.org/abs/2602.08586)
*Yiming Yang,Zhuoyuan Li,Fanxiang Zeng,Hao Fu,Yue Liu*

Main category: cs.AI

TL;DR: PRISM框架通过探索、信息、聚合三个维度系统优化多智能体推理，在数学推理、代码生成等任务上实现SOTA性能


<details>
  <summary>Details</summary>
Motivation: 现有多智能体协作方法缺乏理论指导，不清楚为何优于单智能体以及哪些设计选择最关键，难以系统优化

Method: 提出PRISM框架：通过角色多样性最大化探索，基于执行的证据交叉评估提供高保真反馈，迭代合成与闭环验证实现原则性共识

Result: 在数学推理、代码生成和函数调用基准测试中实现最先进性能，计算效率优于仅优化部分维度的方法

Conclusion: 理论框架为未来多智能体推理系统提供可操作的设计原则，PRISM通过联合优化三个维度实现系统性改进

Abstract: Multi-agent collaboration has emerged as a promising paradigm for enhancing reasoning capabilities of Large Language Models (LLMs). However, existing approaches remain largely heuristic, lacking principled guidance on what drives performance gains and how to systematically optimize multi-agent reasoning. Specifically, it remains unclear why multi-agent collaboration outperforms single-agent reasoning and which design choices contribute most to these gains, making it difficult to build better systems.
  We address this gap by introducing a unified theoretical framework that decomposes multi-agent reasoning gains into three conceptually independent dimensions: Exploration for diverse solution coverage, Information for high-fidelity feedback, and Aggregation for principled consensus. Through this lens, existing methods can be understood as special cases that optimize only subsets of these dimensions. Building upon this decomposition, a novel framework called PRISM (Propose-Review-Integrate Synthesis for Multi-agent Reasoning) is proposed, which jointly maximizes all three dimensions through role-based diversity, execution-grounded feedback with evidence-based cross-evaluation, and iterative synthesis with closed-loop validation. Extensive experiments across mathematical reasoning, code generation, and function calling benchmarks demonstrate that PRISM achieves state-of-the-art performance with superior compute-efficiency compared to methods optimizing partial dimensions. The theoretical framework provides actionable design principles for future multi-agent reasoning systems.

</details>


### [391] [An Attention Mechanism for Robust Multimodal Integration in a Global Workspace Architecture](https://arxiv.org/abs/2602.08597)
*Roland Bertin-Johannet,Lara Scipio,Leopold Maytié,Rufin VanRullen*

Main category: cs.AI

TL;DR: 提出一种用于全局工作空间理论（GWT）的top-down注意力机制，增强多模态系统的噪声鲁棒性和泛化能力


<details>
  <summary>Details</summary>
Motivation: 全局工作空间理论（GWT）作为认知神经科学启发的框架，能够指导多模态整合计算架构的设计。然而，现有GWT实现主要关注多模态表示能力，相关的注意力机制研究不足，需要开发有效的注意力选择机制来提升系统性能。

Method: 提出一种top-down注意力机制，用于在全局工作空间中选择相关模态。该方法首先在Simple Shapes和MM-IMDb 1.0两个复杂度递增的多模态数据集上验证噪声鲁棒性，然后评估其跨任务和跨模态泛化能力。

Result: 1. 注意力机制显著提升了全局工作空间系统在两个数据集上的噪声鲁棒性；2. 展示了文献中多模态注意力模型不具备的跨任务和跨模态泛化能力；3. 在MM-IMDb 1.0基准测试中，该机制使全局工作空间系统达到与当前最优方法竞争的水平。

Conclusion: 提出的top-down注意力机制有效增强了全局工作空间理论在多模态整合中的实用性，不仅提升了噪声鲁棒性，还赋予了独特的泛化能力，使GWT框架在多模态学习任务中具有竞争力。

Abstract: Global Workspace Theory (GWT), inspired by cognitive neuroscience, posits that flexible cognition could arise via the attentional selection of a relevant subset of modalities within a multimodal integration system. This cognitive framework can inspire novel computational architectures for multimodal integration. Indeed, recent implementations of GWT have explored its multimodal representation capabilities, but the related attention mechanisms remain understudied. Here, we propose and evaluate a top-down attention mechanism to select modalities inside a global workspace. First, we demonstrate that our attention mechanism improves noise robustness of a global workspace system on two multimodal datasets of increasing complexity: Simple Shapes and MM-IMDb 1.0. Second, we highlight various cross-task and cross-modality generalization capabilities that are not shared by multimodal attention models from the literature. Comparing against existing baselines on the MM-IMDb 1.0 benchmark, we find our attention mechanism makes the global workspace competitive with the state of the art.

</details>


### [392] [OSCAR: Optimization-Steered Agentic Planning for Composed Image Retrieval](https://arxiv.org/abs/2602.08603)
*Teng Wang,Rong Shan,Jianghao Lin,Junjie Wu,Tianyi Xu,Jianping Zhang,Wenteng Chen,Changwang Zhang,Zhaoxiang Wang,Weinan Zhang,Jun Wang*

Main category: cs.AI

TL;DR: OSCAR是一个基于优化引导的智能体规划框架，用于组合图像检索，将启发式搜索转化为轨迹优化问题，通过离线-在线范式实现高效检索。


<details>
  <summary>Details</summary>
Motivation: 现有组合图像检索方法存在两个主要问题：统一嵌入检索受限于单一模型视野，启发式智能体检索则受限于次优的试错编排。需要一种更系统化的方法来处理视觉和文本约束的复杂推理。

Method: 提出OSCAR框架，采用离线-在线范式：1）离线阶段将CIR建模为两阶段混合整数规划问题，通过布尔集合运算推导最优轨迹；2）在线阶段使用VLM规划器，以离线生成的最优轨迹作为上下文演示进行引导推理。

Result: 在三个公共基准和一个私有工业基准上的实验表明，OSCAR始终优于现有SOTA基线。仅使用10%训练数据就能达到优越性能，证明了规划逻辑的强泛化能力而非数据集特定记忆。

Conclusion: OSCAR成功将智能体CIR从启发式搜索过程重新定义为原则性轨迹优化问题，通过数学推导的最优轨迹引导在线推理，实现了更好的泛化性能和样本效率。

Abstract: Composed image retrieval (CIR) requires complex reasoning over heterogeneous visual and textual constraints. Existing approaches largely fall into two paradigms: unified embedding retrieval, which suffers from single-model myopia, and heuristic agentic retrieval, which is limited by suboptimal, trial-and-error orchestration. To this end, we propose OSCAR, an optimization-steered agentic planning framework for composed image retrieval. We are the first to reformulate agentic CIR from a heuristic search process into a principled trajectory optimization problem. Instead of relying on heuristic trial-and-error exploration, OSCAR employs a novel offline-online paradigm. In the offline phase, we model CIR via atomic retrieval selection and composition as a two-stage mixed-integer programming problem, mathematically deriving optimal trajectories that maximize ground-truth coverage for training samples via rigorous boolean set operations. These trajectories are then stored in a golden library to serve as in-context demonstrations for online steering of VLM planner at online inference time. Extensive experiments on three public benchmarks and a private industrial benchmark show that OSCAR consistently outperforms SOTA baselines. Notably, it achieves superior performance using only 10% of training data, demonstrating strong generalization of planning logic rather than dataset-specific memorization.

</details>


### [393] [Debate is efficient with your time](https://arxiv.org/abs/2602.08630)
*Jonah Brown-Cohen,Geoffrey Irving,Simon C. Marshall,Ilan Newman,Georgios Piliouras,Mario Szegedy*

Main category: cs.AI

TL;DR: 本文引入辩论查询复杂度(DQC)概念，分析人类监督辩论所需的查询次数，发现PSPACE/poly问题仅需O(log n)次查询即可判定，且证明DQC下界与电路复杂性核心问题相关。


<details>
  <summary>Details</summary>
Motivation: 现有研究已证明辩论在理论上能解决哪些问题，但未分析人类监督的实际成本——法官需要检查辩论记录多少次查询。本文旨在量化辩论中人类监督的效率。

Method: 引入辩论查询复杂度(DQC)作为衡量标准，即验证者正确判定辩论所需检查的最小比特数。通过理论分析建立DQC与计算复杂性类的关系。

Result: 发现PSPACE/poly（辩论能高效判定的问题类）恰好是O(log n)查询可判定的函数类，表明辩论具有极高的查询效率。还证明任何依赖所有输入比特的函数需要Ω(log n)查询，且大小为s的电路可计算函数满足DQC(f) ≤ log(s) + 3。

Conclusion: 辩论在查询效率方面表现卓越，即使对于高度复杂问题，对数级监督已足够。更重要的是，证明P类语言的log(n)+6 DQC下界将产生新的电路下界，将辩论查询复杂度与电路复杂性核心问题联系起来。

Abstract: AI safety via debate uses two competing models to help a human judge verify complex computational tasks. Previous work has established what problems debate can solve in principle, but has not analysed the practical cost of human oversight: how many queries must the judge make to the debate transcript? We introduce Debate Query Complexity}(DQC), the minimum number of bits a verifier must inspect to correctly decide a debate.
  Surprisingly, we find that PSPACE/poly (the class of problems which debate can efficiently decide) is precisely the class of functions decidable with O(log n) queries. This characterisation shows that debate is remarkably query-efficient: even for highly complex problems, logarithmic oversight suffices. We also establish that functions depending on all their input bits require Omega(log n) queries, and that any function computable by a circuit of size s satisfies DQC(f) <= log(s) + 3. Interestingly, this last result implies that proving DQC lower bounds of log(n) + 6 for languages in P would yield new circuit lower bounds, connecting debate query complexity to central questions in circuit complexity.

</details>


### [394] [Why do we Trust Chatbots? From Normative Principles to Behavioral Drivers](https://arxiv.org/abs/2602.08707)
*Aditya Gulati,Nuria Oliver*

Main category: cs.AI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: As chatbots increasingly blur the boundary between automated systems and human conversation, the foundations of trust in these systems warrant closer examination. While regulatory and policy frameworks tend to define trust in normative terms, the trust users place in chatbots often emerges from behavioral mechanisms. In many cases, this trust is not earned through demonstrated trustworthiness but is instead shaped by interactional design choices that leverage cognitive biases to influence user behavior. Based on this observation, we propose reframing chatbots not as companions or assistants, but as highly skilled salespeople whose objectives are determined by the deploying organization. We argue that the coexistence of competing notions of "trust" under a shared term obscures important distinctions between psychological trust formation and normative trustworthiness. Addressing this gap requires further research and stronger support mechanisms to help users appropriately calibrate trust in conversational AI systems.

</details>


### [395] [Intermediate Results on the Complexity of STRIPS$_{1}^{1}$](https://arxiv.org/abs/2602.08708)
*Stefan Edelkamp,Jiří Fink,Petr Gregor,Anders Jonsson,Bernhard Nebel*

Main category: cs.AI

TL;DR: 本文研究STRIPS规划的计算复杂度，探讨只有一个前提条件和一个效果的运算符是否NP完全的问题。


<details>
  <summary>Details</summary>
Motivation: Bylander已证明命题STRIPS规划在仅允许基文字时，即使运算符限制为两个前提条件和两个后置条件，确定规划存在性也是PSPACE完全的。虽然NP困难性已确定，但只有一个前提条件和一个效果的命题STRIPS是否NP完全仍是未知问题。

Method: 通过调用SAT求解器处理小规模实例、引入文字图（literal graph）并将其映射到Petri网来研究STRIPS¹₁的小解假设问题。

Result: 论文对只有一个前提条件和一个效果的STRIPS规划的计算复杂度问题提供了新的见解，但具体结果需要进一步分析。

Conclusion: 本文为理解STRIPS¹₁规划的计算复杂度边界提供了新的方法和见解，有助于澄清该领域的重要开放问题。

Abstract: This paper is based on Bylander's results on the computational complexity of propositional STRIPS planning. He showed that when only ground literals are permitted, determining plan existence is PSPACE-complete even if operators are limited to two preconditions and two postconditions. While NP-hardness is settled, it is unknown whether propositional STRIPS with operators that only have one precondition and one effect is NP-complete. We shed light on the question whether this small solution hypothesis for STRIPS$^1_1$ is true, calling a SAT solver for small instances, introducing the literal graph, and mapping it to Petri nets.

</details>


### [396] [Exploring SAIG Methods for an Objective Evaluation of XAI](https://arxiv.org/abs/2602.08715)
*Miquel Miró-Nicolau,Gabriel Moyà-Alcover,Anna Arias-Duart*

Main category: cs.AI

TL;DR: 本文首次系统综述了合成人工智能基准真值（SAIG）方法，提出了一种新的分类法，揭示了XAI评估领域缺乏共识的问题。


<details>
  <summary>Details</summary>
Motivation: 可解释人工智能（XAI）评估领域方法多样，但由于缺乏解释的普遍正确基准真值，客观评估具有挑战性。SAIG方法通过生成人工基准真值来直接评估XAI技术，为解决这一问题提供了有前景的方向。

Method: 本文对SAIG方法进行了首次系统综述和分析，提出了一种新的分类法，通过七个关键特征来区分不同的SAIG方法，并进行了比较研究。

Result: 研究发现XAI评估技术缺乏共识，最有效的评估方法尚未达成一致，这凸显了该领域需要进一步研究和标准化。

Conclusion: SAIG方法为XAI评估提供了有前景的解决方案，但当前领域缺乏共识，需要更多研究和标准化工作来推动XAI评估的发展。

Abstract: The evaluation of eXplainable Artificial Intelligence (XAI) methods is a rapidly growing field, characterized by a wide variety of approaches. This diversity highlights the complexity of the XAI evaluation, which, unlike traditional AI assessment, lacks a universally correct ground truth for the explanation, making objective evaluation challenging. One promising direction to address this issue involves the use of what we term Synthetic Artificial Intelligence Ground truth (SAIG) methods, which generate artificial ground truths to enable the direct evaluation of XAI techniques. This paper presents the first review and analysis of SAIG methods. We introduce a novel taxonomy to classify these approaches, identifying seven key features that distinguish different SAIG methods. Our comparative study reveals a concerning lack of consensus on the most effective XAI evaluation techniques, underscoring the need for further research and standardization in this area.

</details>


### [397] [Finite-State Controllers for (Hidden-Model) POMDPs using Deep Reinforcement Learning](https://arxiv.org/abs/2602.08734)
*David Hudák,Maris F. L. Galesloot,Martin Tappler,Martin Kurečka,Nils Jansen,Milan Češka*

Main category: cs.AI

TL;DR: Lexpop框架结合深度强化学习和有限状态控制器提取，为POMDP和HM-POMDP提供可形式化验证的鲁棒策略


<details>
  <summary>Details</summary>
Motivation: 现有POMDP求解器可扩展性有限，且许多场景需要跨多个POMDP的鲁棒策略，进一步加剧了可扩展性问题

Method: 1) 使用深度强化学习训练循环神经网络策略；2) 通过高效提取方法构建模仿神经策略的有限状态控制器；3) 扩展到HM-POMDP，为每个控制器关联最坏情况POMDP，迭代训练鲁棒神经策略并提取鲁棒控制器

Result: 在大状态空间问题上，Lexpop在POMDP和HM-POMDP求解方面均优于现有最先进求解器

Conclusion: Lexpop框架通过结合神经网络的表达能力与控制器的可验证性，有效解决了POMDP和HM-POMDP的可扩展性和鲁棒性问题

Abstract: Solving partially observable Markov decision processes (POMDPs) requires computing policies under imperfect state information. Despite recent advances, the scalability of existing POMDP solvers remains limited. Moreover, many settings require a policy that is robust across multiple POMDPs, further aggravating the scalability issue. We propose the Lexpop framework for POMDP solving. Lexpop (1) employs deep reinforcement learning to train a neural policy, represented by a recurrent neural network, and (2) constructs a finite-state controller mimicking the neural policy through efficient extraction methods. Crucially, unlike neural policies, such controllers can be formally evaluated, providing performance guarantees. We extend Lexpop to compute robust policies for hidden-model POMDPs (HM-POMDPs), which describe finite sets of POMDPs. We associate every extracted controller with its worst-case POMDP. Using a set of such POMDPs, we iteratively train a robust neural policy and consequently extract a robust controller. Our experiments show that on problems with large state spaces, Lexpop outperforms state-of-the-art solvers for POMDPs as well as HM-POMDPs.

</details>


### [398] [Belief Offloading in Human-AI Interaction](https://arxiv.org/abs/2602.08754)
*Rose E. Guingrich,Dvija Mehta,Umang Bhatt*

Main category: cs.AI

TL;DR: 本文探讨人类在与LLM交互时发生的"信念卸载"现象，即人们将信念形成和维护过程外包给AI系统，从而影响其行为和信念体系。


<details>
  <summary>Details</summary>
Motivation: 随着LLM聊天机器人成为人们的思考伙伴，认知卸载可能导致过度依赖并损害认知能力。本文旨在研究人类与AI交互中特定类型的认知卸载——"信念卸载"现象及其影响。

Method: 基于哲学、心理学和计算机科学研究，明确定义信念卸载的边界条件，提供描述性分类法，并分析其规范性影响。

Result: 提出了信念卸载的概念框架和分类体系，阐明了信念卸载发生的条件及其对人类行为和信念体系的潜在影响。

Conclusion: 信念卸载是人类-AI交互中的重要现象，需要进一步研究其发生机制和后果，以指导未来人机交互设计。

Abstract: What happens when people's beliefs are derived from information provided by an LLM? People's use of LLM chatbots as thought partners can contribute to cognitive offloading, which can have adverse effects on cognitive skills in cases of over-reliance. This paper defines and investigates a particular kind of cognitive offloading in human-AI interaction, "belief offloading," in which people's processes of forming and upholding beliefs are offloaded onto an AI system with downstream consequences on their behavior and the nature of their system of beliefs. Drawing on philosophy, psychology, and computer science research, we clarify the boundary conditions under which belief offloading occurs and provide a descriptive taxonomy of belief offloading and its normative implications. We close with directions for future work to assess the potential for and consequences of belief offloading in human-AI interaction.

</details>


### [399] [Dynamics Within Latent Chain-of-Thought: An Empirical Study of Causal Structure](https://arxiv.org/abs/2602.08783)
*Zirui Li,Xuefeng Bai,Kehai Chen,Yizhi Li,Jian Yang,Chenghua Lin,Min Zhang*

Main category: cs.AI

TL;DR: 该论文通过将潜在思维链建模为结构因果模型中的变量，使用干预分析研究潜在推理步骤的因果效应，发现潜在步骤预算表现为阶段性功能而非均匀深度，并识别出早期输出偏差与晚期表征承诺之间的差距。


<details>
  <summary>Details</summary>
Motivation: 潜在思维链方法使用内部潜在步骤替代显式文本推理，但这些中间计算难以评估。研究者希望将潜在思维链视为表示空间中可操作的因果过程，通过因果干预分析来理解其工作机制。

Method: 将潜在推理步骤建模为结构因果模型中的变量，使用逐步干预分析。研究两种代表性范式（Coconut和CODI），在数学和一般推理任务上分析三个关键问题：步骤的因果必要性、影响传播机制、以及中间轨迹是否保留竞争答案模式。

Result: 发现潜在步骤预算更像阶段性功能而非均匀额外深度，具有非局部路由特性。识别出早期输出偏差与晚期表征承诺之间的持续差距。潜在推理系统表现出模式条件和稳定性特征。

Conclusion: 研究结果支持采用模式条件和稳定性感知的分析方法，以及相应的训练/解码目标，作为解释和改进潜在推理系统的更可靠工具。

Abstract: Latent or continuous chain-of-thought methods replace explicit textual rationales with a number of internal latent steps, but these intermediate computations are difficult to evaluate beyond correlation-based probes. In this paper, we view latent chain-of-thought as a manipulable causal process in representation space by modeling latent steps as variables in a structural causal model (SCM) and analyzing their effects through step-wise $\mathrm{do}$-interventions. We study two representative paradigms (i.e., Coconut and CODI) on both mathematical and general reasoning tasks to investigate three key questions: (1) which steps are causally necessary for correctness and when answers become decidable early; (2) how does influence propagate across steps, and how does this structure compare to explicit CoT; and (3) do intermediate trajectories retain competing answer modes, and how does output-level commitment differ from representational commitment across steps. We find that latent-step budgets behave less like homogeneous extra depth and more like staged functionality with non-local routing, and we identify a persistent gap between early output bias and late representational commitment. These results motivate mode-conditional and stability-aware analyses -- and corresponding training/decoding objectives -- as more reliable tools for interpreting and improving latent reasoning systems.

</details>


### [400] [The Use of AI Tools to Develop and Validate Q-Matrices](https://arxiv.org/abs/2602.08796)
*Kevin Fan,Jacquelyn A. Bialo,Hongli Li*

Main category: cs.AI

TL;DR: AI工具（通用语言模型）可以支持Q矩阵开发，但效果因模型而异且随时间变化，Google Gemini 2.5 Pro表现最佳，甚至超过人类专家。


<details>
  <summary>Details</summary>
Motivation: 认知诊断模型（CDM）中构建Q矩阵是关键但劳动密集型步骤，研究探索AI工具是否能支持Q矩阵开发，减轻人工负担。

Method: 使用多个AI模型（通用语言模型）与人类专家相同的训练材料生成Q矩阵，与Li和Suen（2013）验证的Q矩阵比较，使用Cohen's kappa评估一致性，并在2026年1月用新版AI模型进行后续分析。

Result: 不同AI模型表现差异很大，Google Gemini 2.5 Pro与验证Q矩阵的一致性最高（Kappa=0.63），超过所有人类专家；但2026年新版AI模型的一致性反而下降。

Conclusion: AI工具可以支持Q矩阵开发，但效果不稳定且随时间变化，需要进一步研究如何可靠地利用AI进行认知诊断评估。

Abstract: Constructing a Q-matrix is a critical but labor-intensive step in cognitive diagnostic modeling (CDM). This study investigates whether AI tools (i.e., general language models) can support Q-matrix development by comparing AI-generated Q-matrices with a validated Q-matrix from Li and Suen (2013) for a reading comprehension test. In May 2025, multiple AI models were provided with the same training materials as human experts. Agreement among AI-generated Q-matrices, the validated Q-matrix, and human raters' Q-matrices was assessed using Cohen's kappa. Results showed substantial variation across AI models, with Google Gemini 2.5 Pro achieving the highest agreement (Kappa = 0.63) with the validated Q-matrix, exceeding that of all human experts. A follow-up analysis in January 2026 using newer AI versions, however, revealed lower agreement with the validated Q-matrix. Implications and directions for future research are discussed.

</details>


### [401] [Root Cause Analysis Method Based on Large Language Models with Residual Connection Structures](https://arxiv.org/abs/2602.08804)
*Liming Zhou,Ailing Liu,Hongwei Liu,Min He,Heng Zhang*

Main category: cs.AI

TL;DR: RC-LLM：基于残差连接和大语言模型的微服务根因定位方法，通过多源遥测数据融合和上下文推理能力提升复杂微服务架构中的故障分析效果。


<details>
  <summary>Details</summary>
Motivation: 微服务架构复杂且规模庞大，故障在微服务间传播复杂，遥测数据（指标、日志、追踪）维度高，现有根因分析方法效果有限。

Method: 提出RC-LLM方法：设计残差式分层融合结构整合多源遥测数据，利用大语言模型的上下文推理能力建模时间和跨微服务的因果依赖关系。

Result: 在CCF-AIOps微服务数据集上的实验结果表明，RC-LLM在根因分析中实现了强大的准确性和效率。

Conclusion: RC-LLM通过结合残差连接结构和大语言模型，有效解决了复杂微服务架构中的根因定位挑战，提升了故障分析的准确性和效率。

Abstract: Root cause localization remain challenging in complex and large-scale microservice architectures. The complex fault propagation among microservices and the high dimensionality of telemetry data, including metrics, logs, and traces, limit the effectiveness of existing root cause analysis (RCA) methods. In this paper, a residual-connection-based RCA method using large language model (LLM), named RC-LLM, is proposed. A residual-like hierarchical fusion structure is designed to integrate multi-source telemetry data, while the contextual reasoning capability of large language models is leveraged to model temporal and cross-microservice causal dependencies. Experimental results on CCF-AIOps microservice datasets demonstrate that RC-LLM achieves strong accuracy and efficiency in root cause analysis.

</details>


### [402] [Negative-Aware Diffusion Process for Temporal Knowledge Graph Extrapolation](https://arxiv.org/abs/2602.08815)
*Yanglei Gan,Peng He,Yuxiang Cai,Run Lin,Guanyu Zhou,Qiao Liu*

Main category: cs.AI

TL;DR: NADEx提出了一种负感知扩散模型用于时序知识图谱推理，通过结合负样本信息改进传统扩散模型，在四个公开基准上取得SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 当前时序知识图谱推理中，扩散模型存在两个主要问题：1）生成路径仅基于正样本证据，忽略了信息丰富的负上下文；2）训练目标被交叉熵排序主导，虽然改善了候选排序但对去噪嵌入的校准监督不足。

Method: NADEx将实体、关系和时序间隔的主体中心历史编码为序列嵌入。在前向过程中扰动查询对象，在反向过程中使用Transformer去噪器结合时序关系上下文进行重建。进一步从批次负原型推导出余弦对齐正则化器，收紧决策边界以对抗不合理候选。

Result: 在四个公开时序知识图谱基准上的综合实验表明，NADEx实现了最先进的性能。

Conclusion: NADEx通过引入负感知机制改进了时序知识图谱推理中的扩散模型，有效利用了负样本信息并提供了更好的校准监督，在多个基准上取得了优异表现。

Abstract: Temporal Knowledge Graph (TKG) reasoning seeks to predict future missing facts from historical evidence. While diffusion models (DM) have recently gained attention for their ability to capture complex predictive distributions, two gaps remain: (i) the generative path is conditioned only on positive evidence, overlooking informative negative context, and (ii) training objectives are dominated by cross-entropy ranking, which improves candidate ordering but provides little supervision over the calibration of the denoised embedding. To bridge this gap, we introduce Negative-Aware Diffusion model for TKG Extrapolation (NADEx). Specifically, NADEx encodes subject-centric histories of entities, relations and temporal intervals into sequential embeddings. NADEx perturbs the query object in the forward process and reconstructs it in reverse with a Transformer denoiser conditioned on the temporal-relational context. We further derive a cosine-alignment regularizer derived from batch-wise negative prototypes, which tightens the decision boundary against implausible candidates. Comprehensive experiments on four public TKG benchmarks demonstrate that NADEx delivers state-of-the-art performance.

</details>


### [403] [Learning the Value Systems of Societies with Preference-based Multi-objective Reinforcement Learning](https://arxiv.org/abs/2602.08835)
*Andrés Holgado-Sánchez,Peter Vamplew,Richard Dazeley,Sascha Ossowski,Holger Billhardt*

Main category: cs.AI

TL;DR: 提出基于聚类和偏好多目标强化学习的算法，用于学习社会智能体的价值对齐模型和价值系统，解决价值操作化中的误规范和多样性问题。


<details>
  <summary>Details</summary>
Motivation: 价值感知AI需要识别人类价值观并适应不同用户的价值系统。当前方法存在价值操作化容易误规范、缺乏价值可解释性、难以适应多样化用户偏好的问题。

Method: 基于聚类和偏好多目标强化学习(PbMORL)，联合学习社会衍生的价值对齐模型(groundings)和代表不同用户群体的价值系统。每个聚类包含代表成员价值偏好的价值系统和反映该价值系统对齐行为的近似帕累托最优策略。

Result: 在两个包含人类价值的MDP环境中，评估了所提方法相对于最先进的PbMORL算法和基线方法的性能。

Conclusion: 该方法能够学习社会智能体的价值对齐模型和价值系统，解决价值多样性和操作化问题，为价值感知AI提供更有效的框架。

Abstract: Value-aware AI should recognise human values and adapt to the value systems (value-based preferences) of different users. This requires operationalization of values, which can be prone to misspecification. The social nature of values demands their representation to adhere to multiple users while value systems are diverse, yet exhibit patterns among groups. In sequential decision making, efforts have been made towards personalization for different goals or values from demonstrations of diverse agents. However, these approaches demand manually designed features or lack value-based interpretability and/or adaptability to diverse user preferences.
  We propose algorithms for learning models of value alignment and value systems for a society of agents in Markov Decision Processes (MDPs), based on clustering and preference-based multi-objective reinforcement learning (PbMORL). We jointly learn socially-derived value alignment models (groundings) and a set of value systems that concisely represent different groups of users (clusters) in a society. Each cluster consists of a value system representing the value-based preferences of its members and an approximately Pareto-optimal policy that reflects behaviours aligned with this value system. We evaluate our method against a state-of-the-art PbMORL algorithm and baselines on two MDPs with human values.

</details>


### [404] [Deciding the Satisfiability of Combined Qualitative Constraint Networks](https://arxiv.org/abs/2602.08848)
*Quentin Cohen-Solal,Alexandre Niveau,Maroua Bouzid*

Main category: cs.AI

TL;DR: 提出一个统一框架，用于整合多种定性推理的扩展与组合形式，包括多尺度推理、时间序列和松散集成，并研究其可满足性决策的复杂性。


<details>
  <summary>Details</summary>
Motivation: 定性推理能够在信息不精确、不完整且无数值的情况下推断新知识，但现有研究缺乏统一框架来处理多种扩展与组合形式，需要系统研究其可满足性决策的复杂性。

Method: 提出一个形式化框架，统一处理多尺度推理、时间序列和松散集成等定性形式主义的扩展与组合，并建立两个互补定理来保证可满足性决策的多项式复杂度。

Result: 建立了两个互补定理，确保可满足性决策是多项式时间的，并利用这些定理恢复了已知的size-topology组合结果，同时扩展了定性形式主义的定义以包含文献中被排除的重要组合形式。

Conclusion: 提出的统一框架不仅支持各种定性推理扩展与组合的推理，还提供了研究可满足性决策及其复杂性的统一方法，扩展了定性形式主义的定义范围，为组合推理提供了更全面的理论基础。

Abstract: Among the various forms of reasoning studied in the context of artificial intelligence, qualitative reasoning makes it possible to infer new knowledge in the context of imprecise, incomplete information without numerical values. In this paper, we propose a formal framework unifying several forms of extensions and combinations of qualitative formalisms, including multi-scale reasoning, temporal sequences, and loose integrations. This framework makes it possible to reason in the context of each of these combinations and extensions, but also to study in a unified way the satisfiability decision and its complexity. In particular, we establish two complementary theorems guaranteeing that the satisfiability decision is polynomial, and we use them to recover the known results of the size-topology combination. We also generalize the main definition of qualitative formalism to include qualitative formalisms excluded from the definitions of the literature, important in the context of combinations.

</details>


### [405] [Scalable Delphi: Large Language Models for Structured Risk Estimation](https://arxiv.org/abs/2602.08889)
*Tobias Lorenz,Mario Fritz*

Main category: cs.AI

TL;DR: LLM驱动的可扩展德尔菲方法将专家评估时间从数月缩短到数分钟，在网络安全风险评估中与人类专家表现相当甚至更好。


<details>
  <summary>Details</summary>
Motivation: 传统德尔菲专家评估方法虽然准确但耗时数月且成本高昂，限制了其在大多数高风险领域的应用。需要寻找可扩展的替代方案来使严谨的风险评估更普及。

Method: 提出"可扩展德尔菲"方法，将经典德尔菲协议适配到LLM：使用多样化专家角色、迭代精炼和理由共享。建立基于必要条件的评估框架：可验证代理的校准、对证据的敏感性、与人类专家判断的一致性。

Result: LLM专家小组在AI增强网络安全风险评估中表现优异：与基准真值的皮尔逊相关系数达0.87-0.95；随证据增加系统改进；与人类专家小组高度一致（在某些情况下，LLM与人类小组的一致性甚至高于两个人类小组之间的相互一致性）。

Conclusion: LLM驱动的专家评估能够将结构化专家判断扩展到传统方法不可行的场景，将评估时间从数月减少到数分钟，为高风险领域的定量风险评估提供了可扩展的解决方案。

Abstract: Quantitative risk assessment in high-stakes domains relies on structured expert elicitation to estimate unobservable properties. The gold standard - the Delphi method - produces calibrated, auditable judgments but requires months of coordination and specialist time, placing rigorous risk assessment out of reach for most applications. We investigate whether Large Language Models (LLMs) can serve as scalable proxies for structured expert elicitation. We propose Scalable Delphi, adapting the classical protocol for LLMs with diverse expert personas, iterative refinement, and rationale sharing. Because target quantities are typically unobservable, we develop an evaluation framework based on necessary conditions: calibration against verifiable proxies, sensitivity to evidence, and alignment with human expert judgment. We evaluate in the domain of AI-augmented cybersecurity risk, using three capability benchmarks and independent human elicitation studies. LLM panels achieve strong correlations with benchmark ground truth (Pearson r=0.87-0.95), improve systematically as evidence is added, and align with human expert panels - in one comparison, closer to a human panel than the two human panels are to each other. This demonstrates that LLM-based elicitation can extend structured expert judgment to settings where traditional methods are infeasible, reducing elicitation time from months to minutes.

</details>


### [406] [Efficient and Stable Reinforcement Learning for Diffusion Language Models](https://arxiv.org/abs/2602.08905)
*Jiawei Liu,Xiting Wang,Yuanyuan Zhong,Defu Lian,Yu Yang*

Main category: cs.AI

TL;DR: STP框架通过时空剪枝提升扩散大语言模型强化学习的效率和稳定性


<details>
  <summary>Details</summary>
Motivation: 扩散大语言模型（dLLMs）的强化学习面临效率和稳定性挑战，需要专门解决方案

Method: 提出时空剪枝（STP）框架：空间剪枝利用静态先验约束探索空间，时间剪枝绕过冗余后期细化步骤

Result: 理论分析证明STP严格降低对数似然估计方差，实验显示在效率和准确率上超越现有基线

Conclusion: STP有效解决了dLLMs强化学习的效率和稳定性问题，为复杂推理能力解锁提供了实用框架

Abstract: Reinforcement Learning (RL) is crucial for unlocking the complex reasoning capabilities of Diffusion-based Large Language Models (dLLMs). However, applying RL to dLLMs faces unique challenges in efficiency and stability. To address these challenges, we propose Spatio-Temporal Pruning (STP), a framework designed to simultaneously improve the efficiency and stability of RL for dLLMs. STP compresses the redundancy in the generative process through: (1) \textit{spatial pruning}, which constrains the exploration space using static priors; and (2) \textit{temporal pruning}, which bypasses redundant late-stage refinement steps. Our theoretical analysis demonstrates that STP strictly reduces the variance of the log-likelihood estimation, thereby ensuring more stable policy updates. Extensive experiments demonstrate that STP surpasses state-of-the-art baselines in both efficiency and accuracy. Our code is available at https://github.com/Lolo1222/STP.

</details>


### [407] [CausalT5K: Diagnosing and Informing Refusal for Trustworthy Causal Reasoning of Skepticism, Sycophancy, Detection-Correction, and Rung Collapse](https://arxiv.org/abs/2602.08939)
*Longling Geng,Andy Ouyang,Theodore Wu,Daphne Barretto,Matthew John Hayes,Rachael Cooper,Yuqiao Zeng,Sameer Vijay,Gia Ancone,Ankit Rai,Matthew Wolfman,Patrick Flanagan,Edward Y. Chang*

Main category: cs.AI

TL;DR: CausalT5K是一个包含5000多个案例的诊断基准，用于系统检测LLM在因果推理中的失败模式，包括阶梯崩溃、谄媚漂移和错误拒绝，通过实用性和安全性指标揭示聚合准确率无法发现的故障模式。


<details>
  <summary>Details</summary>
Motivation: LLM在因果推理中存在多种失败模式（谄媚、阶梯崩溃、错误校准的拒绝），但由于缺乏系统性诊断基准，修复进展缓慢。需要创建一个能够系统检测这些故障模式的基准来推动可信推理系统的发展。

Method: 开发了CausalT5K基准，包含5000多个案例，覆盖10个领域，测试三个关键能力：检测阶梯崩溃、抵抗谄媚漂移、生成明智拒绝。采用人机协作流程，涉及40名领域专家、迭代交叉验证循环，以及基于规则、LLM和人工评分的复合验证。

Result: 初步实验揭示了四象限控制景观，静态审计策略普遍失败。基准能够将性能分解为实用性（敏感性）和安全性（特异性），揭示聚合准确率无法发现的故障模式。

Conclusion: CausalT5K作为研究基础设施实现了Pearl的因果阶梯，为推进可信推理系统提供了有价值的诊断工具，能够系统识别LLM在因果推理中的失败模式。

Abstract: LLM failures in causal reasoning, including sycophancy, rung collapse, and miscalibrated refusal, are well-documented, yet progress on remediation is slow because no benchmark enables systematic diagnosis. We introduce CausalT5K, a diagnostic benchmark of over 5,000 cases across 10 domains that tests three critical capabilities: (1) detecting rung collapse, where models answer interventional queries with associational evidence; (2) resisting sycophantic drift under adversarial pressure; and (3) generating Wise Refusals that specify missing information when evidence is underdetermined. Unlike synthetic benchmarks, CausalT5K embeds causal traps in realistic narratives and decomposes performance into Utility (sensitivity) and Safety (specificity), revealing failure modes invisible to aggregate accuracy. Developed through a rigorous human-machine collaborative pipeline involving 40 domain experts, iterative cross-validation cycles, and composite verification via rule-based, LLM, and human scoring, CausalT5K implements Pearl's Ladder of Causation as research infrastructure. Preliminary experiments reveal a Four-Quadrant Control Landscape where static audit policies universally fail, a finding that demonstrates CausalT5K's value for advancing trustworthy reasoning systems. Repository: https://github.com/genglongling/CausalT5kBench

</details>


### [408] [CoRefine: Confidence-Guided Self-Refinement for Adaptive Test-Time Compute](https://arxiv.org/abs/2602.08948)
*Chen Jin,Ryutaro Tanno,Tom Diethe,Philip Teare*

Main category: cs.AI

TL;DR: CoRefine是一种基于置信度引导的自优化方法，通过轻量级控制器实现高效推理，大幅减少计算开销


<details>
  <summary>Details</summary>
Motivation: 大语言模型通常依赖并行解码（如512个样本）来提高推理准确性，但这会带来巨大的计算开销。需要一种更高效的方法来减少计算成本。

Method: CoRefine使用一个轻量级的211k参数Conv1D控制器，基于完整追踪的置信度来决定是否停止、重新检查或尝试不同方法。控制器在冻结的LLM之上工作，实现有针对性的自我修正。

Result: 平均每个问题只需2.7个优化步骤，相对于512样本基线减少约190倍的token使用。在控制器自信停止时达到92.6%的精确度，表明置信度动态可靠地指示正确性。CoRefine-Tree变体能自适应平衡探索和利用。

Conclusion: 通过将置信度视为控制信号而非正确性保证，CoRefine为可扩展推理和不完美验证器的智能体设置提供了模块化原语。

Abstract: Large Language Models (LLMs) often rely on test-time scaling via parallel decoding (for example, 512 samples) to boost reasoning accuracy, but this incurs substantial compute. We introduce CoRefine, a confidence-guided self-refinement method that achieves competitive accuracy using a fraction of the tokens via a lightweight 211k-parameter Conv1D controller atop a frozen LLM. The controller consumes full-trace confidence to decide whether to halt, re-examine, or try a different approach, enabling targeted self-correction with an average of 2.7 refinement steps per problem and roughly 190-fold token reduction relative to 512-sample baselines. Across diverse reasoning benchmarks and three open-source models, the controller achieves 92.6 percent precision when it confidently halts, indicating that confidence dynamics reliably signal correctness without ground-truth verification. We extend this to CoRefine-Tree, a hybrid sequential-parallel variant that adaptively balances exploration and exploitation, with easy serving integration and verifier compatibility. By treating confidence as a control signal rather than a correctness guarantee, CoRefine provides a modular primitive for scalable reasoning and agentic settings with imperfect verifiers.

</details>


### [409] [Digital Twin and Agentic AI for Wild Fire Disaster Management: Intelligent Virtual Situation Room](https://arxiv.org/abs/2602.08949)
*Mohammad Morsali,Siavash H. Khajavi*

Main category: cs.AI

TL;DR: IVSR是一个结合数字孪生和自主AI代理的双向平台，用于实时自适应野火灾害管理，显著减少检测到干预的延迟并提高资源协调效率。


<details>
  <summary>Details</summary>
Motivation: 由于全球变暖，野火频率和强度预计到2030年将增加14%，到2050年将增加30%，对生命、基础设施和生态系统构成严重威胁。传统的灾害管理框架依赖静态模拟和被动数据采集，无法实时适应不断演变的野火情况。

Method: 提出智能虚拟态势室（IVSR），这是一个由自主AI代理增强的双向数字孪生平台。IVSR持续摄入多源传感器图像、天气数据和3D森林模型，创建火灾环境的实时虚拟副本。AI驱动的相似性引擎将新兴条件与预计算的灾害模拟库对齐，检索并校准干预策略。授权行动（从无人机重新部署到人员重新分配）通过标准化程序反馈到物理层，完成响应与分析之间的闭环。

Result: 通过工业合作伙伴提供的详细案例研究模拟验证了IVSR，展示了在局部事件检测、隐私保护回放、基于碰撞器的火势蔓延预测和特定站点ML重新训练方面的能力。结果显示与传统系统相比，检测到干预的延迟显著减少，资源协调更加有效。

Conclusion: IVSR通过将实时双向数字孪生与代理AI相结合，为主动、自适应的野火灾害管理提供了一个可扩展、半自动化的决策支持范式。

Abstract: According to the United Nations, wildfire frequency and intensity are projected to increase by approximately 14% by 2030 and 30% by 2050 due to global warming, posing critical threats to life, infrastructure, and ecosystems. Conventional disaster management frameworks rely on static simulations and passive data acquisition, hindering their ability to adapt to arbitrarily evolving wildfire episodes in real-time. To address these limitations, we introduce the Intelligent Virtual Situation Room (IVSR), a bidirectional Digital Twin (DT) platform augmented by autonomous AI agents. The IVSR continuously ingests multisource sensor imagery, weather data, and 3D forest models to create a live virtual replica of the fire environment. A similarity engine powered by AI aligns emerging conditions with a precomputed Disaster Simulation Library, retrieving and calibrating intervention tactics under the watchful eyes of experts. Authorized action-ranging from UAV redeployment to crew reallocation-is cycled back through standardized procedures to the physical layer, completing the loop between response and analysis. We validate IVSR through detailed case-study simulations provided by an industrial partner, demonstrating capabilities in localized incident detection, privacy-preserving playback, collider-based fire-spread projection, and site-specific ML retraining. Our results indicate marked reductions in detection-to-intervention latency and more effective resource coordination versus traditional systems. By uniting real-time bidirectional DTs with agentic AI, IVSR offers a scalable, semi-automated decision-support paradigm for proactive, adaptive wildfire disaster management.

</details>


### [410] [stable-worldmodel-v1: Reproducible World Modeling Research and Evaluation](https://arxiv.org/abs/2602.08968)
*Lucas Maes,Quentin Le Lidec,Dan Haramati,Nassim Massaudi,Damien Scieur,Yann LeCun,Randall Balestriero*

Main category: cs.AI

TL;DR: SWM是一个模块化、经过测试和文档化的世界模型研究生态系统，提供高效的数据收集工具、标准化环境、规划算法和基线实现，旨在解决现有世界模型实现可重用性差、bug风险高和评估标准化不足的问题。


<details>
  <summary>Details</summary>
Motivation: 现有世界模型实现大多针对特定论文，可重用性差，增加了bug风险，降低了评估标准化程度。为了解决这些问题，作者开发了一个统一的世界模型研究生态系统。

Method: 开发了stable-worldmodel (SWM)生态系统，包含模块化架构、测试框架、详细文档，提供数据收集工具、标准化环境、规划算法和基线实现。每个环境还支持可控的变化因素（包括视觉和物理属性），以支持鲁棒性和持续学习研究。

Result: 成功构建了SWM生态系统，并通过在DINO-WM中研究零样本鲁棒性来展示其效用。该系统提高了世界模型研究的可重用性、减少了bug风险，并促进了评估标准化。

Conclusion: SWM为世界模型研究提供了一个可靠、可扩展的生态系统，解决了现有实现中的关键问题，并支持鲁棒性和持续学习等前沿研究方向。

Abstract: World Models have emerged as a powerful paradigm for learning compact, predictive representations of environment dynamics, enabling agents to reason, plan, and generalize beyond direct experience. Despite recent interest in World Models, most available implementations remain publication-specific, severely limiting their reusability, increasing the risk of bugs, and reducing evaluation standardization. To mitigate these issues, we introduce stable-worldmodel (SWM), a modular, tested, and documented world-model research ecosystem that provides efficient data-collection tools, standardized environments, planning algorithms, and baseline implementations. In addition, each environment in SWM enables controllable factors of variation, including visual and physical properties, to support robustness and continual learning research. Finally, we demonstrate the utility of SWM by using it to study zero-shot robustness in DINO-WM.

</details>


### [411] [InternAgent-1.5: A Unified Agentic Framework for Long-Horizon Autonomous Scientific Discovery](https://arxiv.org/abs/2602.08990)
*Shiyang Feng,Runmin Ma,Xiangchao Yan,Yue Fan,Yusong Hu,Songtao Huang,Shuaiyu Zhang,Zongsheng Cao,Tianshuo Peng,Jiakang Yuan,Zijie Guo,Zhijie Zhong,Shangheng Du,Weida Wang,Jinxin Shi,Yuhao Zhou,Xiaohan He,Zhiyin Yu,Fangchen Yu,Qihao Zheng,Jiamin Wu,Mianxin Liu,Chi Zhang,Shaowei Hou,Shuya Li,Yankai Jiang,Wenjie Lou,Lilong Wang,Zifu Wang,Jiong Wang,Wanghan Xu,Yue Deng,Dongrui Liu,Yiheng Wang,Wenlong Zhang,Fenghua Ling,Shufei Zhang,Xiaosong Wang,Shuangjia Zheng,Xun Huang,Siqi Sun,Shuyue Hu,Peng Ye,Chunfeng Song,Bin Wang,Conghui He,Yihao Liu,Xin Li,Qibin Hou,Tao Chen,Xiangyu Yue,Bin Wang,Liang He,Dahua Lin,Bowen Zhou,Bo Zhang,Lei Bai*

Main category: cs.AI

TL;DR: InternAgent-1.5是一个用于端到端科学发现的统一系统，通过生成、验证和演化三个协调子系统，在计算和实验领域实现自主科学发现。


<details>
  <summary>Details</summary>
Motivation: 构建一个能够在计算建模和实验室实验之间协调工作的统一系统，实现跨领域的端到端科学发现，解决传统方法中计算与实验分离的问题。

Method: 采用结构化架构，包含三个协调子系统：生成、验证和演化，并具备深度研究、解决方案优化和长时程记忆等基础能力。系统支持连续运行和跨领域协调。

Result: 在科学推理基准测试（GAIA、HLE、GPQA、FrontierScience）中取得领先性能；在算法发现任务中自主设计机器学习方法；在实验发现任务中执行完整计算或湿实验，在地球、生命、生物和物理领域产生科学发现。

Conclusion: InternAgent-1.5为自主科学发现提供了一个通用且可扩展的框架，能够协调计算和实验工作，实现跨领域的端到端科学发现。

Abstract: We introduce InternAgent-1.5, a unified system designed for end-to-end scientific discovery across computational and empirical domains. The system is built on a structured architecture composed of three coordinated subsystems for generation, verification, and evolution. These subsystems are supported by foundational capabilities for deep research, solution optimization, and long horizon memory. The architecture allows InternAgent-1.5 to operate continuously across extended discovery cycles while maintaining coherent and improving behavior. It also enables the system to coordinate computational modeling and laboratory experimentation within a single unified system. We evaluate InternAgent-1.5 on scientific reasoning benchmarks such as GAIA, HLE, GPQA, and FrontierScience, and the system achieves leading performance that demonstrates strong foundational capabilities. Beyond these benchmarks, we further assess two categories of discovery tasks. In algorithm discovery tasks, InternAgent-1.5 autonomously designs competitive methods for core machine learning problems. In empirical discovery tasks, it executes complete computational or wet lab experiments and produces scientific findings in earth, life, biological, and physical domains. Overall, these results show that InternAgent-1.5 provides a general and scalable framework for autonomous scientific discovery.

</details>


### [412] [iGRPO: Self-Feedback-Driven LLM Reasoning](https://arxiv.org/abs/2602.09000)
*Ali Hatamizadeh,Shrimai Prabhumoye,Igor Gitman,Ximing Lu,Seungju Han,Wei Ping,Yejin Choi,Jan Kautz*

Main category: cs.AI

TL;DR: iGRPO是一种两阶段强化学习方法，通过模型生成草稿进行动态自我调节，在数学推理任务上超越GRPO并达到SOTA效果。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在解决复杂数学问题方面显示出潜力，但仍难以产生准确一致的解决方案。需要强化学习框架来对齐任务特定奖励，提高质量和可靠性。

Method: iGRPO是GRPO的两阶段扩展：第一阶段采样多个探索性草稿并选择最高奖励草稿；第二阶段将最佳草稿附加到原始提示后，在草稿条件化的改进上应用GRPO风格更新，训练策略超越先前最佳尝试。

Result: 在匹配的rollout预算下，iGRPO在不同基础模型上一致优于GRPO。应用于OpenReasoning-Nemotron-7B在AceReason-Math上训练后，在AIME24和AIME25上分别达到85.62%和79.64%的新SOTA结果。

Conclusion: 迭代的、基于自我反馈的强化学习在推进可验证数学推理方面具有潜力，改进包装器可推广到GRPO变体之外，受益于生成式评判器，并通过延迟熵崩溃改变学习动态。

Abstract: Large Language Models (LLMs) have shown promise in solving complex mathematical problems, yet they still fall short of producing accurate and consistent solutions. Reinforcement Learning (RL) is a framework for aligning these models with task-specific rewards, improving overall quality and reliability. Group Relative Policy Optimization (GRPO) is an efficient, value-function-free alternative to Proximal Policy Optimization (PPO) that leverages group-relative reward normalization. We introduce Iterative Group Relative Policy Optimization (iGRPO), a two-stage extension of GRPO that adds dynamic self-conditioning through model-generated drafts. In Stage 1, iGRPO samples multiple exploratory drafts and selects the highest-reward draft using the same scalar reward signal used for optimization. In Stage 2, it appends this best draft to the original prompt and applies a GRPO-style update on draft-conditioned refinements, training the policy to improve beyond its strongest prior attempt. Under matched rollout budgets, iGRPO consistently outperforms GRPO across base models (e.g., Nemotron-H-8B-Base-8K and DeepSeek-R1 Distilled), validating its effectiveness on diverse reasoning benchmarks. Moreover, applying iGRPO to OpenReasoning-Nemotron-7B trained on AceReason-Math achieves new state-of-the-art results of 85.62\% and 79.64\% on AIME24 and AIME25, respectively. Ablations further show that the refinement wrapper generalizes beyond GRPO variants, benefits from a generative judge, and alters learning dynamics by delaying entropy collapse. These results underscore the potential of iterative, self-feedback-based RL for advancing verifiable mathematical reasoning.

</details>


### [413] [Data Science and Technology Towards AGI Part I: Tiered Data Management](https://arxiv.org/abs/2602.09003)
*Yudong Wang,Zixuan Fu,Hengyu Zhao,Chen Zhao,Chuyue Zhou,Xinle Lin,Hongya Lyu,Shuaikang Xue,Yi Yi,Yingjiao Wang,Zhi Zheng,Yuzhou Zhang,Jie Zhou,Chaojun Xiao,Xu Han,Zhiyuan Liu,Maosong Sun*

Main category: cs.AI

TL;DR: 提出分层数据管理框架L0-L4，实现数据与模型协同进化，提升LLM训练效率与性能


<details>
  <summary>Details</summary>
Motivation: 当前LLM研究过度依赖数据规模单向扩展，面临数据可用性、获取成本和训练效率瓶颈。AGI发展需要进入数据-模型协同进化的新阶段，让模型主动指导数据管理，同时高质量数据增强模型能力。

Method: 提出L0-L4分层数据管理框架：从原始未整理资源到组织化可验证知识。利用LLM进行数据质量评分和内容编辑等管理过程，每层具有不同数据特性、管理策略和训练角色，支持预训练、中期训练和对齐等阶段。

Result: 通过实证研究验证框架有效性，分层数据集显著提升训练效率和模型性能。发布分层数据集和处理工具供社区使用。

Conclusion: 分层数据管理框架平衡数据质量、获取成本和边际训练收益，为可扩展和可持续的数据管理提供系统化方法，推动AGI向数据-模型协同进化方向发展。

Abstract: The development of artificial intelligence can be viewed as an evolution of data-driven learning paradigms, with successive shifts in data organization and utilization continuously driving advances in model capability. Current LLM research is dominated by a paradigm that relies heavily on unidirectional scaling of data size, increasingly encountering bottlenecks in data availability, acquisition cost, and training efficiency. In this work, we argue that the development of AGI is entering a new phase of data-model co-evolution, in which models actively guide data management while high-quality data, in turn, amplifies model capabilities. To implement this vision, we propose a tiered data management framework, designed to support the full LLM training lifecycle across heterogeneous learning objectives and cost constraints. Specifically, we introduce an L0-L4 tiered data management framework, ranging from raw uncurated resources to organized and verifiable knowledge. Importantly, LLMs are fully used in data management processes, such as quality scoring and content editing, to refine data across tiers. Each tier is characterized by distinct data properties, management strategies, and training roles, enabling data to be strategically allocated across LLM training stages, including pre-training, mid-training, and alignment. The framework balances data quality, acquisition cost, and marginal training benefit, providing a systematic approach to scalable and sustainable data management. We validate the effectiveness of the proposed framework through empirical studies, in which tiered datasets are constructed from raw corpora and used across multiple training phases. Experimental results demonstrate that tier-aware data utilization significantly improves training efficiency and model performance. To facilitate further research, we release our tiered datasets and processing tools to the community.

</details>


### [414] [GEBench: Benchmarking Image Generation Models as GUI Environments](https://arxiv.org/abs/2602.09007)
*Haodong Li,Jingwei Wu,Quan Sun,Guopeng Li,Juanxi Tian,Huanyu Zhang,Yanlin Lai,Ruichuan An,Hongbo Peng,Yuhong Dai,Chenxi Li,Chunmei Qing,Jia Wang,Ziyang Meng,Zheng Ge,Xiangyu Zhang,Daxin Jiang*

Main category: cs.AI

TL;DR: 提出GEBench基准测试，用于评估GUI生成中的动态交互和时间一致性，包含700个样本和五维评估指标GE-Score，发现现有模型在单步转换表现良好但在长时间序列中保持时间一致性和空间定位方面存在困难。


<details>
  <summary>Details</summary>
Motivation: 现有图像生成模型能够基于用户指令预测未来GUI状态，但现有基准主要关注通用领域的视觉保真度，对GUI特定场景中的状态转换和时间一致性评估不足，需要专门的评估框架。

Method: 提出GEBench基准测试，包含700个精心策划的样本，涵盖五个任务类别，包括单步交互和多步轨迹，以及定位点接地。同时提出GE-Score五维评估指标，评估目标达成、交互逻辑、内容一致性、UI合理性和视觉质量。

Result: 对当前模型的广泛评估表明，它们在单步转换上表现良好，但在保持长时间交互序列的时间一致性和空间定位方面存在显著困难。图标解释、文本渲染和定位精度被识别为关键瓶颈。

Conclusion: 这项工作为系统评估提供了基础，并为未来构建高保真生成式GUI环境的研究指明了有前景的方向。代码已开源。

Abstract: Recent advancements in image generation models have enabled the prediction of future Graphical User Interface (GUI) states based on user instructions. However, existing benchmarks primarily focus on general domain visual fidelity, leaving the evaluation of state transitions and temporal coherence in GUI-specific contexts underexplored. To address this gap, we introduce GEBench, a comprehensive benchmark for evaluating dynamic interaction and temporal coherence in GUI generation. GEBench comprises 700 carefully curated samples spanning five task categories, covering both single-step interactions and multi-step trajectories across real-world and fictional scenarios, as well as grounding point localization. To support systematic evaluation, we propose GE-Score, a novel five-dimensional metric that assesses Goal Achievement, Interaction Logic, Content Consistency, UI Plausibility, and Visual Quality. Extensive evaluations on current models indicate that while they perform well on single-step transitions, they struggle significantly with maintaining temporal coherence and spatial grounding over longer interaction sequences. Our findings identify icon interpretation, text rendering, and localization precision as critical bottlenecks. This work provides a foundation for systematic assessment and suggests promising directions for future research toward building high-fidelity generative GUI environments. The code is available at: https://github.com/stepfun-ai/GEBench.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [415] [Clarifying Core Dimensions in Digital Maturity Models: An Integrative Approach](https://arxiv.org/abs/2602.07569)
*Eduardo C. Peixoto,Hector Oliveira,Geber L. Ramalho,Cesar França*

Main category: cs.SE

TL;DR: 该研究通过系统映射方法分析76个数字成熟度模型，识别出10个最常用维度并提出整合性定义，以解决现有模型维度定义不清晰、不一致的问题。


<details>
  <summary>Details</summary>
Motivation: 数字转型项目失败率高，数字成熟度模型虽提供解决方案但存在明显缺陷：维度定义不一致、不清晰，且组件不明确。需要更清晰理解DMMs以提升其有效性。

Method: 采用系统映射方法，包括自动搜索和滚雪球技术，分析76个数字成熟度模型，回答两个研究问题：最常用维度是什么？这些维度如何描述及其组件是什么？

Result: 识别出10个最频繁维度：组织、战略、技术、文化、流程、运营、人员、管理、客户和数据。对这些维度提出整合性定义，调和不同解释。

Conclusion: 相比先前分析，本研究提供了更广泛、更新的数字成熟度模型视角，通过清晰定义核心维度为数字转型实践提供更可靠的理论基础。

Abstract: Digital Transformation (DT) initiatives frequently face high failure rates, and while Digital Maturity Models (DMMs) offer potential solutions, they have notable shortcomings. Specifically, there is significant disparity in the dimensions considered relevant, a lack of clarity in their definitions, and uncertainty regarding their components. This study aims to provide a clearer understanding of DMMs by proposing integrative definitions of the most frequently used dimensions. Using a Systematic Mapping approach, including automatic search and snowballing techniques, we analyzed 76 DMMs to answer two Research Questions: (RQ1) What are the most frequent dimensions in DMMs? and (RQ2) How are these dimensions described, including their components? We reconcile varying interpretations of the ten most frequent dimensions -- Organization, Strategy, Technology, Culture, Process, Operations, People, Management, Customer, and Data -- and propose integrative definitions for each. Compared to previous analyses, this study provides a broader and more recent perspective on Digital Maturity Models.

</details>


### [416] [Agent Skills: A Data-Driven Analysis of Claude Skills for Extending Large Language Model Functionality](https://arxiv.org/abs/2602.08004)
*George Ling,Shanshan Zhong,Richard Huang*

Main category: cs.SE

TL;DR: 该论文对大型语言模型(LLM)代理技能市场进行了首次大规模数据分析，研究了40,285个公开技能的类型分布、用户采用模式、供应需求失衡、安全风险等关键问题。


<details>
  <summary>Details</summary>
Motivation: 随着LLM代理技能在公共市场中的激增，目前缺乏对这些技能的类型分布、用户采用模式以及潜在风险的系统性理解。研究旨在填补这一空白，为技能重用、标准化和安全设计提供数据支持。

Method: 采用数据驱动的方法，对来自主要市场的40,285个公开技能进行大规模分析，涵盖技能发布模式、内容分类、采用情况、长度分布、生态系统同质性和安全风险评估等多个维度。

Result: 研究发现：1)技能发布呈现与社区关注度相关的短期爆发模式；2)内容高度集中在软件开发工作流，但信息检索和内容创建技能采用率最高；3)存在明显的供需失衡；4)技能长度呈重尾分布但大多在提示预算内；5)生态系统同质性强，存在大量意图级冗余；6)识别出非平凡的安全风险，包括支持状态变更和系统级操作的技能。

Conclusion: 研究为代理技能这一新兴基础设施层提供了定量快照，揭示了当前市场的结构特征和安全挑战，为未来的技能重用、标准化和安全感知设计提供了重要参考。

Abstract: Agent skills extend large language model (LLM) agents with reusable, program-like modules that define triggering conditions, procedural logic, and tool interactions. As these skills proliferate in public marketplaces, it is unclear what types are available, how users adopt them, and what risks they pose. To answer these questions, we conduct a large-scale, data-driven analysis of 40,285 publicly listed skills from a major marketplace. Our results show that skill publication tends to occur in short bursts that track shifts in community attention. We also find that skill content is highly concentrated in software engineering workflows, while information retrieval and content creation account for a substantial share of adoption. Beyond content trends, we uncover a pronounced supply-demand imbalance across categories, and we show that most skills remain within typical prompt budgets despite a heavy-tailed length distribution. Finally, we observe strong ecosystem homogeneity, with widespread intent-level redundancy, and we identify non-trivial safety risks, including skills that enable state-changing or system-level actions. Overall, our findings provide a quantitative snapshot of agent skills as an emerging infrastructure layer for agents and inform future work on skill reuse, standardization, and safety-aware design.

</details>


### [417] [Software Testing at the Network Layer: Automated HTTP API Quality Assessment and Security Analysis of Production Web Applications](https://arxiv.org/abs/2602.08242)
*Ali Hassaan Mughal,Muhammad Bilal*

Main category: cs.SE

TL;DR: 自动化测试框架分析18个生产网站HTTP流量质量，发现API调用质量差异巨大，冗余请求和缺失缓存头是最常见问题


<details>
  <summary>Details</summary>
Motivation: 现代Web应用严重依赖客户端API调用，但这些网络交互的质量（冗余请求、缺失缓存头、过大负载、过多第三方依赖）很少被系统测试，且这些质量问题常带来安全风险

Method: 使用Playwright自动化浏览器工具记录18个生产网站的完整HTTP流量，生成108个HAR文件（每页3次独立运行），应用8个基于启发式的反模式检测器为每个网站生成0-100的综合质量评分

Result: 质量差异显著：简约的服务器渲染网站得满分100，内容丰富的商业网站最低56.8分。冗余API调用和缺失缓存头各影响67%网站，72%网站第三方开销超过20%。一个工具网站每页加载2,684个请求，是最简约网站的447倍

Conclusion: 本研究为现代Web的HTTP API调用质量建立了经验基准，提供了可复现的测试框架，研究人员和从业者可应用于自己的应用程序

Abstract: Modern web applications rely heavily on client-side API calls to fetch data, render content, and communicate with backend services. However, the quality of these network interactions (redundant requests, missing cache headers, oversized payloads, and excessive third-party dependencies) is rarely tested in a systematic way. Moreover, many of these quality deficiencies carry security implications: missing cache headers enable cache poisoning, excessive third-party dependencies expand the supply-chain attack surface, and error responses risk leaking server internals. In this study, we present an automated software testing framework that captures and analyzes the complete HTTP traffic of 18 production websites spanning 11 categories (e-commerce, news, government, developer tools, travel, and more). Using automated browser instrumentation via Playwright, we record 108 HAR (HTTP Archive) files across 3 independent runs per page, then apply 8 heuristic-based anti-pattern detectors to produce a composite quality score (0-100) for each site. Our results reveal a wide quality spectrum: minimalist server-rendered sites achieve perfect scores of 100, while content-heavy commercial sites score as low as 56.8. We identify redundant API calls and missing cache headers as the two most pervasive anti-patterns, each affecting 67% of sites, while third-party overhead exceeds 20% on 72% of sites. One utility site makes 2,684 requests per page load, which is 447x more than the most minimal site. To protect site reputations, all identities are anonymized using category-based pseudonyms. We provide all analysis scripts, anonymized results, and reproducibility instructions as an open artifact. This work establishes an empirical baseline for HTTP API call quality across the modern web and offers a reproducible testing framework that researchers and practitioners can apply to their own applications.

</details>


### [418] [Comprehensive Evaluation of Large Language Models on Software Engineering Tasks: A Multi-Task Benchmark](https://arxiv.org/abs/2602.07079)
*Go Frendi Gunawan,Mukhlis Amien*

Main category: cs.SE

TL;DR: 该研究对11个先进大语言模型在5个软件工程任务上进行多任务评估，发现模型性能存在显著差异：相同完美得分模型在完成时间、工具效率和成本上差异巨大，工具使用频率与成功率无关，编码任务成功率100%而研究任务更具挑战性。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在软件工程领域展现出卓越能力，但缺乏覆盖多样化SE活动的综合基准测试。现有研究通常只关注单一任务，无法全面评估模型在实际软件工程工作流中的表现。

Method: 研究采用多任务评估框架，对11个最先进的大语言模型在5个代表性软件工程任务上进行测试：bug修复、功能开发、代码重构、技术文案撰写和研究综合。使用自动化验证框架同时测量输出质量和完成效率。

Result: 关键发现包括：1) 获得相同完美得分的模型在完成时间上存在22倍差异，工具效率49倍差异，估计成本53倍差异；2) 工具使用频率与成功率无相关性(r=0.077, p=0.575)；3) 识别出两种低效模式：循环低效和推理低效；4) 编码任务成功率100%，研究任务更具挑战性(90.9%)。

Conclusion: 该研究强调了在评估大语言模型时需要考虑效率维度的重要性，仅凭输出质量评分不足以全面评估模型性能。研究提供了完整的实验数据、验证脚本和分析代码，确保可复现性，为未来软件工程领域的LLM评估提供基准。

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities in software engineering, yet comprehensive benchmarks covering diverse SE activities remain limited. We present a multi-task evaluation of 11 state-of-the-art LLMs across five representative software engineering tasks: bug fixing, feature development, code refactoring, technical copywriting, and research synthesis. Our automated verification framework measures both output quality and completion efficiency. Key findings reveal that (1) models achieving identical perfect scores exhibit 22x variation in completion time, 49x variation in tool efficiency, and 53x variation in estimated cost; (2) tool usage frequency shows no correlation with success (r = 0.077, p = 0.575) - one model used 917 tool calls while another solved the same task with 3 calls; (3) we identify two distinct inefficiency patterns: loop inefficiency and inference inefficiency; and (4) coding tasks achieve 100 percent success while research tasks present greater challenges (90.9 percent). We release all experimental data, verification scripts, and analysis code for full reproducibility.

</details>


### [419] [Evaluating Retrieval-Augmented Generation Variants for Natural Language-Based SQL and API Call Generation](https://arxiv.org/abs/2602.07086)
*Michael Marketsmüller,Simon Martin,Tim Schlippe*

Main category: cs.SE

TL;DR: 该论文评估了三种RAG变体在SQL查询和REST API调用生成任务中的表现，发现CoRAG在混合文档环境下表现最佳，检索对准确率提升至关重要。


<details>
  <summary>Details</summary>
Motivation: 企业系统需要自然语言接口将用户请求转换为结构化操作（如SQL查询和REST API调用），但LLM在特定领域企业环境中的效果尚未充分探索，特别是在需要同时处理检索和修改任务时。

Method: 使用SAP Transactional Banking作为企业用例，构建新的测试数据集，评估三种RAG变体（标准RAG、Self-RAG、CoRAG）在SQL查询生成、REST API调用生成以及需要动态任务分类的联合任务中的表现，共测试18种实验配置。

Result: 检索至关重要：无检索时所有任务的精确匹配准确率为0%，而检索使执行准确率最高达79.30%，组件匹配准确率最高达78.86%。CoRAG在混合文档环境下表现最稳健，在联合任务中实现10.29%的精确匹配（标准RAG为7.45%），主要得益于SQL生成性能优势（15.32% vs 11.56%）。

Conclusion: 检索策略设计是生产级自然语言接口的关键决定因素，迭代查询分解在文档异构性下优于top-k检索和二元相关性过滤。

Abstract: Enterprise systems increasingly require natural language interfaces that can translate user requests into structured operations such as SQL queries and REST API calls. While large language models (LLMs) show promise for code generation [Chen et al., 2021; Huynh and Lin, 2025], their effectiveness in domain-specific enterprise contexts remains underexplored, particularly when both retrieval and modification tasks must be handled jointly. This paper presents a comprehensive evaluation of three retrieval-augmented generation (RAG) variants [Lewis et al., 2021] -- standard RAG, Self-RAG [Asai et al., 2024], and CoRAG [Wang et al., 2025] -- across SQL query generation, REST API call generation, and a combined task requiring dynamic task classification. Using SAP Transactional Banking as a realistic enterprise use case, we construct a novel test dataset covering both modalities and evaluate 18 experimental configurations under database-only, API-only, and hybrid documentation contexts. Results demonstrate that RAG is essential: Without retrieval, exact match accuracy is 0% across all tasks, whereas retrieval yields substantial gains in execution accuracy (up to 79.30%) and component match accuracy (up to 78.86%). Critically, CoRAG proves most robust in hybrid documentation settings, achieving statistically significant improvements in the combined task (10.29% exact match vs. 7.45% for standard RAG), driven primarily by superior SQL generation performance (15.32% vs. 11.56%). Our findings establish retrieval-policy design as a key determinant of production-grade natural language interfaces, showing that iterative query decomposition outperforms both top-k retrieval and binary relevance filtering under documentation heterogeneity.

</details>


### [420] [Measuring Complexity at the Requirements Stage: Spectral Metrics as Development Effort Predictors](https://arxiv.org/abs/2602.07182)
*Maximilian Vierlboeck,Antonio Pugliese,Roshanak Nilchian,Paul Grogan,Rashika Sugganahalli Natesh Babu*

Main category: cs.SE

TL;DR: 研究提出使用自然语言处理从需求文本中提取结构网络，并通过分子集成任务作为代理实验，验证了谱测度能有效预测集成工作量（相关性>0.95）。


<details>
  <summary>Details</summary>
Motivation: 需求规范中的结构复杂性长期未被充分理解和量化，而需求复杂性会传播到系统设计、实现和集成的各个阶段，导致成本超支、进度延迟和项目失败。

Method: 基于NLP方法从文本需求中提取结构网络，使用分子集成任务作为结构同构代理进行对照实验，利用分子图与需求网络的拓扑等价性，消除领域专业知识和语义歧义等混杂因素。

Result: 谱测度预测集成工作量的相关性超过0.95，结构指标相关性超过0.89，而基于密度的指标没有显著预测有效性。特征值衍生指标能捕捉简单连接性指标无法捕获的认知和工作量维度。

Conclusion: 该研究填补了架构复杂性分析与需求工程实践之间的方法学空白，为在需求工程中应用这些指标提供了验证基础，表明类似的结构复杂性模式可以预测集成工作量。

Abstract: Complexity in engineered systems presents one of the most persistent challenges in modern development since it is driving cost overruns, schedule delays, and outright project failures. Yet while architectural complexity has been studied, the structural complexity embedded within requirements specifications remains poorly understood and inadequately quantified. This gap is consequential: requirements fundamentally drive system design, and complexity introduced at this stage propagates through architecture, implementation, and integration. To address this gap, we build on Natural Language Processing methods that extract structural networks from textual requirements. Using these extracted structures, we conducted a controlled experiment employing molecular integration tasks as structurally isomorphic proxies for requirements integration - leveraging the topological equivalence between molecular graphs and requirement networks while eliminating confounding factors such as domain expertise and semantic ambiguity. Our results demonstrate that spectral measures predict integration effort with correlations exceeding 0.95, while structural metrics achieve correlations above 0.89. Notably, density-based metrics show no significant predictive validity. These findings indicate that eigenvalue-derived measures capture cognitive and effort dimensions that simpler connectivity metrics cannot. As a result, this research bridges a critical methodological gap between architectural complexity analysis and requirements engineering practice, providing a validated foundation for applying these metrics to requirements engineering, where similar structural complexity patterns may predict integration effort.

</details>


### [421] [Pull Requests as a Training Signal for Repo-Level Code Editing](https://arxiv.org/abs/2602.07457)
*Qinglin Zhu,Tianyu Chen,Shuai Lu,Lei Ji,Runcong Zhao,Murong Ma,Xiangxiang Dai,Yulan He,Lin Gui,Peng cheng,Yeyun Gong*

Main category: cs.SE

TL;DR: Clean-PR：利用GitHub拉取请求作为训练信号，通过重构和验证将嘈杂的diff转换为搜索/替换编辑块，训练模型实现仓库级代码编辑，在SWE-bench上显著超越基线


<details>
  <summary>Details</summary>
Motivation: 当前仓库级代码编辑主要依赖复杂的代理框架，但尚不清楚这种能力有多少可以通过高质量训练信号内化到模型权重中

Method: 提出Clean-PR中训练范式：1）构建可扩展的流水线，将嘈杂的拉取请求diff转换为搜索/替换编辑块；2）创建包含200万拉取请求、涵盖12种编程语言的语料库；3）进行中训练阶段和基于错误驱动的数据增强的无代理对齐监督微调

Result: 在SWE-bench上显著优于指令调优基线：SWE-bench Lite绝对提升13.6%，SWE-bench Verified绝对提升12.3%

Conclusion: 仓库级代码理解和编辑能力可以通过简化的无代理协议有效内化到模型权重中，无需依赖复杂推理时框架

Abstract: Repository-level code editing requires models to understand complex dependencies and execute precise multi-file modifications across a large codebase. While recent gains on SWE-bench rely heavily on complex agent scaffolding, it remains unclear how much of this capability can be internalised via high-quality training signals. To address this, we propose Clean Pull Request (Clean-PR), a mid-training paradigm that leverages real-world GitHub pull requests as a training signal for repository-level editing. We introduce a scalable pipeline that converts noisy pull request diffs into Search/Replace edit blocks through reconstruction and validation, resulting in the largest publicly available corpus of 2 million pull requests spanning 12 programming languages. Using this training signal, we perform a mid-training stage followed by an agentless-aligned supervised fine-tuning process with error-driven data augmentation. On SWE-bench, our model significantly outperforms the instruction-tuned baseline, achieving absolute improvements of 13.6% on SWE-bench Lite and 12.3% on SWE-bench Verified. These results demonstrate that repository-level code understanding and editing capabilities can be effectively internalised into model weights under a simplified, agentless protocol, without relying on heavy inference-time scaffolding.

</details>


### [422] [On Sequence-to-Sequence Models for Automated Log Parsing](https://arxiv.org/abs/2602.07698)
*Adam Sorrenti,Andriy Miranskyy*

Main category: cs.SE

TL;DR: 系统评估了四种序列建模架构（Transformer、Mamba、单向LSTM、双向LSTM）在日志解析任务中的性能，发现Transformer表现最佳，Mamba在计算成本上具有优势。


<details>
  <summary>Details</summary>
Motivation: 自动化日志解析面临异构日志格式、训练与部署数据分布偏移以及基于规则方法的脆弱性等挑战，需要系统评估不同序列建模架构的影响。

Method: 通过控制实验比较四种序列建模架构（Transformer、Mamba状态空间、单向LSTM、双向LSTM），训练396个模型，使用相对Levenshtein编辑距离评估，并进行统计显著性检验。

Result: Transformer获得最低平均相对编辑距离（0.111），其次是Mamba（0.145）、单向LSTM（0.186）和双向LSTM（0.265）。Mamba在保持竞争力的同时显著降低计算成本。字符级分词通常提升性能，序列长度对Transformer精度影响可忽略。

Conclusion: Transformer将解析错误减少23.4%，而Mamba在数据或计算资源受限时是强有力的替代方案。研究为研究者和实践者提供了关于表示选择、序列长度和样本效率的实用指导。

Abstract: Log parsing is a critical standard operating procedure in software systems, enabling monitoring, anomaly detection, and failure diagnosis. However, automated log parsing remains challenging due to heterogeneous log formats, distribution shifts between training and deployment data, and the brittleness of rule-based approaches. This study aims to systematically evaluate how sequence modelling architecture, representation choice, sequence length, and training data availability influence automated log parsing performance and computational cost. We conduct a controlled empirical study comparing four sequence modelling architectures: Transformer, Mamba state-space, monodirectional LSTM, and bidirectional LSTM models. In total, 396 models are trained across multiple dataset configurations and evaluated using relative Levenshtein edit distance with statistical significance testing. Transformer achieves the lowest mean relative edit distance (0.111), followed by Mamba (0.145), mono-LSTM (0.186), and bi-LSTM (0.265), where lower values are better. Mamba provides competitive accuracy with substantially lower computational cost. Character-level tokenization generally improves performance, sequence length has negligible practical impact on Transformer accuracy, and both Mamba and Transformer demonstrate stronger sample efficiency than recurrent models. Overall, Transformers reduce parsing error by 23.4%, while Mamba is a strong alternative under data or compute constraints. These results also clarify the roles of representation choice, sequence length, and sample efficiency, providing practical guidance for researchers and practitioners.

</details>


### [423] [Automating Computational Reproducibility in Social Science: Comparing Prompt-Based and Agent-Based Approaches](https://arxiv.org/abs/2602.08561)
*Syed Mehtab Hussain Shah,Frank Hopfgartner,Arnim Bleier*

Main category: cs.SE

TL;DR: 研究评估大语言模型和AI代理能否自动诊断修复计算研究中的可复现性失败，在R语言社会科学研究中测试，发现基于代理的工作流成功率更高（69-96%）。


<details>
  <summary>Details</summary>
Motivation: 计算研究的可复现性常因缺失包、文件路径、版本冲突或不完整逻辑而失败，即使共享了材料。本研究旨在探索AI能否自动诊断修复这些失败，使计算结果更易复现验证。

Method: 使用五个完全可复现的R语言社会科学研究构建受控测试平台，注入从简单到复杂缺失逻辑的现实失败。测试两种自动修复工作流：1）基于提示的工作流，使用不同上下文的结构化提示反复查询语言模型；2）基于代理的系统，自主检查文件、修改代码并重新运行分析。在干净的Docker环境中进行评估。

Result: 基于提示的工作流复现成功率在31-79%之间，性能受提示上下文和错误复杂度影响显著，复杂案例从额外上下文中获益最多。基于代理的工作流表现显著更好，在所有复杂度水平上成功率达到69-96%。

Conclusion: 自动化工作流，特别是基于代理的系统，能显著减少手动工作量并提高各种错误类型的复现成功率。与先前基准不同，该测试平台在受控失败模式下隔离了发布后修复，允许直接比较基于提示和基于代理的方法。

Abstract: Reproducing computational research is often assumed to be as simple as rerunning the original code with provided data. In practice, missing packages, fragile file paths, version conflicts, or incomplete logic frequently cause analyses to fail, even when materials are shared. This study investigates whether large language models and AI agents can automate the diagnosis and repair of such failures, making computational results easier to reproduce and verify. We evaluate this using a controlled reproducibility testbed built from five fully reproducible R-based social science studies. Realistic failures were injected, ranging from simple issues to complex missing logic, and two automated repair workflows were tested in clean Docker environments. The first workflow is prompt-based, repeatedly querying language models with structured prompts of varying context, while the second uses agent-based systems that inspect files, modify code, and rerun analyses autonomously. Across prompt-based runs, reproduction success ranged from 31-79 percent, with performance strongly influenced by prompt context and error complexity. Complex cases benefited most from additional context. Agent-based workflows performed substantially better, with success rates of 69-96 percent across all complexity levels. These results suggest that automated workflows, especially agent-based systems, can significantly reduce manual effort and improve reproduction success across diverse error types. Unlike prior benchmarks, our testbed isolates post-publication repair under controlled failure modes, allowing direct comparison of prompt-based and agent-based approaches.

</details>


### [424] [Artificial Intelligence in Open Source Software Engineering: A Foundation for Sustainability](https://arxiv.org/abs/2602.07071)
*S M Rakib UI Karim,Wenyi Lu,Sean Goggins*

Main category: cs.SE

TL;DR: 这篇文献综述探讨了AI如何帮助解决开源软件可持续性挑战，包括维护贡献者参与、资金保障、代码质量与安全、社区健康以及防止项目废弃等问题，同时分析了AI应用的局限性和伦理问题。


<details>
  <summary>Details</summary>
Motivation: 开源软件是现代数字基础设施的基础，但在许多关键情况下仍难以确保足够的贡献。本文旨在探索人工智能如何帮助解决开源软件可持续性的关键挑战，支持更强大和公平的开源生态系统。

Method: 采用文献综述方法，综合近期跨学科研究，分析AI在开源软件领域的应用，包括自动bug分类、系统维护、贡献者引导与指导、社区健康分析、漏洞检测和任务自动化等方面。

Result: 识别了AI在开源软件可持续性中的关键应用领域，同时揭示了应用AI的局限性和伦理问题，包括数据可用性、偏见与公平性、透明度、滥用风险以及在协作开发中保持以人为本价值观的挑战。

Conclusion: AI不应被视为替代品，而是增强人类基础设施的工具。研究强调了AI驱动干预的承诺与陷阱，指出了AI、可持续性和开源软件交叉领域的关键研究空白，并提出了未来研究方向，旨在支持更具韧性和公平性的开源生态系统。

Abstract: Open-source software (OSS) is foundational to modern digital infrastructure, yet this context for group work continues to struggle to ensure sufficient contributions in many critical cases. This literature review explores how artificial intelligence (AI) is being leveraged to address critical challenges to OSS sustainability, including maintaining contributor engagement, securing funding, ensuring code quality and security, fostering healthy community dynamics, and preventing project abandonment. Synthesizing recent interdisciplinary research, the paper identifies key applications of AI in this domain, including automated bug triaging, system maintenance, contributor onboarding and mentorship, community health analytics, vulnerability detection, and task automation. The review also examines the limitations and ethical concerns that arise from applying AI in OSS contexts, including data availability, bias and fairness, transparency, risks of misuse, and the preservation of human-centered values in collaborative development. By framing AI not as a replacement but as a tool to augment human infrastructure, this study highlights both the promise and pitfalls of AI-driven interventions. It concludes by identifying critical research gaps and proposing future directions at the intersection of AI, sustainability, and OSS, aiming to support more resilient and equitable open-source ecosystems.

</details>


### [425] [CodeCircuit: Toward Inferring LLM-Generated Code Correctness via Attribution Graphs](https://arxiv.org/abs/2602.07080)
*Yicheng He,Zheng Zhao,Zhou Kaiyu,Bryan Dai,Jie Fu,Yonghui Yang*

Main category: cs.SE

TL;DR: LLM代码验证新范式：通过分析模型内部计算结构（神经动力学）来预测代码生成的逻辑正确性，无需外部测试或评判模型。


<details>
  <summary>Details</summary>
Motivation: 当前代码验证方法依赖外部机制（如单元测试或辅助LLM评判），这些方法劳动密集且受评判模型能力限制。需要探索能否从LLM内部计算结构直接评估其功能正确性。

Method: 将代码验证视为机制诊断任务，将模型的算法轨迹映射到行级归因图，通过分解复杂残差流识别区分正确推理和逻辑失败的结构特征。

Result: 在Python、C++和Java上的分析表明，内在正确性信号在不同语法中具有鲁棒性。内部图的拓扑特征比表面启发式方法更可靠地预测正确性，并能实现针对性因果干预修复错误逻辑。

Conclusion: 内部自省可作为验证生成代码的可解码属性，为代码验证提供了基于模型内部结构的新范式。

Abstract: Current paradigms for code verification rely heavily on external mechanisms-such as execution-based unit tests or auxiliary LLM judges-which are often labor-intensive or limited by the judging model's own capabilities. This raises a fundamental, yet unexplored question: Can an LLM's functional correctness be assessed purely from its internal computational structure? Our primary objective is to investigate whether the model's neural dynamics encode internally decodable signals that are predictive of logical validity during code generation. Inspired by mechanistic interpretability, we propose to treat code verification as a mechanistic diagnostic task, mapping the model's explicit algorithmic trajectory into line-level attribution graphs. By decomposing complex residual flows, we aim to identify the structural signatures that distinguish sound reasoning from logical failure within the model's internal circuits. Analysis across Python, C++, and Java confirms that intrinsic correctness signals are robust across diverse syntaxes. Topological features from these internal graphs predict correctness more reliably than surface heuristics and enable targeted causal interventions to fix erroneous logic. These findings establish internal introspection as a decodable property for verifying generated code. Our code is at https:// github.com/bruno686/CodeCircuit.

</details>


### [426] [Rethinking Scientific Modeling: Toward Physically Consistent and Simulation-Executable Programmatic Generation](https://arxiv.org/abs/2602.07083)
*Yongqing Jiang,Jianze Wang,Zhiqi Shen,Zhenghong Lin,Jiayuan Wang,Yijian Yang,Kaoshan Dai,Haoran Luo*

Main category: cs.SE

TL;DR: 提出一个物理一致性的自动建筑建模框架，通过领域知识构建、约束导向模型对齐和验证驱动评估，显著减少幻觉和非合规输出


<details>
  <summary>Details</summary>
Motivation: 结构建模是计算工程科学的基础，即使微小的物理不一致或规范违反都可能使下游模拟无效。虽然大语言模型在自动生成建模代码方面显示出潜力，但在严格的工程约束下，不可执行或物理不一致的输出仍然普遍存在

Method: 提出物理一致的自动建筑建模框架，包含：1）CivilInstruct领域特定数据集，形式化结构工程知识和约束推理；2）两阶段微调策略，强制约束满足和API合规性；3）MBEval验证驱动基准，通过闭环验证评估可执行性和结构动力学一致性

Result: 实验结果显示，在严格的验证指标上相比基线模型有持续改进，显著减少了幻觉和非合规输出

Conclusion: 该框架通过整合领域知识构建、约束导向模型对齐和验证驱动评估，实现了物理一致的自动建筑建模，为工程应用提供了可靠的建模代码生成解决方案

Abstract: Structural modeling is a fundamental component of computational engineering science, in which even minor physical inconsistencies or specification violations may invalidate downstream simulations. The potential of large language models (LLMs) for automatic generation of modeling code has been demonstrated. However, non-executable or physically inconsistent outputs remain prevalent under stringent engineering constraints. A framework for physics-consistent automatic building modeling is therefore proposed, integrating domain knowledge construction, constraint-oriented model alignment, and verification-driven evaluation. CivilInstruct is introduced as a domain-specific dataset that formalizes structural engineering knowledge and constraint reasoning to enable simulation-ready model generation. A two-stage fine-tuning strategy is further employed to enforce constraint satisfaction and application programming interface compliance, substantially reducing hallucinated and non-conforming outputs. MBEval is presented as a verification-driven benchmark that evaluates executability and structural dynamics consistency through closed-loop validation. Experimental results show consistent improvements over baselines across rigorous verification metrics. Our code is available at https://github.com/Jovanqing/AutoBM.

</details>


### [427] [Evaluating Large Language Models for Detecting Architectural Decision Violations](https://arxiv.org/abs/2602.07609)
*Ruoyu Su,Alexander Bakhtin,Noman Ahmad,Matteo Esposito,Valentina Lenarduzzi,Davide Taibi*

Main category: cs.SE

TL;DR: LLMs can effectively检测代码相关的架构决策违规，但对于依赖部署配置或组织知识的隐式决策准确性不足，需要与人类专家结合使用。


<details>
  <summary>Details</summary>
Motivation: 软件架构决策记录（ADRs）对维护架构质量至关重要，但许多决策违规未被发现，因为项目缺乏系统化文档和自动化检测机制。LLMs的发展为大规模自动化架构推理提供了新可能。

Method: 研究分析了109个GitHub仓库中的980个ADRs，采用多模型流水线方法：一个LLM主模型筛选潜在决策违规，另外三个LLM独立验证推理过程。评估了模型间一致性、准确性、精确率和召回率，并辅以专家评估。

Result: LLMs在显式、可代码推断的决策上表现出显著的一致性和高准确性。但对于隐式或部署导向的决策（依赖部署配置或组织知识），准确性不足。模型间达成实质性共识，在代码相关决策上表现强劲。

Conclusion: LLMs能够有意义地支持架构决策合规性验证，但对于非代码相关的决策，目前尚不能替代人类专业知识，需要与专家结合使用。

Abstract: Architectural Decision Records (ADRs) play a central role in maintaining software architecture quality, yet many decision violations go unnoticed because projects lack both systematic documentation and automated detection mechanisms. Recent advances in Large Language Models (LLMs) open up new possibilities for automating architectural reasoning at scale. We investigated how effectively LLMs can identify decision violations in open-source systems by examining their agreement, accuracy, and inherent limitations. Our study analyzed 980 ADRs across 109 GitHub repositories using a multi-model pipeline in which one LLM primary screens potential decision violations, and three additional LLMs independently validate the reasoning. We assessed agreement, accuracy, precision, and recall, and complemented the quantitative findings with expert evaluation. The models achieved substantial agreement and strong accuracy for explicit, code-inferable decisions. Accuracy falls short for implicit or deployment-oriented decisions that depend on deployment configuration or organizational knowledge. Therefore, LLMs can meaningfully support validation of architectural decision compliance; however, they are not yet replacing human expertise for decisions not focused on code.

</details>


### [428] [Debugging code world models](https://arxiv.org/abs/2602.07672)
*Babak Rahmani*

Main category: cs.SE

TL;DR: CWMs通过预测程序执行状态来模拟程序运行，但存在两大主要失败模式：长执行历史导致的token预算耗尽，以及字符串状态处理中的子词分词限制问题。


<details>
  <summary>Details</summary>
Motivation: 研究代码世界模型(CWMs)的错误来源和局限性，理解其在局部语义执行和长时状态跟踪方面的表现，为改进模型提供方向。

Method: 从两个互补角度研究CWMs：局部语义执行和长时状态跟踪。使用真实代码基准测试和受控的排列跟踪基准，分析失败模式，并测试在真实命令替换下的状态传播能力。

Result: 发现两大主要失败模式：1)密集运行时状态产生token密集型执行轨迹，导致长执行历史程序token预算耗尽；2)失败主要集中在字符串值状态，归因于子词分词限制而非程序结构。在长时状态跟踪中，错误主要由动作生成引起，当使用真实命令替换时，Transformer-based CWM能准确传播状态。

Conclusion: CWMs的局限性主要源于token预算和分词问题，而非长时状态跟踪能力。这为设计更高效的监督和状态表示提供了方向，使其更好地与程序执行和数据类型对齐。

Abstract: Code World Models (CWMs) are language models trained to simulate program execution by predicting explicit runtime state after every executed command. This execution-based world modeling enables internal verification within the model, offering an alternative to natural language chain-of-thought reasoning. However, the sources of errors and the nature of CWMs' limitations remain poorly understood. We study CWMs from two complementary perspectives: local semantic execution and long-horizon state tracking. On real-code benchmarks, we identify two dominant failure regimes. First, dense runtime state reveals produce token-intensive execution traces, leading to token-budget exhaustion on programs with long execution histories. Second, failures disproportionately concentrate in string-valued state, which we attribute to limitations of subword tokenization rather than program structure. To study long-horizon behavior, we use a controlled permutation-tracking benchmark that isolates state propagation under action execution. We show that long-horizon degradation is driven primarily by incorrect action generation: when actions are replaced with ground-truth commands, a Transformer-based CWM propagates state accurately over long horizons, despite known limitations of Transformers in long-horizon state tracking. These findings suggest directions for more efficient supervision and state representations in CWMs that are better aligned with program execution and data types.

</details>


### [429] [Still Manual? Automated Linter Configuration via DSL-Based LLM Compilation of Coding Standards](https://arxiv.org/abs/2602.07783)
*Zejun Zhang,Yixin Gan,Zhenchang Xing,Tian Zhang,Yi Li,Xiwei Xu,Qinghua Lu,Liming Zhu*

Main category: cs.SE

TL;DR: LintCFG：一种基于DSL和LLM的自动化linter配置生成方法，通过编译器设计思路将自然语言编码标准转换为特定linter配置，显著提高配置效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 手动配置linter存在复杂性高、专业知识需求大、维护成本高等问题，且编程语言、编码标准和linter的多样性及演化导致重复配置工作繁重。需要自动化方法来减少人工工作量。

Method: 提出LintCFG方法：1）设计领域特定语言（DSL）以工具无关、结构化、可读且精确的方式表达编码规则；2）将linter配置构建为DSL配置指令；3）通过编译过程将自然语言编码标准解析为DSL编码标准，与DSL配置指令匹配设置配置参数，验证一致性，最终生成特定linter配置。

Result: 在Java编码标准的Checkstyle实验中，DSL表示达到90%以上的精确率和召回率，细粒度linter配置生成的准确率、精确率、召回率和F1分数接近70%（部分超过70%）。方法在精确率上比基线提升超过100%。用户研究表明能提高开发者的linter配置效率。方法具有通用性，成功为JavaScript编码标准生成ESLint配置。

Conclusion: LintCFG通过DSL驱动的LLM编译方法，能够跨编程语言、编码标准和linter自动化生成linter配置，显著减少人工工作量，提高配置准确性和开发效率，具有广泛的适用性。

Abstract: Coding standards are essential for maintaining consistent and high-quality code across teams and projects. Linters help developers enforce these standards by detecting code violations. However, manual linter configuration is complex and expertise-intensive, and the diversity and evolution of programming languages, coding standards, and linters lead to repetitive and maintenance-intensive configuration work. To reduce manual effort, we propose LintCFG, a domain-specific language (DSL)-driven, LLM-based compilation approach to automate linter configuration generation for coding standards, independent of programming languages, coding standards, and linters. Inspired by compiler design, we first design a DSL to express coding rules in a tool-agnostic, structured, readable, and precise manner. Then, we build linter configurations into DSL configuration instructions. For a given natural language coding standard, the compilation process parses it into DSL coding standards, matches them with the DSL configuration instructions to set configuration names, option names and values, verifies consistency between the standards and configurations, and finally generates linter-specific configurations. Experiments with Checkstyle for Java coding standard show that our approach achieves over 90% precision and recall in DSL representation, with accuracy, precision, recall, and F1-scores close to 70% (with some exceeding 70%) in fine-grained linter configuration generation. Notably, our approach outperforms baselines by over 100% in precision. A user study further shows that our approach improves developers' efficiency in configuring linters for coding standards. Finally, we demonstrate the generality of the approach by generating ESLint configurations for JavaScript coding standards, showcasing its broad applicability across other programming languages, coding standards, and linters.

</details>


### [430] [Rethinking the Value of Agent-Generated Tests for LLM-Based Software Engineering Agents](https://arxiv.org/abs/2602.07900)
*Zhi Chen,Zhensu Sun,Yuling Shi,Chao Peng,Xiaodong Gu,David Lo,Lingxiao Jiang*

Main category: cs.SE

TL;DR: 研究发现当前LLM代码代理在解决仓库级问题时编写的测试效用有限，测试频率与任务解决成功率无显著关联，且代理更倾向于使用打印语句而非正式断言检查。


<details>
  <summary>Details</summary>
Motivation: 研究动机源于观察到GPT-5.2几乎不编写新测试却能取得与顶级代理相当的性能，这引发了对代理编写测试在问题解决中实际效用的质疑，需要探究这些测试是否真正改善问题解决还是仅仅模仿人类测试实践并消耗大量交互预算。

Method: 方法包括：1) 在SWE-bench Verified上分析六个最先进LLM的代理轨迹；2) 比较已解决和未解决任务中的测试编写频率；3) 分析测试类型（打印语句 vs 断言检查）；4) 通过修改四个代理的提示进行对照实验，增加或减少测试编写。

Result: 结果显示：1) 测试编写虽普遍但已解决和未解决任务的测试频率相似；2) 代理更偏好使用值揭示的打印语句而非正式断言检查；3) 改变测试编写量对最终结果无显著影响；4) 当前测试编写实践在自主软件工程任务中提供边际效用。

Conclusion: 结论表明当前LLM代码代理的测试编写实践可能效用有限，测试频率与任务解决成功率无直接关联，代理更倾向于使用简单打印语句而非正式测试，这为优化自主软件工程代理的设计提供了重要见解。

Abstract: Large Language Model (LLM) code agents increasingly resolve repository-level issues by iteratively editing code, invoking tools, and validating candidate patches. In these workflows, agents often write tests on the fly, a paradigm adopted by many high-ranking agents on the SWE-bench leaderboard. However, we observe that GPT-5.2, which writes almost no new tests, can even achieve performance comparable to top-ranking agents. This raises the critical question: whether such tests meaningfully improve issue resolution or merely mimic human testing practices while consuming a substantial interaction budget.
  To reveal the impact of agent-written tests, we present an empirical study that analyzes agent trajectories across six state-of-the-art LLMs on SWE-bench Verified. Our results show that while test writing is commonly adopted, but resolved and unresolved tasks within the same model exhibit similar test-writing frequencies Furthermore, these tests typically serve as observational feedback channels, where agents prefer value-revealing print statements significantly more than formal assertion-based checks. Based on these insights, we perform a controlled experiment by revising the prompts of four agents to either increase or reduce test writing. The results suggest that changes in the volume of agent-written tests do not significantly change final outcomes. Taken together, our study reveals that current test-writing practices may provide marginal utility in autonomous software engineering tasks.

</details>


### [431] [SWE Context Bench: A Benchmark for Context Learning in Coding](https://arxiv.org/abs/2602.08316)
*Jared Zhu,Minhao Hu,Junde Wu*

Main category: cs.SE

TL;DR: SWE-ContextBench是一个评估编程代理经验复用能力的基准测试，基于SWE-Bench Lite构建，包含300个基础任务和99个相关任务，评估准确性、时间效率和成本效率三个维度。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试主要评估编程代理在独立任务上的正确性，但缺乏对跨相关任务经验复用能力的评估，无法衡量代理积累、检索和应用先前经验的能力及其效率收益。

Method: 基于SWE-Bench Lite构建SWE-ContextBench，通过GitHub问题和拉取请求的真实依赖和引用关系，将300个基础任务与99个相关任务形成任务序列，评估经验复用的多种设置（包括oracle引导和自主检索，完整执行轨迹和紧凑摘要）。

Result: 正确选择的摘要化经验能提高解决准确性，并显著减少运行时间和token成本，特别是在较难任务上；而未过滤或错误选择的经验则带来有限或负面影响。

Conclusion: 经验表示和检索质量对编程代理的经验复用至关重要，SWE-ContextBench为研究编程代理的经验复用提供了一个原则性的基准测试框架。

Abstract: Large language models are increasingly used as programming agents for repository level software engineering tasks. While recent benchmarks evaluate correctness in realistic codebases, they largely treat tasks as independent and do not assess whether agents can reuse experience across related problems. As a result, the ability of agents to accumulate, retrieve, and apply prior experience, as well as the efficiency gains from such reuse, remains difficult to measure. We introduce SWE-ContextBench, a benchmark designed to explicitly evaluate experience reuse in programming agents. Built on SWE-Bench Lite, SWE-ContextBench augments 300 base tasks with 99 related tasks derived from real dependency and reference relationships among GitHub issues and pull requests, forming task sequences with shared context. The benchmark evaluates agents along three complementary dimensions: prediction accuracy, time efficiency, and cost efficiency. Using SWE-ContextBench, we study multiple experience reuse settings, including oracle guided and autonomous retrieval, as well as full execution trajectories and compact summaries. Our results show that correctly selected summarized experience improves resolution accuracy and substantially reduces runtime and token cost, particularly on harder tasks. In contrast, unfiltered or incorrectly selected experience provides limited or negative benefits. These findings highlight the importance of experience representation and retrieval quality, and position SWE-ContextBench as a principled benchmark for studying experience reuse in programming agents.

</details>


### [432] [Taming Scylla: Understanding the multi-headed agentic daemon of the coding seas](https://arxiv.org/abs/2602.08765)
*Micah Villmow*

Main category: cs.SE

TL;DR: Scylla是一个评估代理编码工具的框架，通过结构化消融研究使用七个测试层级(T0-T6)逐步增加复杂性，以隔离直接影响结果的因素，关键指标是Cost-of-Pass(CoP)：获得一个正确解决方案的预期美元成本。


<details>
  <summary>Details</summary>
Motivation: LLM工具正在快速自动化软件开发任务，但缺乏严格的方法来评估不同架构选择（提示、技能、工具、多代理设置）如何实质性地影响能力和成本。

Method: 引入Scylla评估框架，通过七个测试层级(T0-T6)进行结构化消融研究，逐步增加复杂性以隔离影响因素。使用Cost-of-Pass(CoP)作为关键指标，框架与模型无关，可与任何CLI工具配合使用。使用Claude Sonnet 4.5进行演示，采用同一供应商的多个LLM法官(Opus 4.5, Sonnet 4.5, Haiku 4.5)进行评估共识，法官使用直接测试、人工设计的LLM评估量表和定性评估来评分结果。

Result: 创建了一个可重复的框架，量化了代理复杂性与实际结果之间的权衡，表明架构复杂性并不总是能提高质量。

Conclusion: Scylla提供了一个系统化的方法来评估代理编码工具，通过Cost-of-Pass指标直接量化复杂性与效率之间的权衡，为LLM工具架构选择提供了实证依据。

Abstract: LLM-based tools are automating more software development tasks at a rapid pace, but there is no rigorous way to evaluate how different architectural choices -- prompts, skills, tools, multi-agent setups -- materially affect both capability and cost. This paper introduces Scylla, an evaluation framework for benchmarking agentic coding tools through structured ablation studies that uses seven testing tiers (T0-T6) progressively adding complexity to isolate what directly influences results and how. The key metric is Cost-of-Pass (CoP): the expected dollar cost to get one correct solution, which directly quantifies the trade-off between complexity and efficiency. The framework is model-agnostic, designed to work with any CLI tool; this paper demonstrates it with Claude Sonnet 4.5, using multiple LLM judges (Opus 4.5, Sonnet 4.5, Haiku 4.5) from the same vendor for evaluation consensus, where judges score results using direct tests, human-designed LLM-evaluated rubrics, and qualitative assessment. The result is a reproducible framework that quantifies trade-offs between agent complexity and actual outcomes, suggesting that architectural complexity does not always improve quality.

</details>


### [433] [DeepQuali: Initial results of a study on the use of large language models for assessing the quality of user stories](https://arxiv.org/abs/2602.08887)
*Adam Trendowicz,Daniel Seifert,Andreas Jedlitschka,Marcus Ciolkowski,Anton Strahilov*

Main category: cs.SE

TL;DR: 提出DeepQuali方法，使用GPT-4o评估和改进敏捷开发中的需求质量，在两家小公司验证，专家基本认可LLM的质量评估结果。


<details>
  <summary>Details</summary>
Motivation: 生成式AI在软件工程中主要用于编码任务，但在需求工程特别是需求验证方面应用有限。当前GAI在需求领域的应用主要集中在需求获取、转换和分类，而非质量评估。

Method: 提出DeepQuali方法，基于GPT-4o评估和改进敏捷软件开发中的需求质量。在两家小公司的项目中应用，将LLM的质量评估与专家判断进行比较，专家参与解决方案的走查并提供反馈。

Result: 专家在很大程度上同意LLM的质量评估，特别是在整体评分和解释方面。但专家之间在详细评分上并不总是一致，表明专业知识和经验可能影响判断。专家认可方法的实用性，但批评其未集成到工作流程中。

Conclusion: LLM在支持软件工程师进行需求质量评估和改进方面具有潜力。明确使用质量模型和解释性反馈可以提高接受度。

Abstract: Generative artificial intelligence (GAI), specifically large language models (LLMs), are increasingly used in software engineering, mainly for coding tasks. However, requirements engineering - particularly requirements validation - has seen limited application of GAI. The current focus of using GAI for requirements is on eliciting, transforming, and classifying requirements, not on quality assessment. We propose and evaluate the LLM-based (GPT-4o) approach "DeepQuali", for assessing and improving requirements quality in agile software development. We applied it to projects in two small companies, where we compared LLM-based quality assessments with expert judgments. Experts also participated in walkthroughs of the solution, provided feedback, and rated their acceptance of the approach. Experts largely agreed with the LLM's quality assessments, especially regarding overall ratings and explanations. However, they did not always agree with the other experts on detailed ratings, suggesting that expertise and experience may influence judgments. Experts recognized the usefulness of the approach but criticized the lack of integration into their workflow. LLMs show potential in supporting software engineers with the quality assessment and improvement of requirements. The explicit use of quality models and explanatory feedback increases acceptance.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [434] [Performance Evaluation of V2X Communication Using Large-Scale Traffic Data](https://arxiv.org/abs/2602.07244)
*John Pravin Arockiasamy,Alexey Vinel*

Main category: cs.NI

TL;DR: 该论文使用真实交通数据（HighD和InD数据集）进行大规模V2X通信性能评估，发现协同感知服务在真实交通条件下仍然可行，并揭示了交通密度、移动模式和通信范围对性能的影响。


<details>
  <summary>Details</summary>
Motivation: V2X技术对协同自动驾驶至关重要，但大规模实际部署有限。现有性能评估多依赖模拟器生成的合成交通场景，可能无法完全捕捉真实交通特征，因此需要基于真实交通数据的大规模评估。

Method: 将HighD和InD数据集的真实车辆轨迹转换为仿真就绪格式，结合标准化V2X网络协议栈，对包含数十万辆车的整个交通群体进行消息级性能分析。评估了生成间隔、包间隔、包投递率和信道繁忙率等关键指标。

Result: 结果表明：1) 协同感知服务在真实交通条件下仍然可行；2) 交通密度、移动模式和通信范围显著影响V2X性能；3) 合成交通假设可能高估信道拥塞程度。

Conclusion: 基于真实交通数据的大规模V2X性能评估显示，协同感知服务在实际部署中具有可行性，同时揭示了真实交通特征对性能的影响，为V2X系统设计和优化提供了重要见解。

Abstract: Vehicular communication (V2X) technologies are widely regarded as a cornerstone for cooperative and automated driving, yet their large-scale real-world deployment remains limited. As a result, understanding V2X performance under realistic, full-scale traffic conditions continues to be relevant. Most existing performance evaluations rely on synthetic traffic scenarios generated by simulators, which, while useful, may not fully capture the features of real-world traffic. In this paper, we present a large-scale, data-driven evaluation of V2X communication performance using real-world traffic datasets. Vehicle trajectories derived from the Highway Drone (HighD) and Intersection Drone (InD) datasets are converted into simulation-ready formats and coupled with a standardized V2X networking stack to enable message-level performance analysis for entire traffic populations comprising over hundred thousands vehicles across multiple locations. We evaluate key V2X performance indicators, including inter-generation gap, inter-packet gap, packet delivery ratio, and channel busy ratio, across both highway and urban intersection environments. Our results show that cooperative awareness services remain feasible at scale under realistic traffic conditions. In addition, the findings highlight how traffic density, mobility patterns, and communication range influence V2X performance and how synthetic traffic assumptions may overestimate channel congestion.

</details>


### [435] [Mirage: Transmitting a Video as a Perceptual Illusion for 50,000X Speedup](https://arxiv.org/abs/2602.07396)
*Junjie Wu,Tianrui Li,Yi Zhang,Ziyuan Yang*

Main category: cs.NI

TL;DR: Mirage提出了一种无视觉数据的视频通信框架，通过语义分解和生成模型实现高效传输，在保持语义信息的同时实现高达50000倍的数据压缩


<details>
  <summary>Details</summary>
Motivation: 现有通信框架主要关注信号级精确重建，导致高通信开销和系统复杂度，特别是在视频通信中传输原始视觉数据消耗大量带宽

Method: 将视频内容分解为时间序列信息（通过视频描述捕捉运动动态）和空间外观表示（关键帧编码为紧凑语义表示），接收端使用生成视频模型合成视频

Result: Mirage实现了高达50000倍的数据级压缩加速，且随着视频内容增大预期增益会进一步扩大，同时具有隐私保护特性

Conclusion: Mirage提供了一种高效、隐私保护且可个性化适应的视频通信框架，在效率、隐私、控制和感知质量之间实现灵活权衡

Abstract: The existing communication framework mainly aims at accurate reconstruction of source signals to ensure reliable transmission. However, this signal-level fidelity-oriented design often incurs high communication overhead and system complexity, particularly in video communication scenarios where mainstream frameworks rely on transmitting visual data itself, resulting in significant bandwidth consumption. To address this issue, we propose a visual data-free communication framework, Mirage, for extremely efficient video transmission while preserving semantic information. Mirage decomposes video content into two complementary components: temporal sequence information capturing motion dynamics and spatial appearance representations describing overall visual structure. Temporal information is preserved through video captioning, while key frames are encoded into compact semantic representations for spatial appearance. These representations are transmitted to the receiver, where videos are synthesized using generative video models. Since no raw visual data is transmitted, Mirage is inherently privacy-preserving. Mirage also supports personalized adaptation across deployment scenarios. The sender, network, and receiver can independently impose constraints on semantic representation, transmission, and generation, enabling flexible trade-offs between efficiency, privacy, control, and perceptual quality. Experimental results in video transmission demonstrate that Mirage achieves up to a 50000X data-level compression speedup over raw video transmission, with gains expected to scale with larger video content sizes.

</details>


### [436] [NOMA-Assisted Multi-BS MEC Networks for Delay-Sensitive and Computation-Intensive IoT Applications](https://arxiv.org/abs/2602.07456)
*Yuang Chen,Fengqian Guo,Chang Wu,Mingyu Peng,Hancheng Lu,Chang Wen Chen*

Main category: cs.NI

TL;DR: 提出了一种基于NOMA的多基站移动边缘计算网络，用于大规模物联网连接，通过联合任务卸载、用户分组和功率分配优化来最小化系统总延迟。


<details>
  <summary>Details</summary>
Motivation: 物联网大规模部署面临超低延迟需求，特别是在计算密集型任务和大规模连接场景下。需要解决子信道访问不平衡、组间干扰、计算负载差异和设备异构性等问题。

Method: 1) 将任务卸载和用户分组建模为非合作博弈，提出基于精确势博弈的联合决策算法(EPG-JDM)；2) 提出基于主最小化(MM)的功率分配算法，将原问题转化为可处理的凸优化问题。

Result: 仿真实验表明，EPG-JDM算法显著优于现有决策算法和经典启发式算法，在总延迟和功耗方面分别实现了19.3%和14.7%的性能提升。

Conclusion: 提出的NOMA辅助多基站MEC网络和联合优化算法能有效满足大规模物联网的超低延迟需求，解决了现有系统中的关键挑战。

Abstract: The burgeoning and ubiquitous deployment of the Internet of Things (IoT) landscape struggles with ultra-low latency demands for computation-intensive tasks in massive connectivity scenarios. In this paper, we propose an innovative uplink non-orthogonal multiple access (NOMA)-assisted multi-base station (BS) mobile edge computing (BS-MEC) network tailored for massive IoT connectivity. To fulfill the quality-of-service (QoS) requirements of delay-sensitive and computation-intensive IoT applications, we formulate a joint task offloading, user grouping, and power allocation optimization problem with the overarching objective of minimizing the system's total delay, aiming to address issues of unbalanced subchannel access, inter-group interference, computational load disparities, and device heterogeneity. To effectively tackle this problem, we first reformulate task offloading and user grouping into a non-cooperative game model and propose an exact potential game-based joint decision-making (EPG-JDM) algorithm, which dynamically selects optimal task offloading and subchannel access decisions for each IoT device based on its channel conditions, thereby achieving the Nash Equilibrium. Then, we propose a majorization-minimization (MM)-based power allocation algorithm, which transforms the original subproblem into a tractable convex optimization paradigm. Extensive simulation experiments demonstrate that our proposed EPG-JDM algorithm significantly outperforms state-of-the-art decision-making algorithms and classic heuristic algorithms, yielding performance improvements of up to 19.3% and 14.7% in terms of total delay and power consumption, respectively.

</details>


### [437] [LEO Topology Design Under Real-World Deployment Constraints](https://arxiv.org/abs/2602.07756)
*Muaz Ali,Beichuan Zhang*

Main category: cs.NI

TL;DR: 本文针对大规模低轨卫星网络提出两种考虑实际部署约束的拓扑设计方法：长短链路法和模拟退火法，显著提升了网络性能。


<details>
  <summary>Details</summary>
Motivation: 现有大规模低轨卫星网络拓扑设计通常假设理想条件，未考虑实际部署动态（如部分星座部署、每日节点更替、链路可用性变化），导致不适用于真实网络。

Method: 提出两种方法：1) 长短链路法：系统性地结合长距离捷径链路和短距离本地链路；2) 模拟退火法：通过随机优化构建拓扑。两种方法都能通过增量更新处理每日节点更替。

Result: 使用3个月Starlink数据评估，在完全部署和部分部署场景下，相比+Grid方法，平均端到端延迟降低45%，跳数减少65%，网络容量提升2.3倍。

Conclusion: 提出的两种拓扑设计方法能有效处理实际部署约束，显著提升大规模低轨卫星网络性能，同时通过增量更新避免昂贵的完全重构。

Abstract: The performance of large-scale Low-Earth-Orbit (LEO) networks, which consist of thousands of satellites interconnected by optical links, is dependent on its network topology. Existing topology designs often assume idealized conditions and do not account for real-world deployment dynamics, such as partial constellation deployment, daily node turnovers, and varying link availability, making them inapplicable to real LEO networks. In this paper, we develop two topology design methods that explicitly operate under real-world deployment constraints: the Long--Short Links (LSL) method, which systematically combines long-distance shortcut links with short-distance local links, and the Simulated Annealing (SA) method, which constructs topologies via stochastic optimization. Evaluated under both full deployment and partial deployment scenarios using 3-months of Starlink data, our methods achieve up to 45% lower average end-to-end delay, 65% fewer hops, and up to $2.3\times$ higher network capacity compared to +Grid. Both methods are designed to handle daily node turnovers by incrementally updating the topology, maintaining good network performance while avoiding costly full reconstruction of the topology.

</details>


### [438] [Interference Propagation Analysis for Large-Scale Multi-RIS-Empowered Wireless Communications:An Epidemiological Perspective](https://arxiv.org/abs/2602.07922)
*Kaining Wang,Xueyao Zhang,Bo Yang,Xuelin Cao,Qiang Cheng,Zhiwen Yu,Bin Guo,George C. Alexandropoulos,Kai-Kit Wong,Chan-Byoung Chae,Mérouane Debbah*

Main category: cs.NI

TL;DR: 该论文研究RIS在用户移动性场景下的干扰传播问题，采用随机几何模型分析干扰特性，并引入流行病学模型描述干扰动态传播。


<details>
  <summary>Details</summary>
Motivation: 传统研究主要关注RIS的优势，而本文关注RIS的负面影响，特别是用户移动性在下行无线系统中引起的干扰传播问题。

Method: 使用随机几何模型：基站和RIS位置采用Matérn硬核点过程建模，用户位置采用齐次泊松点过程。推导接收信号和干扰信号的功率分布闭式表达式，提出覆盖概率新表达式和干扰传播强度概念。采用流行病学中的SIS模型描述用户移动性引起的干扰动态传播。

Result: 推导了接收信号和干扰信号的功率分布闭式表达式，提出了覆盖概率新表达式和干扰传播强度概念。数值结果验证了理论分析，并提供了大规模多RIS无线通信网络中干扰传播管理的建议。

Conclusion: RIS在带来优势的同时也会导致干扰传播问题，特别是在用户移动性场景下。通过随机几何和流行病学模型可以分析干扰传播特性，为大规模多RIS网络中的干扰管理提供理论指导。

Abstract: Reconfigurable intelligent surfaces (RISs) have gained significant attention in recent years due to their ability to control the reflection of radio-frequency signals and reshape the wireless propagation environment. Unlike traditional studies that primarily focus on the advantages of RISs, this paper examines the negative impacts of RISs by investigating interference propagation caused by user mobility in downlink wireless systems. We employ a stochastic geometric model to simulate the locations of base stations and RISs using the Matérn hard core point process, while user locations are modeled with the homogeneous Poisson point process. We derive novel closed-form expressions for the power distributions of the received signal at the users and the interfering signal. Additionally, we present a novel expression for coverage probability and introduce the concept of interference propagation intensity. To characterize the dynamics of interference caused by user mobility, we adopt an epidemiological approach using the susceptible-infected-susceptible model. Finally, crucial factors influencing the propagation of interference are analyzed. Numerical results validate our theoretical analysis and provide suggestions for managing interference propagation in large-scale multi-RIS wireless communication networks.

</details>


### [439] [Trajectory-Aware Multi-RIS Activation and Configuration: A Riemannian Diffusion Method](https://arxiv.org/abs/2602.07937)
*Kaining Wang,Bo Yang,Yusheng Lei,Zhibo Li,Zhiwen Yu,Xuelin Cao,Bin Guo,George C. Alexandropoulos,Dusit Niyato,Mérouane Debbah,Zhu Han*

Main category: cs.NI

TL;DR: 提出生成式多RIS控制框架，通过LSTM预测用户轨迹，黎曼扩散模型优化相位配置，强化学习动态指导，实现智能RIS开关控制和相位优化，显著提升SINR性能。


<details>
  <summary>Details</summary>
Motivation: 可重构智能表面(RIS)虽然能增强无线覆盖，但其可编程反射特性在大规模多RIS移动通信场景中可能无意放大干扰。密集用户移动和频繁视距重叠会严重降低信号干扰噪声比(SINR)，需要智能控制多RIS以优化性能。

Method: 1) 设计LSTM神经网络，结合速度和航向特征预测多用户轨迹，重构未来信道状态信息；2) 针对多RIS控制的高度非凸问题，开发环面上的黎曼扩散模型生成几何一致的相位配置，反向扩散过程由强化学习动态指导；3) 通过比较RIS激活和去激活条件下的预测可达速率，严格推导超表面的最优开关状态。

Result: 广泛仿真表明，所提框架相比基于学习的控制方案实现高达30%的SINR提升，相比RIS始终开启方案获得高达44%增益，在不同发射功率、RIS配置和干扰密度下均优于最先进的基线方法。

Conclusion: 提出的生成式多RIS控制框架能有效预测用户移动和干扰模式，通过智能优化RIS开关状态和相位配置，显著改善无线通信性能，为解决大规模多RIS场景中的干扰放大问题提供了有效解决方案。

Abstract: Reconfigurable intelligent surfaces (RISs) offer a low-cost, energy-efficient means for enhancing wireless coverage. Yet, their inherently programmable reflections may unintentionally amplify interference, particularly in large-scale, multi-RIS-enabled mobile communication scenarios where dense user mobility and frequent line-of-sight overlaps can severely degrade the signal-to-interference-plus-noise ratio (SINR). To address this challenge, this paper presents a novel generative multi-RIS control framework that jointly optimizes the ON/OFF activation patterns of multiple RISs in the smart wireless environment and the phase configurations of the activated RISs based on predictions of multi-user trajectories and interference patterns. We specially design a long short-term memory (LSTM) artificial neural network, enriched with speed and heading features, to forecast multi-user trajectories, thereby enabling reconstruction of future channel state information. To overcome the highly nonconvex nature of the multi-RIS control problem, we develop a Riemannian diffusion model on the torus to generate geometry-consistent phase-configuration, where the reverse diffusion process is dynamically guided by reinforcement learning. We then rigorously derive the optimal ON/OFF states of the metasurfaces by comparing predicted achievable rates under RIS activation and deactivation conditions. Extensive simulations demonstrate that the proposed framework achieves up to 30\% SINR improvement over learning-based control and up to 44\% gain compared with the RIS always-on scheme, while consistently outperforming state-of-the-art baselines across different transmit powers, RIS configurations, and interference densities.

</details>


### [440] [DHEA-MECD: An Embodied Intelligence-Powered DRL Algorithm for AUV Tracking in Underwater Environments with High-Dimensional Features](https://arxiv.org/abs/2602.07947)
*Kai Tian,Chuan Lin,Guangjie Han,Chen An,Qian Zhu,Shengzhao Zhu,Zhenyu Wang*

Main category: cs.NI

TL;DR: 提出基于分层具身智能架构的DHEA-MECD深度强化学习算法，用于AUV在复杂水下环境中的多目标跟踪，通过双头编码器注意力框架和多专家协同决策机制实现高效鲁棒的跟踪性能。


<details>
  <summary>Details</summary>
Motivation: AUV在复杂水下环境中的多目标跟踪面临高维特征、耦合运动状态、空间约束、时变环境干扰等挑战，现有方法难以有效处理这些复杂因素。

Method: 提出分层具身智能架构，在此基础上设计DHEA-MECD算法：1）双头编码器注意力框架分解原始感知观测并建模异构特征间复杂依赖；2）基于运动阶段感知的多专家协同决策机制，采用Top-k专家选择策略实现阶段自适应决策。

Result: 实验结果表明，相比主流DRL方法，该方法在复杂干扰丰富的海洋环境中实现了更高的跟踪成功率、更快的收敛速度和更好的运动最优性。

Conclusion: DHEA-MECD算法能够使AUV在复杂水下环境中实现智能、稳定、抗干扰的多目标跟踪，为水下自主系统提供了有效的解决方案。

Abstract: In recent years, autonomous underwater vehicle (AUV) systems have demonstrated significant potential in complex marine exploration. However, effective AUV-based tracking remains challenging in realistic underwater environments characterized by high-dimensional features, including coupled kinematic states, spatial constraints, time-varying environmental disturbances, etc. To address these challenges, this paper proposes a hierarchical embodied-intelligence (EI) architecture for underwater multi-target tracking with AUVs in complex underwater environments. Built upon this architecture, we introduce the Double-Head Encoder-Attention-based Multi-Expert Collaborative Decision (DHEA-MECD), a novel Deep Reinforcement Learning (DRL) algorithm designed to support efficient and robust multi-target tracking. Specifically, in DHEA-MECD, a Double-Head Encoder-Attention-based information extraction framework is designed to semantically decompose raw sensory observations and explicitly model complex dependencies among heterogeneous features, including spatial configurations, kinematic states, structural constraints, and stochastic perturbations. On this basis, a motion-stage-aware multi-expert collaborative decision mechanism with Top-k expert selection strategy is introduced to support stage-adaptive decision-making. Furthermore, we propose the DHEA-MECD-based underwater multitarget tracking algorithm to enable AUV smart, stable, and anti-interference multi-target tracking. Extensive experimental results demonstrate that the proposed approach achieves superior tracking success rates, faster convergence, and improved motion optimality compared with mainstream DRL-based methods, particularly in complex and disturbance-rich marine environments.

</details>


### [441] [NeuroScaler: Towards Energy-Optimal Autoscaling for Container-Based Services](https://arxiv.org/abs/2602.08191)
*Alisson O. Chaves,Rodrigo Moreira,Larissa F. Rodrigues Moreira,Joao Correia,David Santos,Rui Silva,Tiago Barros,Daniel Corujo,Miguel Rocha,Flavio de Oliveira Silva*

Main category: cs.NI

TL;DR: NeuroScaler是一个AI原生的、节能的、碳感知的编排器，用于绿色云边网络，通过多层级遥测和模型预测控制，相比传统HPA减少34.68%能耗同时保持目标延迟。


<details>
  <summary>Details</summary>
Motivation: 当前网络需要在严格的能源和碳排放约束下运行，但现有的自动扩缩机制仍然是工作负载中心化和基础设施孤岛化的，且大多不了解其环境影响。

Method: NeuroScaler聚合从PDU到裸机服务器再到Kubernetes管理的容器化虚拟基础设施的多层级遥测数据，使用不同层级的能源和计算指标。它支持多个连接负载、性能和功耗的机器学习管道，并在统一的可观测性层中采用模型预测控制策略来优化能源使用同时满足服务级别目标。

Result: 在支持真实服务的生产级服务器的真实测试平台中，NeuroScaler相比水平Pod自动扩缩器(HPA)减少了34.68%的能耗，同时保持了目标延迟。

Conclusion: NeuroScaler展示了AI原生、能源高效且碳感知的编排器可以有效减少云边网络的能源消耗，同时满足服务级别目标，为绿色网络基础设施提供了有前景的解决方案。

Abstract: Future networks must meet stringent requirements while operating within tight energy and carbon constraints. Current autoscaling mechanisms remain workload-centric and infrastructure-siloed, and are largely unaware of their environmental impact. We present NeuroScaler, an AI-native, energy-efficient, and carbon-aware orchestrator for green cloud and edge networks. NeuroScaler aggregates multi-tier telemetry, from Power Distribution Units (PDUs) through bare-metal servers to virtualized infrastructure with containers managed by Kubernetes, using distinct energy and computing metrics at each tier. It supports several machine learning pipelines that link load, performance, and power. Within this unified observability layer, a model-predictive control policy optimizes energy use while meeting service-level objectives. In a real testbed with production-grade servers supporting real services, NeuroScaler reduces energy consumption by 34.68% compared to the Horizontal Pod Autoscaler (HPA) while maintaining target latency.

</details>


### [442] [MonkeyTree: Near-Minimal Congestion for Multi-tenant Training via Migration](https://arxiv.org/abs/2602.08296)
*Anton A. Zabreyko,Weiyang Wang,Manya Ghobadi*

Main category: cs.NI

TL;DR: MonkeyTree通过作业迁移而非网络层技术缓解多租户GPU集群的网络拥塞，利用ML训练流量特性实现无拥塞放置，将平均作业完成时间提升14%。


<details>
  <summary>Details</summary>
Motivation: 云运营商在共享过载网络上共置ML训练作业时，超过三分之一的作业因拥塞导致训练吞吐量下降。现有方法要么依赖路由和流调度（在流量超过容量时有根本限制），要么需要昂贵的全二分带宽拓扑。

Method: MonkeyTree利用ML训练流量的环状集合特性，将碎片整理建模为整数线性规划问题，最小化工作节点移动，同时满足每个机架碎片边界。通过RDMA实现内存检查点恢复迁移，端到端系统开销仅9.02秒。

Result: 在2048个H200 GPU集群模拟和5节点A100测试床验证中，MonkeyTree在1024 GPU、4:1过载比下平均作业完成时间比最佳基线提升14%；在16:1过载比、2048 GPU下，p99作业完成时间保持在理想值的5%以内。

Conclusion: MonkeyTree首次通过作业迁移而非网络层技术缓解GPU集群拥塞，证明基于碎片整理的方法能有效提升ML训练性能，特别是在高过载比的大规模集群中。

Abstract: We present MonkeyTree, the first system to mitigate network congestion in multi-tenant GPU clusters through job-migration based defragmentation rather than network-layer techniques. As cloud operators co-locate ML training jobs on shared, oversubscribed networks, congestion degrades training throughput for over a third of jobs. Prior approaches either rely on routing and flow scheduling--which we show have fundamental limits when traffic exceeds capacity--or require costly full-bisection bandwidth topologies with packet spraying.
  MonkeyTree exploits characteristics of ML training traffic: ring-based collectives generate exactly one cross-rack flow per rack a job spans, making congestion-free placements achievable. The sparse constraint structure admits abundant valid configurations, making them easy to reach with few migrations. Once reached, low fragmentation is self-reinforcing, as new arrivals disturb only a few racks. MonkeyTree formulates defragmentation as an integer linear program that minimizes worker movements, subject to per-rack fragmentation bounds. We prove a tight bound showing any placement can be defragmented to at most two cross-rack fragments per ToR, and extend the formulation to hybrid parallelism with multiple rings per server. Migration is implemented via in-memory checkpoint-and-restore over RDMA, incurring only 9.02 seconds of system overhead end-to-end per worker. We evaluate MonkeyTree using a custom simulator modeling clusters of up to 2,048 H200 GPUs and prototype on a five-node A100 testbed. MonkeyTree improves average job completion time by 14 percent over the next best baseline on a cluster of 1,024 GPUs with a 4:1 oversubscription. With a high 16:1 oversubscription ratio and 2,048 GPUs, MonkeyTree keeps p99 job completion time within 5 percent of ideal.

</details>


### [443] [PACC: Protocol-Aware Cross-Layer Compression for Compact Network Traffic Representation](https://arxiv.org/abs/2602.08331)
*Zhaochen Guo,Tianyufei Zhou,Honghao Wang,Ronghua Li,Shinan Liu*

Main category: cs.NI

TL;DR: PACC提出了一种冗余感知、层次感知的网络流量表示框架，通过分解协议栈为共享和私有组件，在加密流量分类任务上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 网络流量分类面临加密和协议演变的挑战。现有方法存在局限性：手工特征损失信息多，原始比特编码成本高，预训练嵌入会扁平化协议栈并跨层纠缠信号。真实流量在跨层和层内都存在大量冗余，现有范式未能明确识别和消除这些冗余，导致容量浪费、捷径学习和泛化能力下降。

Method: PACC将协议栈视为多视图输入，学习紧凑的层次投影，将表示分解为共享（跨层）和私有（层特定）组件。采用联合目标函数：通过重构保留层特定信息，通过对比互信息学习捕获共享结构，通过监督损失最大化任务相关信息，生成适合高效推理的紧凑潜在表示。

Result: 在加密应用分类、物联网设备识别和入侵检测等数据集上，PACC一致优于特征工程和原始比特基线方法。在加密子集上，比nPrint准确率提升高达12.9%。PACC匹配或超越了强基础模型基线，同时端到端效率提升高达3.16倍。

Conclusion: PACC通过冗余感知和层次感知的表示学习框架，有效解决了网络流量分类中的表示瓶颈问题，在保持高效性的同时显著提升了分类性能，特别是在加密流量场景下表现出色。

Abstract: Network traffic classification is a core primitive for network security and management, yet it is increasingly challenged by pervasive encryption and evolving protocols. A central bottleneck is representation: hand-crafted flow statistics are efficient but often too lossy, raw-bit encodings can be accurate but are costly, and recent pre-trained embeddings provide transfer but frequently flatten the protocol stack and entangle signals across layers. We observe that real traffic contains substantial redundancy both across network layers and within each layer; existing paradigms do not explicitly identify and remove this redundancy, leading to wasted capacity, shortcut learning, and degraded generalization. To address this, we propose PACC, a redundancy-aware, layer-aware representation framework. PACC treats the protocol stack as multi-view inputs and learns compact layer-wise projections that remain faithful to each layer while explicitly factorizing representations into shared (cross-layer) and private (layer-specific) components. We operationalize these goals with a joint objective that preserves layer-specific information via reconstruction, captures shared structure via contrastive mutual-information learning, and maximizes task-relevant information via supervised losses, yielding compact latents suitable for efficient inference. Across datasets covering encrypted application classification, IoT device identification, and intrusion detection, PACC consistently outperforms feature-engineered and raw-bit baselines. On encrypted subsets, it achieves up to a 12.9% accuracy improvement over nPrint. PACC matches or surpasses strong foundation-model baselines. At the same time, it improves end-to-end efficiency by up to 3.16x.

</details>


### [444] [Decentralized Spatial Reuse Optimization in Wi-Fi: An Internal Regret Minimization Approach](https://arxiv.org/abs/2602.08456)
*Francesc Wilhelmi,Boris Bellalta,Miguel Casasnovas,Aleksandra Kijanka,Miguel Calvo-Fullana*

Main category: cs.NI

TL;DR: 该论文提出了一种基于遗憾匹配的去中心化学习算法，用于优化Wi-Fi网络中的空间复用参数，通过内部遗憾最小化实现相关均衡，无需显式协调即可达到接近最优的全局性能。


<details>
  <summary>Details</summary>
Motivation: 在密集的IEEE 802.11部署中，空间复用技术能提高频谱效率，但去中心化优化传输功率和载波侦听阈值面临挑战：缺乏全局状态信息，多智能体并发操作导致高度非平稳环境，常导致次优配置（如默认使用最大传输功率）。

Method: 提出基于遗憾匹配的去中心化学习算法，采用内部遗憾最小化方法。与标准去中心化"自私"方法不同，内部遗憾最小化引导竞争智能体走向相关均衡，有效模拟协调而无需显式通信。

Result: 通过仿真结果展示了所提方法的优越性，能够达到接近最优的全局性能。结果证实了可扩展去中心化解决方案的潜力，并对新兴集中式解决方案（如多接入点协调）所需的繁重信令开销和架构复杂性提出质疑。

Conclusion: 该研究展示了基于内部遗憾最小化的去中心化学习算法在优化Wi-Fi空间复用参数方面的有效性，为密集网络部署提供了更简单、更可扩展的解决方案，挑战了当前集中式协调方法的必要性。

Abstract: Spatial Reuse (SR) is a cost-effective technique for improving spectral efficiency in dense IEEE 802.11 deployments by enabling simultaneous transmissions. However, the decentralized optimization of SR parameters -- transmission power and Carrier Sensing Threshold (CST) -- across different Basic Service Sets (BSSs) is challenging due to the lack of global state information. In addition, the concurrent operation of multiple agents creates a highly non-stationary environment, often resulting in suboptimal global configurations (e.g., using the maximum possible transmission power by default). To overcome these limitations, this paper introduces a decentralized learning algorithm based on regret-matching, grounded in internal regret minimization. Unlike standard decentralized ``selfish'' approaches that often converge to inefficient Nash Equilibria (NE), internal regret minimization guides competing agents toward Correlated Equilibria (CE), effectively mimicking coordination without explicit communication. Through simulation results, we showcase the superiority of our proposed approach and its ability to reach near-optimal global performance. These results confirm the not-yet-unleashed potential of scalable decentralized solutions and question the need for the heavy signaling overheads and architectural complexity associated with emerging centralized solutions like Multi-Access Point Coordination (MAPC).

</details>


### [445] [From Raw Data to Shared 3D Semantics: Task-Oriented Communication for Multi-Robot Collaboration](https://arxiv.org/abs/2602.08624)
*Ruibo Xue,Jiedan Tan,Fang Liu,Jingwen Tong,Taotao Wang,Shuoyao Wang*

Main category: cs.NI

TL;DR: 提出面向任务的多机器人语义通信框架，通过提取任务相关语义而非原始数据，实现200倍通信压缩，同时提升协作效率。


<details>
  <summary>Details</summary>
Motivation: 多机器人系统在复杂3D环境中通常需要交换原始感知数据，导致通信拥塞和传输延迟，严重影响协作效率。

Method: 采用去中心化的任务导向语义通信框架，每个机器人使用轻量级像素差异网络（PiDiNet）结合几何处理，本地提取紧凑的任务相关语义，仅共享语义更新来构建任务充分的3D场景表示。

Result: 通信开销从858.6Mb大幅降低至4.0Mb（超过200倍压缩增益），同时协作效率提升，任务完成步数从1,054步缩短至281步。

Conclusion: 提出的语义通信框架能显著减少多机器人协作的通信负担，同时提高协作效率，为未知3D环境中的多机器人协作提供了有效解决方案。

Abstract: Multi-robot systems (MRS) rely on exchanging raw sensory data to cooperate in complex three-dimensional (3D) environments. However, this strategy often leads to severe communication congestion and high transmission latency, significantly degrading collaboration efficiency. This paper proposes a decentralized task-oriented semantic communication framework for multi-robot collaboration in unknown 3D environments. Each robot locally extracts compact, task-relevant semantics using a lightweight Pixel Difference Network (PiDiNet) with geometric processing. It shares only these semantic updates to build a task-sufficient 3D scene representation that supports cooperative perception, navigation, and object transport. Our numerical results show that the proposed method exhibits a dramatic reduction in communication overhead from $858.6$ Mb to $4.0$ Mb (over $200\times$ compression gain) while improving collaboration efficiency by shortening task completion from $1,054$ to $281$ steps.

</details>


### [446] [6G-Bench: An Open Benchmark for Semantic Communication and Network-Level Reasoning with Foundation Models in AI-Native 6G Networks](https://arxiv.org/abs/2602.08675)
*Mohamed Amine Ferrag,Abderrahmane Lakas,Merouane Debbah*

Main category: cs.NI

TL;DR: 6G-Bench是一个用于评估6G网络中语义通信和网络级推理能力的开放基准，包含30个决策任务和3,722个经过验证的高难度多选题，用于测试AI模型在6G场景下的推理能力。


<details>
  <summary>Details</summary>
Motivation: 随着6G网络向AI原生方向发展，需要评估AI模型在语义通信和网络级推理方面的能力。目前缺乏专门针对6G场景的标准化评估基准，无法系统衡量不同模型在复杂网络决策任务中的表现。

Method: 从3GPP、IETF、ETSI、ITU-T和O-RAN联盟等标准化组织的活动中提取30个决策任务，分为5个能力类别。从113,475个场景中生成10,000个高难度多选题，使用任务条件提示强制多步定量推理和不确定性下的最坏情况后悔最小化。经过自动过滤和专家人工验证，保留3,722个问题作为高置信度评估集。

Result: 评估了22个基础模型，包括密集和混合专家架构、短长上下文设计（最高100万tokens）、开源和专有系统。确定性单次准确率（pass@1）范围从0.22到0.82，显示语义推理能力存在显著差异。领先模型在意图和政策推理方面达到0.87-0.89的准确率，在推理密集型任务的选择性鲁棒性分析中，pass@5值范围为0.20到0.91。

Conclusion: 6G-Bench为评估6G专用AI模型的语义推理能力提供了标准化基准，揭示了当前模型在复杂网络决策任务中的能力差异，并开源数据集支持开放科学和可重复性研究。

Abstract: This paper introduces 6G-Bench, an open benchmark for evaluating semantic communication and network-level reasoning in AI-native 6G networks. 6G-Bench defines a taxonomy of 30 decision-making tasks (T1--T30) extracted from ongoing 6G and AI-agent standardization activities in 3GPP, IETF, ETSI, ITU-T, and the O-RAN Alliance, and organizes them into five standardization-aligned capability categories. Starting from 113,475 scenarios, we generate a balanced pool of 10,000 very-hard multiple-choice questions using task-conditioned prompts that enforce multi-step quantitative reasoning under uncertainty and worst-case regret minimization over multi-turn horizons. After automated filtering and expert human validation, 3,722 questions are retained as a high-confidence evaluation set, while the full pool is released to support training and fine-tuning of 6G-specialized models. Using 6G-Bench, we evaluate 22 foundation models spanning dense and mixture-of-experts architectures, short- and long-context designs (up to 1M tokens), and both open-weight and proprietary systems. Across models, deterministic single-shot accuracy (pass@1) spans a wide range from 0.22 to 0.82, highlighting substantial variation in semantic reasoning capability. Leading models achieve intent and policy reasoning accuracy in the range 0.87--0.89, while selective robustness analysis on reasoning-intensive tasks shows pass@5 values ranging from 0.20 to 0.91. To support open science and reproducibility, we release the 6G-Bench dataset on GitHub: https://github.com/maferrag/6G-Bench

</details>


### [447] [Rethinking IPv6 Defense: A Unified Edge-Centric Zero-Trust Data-Plane Architecture](https://arxiv.org/abs/2602.08891)
*Walid Aljoby,Mohammed Alzayani,Md. Kamrul Hossain,Khaled A. Harras*

Main category: cs.NI

TL;DR: 提出一个零信任边缘架构，在单一可编程数据平面流水线中统一处理IPv6的欺骗和泛洪攻击，通过先验证身份可信性再检查速率可信性的设计，有效应对IPv6大规模地址空间带来的安全挑战。


<details>
  <summary>Details</summary>
Motivation: IPv6的邻居发现、路由器通告和ICMPv6等协议虽然对正确运行至关重要，但也暴露了广泛的欺骗和泛洪攻击面。同时，IPv6的巨大地址空间破坏了基于IP的声誉系统，使得许多防御措施要么不可扩展，要么范围狭窄。

Method: 提出零信任边缘架构，在单一可编程数据平面流水线中实现四个模块：外部欺骗、内部欺骗、外部泛洪和内部泛洪。关键设计选择是在速率可信性之前强制执行身份可信性，通过无状态每包验证早期过滤欺骗流量。具体P4设计包括前缀跳数限制带、DAD锚定的地址-端口绑定和Count-Min Sketch窗口计数。

Result: 在包含15个场景的系统测试套件中进行了评估，涵盖单向量、双向量和多向量组合。报告了BMv2原型的结果，并在Netronome NFP-4000 SmartNIC上验证了相同的流水线。

Conclusion: 提出的零信任边缘架构能够有效统一处理IPv6的欺骗和泛洪攻击，通过先验证身份再检查速率的设计策略，为IPv6安全提供了可扩展的解决方案，同时讨论了局限性和未来研究方向。

Abstract: IPv6 dependability is increasingly inseparable from IPv6 security: Neighbor Discovery (ND), Router Advertisements (RA), and ICMPv6 are essential for correct operation yet expose a broad attack surface for spoofing and flooding. Meanwhile, IPv6's massive address space breaks per-IP reputation and makes many defenses either non-scalable or narrowly scoped (e.g., only internal threats, only RA abuse, or only volumetric floods). We propose a zero-trust edge architecture implemented in a single programmable data-plane pipeline that unifies four modules: external spoofing, internal spoofing, external flooding, and internal flooding. A key design choice is to enforce identity plausibility before rate plausibility: stateless per-packet validation filters spoofed traffic early so that time-window statistics for flooding operate on credible identities. We outline a concrete P4 design (prefix Hop-Limit bands, DAD-anchored address-port bindings, and Count-Min Sketch windowed counting) and evaluate it across a systematic 15-scenario suite spanning single-, dual-, and multi-vector compositions. We report results from a BMv2 prototype and validate the same pipeline on a Netronome NFP-4000 SmartNIC, and we discuss limitations and open directions.

</details>


### [448] [Zero Trust for Multi-RAT IoT: Trust Boundary Management in Heterogeneous Wireless Network Environments](https://arxiv.org/abs/2602.08989)
*Jonathan Shelby*

Main category: cs.NI

TL;DR: 论文指出多无线接入技术的物联网设备（特别是无人机）在零信任架构采用中面临未受重视的挑战，因为设备在不同无线技术间切换时跨越信任边界，导致认证状态、设备证明和上下文信任信号失效。


<details>
  <summary>Details</summary>
Motivation: 随着多无线接入技术物联网设备（如无人机）的普及，这些设备在LoRaWAN、5G/4G蜂窝网络、Meshtastic网状网络、DJI OcuSync、MAVLink、Wi-Fi和卫星等多种协议间频繁切换，对零信任架构的采用提出了根本性挑战。当前ZTA框架假设相对稳定的网络环境，无法应对移动物联网部署中频繁、动态的无线接入技术切换带来的信任问题。

Method: 论文通过分析多无线接入技术物联网设备（特别是无人机）在不同无线技术间切换时的信任边界跨越问题，识别当前零信任架构框架的局限性。研究关注设备从一种网络信任域进入另一种网络信任域时，认证状态、设备证明和上下文信任信号的失效机制。

Result: 研究发现每次无线接入技术切换都构成信任边界跨越，导致设备离开一个网络信任域进入另一个信任域，这可能使现有的认证状态、设备证明和上下文信任信号失效。当前ZTA框架无法有效处理移动物联网部署中这种频繁、动态的无线技术切换。

Conclusion: 多无线接入技术物联网设备（特别是无人机）的无线技术切换对零信任架构构成了根本性挑战，需要新的框架来应对频繁信任边界跨越带来的认证和信任管理问题。当前ZTA框架需要扩展以支持动态、多无线接入技术的移动物联网环境。

Abstract: The proliferation of Multi-Radio Access Technology, Internet of Things devices, particularly Unmanned Aerial Vehicles operating across LoRaWAN, 5G/4G cellular, Meshtastic mesh, proprietary protocols such as DJI OcuSync, MAVLink telemetry links, Wi-Fi, and satellite, creates a fundamental and hitherto unexamined challenge for Zero Trust Architecture adoption. Each transition between radio access technologies constitutes a trust boundary crossing: the device exits one network trust domain and enters another, potentially invalidating authentication state, device attestation, and contextual trust signals. Current ZTA frameworks assume relatively stable network environments and do not address the trust implications of frequent, dynamic RAT switching in mobile IoT deployments.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [449] [SocialPulse: An Open-Source Subreddit Sensemaking Toolkit](https://arxiv.org/abs/2602.07248)
*Stephanie Birkelbach,Maria Teleki,Peter Carragher,Xiangjue Dong,Nehul Bhatnagar,James Caverlee*

Main category: cs.SI

TL;DR: SocialPulse：一个开源Reddit子版块意义建构工具包，整合话题建模、情感分析、用户活动特征分析和机器人检测，提供交互式分析平台。


<details>
  <summary>Details</summary>
Motivation: 现有的大规模话语分析工具通常是闭源的、难以适配或局限于单一分析视角，无法满足在线社区复杂社会议题讨论的分析需求。

Method: 开发SocialPulse开源工具包，统一整合话题建模、情感分析、用户活动特征分析和机器人检测等多种互补分析方法，构建交互式系统，支持在聚合趋势与细粒度内容之间流畅切换。

Result: 创建了一个可扩展的开放平台，支持端到端的探索性工作流程，使研究人员和从业者能够快速发现大型Reddit数据集中的主题、参与模式和新兴动态。

Conclusion: SocialPulse为在线社区话语的透明、可重复的意义建构提供了实用且可重用的基础，解决了现有工具的局限性。

Abstract: Understanding how online communities discuss and make sense of complex social issues is a central challenge in social media research, yet existing tools for large-scale discourse analysis are often closed-source, difficult to adapt, or limited to single analytical views. We present SocialPulse, an open-source subreddit sensemaking toolkit that unifies multiple complementary analyses -- topic modeling, sentiment analysis, user activity characterization, and bot detection -- within a single interactive system. SocialPulse enables users to fluidly move between aggregate trends and fine-grained content, compare highly active and long-tail contributors, and examine temporal shifts in discourse across subreddits. The demo showcases end-to-end exploratory workflows that allow researchers and practitioners to rapidly surface themes, participation patterns, and emerging dynamics in large Reddit datasets. By offering an extensible and openly available platform, SocialPulse provides a practical and reusable foundation for transparent, reproducible sensemaking of online community discourse.

</details>


### [450] [Graph Domain Adaptation via Homophily-Agnostic Reconstructing Structure](https://arxiv.org/abs/2602.07573)
*Ruiyi Fang,Shuo Wang,Ruizhi Pu,Qiuhao Zeng,Hao Zheng,Ziyan Wang,Jiale Cai,Zhimin Mei,Song Tang,Charles Ling,Boyu Wang*

Main category: cs.SI

TL;DR: 提出一种同质性无关的图域适应方法，能够在不同同质性程度的图之间有效迁移知识，特别在异质性图上表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有图域适应方法通常假设源图和目标图都表现出同质性，当存在异质性时性能下降。而且目标图缺乏标签，无法预先评估其同质性水平。

Method: 采用分治策略：首先分别重构源图和目标图的高度同质性和高度异质性变体，然后在对应的图变体之间分别进行知识对齐。

Result: 在五个基准数据集上的广泛实验表明，该方法具有优越性能，特别是在异质性图上展现出显著优势。

Conclusion: 提出的同质性无关方法能够有效处理不同同质性程度的图域适应问题，解决了现有方法在异质性图上的局限性。

Abstract: Graph Domain Adaptation (GDA) transfers knowledge from labeled source graphs to unlabeled target graphs, addressing the challenge of label scarcity. However, existing GDA methods typically assume that both source and target graphs exhibit homophily, leading existing methods to perform poorly when heterophily is present. Furthermore, the lack of labels in the target graph makes it impossible to assess its homophily level beforehand. To address this challenge, we propose a novel homophily-agnostic approach that effectively transfers knowledge between graphs with varying degrees of homophily. Specifically, we adopt a divide-and-conquer strategy that first separately reconstructs highly homophilic and heterophilic variants of both the source and target graphs, and then performs knowledge alignment separately between corresponding graph variants. Extensive experiments conducted on five benchmark datasets demonstrate the superior performance of our approach, particularly highlighting its substantial advantages on heterophilic graphs.

</details>


### [451] [Towards Reliable Social A/B Testing: Spillover-Contained Clustering with Robust Post-Experiment Analysis](https://arxiv.org/abs/2602.08569)
*Xu Min,Zhaoxu Yang,Kaixuan Tan,Juan Yan,Xunbin Xiong,Zihao Zhu,Kaiyu Zhu,Fenglin Cui,Yang Yang,Sihua Yang,Jianhui Bu*

Main category: cs.SI

TL;DR: 提出一个两阶段的溢出控制实验框架，包含平衡Louvain算法进行网络聚类和CUPAC估计器进行方差缩减，用于解决社交产品A/B测试中的网络干扰问题。


<details>
  <summary>Details</summary>
Motivation: 在线社交产品中的A/B测试面临网络干扰问题：用户互动导致处理效应溢出到对照组，这会偏置因果估计并破坏实验结论。现有方法存在局限：用户级随机化忽略网络结构，而基于聚类的方法通常依赖通用聚类算法，这些算法不是专门为溢出控制设计的，难以在无偏性和统计功效之间取得平衡。

Method: 提出两阶段溢出控制实验框架：1) 实验前阶段：构建社交互动图，引入平衡Louvain算法，在最小化跨簇边数的同时生成稳定、大小平衡的簇，实现可靠的基于簇的随机化；2) 实验后阶段：开发定制化的CUPAC估计器，利用实验前行为协变量减少由簇级分配引起的方差，从而提高统计功效。

Result: 在快手平台的大规模社交分享实验中验证了该方法。结果表明，该方法显著减少了溢出效应，相比传统的用户级设计，能更准确地评估社交策略，建立了一个可靠且可扩展的网络化A/B测试框架。

Conclusion: 该研究提出了一个结合结构溢出控制和稳健统计推断的两阶段实验框架，通过平衡Louvain算法和CUPAC估计器的组合，有效解决了社交产品A/B测试中的网络干扰问题，为大规模网络化实验提供了可靠且可扩展的解决方案。

Abstract: A/B testing is the foundation of decision-making in online platforms, yet social products often suffer from network interference: user interactions cause treatment effects to spill over into the control group. Such spillovers bias causal estimates and undermine experimental conclusions. Existing approaches face key limitations: user-level randomization ignores network structure, while cluster-based methods often rely on general-purpose clustering that is not tailored for spillover containment and has difficulty balancing unbiasedness and statistical power at scale. We propose a spillover-contained experimentation framework with two stages. In the pre-experiment stage, we build social interaction graphs and introduce a Balanced Louvain algorithm that produces stable, size-balanced clusters while minimizing cross-cluster edges, enabling reliable cluster-based randomization. In the post-experiment stage, we develop a tailored CUPAC estimator that leverages pre-experiment behavioral covariates to reduce the variance induced by cluster-level assignment, thereby improving statistical power. Together, these components provide both structural spillover containment and robust statistical inference. We validate our approach through large-scale social sharing experiments on Kuaishou, a platform serving hundreds of millions of users. Results show that our method substantially reduces spillover and yields more accurate assessments of social strategies than traditional user-level designs, establishing a reliable and scalable framework for networked A/B testing.

</details>


### [452] [Friedkin-Johnsen Social Influence Dynamics on Networks: A Boundary-Value Formulation and Influenceability Measures](https://arxiv.org/abs/2602.08704)
*Moses Boudourides*

Main category: cs.SI

TL;DR: 本文对Friedkin-Johnsen社会影响力模型进行严格数学分析，将意见动态建模为网络上的离散边值问题，分析顽固节点和易受影响节点如何共同决定意见演化。


<details>
  <summary>Details</summary>
Motivation: 研究社会网络中意见动态的数学基础，特别是网络结构、顽固节点和易受影响节点如何共同决定意见演化，为理解社会影响力提供理论框架。

Method: 将意见动态建模为网络上的离散边值问题，采用两种方法：适用于异质易感性的通用基于预解式的方法，以及适用于同质易感性的谱方法。

Result: 推导了瞬态和稳态解，建立了收敛速率，推导了敏感性公式，证明了扰动边界，定义了影响力度量并证明了其基本性质，在Zachary空手道俱乐部图上进行了蒙特卡洛模拟。

Conclusion: 该研究为Friedkin-Johnsen模型提供了严格的数学分析框架，揭示了网络结构、节点特性与意见演化之间的定量关系，并提出了新的影响力度量方法。

Abstract: This article presents a rigorous mathematical analysis of the Friedkin--Johnsen model of social influence on networks. We frame the opinion dynamics as a discrete boundary-value problem on a network, emphasizing the role of stubborn (boundary) and susceptible (interior) agents in shaping opinion evolution. This perspective allows for a precise analysis of how network structure, stubborn agents (boundary), and susceptible agents (interior) collectively determine the evolution of opinions. We derive the transient and steady-state solutions using two distinct but related approaches: a general resolvent-based method applicable to agents with heterogeneous susceptibilities, and a spectral method valid for the special case of homogeneous susceptibility. We further establish quantitative convergence rates to the steady state, derive explicit sensitivity formulas with respect to susceptibility parameters, and prove perturbation bounds under changes in the influence matrix. Moreover, we formally define a set of influenceability measures and prove some of their basic properties. Finally, we provide a Monte Carlo illustration on the Zachary karate club graph, showing how the proposed opinion broadcasting centralities and centralizations behave under random susceptibility profiles and how they relate to classical network centralities.

</details>


### [453] [Robust Sequential Learning in Random Order Networks](https://arxiv.org/abs/2602.08953)
*William Guo,Edward Xiong,Jie Gao*

Main category: cs.SI

TL;DR: 研究社交网络中随机顺序渐进真理学习的鲁棒性，提出网络改造算法


<details>
  <summary>Details</summary>
Motivation: 传统顺序学习问题中，社交学习对行动顺序、网络拓扑等微小变化高度脆弱，需要研究能够实现随机顺序渐进真理学习的网络及其鲁棒性

Method: 分析实现随机顺序渐进真理学习的网络特性，提出必要条件，设计多种图构造方法，开发随机多项式时间算法将任意网络改造为具有随机顺序学习能力的网络

Result: 证明实现随机顺序渐进真理学习的网络对有限数量的对抗性修改具有鲁棒性，提出了具有可证明近似保证的最小边/顶点修改算法

Conclusion: 揭示了实现随机顺序学习的网络结构特性，为设计鲁棒的社交网络提供了算法工具

Abstract: In the sequential learning problem, agents in a network attempt to predict a binary ground truth, informed by both a noisy private signal and the predictions of neighboring agents before them. It is well known that social learning in this setting can be highly fragile: small changes to the action ordering, network topology, or even the strength of the agents' private signals can prevent a network from converging to the truth. We study networks that achieve random-order asymptotic truth learning, in which almost all agents learn the ground truth when the decision ordering is selected uniformly at random. We analyze the robustness of these networks, showing that those achieving random-order asymptotic truth learning are resilient to a bounded number of adversarial modifications. We characterize necessary conditions for such networks to succeed in this setting and introduce several graph constructions that learn through different mechanisms. Finally, we present a randomized polynomial-time algorithm that transforms an arbitrary network into one achieving random-order learning using minimal edge or vertex modifications, with provable approximation guarantees. Our results reveal structural properties of networks that achieve random-order learning and provide algorithmic tools for designing robust social networks.

</details>


### [454] [Hyperactive Minority Alter the Stability of Community Notes](https://arxiv.org/abs/2602.08970)
*Jacopo Nudo,Eugenio Nerio Nemmi,Edoardo Loru,Alessandro Mei,Walter Quattrociocchi,Matteo Cinelli*

Main category: cs.SI

TL;DR: 社区笔记系统并未实现去中心化的事实核查，而是将权力集中在少数高度活跃、政治极化的用户手中，导致系统结构不稳定。


<details>
  <summary>Details</summary>
Motivation: 随着平台减少专业事实核查，社区化替代方案（如X平台的社区笔记）被宣传为更透明民主。本研究旨在探究用户社交动态如何影响社区笔记的出现。

Method: 分析2021-2025年完整的社区笔记和评分数据，描述参与模式和政治行为；使用生产环境中使用的开源共识算法实现，通过反事实模拟修改评分者群体来改变笔记显示状态。

Result: 贡献活动高度集中：少数用户占据评分的不成比例份额；这些高活跃度贡献者具有选择性参与且政治极化程度显著高于整体贡献者群体；系统结构不稳定，笔记的出现和可见性常依赖几十个高度活跃用户，其参与度的微小变化会导致显著不同结果。

Conclusion: X平台的社区事实核查并未分散认知权威，而是将其重新配置，将实质性权力集中在少数高度活跃、极化的贡献者手中。

Abstract: As platforms increasingly scale down professional fact-checking, community-based alternatives are promoted as more transparent and democratic. The main substitute being proposed is community-based contextualization, most notably Community Notes on X, where users write annotations and collectively rate their helpfulness under a consensus-oriented algorithm. This shift raises a basic empirical question: to what extent do users' social dynamics affect the emergence of Community Notes? We address this question by characterizing participation and political behavior, using the full public release of notes and ratings (between 2021 and 2025). We show that contribution activity is highly concentrated: a small minority of users accounts for a disproportionate share of ratings. Crucially, these high-activity contributors are not neutral volunteers: they are selective in the content they engage with and substantially more politically polarized than the overall contributor population. We replicate the notes' emergence process by integrating the open-source implementation of the Community Notes consensus algorithm used in production. This enables us to conduct counterfactual simulations that modify the display status of notes by varying the pool of raters. Our results reveal that the system is structurally unstable: the emergence and visibility of notes often depend on the behavior of a few dozen highly active users, and even minor perturbations in their participation can lead to markedly different outcomes. In sum, rather than decentralizing epistemic authority, community-based fact-checking on X reconfigures it, concentrating substantial power in the hands of a small, polarized group of highly active contributors.

</details>
