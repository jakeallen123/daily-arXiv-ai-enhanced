<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 68]
- [cs.CL](#cs.CL) [Total: 35]
- [cs.AI](#cs.AI) [Total: 24]
- [cs.SI](#cs.SI) [Total: 1]
- [cs.NI](#cs.NI) [Total: 6]
- [cs.SE](#cs.SE) [Total: 10]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [TeleWorld: Towards Dynamic Multimodal Synthesis with a 4D World Model](https://arxiv.org/abs/2601.00051)
*Yabo Chen,Yuanzhi Liang,Jiepeng Wang,Tingxi Chen,Junfei Cheng,Zixiao Gu,Yuyang Huang,Zicheng Jiang,Wei Li,Tian Li,Weichen Li,Zuoxin Li,Guangce Liu,Jialun Liu,Junqi Liu,Haoyuan Wang,Qizhen Weng,Xuan'er Wu,Xunzhi Xiang,Xiaoyan Yang,Xin Zhang,Shiwen Zhang,Junyu Zhou,Chengcheng Zhou,Haibin Huang,Chi Zhang,Xuelong Li*

Main category: cs.CV

TL;DR: TeleWorld是一个实时多模态4D世界建模框架，通过生成-重建-引导范式统一视频生成、动态场景重建和长期世界记忆，实现交互式、记忆增强的世界模型。


<details>
  <summary>Details</summary>
Motivation: 当前视频生成模型在实时交互、长时一致性和动态场景持久记忆方面存在局限，阻碍了其发展为实用的世界模型。需要一种能够统一视频生成、动态场景重建和长期记忆的框架。

Method: 提出生成-重建-引导范式：生成视频流连续重建为动态4D时空表示，再引导后续生成以保持一致性。采用自回归扩散视频模型，结合宏观-微观规划（MMPL）减少误差累积，使用分布匹配蒸馏（DMD）实现实时合成。

Result: TeleWorld在静态和动态世界理解、长期一致性和实时生成效率方面表现优异，实现了动态对象建模和静态场景表示在统一4D框架中的无缝集成。

Conclusion: TeleWorld是迈向实用、交互式、记忆增强的世界模型的重要一步，为多模态生成和具身智能提供了计算可访问的系统框架。

Abstract: World models aim to endow AI systems with the ability to represent, generate, and interact with dynamic environments in a coherent and temporally consistent manner. While recent video generation models have demonstrated impressive visual quality, they remain limited in real-time interaction, long-horizon consistency, and persistent memory of dynamic scenes, hindering their evolution into practical world models. In this report, we present TeleWorld, a real-time multimodal 4D world modeling framework that unifies video generation, dynamic scene reconstruction, and long-term world memory within a closed-loop system. TeleWorld introduces a novel generation-reconstruction-guidance paradigm, where generated video streams are continuously reconstructed into a dynamic 4D spatio-temporal representation, which in turn guides subsequent generation to maintain spatial, temporal, and physical consistency. To support long-horizon generation with low latency, we employ an autoregressive diffusion-based video model enhanced with Macro-from-Micro Planning (MMPL)--a hierarchical planning method that reduces error accumulation from frame-level to segment-level-alongside efficient Distribution Matching Distillation (DMD), enabling real-time synthesis under practical computational budgets. Our approach achieves seamless integration of dynamic object modeling and static scene representation within a unified 4D framework, advancing world models toward practical, interactive, and computationally accessible systems. Extensive experiments demonstrate that TeleWorld achieves strong performance in both static and dynamic world understanding, long-term consistency, and real-time generation efficiency, positioning it as a practical step toward interactive, memory-enabled world models for multimodal generation and embodied intelligence.

</details>


### [2] [It's Never Too Late: Noise Optimization for Collapse Recovery in Trained Diffusion Models](https://arxiv.org/abs/2601.00090)
*Anne Harrington,A. Sophia Koepke,Shyamgopal Karthik,Trevor Darrell,Alexei A. Efros*

Main category: cs.CV

TL;DR: 提出通过噪声优化解决文本到图像模型的模式崩溃问题，提高生成多样性


<details>
  <summary>Details</summary>
Motivation: 当前文本到图像模型存在严重的模式崩溃问题，即相同文本提示下生成的图像缺乏多样性。现有方法主要通过引导机制或生成大量候选再筛选来解决，本文探索不同的噪声优化方向。

Method: 采用简单的噪声优化目标来缓解模式崩溃，同时保持基础模型的保真度。分析噪声的频率特性，探索不同频率特性的替代噪声初始化方法以改进优化和搜索。

Result: 实验表明，噪声优化方法在生成质量和多样性方面都取得了优越的结果，能有效提高文本到图像生成的多样性。

Conclusion: 噪声优化是解决文本到图像模型模式崩溃问题的有效方法，通过优化噪声可以显著提高生成多样性而不损害模型保真度。

Abstract: Contemporary text-to-image models exhibit a surprising degree of mode collapse, as can be seen when sampling several images given the same text prompt. While previous work has attempted to address this issue by steering the model using guidance mechanisms, or by generating a large pool of candidates and refining them, in this work we take a different direction and aim for diversity in generations via noise optimization. Specifically, we show that a simple noise optimization objective can mitigate mode collapse while preserving the fidelity of the base model. We also analyze the frequency characteristics of the noise and show that alternative noise initializations with different frequency profiles can improve both optimization and search. Our experiments demonstrate that noise optimization yields superior results in terms of generation quality and variety.

</details>


### [3] [Spatial4D-Bench: A Versatile 4D Spatial Intelligence Benchmark](https://arxiv.org/abs/2601.00092)
*Pan Wang,Yang Liu,Guile Wu,Eduardo R. Corral-Soto,Chengjie Huang,Binbin Xu,Dongfeng Bai,Xu Yan,Yuan Ren,Xingxin Chen,Yizhe Wu,Tao Huang,Wenjun Wan,Xin Wu,Pei Zhou,Xuyang Dai,Kangbo Lv,Hongbo Zhang,Yosef Fried,Aixue Ye,Bailan Feng,Zhenyu Chen,Zhen Li,Yingcong Chen,Yiyi Liao,Bingbing Liu*

Main category: cs.CV

TL;DR: Spatial4D-Bench是一个用于评估多模态大语言模型4D空间智能的大规模基准测试，包含约40,000个问答对，覆盖18个任务和6个认知类别。


<details>
  <summary>Details</summary>
Motivation: 人类天生具备4D空间智能（感知物体随时间变化的能力），但当前多模态大语言模型在这方面的能力尚不清楚。现有空间智能基准测试规模小、多样性有限，需要更全面的评估工具。

Method: 构建Spatial4D-Bench基准测试，包含约40,000个问答对，覆盖18个明确定义的任务，系统性地组织为6个认知类别：物体理解、场景理解、空间关系理解、时空关系理解、空间推理和时空推理。

Result: 评估了各种开源和专有的最先进MLLMs，发现它们在多种4D空间推理方面存在显著局限性，如路径规划、动作识别和物理合理性推理等。

Conclusion: Spatial4D-Bench为评估MLLMs的空间认知能力提供了结构化、全面的基准测试，揭示了当前模型的局限性，希望该基准能促进开发具备人类水平4D空间智能的MLLMs。

Abstract: 4D spatial intelligence involves perceiving and processing how objects move or change over time. Humans naturally possess 4D spatial intelligence, supporting a broad spectrum of spatial reasoning abilities. To what extent can Multimodal Large Language Models (MLLMs) achieve human-level 4D spatial intelligence? In this work, we present Spatial4D-Bench, a versatile 4D spatial intelligence benchmark designed to comprehensively assess the 4D spatial reasoning abilities of MLLMs. Unlike existing spatial intelligence benchmarks that are often small-scale or limited in diversity, Spatial4D-Bench provides a large-scale, multi-task evaluation benchmark consisting of ~40,000 question-answer pairs covering 18 well-defined tasks. We systematically organize these tasks into six cognitive categories: object understanding, scene understanding, spatial relationship understanding, spatiotemporal relationship understanding, spatial reasoning and spatiotemporal reasoning. Spatial4D-Bench thereby offers a structured and comprehensive benchmark for evaluating the spatial cognition abilities of MLLMs, covering a broad spectrum of tasks that parallel the versatility of human spatial intelligence. We benchmark various state-of-the-art open-source and proprietary MLLMs on Spatial4D-Bench and reveal their substantial limitations in a wide variety of 4D spatial reasoning aspects, such as route plan, action recognition, and physical plausibility reasoning. We hope that the findings provided in this work offer valuable insights to the community and that our benchmark can facilitate the development of more capable MLLMs toward human-level 4D spatial intelligence. More resources can be found on our project page.

</details>


### [4] [A Spatially Masked Adaptive Gated Network for multimodal post-flood water extent mapping using SAR and incomplete multispectral data](https://arxiv.org/abs/2601.00123)
*Hyunho Lee,Wenwen Li*

Main category: cs.CV

TL;DR: 提出SMAGNet模型，通过自适应融合SAR和多光谱影像数据，提升洪水淹没范围制图精度，增强对缺失数据的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 洪水期间及时准确的水域制图对灾害管理至关重要。虽然SAR数据是主要数据源，但多光谱影像（MSI）能提供互补信息。然而，在洪水响应阶段，MSI数据可能部分缺失，如何自适应地融合这些不完整的多模态数据仍待探索。

Method: 提出SMAGNet（空间掩码自适应门控网络），以SAR数据为主要输入，通过特征融合机制自适应集成MSI数据。模型能处理不同可用程度的MSI数据，包括完全缺失的情况。

Result: 在C2S-MS Floods数据集上，SMAGNet在不同MSI数据可用性水平下均优于其他多模态深度学习模型。即使MSI数据完全缺失，其性能仍与仅使用SAR数据训练的U-Net模型相当。

Conclusion: SMAGNet增强了模型对缺失数据的鲁棒性，提高了多模态深度学习在实际洪水管理场景中的适用性，为灾害响应提供了更可靠的洪水淹没范围制图工具。

Abstract: Mapping water extent during a flood event is essential for effective disaster management throughout all phases: mitigation, preparedness, response, and recovery. In particular, during the response stage, when timely and accurate information is important, Synthetic Aperture Radar (SAR) data are primarily employed to produce water extent maps. Recently, leveraging the complementary characteristics of SAR and MSI data through a multimodal approach has emerged as a promising strategy for advancing water extent mapping using deep learning models. This approach is particularly beneficial when timely post-flood observations, acquired during or shortly after the flood peak, are limited, as it enables the use of all available imagery for more accurate post-flood water extent mapping. However, the adaptive integration of partially available MSI data into the SAR-based post-flood water extent mapping process remains underexplored. To bridge this research gap, we propose the Spatially Masked Adaptive Gated Network (SMAGNet), a multimodal deep learning model that utilizes SAR data as the primary input for post-flood water extent mapping and integrates complementary MSI data through feature fusion. In experiments on the C2S-MS Floods dataset, SMAGNet consistently outperformed other multimodal deep learning models in prediction performance across varying levels of MSI data availability. Furthermore, we found that even when MSI data were completely missing, the performance of SMAGNet remained statistically comparable to that of a U-Net model trained solely on SAR data. These findings indicate that SMAGNet enhances the model robustness to missing data as well as the applicability of multimodal deep learning in real-world flood management scenarios.

</details>


### [5] [Compressed Map Priors for 3D Perception](https://arxiv.org/abs/2601.00139)
*Brady Zhou,Philipp Krähenbühl*

Main category: cs.CV

TL;DR: CMP框架通过压缩历史遍历数据学习空间先验，仅需32KB/km²存储，可无缝集成到3D感知系统，在nuScenes数据集上显著提升3D目标检测性能


<details>
  <summary>Details</summary>
Motivation: 当前自动驾驶视觉系统通常将每个位置视为首次访问，忽略了历史遍历数据中蕴含的宝贵空间先验知识。人类驾驶员会利用历史经验，而现有系统缺乏这种能力。

Method: 提出压缩地图先验（CMP）框架，从历史遍历数据中学习空间先验。使用二值化哈希图存储，存储密度仅需32KB/km²，比密集存储减少20倍。该框架可轻松集成到主流3D感知系统中，计算开销极小。

Result: 在nuScenes数据集上，CMP框架显著且一致地提升了多种架构的3D目标检测性能，证明了利用历史空间先验的有效性。

Conclusion: 压缩地图先验是一种简单有效的框架，能够利用历史遍历数据中的空间先验知识，显著提升自动驾驶3D感知系统的性能，且存储和计算成本极低。

Abstract: Human drivers rarely travel where no person has gone before. After all, thousands of drivers use busy city roads every day, and only one can claim to be the first. The same holds for autonomous computer vision systems. The vast majority of the deployment area of an autonomous vision system will have been visited before. Yet, most autonomous vehicle vision systems act as if they are encountering each location for the first time. In this work, we present Compressed Map Priors (CMP), a simple but effective framework to learn spatial priors from historic traversals. The map priors use a binarized hashmap that requires only $32\text{KB}/\text{km}^2$, a $20\times$ reduction compared to the dense storage. Compressed Map Priors easily integrate into leading 3D perception systems at little to no extra computational costs, and lead to a significant and consistent improvement in 3D object detection on the nuScenes dataset across several architectures.

</details>


### [6] [Attention to Detail: Global-Local Attention for High-Resolution AI-Generated Image Detection](https://arxiv.org/abs/2601.00141)
*Lawrence Han*

Main category: cs.CV

TL;DR: GLASS是一种用于AI生成图像检测的新架构，通过结合全局缩放视图和多个原始分辨率局部裁剪，利用注意力机制聚合信息，在多种骨干网络上提升检测性能。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI快速发展，AI生成图像越来越逼真和高分辨率。现有检测架构通常先对图像进行下采样，这可能导致细粒度细节丢失，影响检测准确性。

Method: 提出GLASS架构：结合全局缩放视图和多个随机采样的局部裁剪。局部裁剪通过空间分层采样高效选择原始分辨率区域，并使用基于注意力的评分机制进行聚合。该架构可集成到各种视觉模型中，处理任意尺寸图像。

Result: 在Vision Transformer、ResNet和ConvNeXt等骨干网络上进行实验，GLASS在可行的计算约束下实现了比标准迁移学习更高的预测性能。

Conclusion: GLASS通过同时利用图像的全局和局部信息，有效提升了AI生成图像检测的准确性，为高分辨率图像检测提供了有效解决方案。

Abstract: The rapid development of generative AI has made AI-generated images increasingly realistic and high-resolution. Most AI-generated image detection architectures typically downsample images before inputting them into models, risking the loss of fine-grained details. This paper presents GLASS (Global-Local Attention with Stratified Sampling), an architecture that combines a globally resized view with multiple randomly sampled local crops. These crops are original-resolution regions efficiently selected through spatially stratified sampling and aggregated using attention-based scoring. GLASS can be integrated into vision models to leverage both global and local information in images of any size. Vision Transformer, ResNet, and ConvNeXt models are used as backbones, and experiments show that GLASS outperforms standard transfer learning by achieving higher predictive performance within feasible computational constraints.

</details>


### [7] [FCMBench: A Comprehensive Financial Credit Multimodal Benchmark for Real-world Applications](https://arxiv.org/abs/2601.00150)
*Yehui Yang,Dalu Yang,Wenshuo Zhou,Fangxin Shang,Yifan Liu,Jie Ren,Haojun Fei,Qing Yang,Tao Chen*

Main category: cs.CV

TL;DR: FCMBench-V1.0是一个金融信贷多模态基准测试，包含4,043张隐私合规图像和8,446个QA样本，用于评估视觉语言模型在信贷风险评估和文档审查中的表现。


<details>
  <summary>Details</summary>
Motivation: 随着多模态AI在信贷风险评估和文档审查中的广泛应用，迫切需要反映金融信贷特定文档和工作流程、包含信贷特定理解与真实世界鲁棒性、同时保持隐私合规性的领域特定基准测试。

Method: 通过封闭式合成-捕获流程构建样本：手动合成带有虚拟内容的文档模板，并在内部捕获场景感知图像。评估框架包含感知、推理和鲁棒性三个维度，包括3个基础感知任务、4个信贷特定推理任务和10种真实世界采集伪影类型。

Result: 在14家顶级AI公司和研究机构的23个最先进视觉语言模型上进行广泛实验。Gemini 3 Pro作为商业模型获得最佳F1分数(64.61%)，Qwen3-VL-235B作为开源基线获得最佳分数(57.27%)，而金融信贷特定模型Qfin-VL-Instruct获得最高总体分数(64.92%)。鲁棒性评估显示即使表现最佳的模型在采集伪影下也会出现明显性能下降。

Conclusion: FCMBench能有效区分现代视觉语言模型的性能差异和鲁棒性，为金融信贷领域的多模态AI评估提供了重要基准，同时解决了隐私合规和真实性的平衡问题。

Abstract: As multimodal AI becomes widely used for credit risk assessment and document review, a domain-specific benchmark is urgently needed that (1) reflects documents and workflows specific to financial credit applications, (2) includes credit-specific understanding and real-world robustness, and (3) preserves privacy compliance without sacrificing practical utility. Here, we introduce FCMBench-V1.0 -- a large-scale financial credit multimodal benchmark for real-world applications, covering 18 core certificate types, with 4,043 privacy-compliant images and 8,446 QA samples. The FCMBench evaluation framework consists of three dimensions: Perception, Reasoning, and Robustness, including 3 foundational perception tasks, 4 credit-specific reasoning tasks that require decision-oriented understanding of visual evidence, and 10 real-world acquisition artifact types for robustness stress testing. To reconcile compliance with realism, we construct all samples via a closed synthesis-capture pipeline: we manually synthesize document templates with virtual content and capture scenario-aware images in-house. This design also mitigates pre-training data leakage by avoiding web-sourced or publicly released images. FCMBench can effectively discriminate performance disparities and robustness across modern vision-language models. Extensive experiments were conducted on 23 state-of-the-art vision-language models (VLMs) from 14 top AI companies and research institutes. Among them, Gemini 3 Pro achieves the best F1(\%) score as a commercial model (64.61), Qwen3-VL-235B achieves the best score as an open-source baseline (57.27), and our financial credit-specific model, Qfin-VL-Instruct, achieves the top overall score (64.92). Robustness evaluations show that even top-performing models suffer noticeable performance drops under acquisition artifacts.

</details>


### [8] [Focal-RegionFace: Generating Fine-Grained Multi-attribute Descriptions for Arbitrarily Selected Face Focal Regions](https://arxiv.org/abs/2601.00156)
*Kaiwen Zheng,Junchen Fu,Songpei Xu,Yaoqing He,Joemon M. Jose,Han Hu,Xuri Ge*

Main category: cs.CV

TL;DR: 提出FaceFocalDesc问题：为任意选定面部区域生成多属性自然语言描述（包含动作单元、情绪状态和年龄估计），并构建相应数据集和基于Qwen2.5-VL的Focal-RegionFace模型，通过渐进式微调实现细粒度面部分析。


<details>
  <summary>Details</summary>
Motivation: 当前面部分析研究缺乏对任意选定面部区域的多属性自然语言描述生成与识别能力，系统聚焦于个体面部区域的能力能带来更好的理解和控制。

Method: 1) 构建新的多属性描述数据集，包含丰富的区域级标注和自然语言描述；2) 基于Qwen2.5-VL提出Focal-RegionFace模型，通过多个渐进式微调阶段逐步细化对局部面部特征的关注。

Result: Focal-RegionFace在新基准测试中取得了最佳性能，在传统指标和新提出的指标上都表现出色，验证了其在细粒度多属性面部区域聚焦分析场景中的有效性和多功能性。

Conclusion: 该研究成功解决了面部分析中未充分探索的FaceFocalDesc问题，通过构建数据集和开发Focal-RegionFace模型，实现了对任意选定面部区域的细粒度多属性分析，为面部状态分析提供了新的视角和方法。

Abstract: In this paper, we introduce an underexplored problem in facial analysis: generating and recognizing multi-attribute natural language descriptions, containing facial action units (AUs), emotional states, and age estimation, for arbitrarily selected face regions (termed FaceFocalDesc). We argue that the system's ability to focus on individual facial areas leads to better understanding and control. To achieve this capability, we construct a new multi-attribute description dataset for arbitrarily selected face regions, providing rich region-level annotations and natural language descriptions. Further, we propose a fine-tuned vision-language model based on Qwen2.5-VL, called Focal-RegionFace for facial state analysis, which incrementally refines its focus on localized facial features through multiple progressively fine-tuning stages, resulting in interpretable age estimation, FAU and emotion detection. Experimental results show that Focal-RegionFace achieves the best performance on the new benchmark in terms of traditional and widely used metrics, as well as new proposed metrics. This fully verifies its effectiveness and versatility in fine-grained multi-attribute face region-focal analysis scenarios.

</details>


### [9] [DichroGAN: Towards Restoration of in-air Colours of Seafloor from Satellite Imagery](https://arxiv.org/abs/2601.00194)
*Salma Gonzalez-Sabbagh,Antonio Robles-Kelly,Shang Gao*

Main category: cs.CV

TL;DR: DichroGAN是一种条件生成对抗网络，通过两步训练从卫星图像恢复海底的空中颜色，消除水下光衰减影响。


<details>
  <summary>Details</summary>
Motivation: 由于光在水柱中随深度呈指数衰减，从卫星图像恢复海底的空中颜色是一个具有挑战性的任务。传统方法难以准确消除水下光吸收和散射的影响。

Method: DichroGAN采用条件生成对抗网络架构，分两步训练：1）两个生成器利用高光谱图像立方体估计漫反射和镜面反射，获得大气场景辐射；2）第三个生成器处理场景辐射的谱带特征，第四个生成器估计水下光传输。这些生成器基于水下图像形成方程协同工作，消除光吸收和散射效应。

Result: 在PRISMA卫星图像数据集上的广泛实验表明，DichroGAN在卫星和水下数据集上都取得了与最先进水下恢复技术相竞争的性能。

Conclusion: DichroGAN通过创新的两步训练策略和条件生成对抗网络架构，能够有效恢复海底的空中颜色，为卫星遥感中的水下图像恢复提供了有前景的解决方案。

Abstract: Recovering the in-air colours of seafloor from satellite imagery is a challenging task due to the exponential attenuation of light with depth in the water column. In this study, we present DichroGAN, a conditional generative adversarial network (cGAN) designed for this purpose. DichroGAN employs a two-steps simultaneous training: first, two generators utilise a hyperspectral image cube to estimate diffuse and specular reflections, thereby obtaining atmospheric scene radiance. Next, a third generator receives as input the generated scene radiance containing the features of each spectral band, while a fourth generator estimates the underwater light transmission. These generators work together to remove the effects of light absorption and scattering, restoring the in-air colours of seafloor based on the underwater image formation equation. DichroGAN is trained on a compact dataset derived from PRISMA satellite imagery, comprising RGB images paired with their corresponding spectral bands and masks. Extensive experiments on both satellite and underwater datasets demonstrate that DichroGAN achieves competitive performance compared to state-of-the-art underwater restoration techniques.

</details>


### [10] [MorphAny3D: Unleashing the Power of Structured Latent in 3D Morphing](https://arxiv.org/abs/2601.00204)
*Xiaokun Sun,Zeyu Cai,Hao Tang,Ying Tai,Jian Yang,Zhenyu Zhang*

Main category: cs.CV

TL;DR: MorphAny3D：基于结构化潜在表示的免训练3D变形框架，通过注意力机制融合源和目标特征，实现高质量跨类别3D变形。


<details>
  <summary>Details</summary>
Motivation: 3D变形面临语义一致性和时间平滑性的挑战，尤其在跨类别变形中更为困难。现有方法难以生成高质量、连贯的变形序列。

Method: 提出免训练框架MorphAny3D，利用结构化潜在(SLAT)表示。核心是变形交叉注意力(MCA)融合源和目标特征保证结构一致性，时间融合自注意力(TFSA)增强时间连贯性，配合方向校正策略解决姿态模糊问题。

Result: 实验表明该方法能生成最先进的变形序列，即使在挑战性的跨类别情况下也能保持高质量。支持解耦变形和3D风格迁移等高级应用，并可推广到其他基于SLAT的生成模型。

Conclusion: MorphAny3D通过智能融合SLAT特征的注意力机制，实现了高质量、语义一致且时间平滑的3D变形，为跨类别3D变形提供了有效的解决方案。

Abstract: 3D morphing remains challenging due to the difficulty of generating semantically consistent and temporally smooth deformations, especially across categories. We present MorphAny3D, a training-free framework that leverages Structured Latent (SLAT) representations for high-quality 3D morphing. Our key insight is that intelligently blending source and target SLAT features within the attention mechanisms of 3D generators naturally produces plausible morphing sequences. To this end, we introduce Morphing Cross-Attention (MCA), which fuses source and target information for structural coherence, and Temporal-Fused Self-Attention (TFSA), which enhances temporal consistency by incorporating features from preceding frames. An orientation correction strategy further mitigates the pose ambiguity within the morphing steps. Extensive experiments show that our method generates state-of-the-art morphing sequences, even for challenging cross-category cases. MorphAny3D further supports advanced applications such as decoupled morphing and 3D style transfer, and can be generalized to other SLAT-based generative models. Project page: https://xiaokunsun.github.io/MorphAny3D.github.io/.

</details>


### [11] [CropNeRF: A Neural Radiance Field-Based Framework for Crop Counting](https://arxiv.org/abs/2601.00207)
*Md Ahmed Al Muzaddid,William J. Beksi*

Main category: cs.CV

TL;DR: 提出基于多视角图像和神经辐射场（NeRF）的3D实例分割框架，用于农业场景中作物的精确计数，解决了遮挡和聚类作物难以区分的问题。


<details>
  <summary>Details</summary>
Motivation: 在户外农田环境中，部分遮挡和从单一视角难以区分聚类作物的问题，给基于图像的分割方法带来了巨大挑战，而精确的作物计数对农业管理和干预策略至关重要。

Method: 利用多视角拍摄的2D图像，结合神经辐射场（NeRF）进行视图合成，引入作物可见性和掩码一致性评分，结合NeRF模型的3D信息，实现3D作物实例分割和精确计数。

Result: 在棉花铃、苹果和梨三个农业数据集上验证了框架的有效性，尽管作物颜色、形状和大小差异很大，但计数性能保持稳定，且优于现有最先进方法。

Conclusion: 该框架通过3D实例分割实现了高精度的作物计数，消除了对作物特定参数调整的依赖，并贡献了棉花植物数据集以促进该领域的进一步研究。

Abstract: Rigorous crop counting is crucial for effective agricultural management and informed intervention strategies. However, in outdoor field environments, partial occlusions combined with inherent ambiguity in distinguishing clustered crops from individual viewpoints poses an immense challenge for image-based segmentation methods. To address these problems, we introduce a novel crop counting framework designed for exact enumeration via 3D instance segmentation. Our approach utilizes 2D images captured from multiple viewpoints and associates independent instance masks for neural radiance field (NeRF) view synthesis. We introduce crop visibility and mask consistency scores, which are incorporated alongside 3D information from a NeRF model. This results in an effective segmentation of crop instances in 3D and highly-accurate crop counts. Furthermore, our method eliminates the dependence on crop-specific parameter tuning. We validate our framework on three agricultural datasets consisting of cotton bolls, apples, and pears, and demonstrate consistent counting performance despite major variations in crop color, shape, and size. A comparative analysis against the state of the art highlights superior performance on crop counting tasks. Lastly, we contribute a cotton plant dataset to advance further research on this topic.

</details>


### [12] [IntraStyler: Exemplar-based Style Synthesis for Cross-modality Domain Adaptation](https://arxiv.org/abs/2601.00212)
*Han Liu,Yubo Fan,Hao Li,Dewei Hu,Daniel Moyer,Zhoubing Xu,Benoit M. Dawant,Ipek Oguz*

Main category: cs.CV

TL;DR: IntraStyler：一种基于示例的风格合成方法，无需先验知识即可捕捉多样化的域内风格，用于增强跨模态域适应的数据多样性


<details>
  <summary>Details</summary>
Motivation: 现有无监督域适应方法主要关注源域和目标域之间的域偏移，而域内变异性研究不足。传统方法需要预先指定域内变化进行风格合成，这在实践中不切实际。

Method: 提出IntraStyler方法，使用示例图像指导风格合成，使输出风格与示例风格匹配。引入基于对比学习的风格编码器来提取纯风格特征，无需先验知识即可学习多样化域内风格。

Result: 在CrossMoDA 2023数据集上的实验表明，该方法在可控风格合成方面有效，多样化的合成数据对下游分割任务有益。

Conclusion: IntraStyler能够无需先验知识捕捉多样化的域内风格，增强跨模态域适应的数据多样性，提升下游分割性能。

Abstract: Image-level domain alignment is the de facto approach for unsupervised domain adaptation, where unpaired image translation is used to minimize the domain gap. Prior studies mainly focus on the domain shift between the source and target domains, whereas the intra-domain variability remains under-explored. To address the latter, an effective strategy is to diversify the styles of the synthetic target domain data during image translation. However, previous methods typically require intra-domain variations to be pre-specified for style synthesis, which may be impractical. In this paper, we propose an exemplar-based style synthesis method named IntraStyler, which can capture diverse intra-domain styles without any prior knowledge. Specifically, IntraStyler uses an exemplar image to guide the style synthesis such that the output style matches the exemplar style. To extract the style-only features, we introduce a style encoder to learn styles discriminatively based on contrastive learning. We evaluate the proposed method on the largest public dataset for cross-modality domain adaptation, CrossMoDA 2023. Our experiments show the efficacy of our method in controllable style synthesis and the benefits of diverse synthetic data for downstream segmentation. Code is available at https://github.com/han-liu/IntraStyler.

</details>


### [13] [From Sight to Insight: Improving Visual Reasoning Capabilities of Multimodal Models via Reinforcement Learning](https://arxiv.org/abs/2601.00215)
*Omar Sharif,Eftekhar Hossain,Patrick Ng*

Main category: cs.CV

TL;DR: 使用强化学习提升多模态大语言模型的视觉推理能力，通过奖励函数激励模型整合视觉信息进行更长的结构化推理，在Qwen-2.5-VL-7B上实现5.56%的性能提升。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型生成的推理链缺乏视觉信息的整合，限制了其在需要准确视觉感知的任务（如视觉谜题）上的表现。研究表明视觉感知是这类任务的关键瓶颈，将图像转换为文本描述能显著提升性能。

Method: 采用奖励驱动的强化学习方法，设计了六个针对不同推理方面的奖励函数（包括图像理解、思考步骤和答案准确性）。使用组相对策略优化（GRPO）来明确激励更长的结构化推理，并防止视觉信息被绕过。

Result: 在Qwen-2.5-VL-7B模型上实现了5.56%的性能提升，在领域内和领域外设置下都取得了稳定的增益。实验表明Claude 3.5和Claude 3.7通过图像转文本描述分别获得了26.7%和23.6%的性能提升。

Conclusion: 强化学习是解锁开源多模态大语言模型长视觉推理能力的有效机制，无需昂贵的监督数据。通过精心设计的奖励函数和GRPO优化，能够显著提升模型在需要视觉感知任务上的表现。

Abstract: Reinforcement learning (RL) has emerged as a promising approach for eliciting reasoning chains before generating final answers. However, multimodal large language models (MLLMs) generate reasoning that lacks integration of visual information. This limits their ability to solve problems that demand accurate visual perception, such as visual puzzles. We show that visual perception is the key bottleneck in such tasks: converting images into textual descriptions significantly improves performance, yielding gains of 26.7% for Claude 3.5 and 23.6% for Claude 3.7.
  To address this, we investigate reward-driven RL as a mechanism to unlock long visual reasoning in open-source MLLMs without requiring costly supervision. We design and evaluate six reward functions targeting different reasoning aspects, including image understanding, thinking steps, and answer accuracy. Using group relative policy optimization (GRPO), our approach explicitly incentivizes longer, structured reasoning and mitigates bypassing of visual information. Experiments on Qwen-2.5-VL-7B achieve 5.56% improvements over the base model, with consistent gains across both in-domain and out-of-domain settings.

</details>


### [14] [LooC: Effective Low-Dimensional Codebook for Compositional Vector Quantization](https://arxiv.org/abs/2601.00222)
*Jie Li,Kwan-Yee K. Wong,Kai Han*

Main category: cs.CV

TL;DR: LooC是一种新的向量量化方法，通过低维码本的组合方式实现更紧凑高效的向量量化，在保持高性能的同时显著减小码本规模。


<details>
  <summary>Details</summary>
Motivation: 随着数据和模型复杂度的增加，需要更高容量但更紧凑的向量量化方法。现有方法在码本容量和紧凑性之间存在冲突。

Method: 1. 引入参数高效的码本，将码向量视为特征向量的低维组合单元进行组合；2. 采用参数无关的外推-插值机制增强特征平滑；3. 作为即插即用模块适用于不同下游任务。

Result: 在不同任务、数据集和架构上的广泛评估表明，LooC优于现有VQ方法，在显著减小码本规模的同时实现了最先进的性能。

Conclusion: LooC成功解决了向量量化中码本容量与紧凑性的冲突，通过低维组合码本和特征增强机制实现了高效、高性能的向量量化。

Abstract: Vector quantization (VQ) is a prevalent and fundamental technique that discretizes continuous feature vectors by approximating them using a codebook. As the diversity and complexity of data and models continue to increase, there is an urgent need for high-capacity, yet more compact VQ methods. This paper aims to reconcile this conflict by presenting a new approach called LooC, which utilizes an effective Low-dimensional codebook for Compositional vector quantization. Firstly, LooC introduces a parameter-efficient codebook by reframing the relationship between codevectors and feature vectors, significantly expanding its solution space. Instead of individually matching codevectors with feature vectors, LooC treats them as lower-dimensional compositional units within feature vectors and combines them, resulting in a more compact codebook with improved performance. Secondly, LooC incorporates a parameter-free extrapolation-by-interpolation mechanism to enhance and smooth features during the VQ process, which allows for better preservation of details and fidelity in feature approximation. The design of LooC leads to full codebook usage, effectively utilizing the compact codebook while avoiding the problem of collapse. Thirdly, LooC can serve as a plug-and-play module for existing methods for different downstream tasks based on VQ. Finally, extensive evaluations on different tasks, datasets, and architectures demonstrate that LooC outperforms existing VQ methods, achieving state-of-the-art performance with a significantly smaller codebook.

</details>


### [15] [Towards Syn-to-Real IQA: A Novel Perspective on Reshaping Synthetic Data Distributions](https://arxiv.org/abs/2601.00225)
*Aobo Li,Jinjian Wu,Yongxu Liu,Leida Li,Weisheng Dong*

Main category: cs.CV

TL;DR: 提出SynDR-IQA框架，通过重塑合成数据分布来解决BIQA模型泛化能力不足的问题，采用分布感知的内容上采样和密度感知的聚类下采样策略。


<details>
  <summary>Details</summary>
Motivation: 当前基于深度学习的盲图像质量评估面临标注数据稀缺问题，合成数据虽为解决方案但训练出的模型泛化能力有限。研究发现合成数据集学习到的特征呈现离散聚类模式（高质量图像围绕参考图像聚类，低质量图像按失真类型聚类），这阻碍了回归性能。

Method: 提出SynDR-IQA框架：1) 分布感知的多样化内容上采样：增强视觉多样性同时保持内容分布；2) 密度感知的冗余聚类下采样：通过减少密集聚类区域的样本密度来平衡样本分布。基于样本多样性和冗余性对泛化误差影响的理论推导。

Result: 在三种跨数据集设置（合成到真实、合成到算法、合成到合成）上进行了广泛实验，证明了方法的有效性。

Conclusion: 通过重塑合成数据分布可以显著提升BIQA模型的泛化能力，SynDR-IQA为解决合成数据训练中的泛化问题提供了有效框架。

Abstract: Blind Image Quality Assessment (BIQA) has advanced significantly through deep learning, but the scarcity of large-scale labeled datasets remains a challenge. While synthetic data offers a promising solution, models trained on existing synthetic datasets often show limited generalization ability. In this work, we make a key observation that representations learned from synthetic datasets often exhibit a discrete and clustered pattern that hinders regression performance: features of high-quality images cluster around reference images, while those of low-quality images cluster based on distortion types. Our analysis reveals that this issue stems from the distribution of synthetic data rather than model architecture. Consequently, we introduce a novel framework SynDR-IQA, which reshapes synthetic data distribution to enhance BIQA generalization. Based on theoretical derivations of sample diversity and redundancy's impact on generalization error, SynDR-IQA employs two strategies: distribution-aware diverse content upsampling, which enhances visual diversity while preserving content distribution, and density-aware redundant cluster downsampling, which balances samples by reducing the density of densely clustered areas. Extensive experiments across three cross-dataset settings (synthetic-to-authentic, synthetic-to-algorithmic, and synthetic-to-synthetic) demonstrate the effectiveness of our method. The code is available at https://github.com/Li-aobo/SynDR-IQA.

</details>


### [16] [Application Research of a Deep Learning Model Integrating CycleGAN and YOLO in PCB Infrared Defect Detection](https://arxiv.org/abs/2601.00237)
*Chao Yang,Haoyuan Zheng,Yue Ma*

Main category: cs.CV

TL;DR: 提出跨模态数据增强框架，结合CycleGAN和YOLOv8，通过可见光PCB图像生成伪红外数据，解决红外数据稀缺问题，提升PCB缺陷检测性能。


<details>
  <summary>Details</summary>
Motivation: 红外（IR）数据稀缺是PCB缺陷检测的关键瓶颈，传统方法依赖配对监督数据，但实际中红外数据获取困难且成本高昂。

Method: 使用CycleGAN进行无配对图像转换，将丰富的可见光PCB图像映射到红外域，生成高保真伪红外样本；然后构建异构训练策略，融合生成的伪红外数据和有限的真实红外样本，训练轻量级YOLOv8检测器。

Result: 该方法在低数据条件下有效增强特征学习，增强后的检测器显著优于仅使用有限真实数据训练的模型，性能接近完全监督训练的基准，证明了伪红外合成作为工业检测的鲁棒增强策略的有效性。

Conclusion: 提出的跨模态数据增强框架通过合成伪红外数据成功解决了红外数据稀缺问题，为工业检测中的小样本学习提供了有效解决方案，具有实际应用价值。

Abstract: This paper addresses the critical bottleneck of infrared (IR) data scarcity in Printed Circuit Board (PCB) defect detection by proposing a cross-modal data augmentation framework integrating CycleGAN and YOLOv8. Unlike conventional methods relying on paired supervision, we leverage CycleGAN to perform unpaired image-to-image translation, mapping abundant visible-light PCB images into the infrared domain. This generative process synthesizes high-fidelity pseudo-IR samples that preserve the structural semantics of defects while accurately simulating thermal distribution patterns. Subsequently, we construct a heterogeneous training strategy that fuses generated pseudo-IR data with limited real IR samples to train a lightweight YOLOv8 detector. Experimental results demonstrate that this method effectively enhances feature learning under low-data conditions. The augmented detector significantly outperforms models trained on limited real data alone and approaches the performance benchmarks of fully supervised training, proving the efficacy of pseudo-IR synthesis as a robust augmentation strategy for industrial inspection.

</details>


### [17] [Context-Aware Pesticide Recommendation via Few-Shot Pest Recognition for Precision Agriculture](https://arxiv.org/abs/2601.00243)
*Anirudha Ghosh,Ritam Sarkar,Debaditya Barman*

Main category: cs.CV

TL;DR: 提出轻量级害虫检测与农药推荐框架，适用于智能手机和无人机等低资源设备，帮助小农户实现精准农业


<details>
  <summary>Details</summary>
Motivation: 传统害虫管理方法依赖人工检查和化学农药，成本高、耗时长、劳动密集且对环境有害，需要适合小农户的低成本解决方案

Method: 包含两个模块：1) 害虫检测模块使用轻量级CNN结合原型元学习，支持小样本学习；2) 农药推荐模块考虑作物类型和生长阶段等环境因素，推荐环保农药。整合多个公开数据集构建综合训练集

Result: 轻量级CNN达到与最先进模型相当的准确率，同时显著降低计算复杂度。决策支持系统减少对传统化学农药的依赖，促进可持续实践

Conclusion: 该框架在精准农业中具有实时应用潜力，特别适合资源有限的农业环境，为小农户提供有效的害虫管理解决方案

Abstract: Effective pest management is crucial for enhancing agricultural productivity, especially for crops such as sugarcane and wheat that are highly vulnerable to pest infestations. Traditional pest management methods depend heavily on manual field inspections and the use of chemical pesticides. These approaches are often costly, time-consuming, labor-intensive, and can have a negative impact on the environment. To overcome these challenges, this study presents a lightweight framework for pest detection and pesticide recommendation, designed for low-resource devices such as smartphones and drones, making it suitable for use by small and marginal farmers.
  The proposed framework includes two main components. The first is a Pest Detection Module that uses a compact, lightweight convolutional neural network (CNN) combined with prototypical meta-learning to accurately identify pests even when only a few training samples are available. The second is a Pesticide Recommendation Module that incorporates environmental factors like crop type and growth stage to suggest safe and eco-friendly pesticide recommendations. To train and evaluate our framework, a comprehensive pest image dataset was developed by combining multiple publicly available datasets. The final dataset contains samples with different viewing angles, pest sizes, and background conditions to ensure strong generalization.
  Experimental results show that the proposed lightweight CNN achieves high accuracy, comparable to state-of-the-art models, while significantly reducing computational complexity. The Decision Support System additionally improves pest management by reducing dependence on traditional chemical pesticides and encouraging sustainable practices, demonstrating its potential for real-time applications in precision agriculture.

</details>


### [18] [TotalFM: An Organ-Separated Framework for 3D-CT Vision Foundation Models](https://arxiv.org/abs/2601.00260)
*Kohei Yamamoto,Tomohiro Kikuchi*

Main category: cs.CV

TL;DR: TotalFM是一个基于器官分离概念的放射学基础模型，通过自动化创建器官体积-发现句子对，结合自监督预训练和对比学习，在3D-CT图像与语言表达对应学习中实现计算效率与表示能力的平衡。


<details>
  <summary>Details</summary>
Motivation: 放射学基础模型在3D-CT体数据训练时面临计算成本约束的挑战，需要开发既能保持表示能力又计算高效的模型。

Method: 基于器官分离概念，利用14万系列大规模数据集，通过分割技术和LLM处理放射报告自动化创建器官体积-发现句子对，结合VideoMAE自监督预训练和体积-文本对比学习。

Result: 在零样本器官级病变分类任务中，相比CT-CLIP在83%器官上获得更高F1分数，相比Merlin在64%器官上表现更好；在零样本发现级病变分类中，相比Merlin在83%类别上获得更高AUROC；在放射报告生成任务中表现与现有VLM相当。

Conclusion: 器官分离学习框架为3D-CT基础模型的实际应用提供了现实有效的设计指南，展示了在临床评估设置中的高泛化性能。

Abstract: While foundation models in radiology are expected to be applied to various clinical tasks, computational cost constraints remain a major challenge when training on 3D-CT volumetric data. In this study, we propose TotalFM, a radiological foundation model that efficiently learns the correspondence between 3D-CT images and linguistic expressions based on the concept of organ separation, utilizing a large-scale dataset of 140,000 series. By automating the creation of organ volume and finding-sentence pairs through segmentation techniques and Large Language Model (LLM)-based radiology report processing, and by combining self-supervised pre-training via VideoMAE with contrastive learning using volume-text pairs, we aimed to balance computational efficiency and representation capability. In zero-shot organ-wise lesion classification tasks, the proposed model achieved higher F1 scores in 83% (5/6) of organs compared to CT-CLIP and 64% (9/14) of organs compared to Merlin. These results suggest that the proposed model exhibits high generalization performance in a clinical evaluation setting using actual radiology report sentences. Furthermore, in zero-shot finding-wise lesion classification tasks, our model achieved a higher AUROC in 83% (25/30) of finding categories compared to Merlin. We also confirmed performance comparable to existing Vision-Language Models (VLMs) in radiology report generation tasks. Our results demonstrate that the organ-separated learning framework can serve as a realistic and effective design guideline for the practical implementation of 3D-CT foundation models.

</details>


### [19] [S1-MMAlign: A Large-Scale, Multi-Disciplinary Dataset for Scientific Figure-Text Understanding](https://arxiv.org/abs/2601.00264)
*He Wang,Longteng Guo,Pengkang Huo,Xuanxu Lin,Yichen Yuan,Jie Jiang,Jing Liu*

Main category: cs.CV

TL;DR: S1-MMAlign是一个包含1550万高质量科学图像-文本对的多学科多模态数据集，通过AI增强管道提升语义对齐，为科学AI提供基础资源。


<details>
  <summary>Details</summary>
Motivation: 当前多模态学习在科学发现中应用受限，主要因为复杂科学图像与稀疏文本描述之间存在巨大语义鸿沟，需要高质量对齐的科学多模态数据。

Method: 从250万开放获取科学论文中收集1550万图像-文本对，使用Qwen-VL多模态大模型系列构建AI就绪的语义增强管道，通过论文摘要和引用上下文重新描述图像。

Result: 增强后的数据质量显著提升：SciBERT伪困惑度指标显示语义模糊性降低，CLIP分数表明图像-文本对齐改善了18.21%。

Conclusion: S1-MMAlign为推进科学推理和跨模态理解提供了基础资源，支持AI for Science时代的发展，数据集已公开可用。

Abstract: Multimodal learning has revolutionized general domain tasks, yet its application in scientific discovery is hindered by the profound semantic gap between complex scientific imagery and sparse textual descriptions. We present S1-MMAlign, a large-scale, multi-disciplinary multimodal dataset comprising over 15.5 million high-quality image-text pairs derived from 2.5 million open-access scientific papers. Spanning disciplines from physics and biology to engineering, the dataset captures diverse visual modalities including experimental setups, heatmaps, and microscopic imagery. To address the pervasive issue of weak alignment in raw scientific captions, we introduce an AI-ready semantic enhancement pipeline that utilizes the Qwen-VL multimodal large model series to recaption images by synthesizing context from paper abstracts and citation contexts. Technical validation demonstrates that this enhancement significantly improves data quality: SciBERT-based pseudo-perplexity metrics show reduced semantic ambiguity, while CLIP scores indicate an 18.21% improvement in image-text alignment. S1-MMAlign provides a foundational resource for advancing scientific reasoning and cross-modal understanding in the era of AI for Science. The dataset is publicly available at https://huggingface.co/datasets/ScienceOne-AI/S1-MMAlign.

</details>


### [20] [ActErase: A Training-Free Paradigm for Precise Concept Erasure via Activation Patching](https://arxiv.org/abs/2601.00267)
*Yi Sun,Xinhao Zhong,Hongyan Li,Yimin Zhou,Junhao Li,Bin Chen,Xuan Wang*

Main category: cs.CV

TL;DR: 提出ActErase：一种无需训练的概念擦除方法，通过分析激活差异区域并动态替换输入激活，在保持模型生成能力的同时高效移除敏感概念


<details>
  <summary>Details</summary>
Motivation: 现有文本到图像扩散模型存在安全、版权和伦理问题，现有概念擦除方法大多依赖数据密集且计算成本高的微调，这成为关键限制

Method: 基于模型激活主要由通用概念组成、只有极小部分表示目标概念的观察，通过提示对分析识别激活差异区域，提取目标激活并在前向传播中动态替换输入激活

Result: 在三个关键擦除任务（裸露、艺术风格和对象移除）上实现SOTA擦除性能，有效保持模型整体生成能力，并展现出对抗攻击的强大鲁棒性

Conclusion: ActErase为扩散模型中的概念操作建立了新的即插即用范式，实现了轻量级但有效的概念擦除，无需训练过程

Abstract: Recent advances in text-to-image diffusion models have demonstrated remarkable generation capabilities, yet they raise significant concerns regarding safety, copyright, and ethical implications. Existing concept erasure methods address these risks by removing sensitive concepts from pre-trained models, but most of them rely on data-intensive and computationally expensive fine-tuning, which poses a critical limitation. To overcome these challenges, inspired by the observation that the model's activations are predominantly composed of generic concepts, with only a minimal component can represent the target concept, we propose a novel training-free method (ActErase) for efficient concept erasure. Specifically, the proposed method operates by identifying activation difference regions via prompt-pair analysis, extracting target activations and dynamically replacing input activations during forward passes. Comprehensive evaluations across three critical erasure tasks (nudity, artistic style, and object removal) demonstrates that our training-free method achieves state-of-the-art (SOTA) erasure performance, while effectively preserving the model's overall generative capability. Our approach also exhibits strong robustness against adversarial attacks, establishing a new plug-and-play paradigm for lightweight yet effective concept manipulation in diffusion models.

</details>


### [21] [FaithSCAN: Model-Driven Single-Pass Hallucination Detection for Faithful Visual Question Answering](https://arxiv.org/abs/2601.00269)
*Chaodong Tong,Qi Zhang,Chen Li,Lei Jiang,Yanbing Liu*

Main category: cs.CV

TL;DR: FaithSCAN：利用VLM内部信号检测VQA幻觉的轻量级网络，通过自动生成监督信号实现无人工标注训练


<details>
  <summary>Details</summary>
Motivation: 现有VQA幻觉检测方法存在局限性：外部验证方法计算开销大且依赖外部资源质量，不确定性方法只能捕捉有限的不确定性方面。两者在效率、鲁棒性和检测性能上都有固有缺陷。

Method: 提出FaithSCAN轻量级网络，利用VLM丰富的内部信号：token级解码不确定性、中间视觉表示和跨模态对齐特征。通过分支证据编码和不确定性感知注意力融合这些信号。扩展LLM-as-a-Judge范式到VQA幻觉，提出低成本自动生成模型相关监督信号的策略。

Result: 在多个VQA基准测试中，FaithSCAN在效果和效率上都显著优于现有方法。深入分析显示幻觉源于视觉感知、跨模态推理和语言解码的系统性内部状态变化。

Conclusion: 不同内部信号提供互补的诊断线索，幻觉模式因VLM架构而异，为理解多模态幻觉的底层原因提供了新见解。FaithSCAN提供了一种高效、鲁棒的VQA幻觉检测解决方案。

Abstract: Faithfulness hallucinations in VQA occur when vision-language models produce fluent yet visually ungrounded answers, severely undermining their reliability in safety-critical applications. Existing detection methods mainly fall into two categories: external verification approaches relying on auxiliary models or knowledge bases, and uncertainty-driven approaches using repeated sampling or uncertainty estimates. The former suffer from high computational overhead and are limited by external resource quality, while the latter capture only limited facets of model uncertainty and fail to sufficiently explore the rich internal signals associated with the diverse failure modes. Both paradigms thus have inherent limitations in efficiency, robustness, and detection performance. To address these challenges, we propose FaithSCAN: a lightweight network that detects hallucinations by exploiting rich internal signals of VLMs, including token-level decoding uncertainty, intermediate visual representations, and cross-modal alignment features. These signals are fused via branch-wise evidence encoding and uncertainty-aware attention. We also extend the LLM-as-a-Judge paradigm to VQA hallucination and propose a low-cost strategy to automatically generate model-dependent supervision signals, enabling supervised training without costly human labels while maintaining high detection accuracy. Experiments on multiple VQA benchmarks show that FaithSCAN significantly outperforms existing methods in both effectiveness and efficiency. In-depth analysis shows hallucinations arise from systematic internal state variations in visual perception, cross-modal reasoning, and language decoding. Different internal signals provide complementary diagnostic cues, and hallucination patterns vary across VLM architectures, offering new insights into the underlying causes of multimodal hallucinations.

</details>


### [22] [Disentangling Hardness from Noise: An Uncertainty-Driven Model-Agnostic Framework for Long-Tailed Remote Sensing Classification](https://arxiv.org/abs/2601.00278)
*Chi Ding,Junxiao Xue,Xinyi Yin,Shi Chen,Yunyun Shi,Yiduo Wang,Fengjian Xue,Xuecheng Wu*

Main category: cs.CV

TL;DR: 提出DUAL框架，通过证据深度学习动态解耦预测不确定性为认知不确定性和偶然不确定性，分别处理长尾分布中的难样本和噪声样本


<details>
  <summary>Details</summary>
Motivation: 遥感数据中存在普遍的长尾分布问题，传统方法难以区分难样本（hard tail data）和噪声模糊样本（noisy ambiguous ones），往往不加区分地强调所有低置信度样本，导致在噪声数据上过拟合

Method: 基于证据深度学习（Evidential Deep Learning），提出模型无关的DUAL框架：1）使用认知不确定性（EU）作为样本稀缺性指标，指导对难学习尾样本的重新加权策略；2）利用偶然不确定性（AU）量化数据模糊性，采用自适应标签平滑机制抑制噪声影响

Result: 在多个数据集和各种骨干网络上进行广泛实验，证明了框架的有效性和泛化能力，超越了TGN和SADE等强基线方法。消融研究进一步验证了设计选择的重要性

Conclusion: DUAL框架成功解决了长尾分布中难样本与噪声样本的区分问题，通过不确定性解耦实现了更鲁棒的遥感目标识别

Abstract: Long-Tailed distributions are pervasive in remote sensing due to the inherently imbalanced occurrence of grounded objects. However, a critical challenge remains largely overlooked, i.e., disentangling hard tail data samples from noisy ambiguous ones. Conventional methods often indiscriminately emphasize all low-confidence samples, leading to overfitting on noisy data. To bridge this gap, building upon Evidential Deep Learning, we propose a model-agnostic uncertainty-aware framework termed DUAL, which dynamically disentangles prediction uncertainty into Epistemic Uncertainty (EU) and Aleatoric Uncertainty (AU). Specifically, we introduce EU as an indicator of sample scarcity to guide a reweighting strategy for hard-to-learn tail samples, while leveraging AU to quantify data ambiguity, employing an adaptive label smoothing mechanism to suppress the impact of noise. Extensive experiments on multiple datasets across various backbones demonstrate the effectiveness and generalization of our framework, surpassing strong baselines such as TGN and SADE. Ablation studies provide further insights into the crucial choices of our design.

</details>


### [23] [SV-GS: Sparse View 4D Reconstruction with Skeleton-Driven Gaussian Splatting](https://arxiv.org/abs/2601.00285)
*Jun-Jee Chao,Volkan Isler*

Main category: cs.CV

TL;DR: SV-GS：一种在稀疏观测下重建动态目标的方法，通过骨架驱动的变形场和运动估计，在稀疏视角和时间采样下实现高质量动态重建。


<details>
  <summary>Details</summary>
Motivation: 现实世界中动态目标重建面临挑战：传统方法需要密集的视角覆盖和时间采样（如多视角视频），但在实际场景中（如安防摄像头），观测往往在时间和空间上都很稀疏，导致重建问题高度不适定。

Method: 提出SV-GS框架：1）利用粗略骨架图和初始静态重建作为输入引导运动估计；2）优化骨架驱动的变形场，包含粗粒度骨架关节姿态估计器和细粒度变形模块；3）仅使关节姿态估计器随时间变化，实现平滑运动插值同时保留几何细节；4）后期可用扩散生成先验替代初始静态重建。

Result: 在合成数据集上，相比现有方法在稀疏观测下PSNR提升高达34%；在真实数据集上，使用显著更少的帧数就能达到与密集单目视频方法相当的性能；验证了扩散生成先验可替代初始静态重建，提升实用性。

Conclusion: SV-GS能够在稀疏观测条件下有效重建动态目标，通过骨架驱动的变形场实现高质量运动估计和几何细节保持，为现实世界动态重建提供了实用解决方案。

Abstract: Reconstructing a dynamic target moving over a large area is challenging. Standard approaches for dynamic object reconstruction require dense coverage in both the viewing space and the temporal dimension, typically relying on multi-view videos captured at each time step. However, such setups are only possible in constrained environments. In real-world scenarios, observations are often sparse over time and captured sparsely from diverse viewpoints (e.g., from security cameras), making dynamic reconstruction highly ill-posed. We present SV-GS, a framework that simultaneously estimates a deformation model and the object's motion over time under sparse observations. To initialize SV-GS, we leverage a rough skeleton graph and an initial static reconstruction as inputs to guide motion estimation. (Later, we show that this input requirement can be relaxed.) Our method optimizes a skeleton-driven deformation field composed of a coarse skeleton joint pose estimator and a module for fine-grained deformations. By making only the joint pose estimator time-dependent, our model enables smooth motion interpolation while preserving learned geometric details. Experiments on synthetic datasets show that our method outperforms existing approaches under sparse observations by up to 34% in PSNR, and achieves comparable performance to dense monocular video methods on real-world datasets despite using significantly fewer frames. Moreover, we demonstrate that the input initial static reconstruction can be replaced by a diffusion-based generative prior, making our method more practical for real-world scenarios.

</details>


### [24] [Towards Automated Differential Diagnosis of Skin Diseases Using Deep Learning and Imbalance-Aware Strategies](https://arxiv.org/abs/2601.00286)
*Ali Anaissi,Ali Braytee,Weidong Huang,Junaid Akram,Alaa Farhat,Jie Hua*

Main category: cs.CV

TL;DR: 基于Swin Transformer的深度学习模型在ISIC2019数据集上对8种皮肤病变分类达到87.71%准确率，可作为临床诊断支持和患者自我评估工具。


<details>
  <summary>Details</summary>
Motivation: 皮肤疾病日益普遍而皮肤科医生资源有限，需要智能工具支持患者和临床医生进行及时准确的皮肤疾病诊断。

Method: 开发基于深度学习的皮肤疾病分类诊断模型，利用公开皮肤疾病图像数据集进行预训练，提取视觉特征，优化模型架构、数据预处理流程，并应用针对性数据增强技术提升性能。

Result: 基于Swin Transformer的最终模型在ISIC2019数据集上对8种皮肤病变类别实现了87.71%的预测准确率。

Conclusion: 该模型展示了作为临床医生诊断支持工具和患者自我评估辅助工具的潜力，能够帮助缓解皮肤科医疗资源不足的问题。

Abstract: As dermatological conditions become increasingly common and the availability of dermatologists remains limited, there is a growing need for intelligent tools to support both patients and clinicians in the timely and accurate diagnosis of skin diseases. In this project, we developed a deep learning based model for the classification and diagnosis of skin conditions. By leveraging pretraining on publicly available skin disease image datasets, our model effectively extracted visual features and accurately classified various dermatological cases. Throughout the project, we refined the model architecture, optimized data preprocessing workflows, and applied targeted data augmentation techniques to improve overall performance. The final model, based on the Swin Transformer, achieved a prediction accuracy of 87.71 percent across eight skin lesion classes on the ISIC2019 dataset. These results demonstrate the model's potential as a diagnostic support tool for clinicians and a self assessment aid for patients.

</details>


### [25] [TimeColor: Flexible Reference Colorization via Temporal Concatenation](https://arxiv.org/abs/2601.00296)
*Bryan Constantine Sadihin,Yihao Meng,Michael Hua Wang,Matteo Jiahao Chen,Hang Su*

Main category: cs.CV

TL;DR: TimeColor是一个基于草图的视频着色模型，支持使用异构、可变数量的参考图像，通过显式的每参考区域分配和时空对应掩码注意力机制来提升着色质量。


<details>
  <summary>Details</summary>
Motivation: 现有着色模型通常只基于单帧参考（通常是场景的第一帧），忽略了其他条件数据源，如角色设定图、背景图像或任意已着色帧。这限制了着色质量和一致性。

Method: 1) 将参考图像编码为额外的潜在帧并时间拼接，使模型能在每个扩散步骤中并行处理参考图像；2) 使用时空对应掩码注意力机制和模态分离的RoPE索引，增强主体-参考绑定，防止捷径学习和跨身份调色板泄漏。

Result: 在SAKUGA-42M数据集上的实验表明，TimeColor在单参考和多参考协议下，相比先前基线方法在颜色保真度、身份一致性和时间稳定性方面都有显著提升。

Conclusion: TimeColor通过支持异构多参考输入和有效的参考绑定机制，显著提升了视频着色的质量和一致性，为基于草图的视频着色提供了更灵活的解决方案。

Abstract: Most colorization models condition only on a single reference, typically the first frame of the scene. However, this approach ignores other sources of conditional data, such as character sheets, background images, or arbitrary colorized frames. We propose TimeColor, a sketch-based video colorization model that supports heterogeneous, variable-count references with the use of explicit per-reference region assignment. TimeColor encodes references as additional latent frames which are concatenated temporally, permitting them to be processed concurrently in each diffusion step while keeping the model's parameter count fixed. TimeColor also uses spatiotemporal correspondence-masked attention to enforce subject-reference binding in addition to modality-disjoint RoPE indexing. These mechanisms mitigate shortcutting and cross-identity palette leakage. Experiments on SAKUGA-42M under both single- and multi-reference protocols show that TimeColor improves color fidelity, identity consistency, and temporal stability over prior baselines.

</details>


### [26] [VisNet: Efficient Person Re-Identification via Alpha-Divergence Loss, Feature Fusion and Dynamic Multi-Task Learning](https://arxiv.org/abs/2601.00307)
*Anns Ijaz,Muhammad Azeem Javed*

Main category: cs.CV

TL;DR: VisNet提出了一种计算高效的人员重识别模型，通过多尺度特征融合、语义聚类和动态权重平均等技术，在保持高精度的同时显著降低计算成本，适合实时监控和移动应用部署。


<details>
  <summary>Details</summary>
Motivation: 当前人员重识别方法虽然精度高但计算成本大，难以在计算资源有限的实时监控和移动应用中部署。需要一种既保持高精度又具有低计算复杂度的实用方法。

Method: VisNet采用多尺度特征融合（融合ResNet50的1-4阶段）、语义聚类（基于解剖学身体分区的规则伪标注）、动态权重平均平衡分类语义正则化，以及FIDI损失函数改进度量学习。

Result: 在Market-1501数据集上达到87.05% Rank-1和77.65% mAP，仅需32.41M参数和4.601 GFLOPs计算量，在精度和效率之间取得良好平衡。

Conclusion: VisNet为计算资源有限的实时监控和移动应用提供了一种实用的人员重识别解决方案，在保持高精度的同时显著降低了计算复杂度。

Abstract: Person re-identification (ReID) is an extremely important area in both surveillance and mobile applications, requiring strong accuracy with minimal computational cost. State-of-the-art methods give good accuracy but with high computational budgets. To remedy this, this paper proposes VisNet, a computationally efficient and effective re-identification model suitable for real-world scenarios. It is the culmination of conceptual contributions, including feature fusion at multiple scales with automatic attention on each, semantic clustering with anatomical body partitioning, a dynamic weight averaging technique to balance classification semantic regularization, and the use of loss function FIDI for improved metric learning tasks. The multiple scales fuse ResNet50's stages 1 through 4 without the use of parallel paths, with semantic clustering introducing spatial constraints through the use of rule-based pseudo-labeling. VisNet achieves 87.05% Rank-1 and 77.65% mAP on the Market-1501 dataset, having 32.41M parameters and 4.601 GFLOPs, hence, proposing a practical approach for real-time deployment in surveillance and mobile applications where computational resources are limited.

</details>


### [27] [ReMA: A Training-Free Plug-and-Play Mixing Augmentation for Video Behavior Recognition](https://arxiv.org/abs/2601.00311)
*Feng-Qi Cui,Jinyang Huang,Sirui Zhao,Jinglong Guo,Qifan Cai,Xin Yan,Zhi Liu*

Main category: cs.CV

TL;DR: ReMA是一种视频数据增强策略，通过受控的混合过程来扩展表示同时保持类别条件稳定性，解决了传统扰动增强方法带来的非判别性因素放大问题。


<details>
  <summary>Details</summary>
Motivation: 现有视频数据增强方法大多是扰动驱动的，会引入不受控制的变异，放大非判别性因素，削弱类内分布结构并导致表示漂移，在不同时间尺度上产生不一致的增益。

Method: 提出Representation-aware Mixing Augmentation (ReMA)，包含两个互补机制：1) Representation Alignment Mechanism (RAM) - 在分布对齐约束下进行结构化类内混合；2) Dynamic Selection Mechanism (DSM) - 生成运动感知的时空掩码来定位扰动，引导其远离判别敏感区域。

Result: 在多个视频行为基准测试上的广泛实验表明，ReMA在不同时空粒度上一致地提升了泛化能力和鲁棒性。

Conclusion: ReMA通过联合控制混合的方式和位置，无需额外监督或可训练参数就能提高表示鲁棒性，是一种有效的即插即用增强策略。

Abstract: Video behavior recognition demands stable and discriminative representations under complex spatiotemporal variations. However, prevailing data augmentation strategies for videos remain largely perturbation-driven, often introducing uncontrolled variations that amplify non-discriminative factors, which finally weaken intra-class distributional structure and representation drift with inconsistent gains across temporal scales. To address these problems, we propose Representation-aware Mixing Augmentation (ReMA), a plug-and-play augmentation strategy that formulates mixing as a controlled replacement process to expand representations while preserving class-conditional stability. ReMA integrates two complementary mechanisms. Firstly, the Representation Alignment Mechanism (RAM) performs structured intra-class mixing under distributional alignment constraints, suppressing irrelevant intra-class drift while enhancing statistical reliability. Then, the Dynamic Selection Mechanism (DSM) generates motion-aware spatiotemporal masks to localize perturbations, guiding them away from discrimination-sensitive regions and promoting temporal coherence. By jointly controlling how and where mixing is applied, ReMA improves representation robustness without additional supervision or trainable parameters. Extensive experiments on diverse video behavior benchmarks demonstrate that ReMA consistently enhances generalization and robustness across different spatiotemporal granularities.

</details>


### [28] [Depth-Synergized Mamba Meets Memory Experts for All-Day Image Reflection Separation](https://arxiv.org/abs/2601.00322)
*Siyan Fang,Long Peng,Yuntao Wang,Ruonan Wei,Yuehuan Wang*

Main category: cs.CV

TL;DR: DMDNet提出深度记忆解耦网络，通过深度感知扫描和状态空间模型增强反射分离，特别针对夜间场景构建数据集并取得SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有反射分离方法依赖单张图像信息，在传输层和反射层对比度相似时容易混淆，夜间场景这一问题更加严重，需要更有效的解决方案。

Method: 提出DMDNet：1) 深度感知扫描(DAScan)引导Mamba关注显著结构；2) 深度协同状态空间模型(DS-SSM)根据深度调制状态激活敏感性；3) 记忆专家补偿模块(MECM)利用跨图像历史知识提供层特定补偿；4) 构建NightIRS夜间反射分离数据集。

Result: DMDNet在白天和夜间场景均优于现有最先进方法，通过深度引导和记忆补偿有效解决了层混淆问题。

Conclusion: 深度引导和记忆补偿机制能有效提升反射分离性能，特别是在夜间等挑战性场景，为图像反射分离提供了新的解决方案。

Abstract: Image reflection separation aims to disentangle the transmission layer and the reflection layer from a blended image. Existing methods rely on limited information from a single image, tending to confuse the two layers when their contrasts are similar, a challenge more severe at night. To address this issue, we propose the Depth-Memory Decoupling Network (DMDNet). It employs the Depth-Aware Scanning (DAScan) to guide Mamba toward salient structures, promoting information flow along semantic coherence to construct stable states. Working in synergy with DAScan, the Depth-Synergized State-Space Model (DS-SSM) modulates the sensitivity of state activations by depth, suppressing the spread of ambiguous features that interfere with layer disentanglement. Furthermore, we introduce the Memory Expert Compensation Module (MECM), leveraging cross-image historical knowledge to guide experts in providing layer-specific compensation. To address the lack of datasets for nighttime reflection separation, we construct the Nighttime Image Reflection Separation (NightIRS) dataset. Extensive experiments demonstrate that DMDNet outperforms state-of-the-art methods in both daytime and nighttime.

</details>


### [29] [HarmoniAD: Harmonizing Local Structures and Global Semantics for Anomaly Detection](https://arxiv.org/abs/2601.00327)
*Naiqi Zhang,Chuancheng Shi,Jingtong Dou,Wenhua Wu,Fei Shen,Jianhua Cao*

Main category: cs.CV

TL;DR: HarmoniAD：一种频率引导的双分支框架，通过高频分支增强纹理边缘检测小缺陷，低频分支捕获长程依赖保持语义一致性，解决现有方法在结构与语义间的权衡问题。


<details>
  <summary>Details</summary>
Motivation: 工业产品质量检测中的异常检测至关重要，但现有方法面临结构-语义权衡：结构导向模型对噪声敏感，语义导向模型常忽略细节。需要平衡精细细节与全局语义。

Method: 提出频率引导的双分支框架：先用CLIP图像编码器提取特征，转换到频域，解耦为高频和低频路径。高频分支使用细粒度结构注意力模块增强纹理边缘，低频分支使用全局结构上下文模块捕获长程依赖。

Result: 在MVTec-AD、VisA和BTAD数据集上实现最先进性能，同时具备高敏感性和鲁棒性。

Conclusion: HarmoniAD通过频率域解耦和双分支互补建模，有效平衡了异常检测中的精细结构细节与全局语义一致性，解决了现有方法的局限性。

Abstract: Anomaly detection is crucial in industrial product quality inspection. Failing to detect tiny defects often leads to serious consequences. Existing methods face a structure-semantics trade-off: structure-oriented models (such as frequency-based filters) are noise-sensitive, while semantics-oriented models (such as CLIP-based encoders) often miss fine details. To address this, we propose HarmoniAD, a frequency-guided dual-branch framework. Features are first extracted by the CLIP image encoder, then transformed into the frequency domain, and finally decoupled into high- and low-frequency paths for complementary modeling of structure and semantics. The high-frequency branch is equipped with a fine-grained structural attention module (FSAM) to enhance textures and edges for detecting small anomalies, while the low-frequency branch uses a global structural context module (GSCM) to capture long-range dependencies and preserve semantic consistency. Together, these branches balance fine detail and global semantics. HarmoniAD further adopts a multi-class joint training strategy, and experiments on MVTec-AD, VisA, and BTAD show state-of-the-art performance with both sensitivity and robustness.

</details>


### [30] [Joint Geometry-Appearance Human Reconstruction in a Unified Latent Space via Bridge Diffusion](https://arxiv.org/abs/2601.00328)
*Yingzhi Tang,Qijian Zhang,Junhui Hou*

Main category: cs.CV

TL;DR: JGA-LBD是一个统一建模几何与外观的3D数字人生成框架，通过联合潜在表示和桥接扩散实现单张RGB图像到高质量3D人体的重建。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常将几何估计和外观合成解耦处理，导致重建不一致且难以统一。需要一种能够同时建模几何和外观的框架，从单张RGB图像实现高保真3D数字人重建。

Method: 1) 将所有输入条件（深度图、SMPL模型等）统一为3D高斯表示，通过共享稀疏变分自编码器压缩到联合潜在空间；2) 采用桥接扩散方法，从目标潜在代码的部分观测开始，专注于推断缺失组件；3) 专用解码模块从推断的潜在表示中提取完整3D人体几何结构并渲染新视角。

Result: 实验表明JGA-LBD在几何保真度和外观质量方面优于当前最先进方法，包括具有挑战性的野外场景。代码将公开提供。

Conclusion: JGA-LBD通过联合潜在表示和桥接扩散，成功实现了从单张RGB图像到高质量3D数字人的统一重建，解决了现有解耦方法的一致性问题。

Abstract: Achieving consistent and high-fidelity geometry and appearance reconstruction of 3D digital humans from a single RGB image is inherently a challenging task. Existing studies typically resort to decoupled pipelines for geometry estimation and appearance synthesis, often hindering unified reconstruction and causing inconsistencies. This paper introduces \textbf{JGA-LBD}, a novel framework that unifies the modeling of geometry and appearance into a joint latent representation and formulates the generation process as bridge diffusion. Observing that directly integrating heterogeneous input conditions (e.g., depth maps, SMPL models) leads to substantial training difficulties, we unify all conditions into the 3D Gaussian representations, which can be further compressed into a unified latent space through a shared sparse variational autoencoder (VAE). Subsequently, the specialized form of bridge diffusion enables to start with a partial observation of the target latent code and solely focuses on inferring the missing components. Finally, a dedicated decoding module extracts the complete 3D human geometric structure and renders novel views from the inferred latent representation. Experiments demonstrate that JGA-LBD outperforms current state-of-the-art approaches in terms of both geometry fidelity and appearance quality, including challenging in-the-wild scenarios. Our code will be made publicly available at https://github.com/haiantyz/JGA-LBD.

</details>


### [31] [Intelligent Traffic Surveillance for Real-Time Vehicle Detection, License Plate Recognition, and Speed Estimation](https://arxiv.org/abs/2601.00344)
*Bruce Mugizi,Sudi Murindanyi,Olivia Nakacwa,Andrew Katumba*

Main category: cs.CV

TL;DR: 基于计算机视觉的实时智能交通监控系统，针对乌干达等发展中国家设计，实现车辆检测、车牌识别、速度估计和自动罚单发放功能。


<details>
  <summary>Details</summary>
Motivation: 超速是道路死亡事故的主要原因，尤其在乌干达等发展中国家，道路安全基础设施有限，急需有效的交通管理解决方案。

Method: 使用计算机视觉技术，包括YOLOv8进行车牌检测，CNN和Transformer模型进行字符识别，基于感兴趣区域进行速度估计，并通过Africa's Talking API实现自动短信罚单发放。

Result: 车牌检测mAP达97.9%，CNN字符识别CER为3.85%，Transformer降至1.79%，速度估计误差在10km/h内，建立了完整的数据库和自动罚单系统。

Conclusion: 该系统能有效解决资源受限环境下的交通管理需求，通过自动化交通执法有望减少道路事故，在发展中国家具有重要应用价值。

Abstract: Speeding is a major contributor to road fatalities, particularly in developing countries such as Uganda, where road safety infrastructure is limited. This study proposes a real-time intelligent traffic surveillance system tailored to such regions, using computer vision techniques to address vehicle detection, license plate recognition, and speed estimation. The study collected a rich dataset using a speed gun, a Canon Camera, and a mobile phone to train the models. License plate detection using YOLOv8 achieved a mean average precision (mAP) of 97.9%. For character recognition of the detected license plate, the CNN model got a character error rate (CER) of 3.85%, while the transformer model significantly reduced the CER to 1.79%. Speed estimation used source and target regions of interest, yielding a good performance of 10 km/h margin of error. Additionally, a database was established to correlate user information with vehicle detection data, enabling automated ticket issuance via SMS via Africa's Talking API. This system addresses critical traffic management needs in resource-constrained environments and shows potential to reduce road accidents through automated traffic enforcement in developing countries where such interventions are urgently needed.

</details>


### [32] [OmniVaT: Single Domain Generalization for Multimodal Visual-Tactile Learning](https://arxiv.org/abs/2601.00352)
*Liuxiang Qiu,Hui Da,Yuzhen Niu,Tiesong Zhao,Yang Cao,Zheng-Jun Zha*

Main category: cs.CV

TL;DR: 提出了OmniVaT框架解决视觉-触觉学习中的单域泛化问题，通过多模态分数傅里叶适配器和离散树生成模块，有效缓解模态差异和领域偏移。


<details>
  <summary>Details</summary>
Motivation: 视觉-触觉学习面临视觉和触觉图像之间的模态差异，以及非标准化触觉传感器和不一致数据收集导致的领域差距问题。这些挑战被形式化为单域泛化多模态VTL任务。

Method: 提出OmniVaT框架：1）多模态分数傅里叶适配器将视觉和触觉嵌入映射到统一的嵌入-频率空间，缓解模态差距；2）离散树生成模块通过层次树结构获得多样可靠的分数表示，增强对未见领域波动的适应性。

Result: 大量实验证明OmniVaT在SDG-VTL任务上具有优越的跨领域泛化性能。

Conclusion: OmniVaT首次成功解决了视觉-触觉学习的单域泛化问题，通过统一嵌入空间和层次表示增强，有效处理模态差异和领域偏移。

Abstract: Visual-tactile learning (VTL) enables embodied agents to perceive the physical world by integrating visual (VIS) and tactile (TAC) sensors. However, VTL still suffers from modality discrepancies between VIS and TAC images, as well as domain gaps caused by non-standardized tactile sensors and inconsistent data collection procedures. We formulate these challenges as a new task, termed single domain generalization for multimodal VTL (SDG-VTL). In this paper, we propose an OmniVaT framework that, for the first time, successfully addresses this task. On the one hand, OmniVaT integrates a multimodal fractional Fourier adapter (MFFA) to map VIS and TAC embeddings into a unified embedding-frequency space, thereby effectively mitigating the modality gap without multi-domain training data or careful cross-modal fusion strategies. On the other hand, it also incorporates a discrete tree generation (DTG) module that obtains diverse and reliable multimodal fractional representations through a hierarchical tree structure, thereby enhancing its adaptivity to fluctuating domain shifts in unseen domains. Extensive experiments demonstrate the superior cross-domain generalization performance of OmniVaT on the SDG-VTL task.

</details>


### [33] [Efficient Prediction of Dense Visual Embeddings via Distillation and RGB-D Transformers](https://arxiv.org/abs/2601.00359)
*Söhnke Benedikt Fischedick,Daniel Seichter,Benedict Stephan,Robin Schmidt,Horst-Michael Gross*

Main category: cs.CV

TL;DR: DVEFormer：基于RGB-D Transformer的高效视觉嵌入预测方法，通过知识蒸馏从Alpha-CLIP学习细粒度像素级嵌入，支持文本查询和3D建图，满足实时性要求


<details>
  <summary>Details</summary>
Motivation: 家庭环境中，机器人需要全面理解周围环境才能与未经训练的人类进行有效直观的交互。传统语义分割方法使用固定预定义类别，限制了灵活性和自然语言交互能力。

Method: 提出DVEFormer，基于RGB-D Transformer架构，通过知识蒸馏从Alpha-CLIP教师模型学习密集文本对齐的视觉嵌入（DVE）。该方法学习细粒度像素级嵌入而非直接进行传统语义分割。

Result: 在常见室内数据集上达到竞争性性能，满足实时要求：完整模型26.3 FPS，小变体77.0 FPS（NVIDIA Jetson AGX Orin）。支持文本查询、3D建图等应用，可作为传统分割方法的直接替代。

Conclusion: DVEFormer作为传统分割方法的替代方案，实现了灵活的基于自然语言的查询能力，并能无缝集成到移动机器人的3D建图流程中，为家庭环境中的机器人交互提供了更直观的解决方案。

Abstract: In domestic environments, robots require a comprehensive understanding of their surroundings to interact effectively and intuitively with untrained humans. In this paper, we propose DVEFormer - an efficient RGB-D Transformer-based approach that predicts dense text-aligned visual embeddings (DVE) via knowledge distillation. Instead of directly performing classical semantic segmentation with fixed predefined classes, our method uses teacher embeddings from Alpha-CLIP to guide our efficient student model DVEFormer in learning fine-grained pixel-wise embeddings. While this approach still enables classical semantic segmentation, e.g., via linear probing, it further enables flexible text-based querying and other applications, such as creating comprehensive 3D maps. Evaluations on common indoor datasets demonstrate that our approach achieves competitive performance while meeting real-time requirements, operating at 26.3 FPS for the full model and 77.0 FPS for a smaller variant on an NVIDIA Jetson AGX Orin. Additionally, we show qualitative results that highlight the effectiveness and possible use cases in real-world applications. Overall, our method serves as a drop-in replacement for traditional segmentation approaches while enabling flexible natural-language querying and seamless integration into 3D mapping pipelines for mobile robotics.

</details>


### [34] [Mask-Conditioned Voxel Diffusion for Joint Geometry and Color Inpainting](https://arxiv.org/abs/2601.00368)
*Aarya Sumuk*

Main category: cs.CV

TL;DR: 提出轻量级两阶段框架，用于受损3D对象的几何和颜色修复，通过分离损伤定位与重建，实现文化遗产物件的数字修复。


<details>
  <summary>Details</summary>
Motivation: 针对文化遗产数字修复需求，需要同时修复3D对象的几何结构和颜色纹理，现有方法难以在保持观测区域完整的同时进行高质量修复。

Method: 两阶段框架：第一阶段使用2D卷积网络在RGB切片上预测损伤掩码并聚合成体积掩码；第二阶段使用基于扩散的3D U-Net进行掩码条件修复，直接处理体素网格，联合预测占据率和颜色。

Result: 在合成损伤的纹理文物数据集上评估，相比基于对称性的基线方法，在固定32^3分辨率下产生更完整的几何结构和更一致的颜色重建效果。

Conclusion: 显式掩码条件引导是指导体积扩散模型进行联合3D几何和颜色修复的实用方法，为文化遗产数字修复提供了有效解决方案。

Abstract: We present a lightweight two-stage framework for joint geometry and color inpainting of damaged 3D objects, motivated by the digital restoration of cultural heritage artifacts. The pipeline separates damage localization from reconstruction. In the first stage, a 2D convolutional network predicts damage masks on RGB slices extracted from a voxelized object, and these predictions are aggregated into a volumetric mask. In the second stage, a diffusion-based 3D U-Net performs mask-conditioned inpainting directly on voxel grids, reconstructing geometry and color while preserving observed regions. The model jointly predicts occupancy and color using a composite objective that combines occupancy reconstruction with masked color reconstruction and perceptual regularization. We evaluate the approach on a curated set of textured artifacts with synthetically generated damage using standard geometric and color metrics. Compared to symmetry-based baselines, our method produces more complete geometry and more coherent color reconstructions at a fixed 32^3 resolution. Overall, the results indicate that explicit mask conditioning is a practical way to guide volumetric diffusion models for joint 3D geometry and color inpainting.

</details>


### [35] [BHaRNet: Reliability-Aware Body-Hand Modality Expertized Networks for Fine-grained Skeleton Action Recognition](https://arxiv.org/abs/2601.00369)
*Seungyeon Cho,Tae-kyun Kim*

Main category: cs.CV

TL;DR: 提出概率双流框架，统一可靠性建模和多模态集成，通过校准无关预处理、概率Noisy-OR融合和跨模态集成，提升基于骨架的细粒度动作识别性能。


<details>
  <summary>Details</summary>
Motivation: 现有骨架动作识别方法大多关注身体大尺度运动，忽略了手部细微关节动作，而这些对于细粒度识别至关重要。需要一种能处理不确定性并整合多模态信息的框架。

Method: 1) 校准无关预处理管道，直接从原生坐标学习；2) 概率Noisy-OR融合，无需显式置信度监督即可稳定可靠性感知的双流学习；3) 从骨架模态到RGB表示的跨模态集成，耦合四种骨架模态（关节、骨骼、关节运动、骨骼运动）。

Result: 在多个基准测试（NTU RGB+D~60/120, PKU-MMD, N-UCLA）和新定义的手部中心基准上均表现出持续改进和鲁棒性，在噪声和异构条件下表现良好。

Conclusion: 提出的概率双流框架通过统一可靠性建模和多模态集成，有效提升了细粒度骨架动作识别性能，特别是在处理手部细微动作和不确定性的能力上表现出色。

Abstract: Skeleton-based human action recognition (HAR) has achieved remarkable progress with graph-based architectures. However, most existing methods remain body-centric, focusing on large-scale motions while neglecting subtle hand articulations that are crucial for fine-grained recognition. This work presents a probabilistic dual-stream framework that unifies reliability modeling and multi-modal integration, generalizing expertized learning under uncertainty across both intra-skeleton and cross-modal domains. The framework comprises three key components: (1) a calibration-free preprocessing pipeline that removes canonical-space transformations and learns directly from native coordinates; (2) a probabilistic Noisy-OR fusion that stabilizes reliability-aware dual-stream learning without requiring explicit confidence supervision; and (3) an intra- to cross-modal ensemble that couples four skeleton modalities (Joint, Bone, Joint Motion, and Bone Motion) to RGB representations, bridging structural and visual motion cues in a unified cross-modal formulation. Comprehensive evaluations across multiple benchmarks (NTU RGB+D~60/120, PKU-MMD, N-UCLA) and a newly defined hand-centric benchmark exhibit consistent improvements and robustness under noisy and heterogeneous conditions.

</details>


### [36] [NeoVerse: Enhancing 4D World Model with in-the-wild Monocular Videos](https://arxiv.org/abs/2601.00393)
*Yuxue Yang,Lue Fan,Ziqi Shi,Junran Peng,Feng Wang,Zhaoxiang Zhang*

Main category: cs.CV

TL;DR: NeoVerse是一个多功能4D世界模型，能够进行4D重建、新轨迹视频生成和丰富的下游应用，通过可扩展的单目视频处理实现通用性


<details>
  <summary>Details</summary>
Motivation: 当前4D世界建模方法存在可扩展性限制，主要由于昂贵的多视角4D数据或繁琐的训练预处理，需要开发能够处理多样化单目视频的可扩展解决方案

Method: 采用无姿态前馈4D重建、在线单目退化模式模拟等技术，构建可扩展的全流程，能够处理多样化的野外单目视频

Result: 在标准重建和生成基准测试中达到最先进性能，具有跨领域的通用性和泛化能力

Conclusion: NeoVerse通过可扩展的单目视频处理框架，成功解决了4D世界建模的可扩展性问题，实现了多功能应用和优越性能

Abstract: In this paper, we propose NeoVerse, a versatile 4D world model that is capable of 4D reconstruction, novel-trajectory video generation, and rich downstream applications. We first identify a common limitation of scalability in current 4D world modeling methods, caused either by expensive and specialized multi-view 4D data or by cumbersome training pre-processing. In contrast, our NeoVerse is built upon a core philosophy that makes the full pipeline scalable to diverse in-the-wild monocular videos. Specifically, NeoVerse features pose-free feed-forward 4D reconstruction, online monocular degradation pattern simulation, and other well-aligned techniques. These designs empower NeoVerse with versatility and generalization to various domains. Meanwhile, NeoVerse achieves state-of-the-art performance in standard reconstruction and generation benchmarks. Our project page is available at https://neoverse-4d.github.io

</details>


### [37] [RoLID-11K: A Dashcam Dataset for Small-Object Roadside Litter Detection](https://arxiv.org/abs/2601.00398)
*Tao Wu,Qing Xu,Xiangjian He,Oakleigh Weekes,James Brown,Wenting Duan*

Main category: cs.CV

TL;DR: RoLID-11K是首个用于车载摄像头路边垃圾检测的大规模数据集，包含超过11,000张标注图像，涵盖英国各种驾驶条件，具有长尾分布和小目标检测挑战。


<details>
  <summary>Details</summary>
Motivation: 当前路边垃圾监测依赖劳动密集型调查和公众报告，空间覆盖有限。现有的垃圾检测视觉数据集主要针对街景静态图像、航拍场景或水环境，无法反映车载摄像头视频中垃圾目标极小、稀疏且嵌入杂乱路侧背景的特点。

Method: 构建了RoLID-11K数据集，包含超过11,000张标注图像，涵盖英国多样驾驶条件。对多种现代检测器进行基准测试，包括基于准确性的Transformer架构和实时YOLO模型，分析它们在极端小目标检测任务中的表现。

Result: CO-DETR及相关Transformer模型在定位准确性方面表现最佳，而实时模型受限于粗糙的特征层次结构。该数据集为动态驾驶场景中的极端小目标检测建立了具有挑战性的基准。

Conclusion: RoLID-11K是首个针对车载摄像头路边垃圾检测的大规模数据集，为开发可扩展、低成本的路边垃圾监测系统提供了支持，并建立了动态驾驶场景中极端小目标检测的挑战性基准。

Abstract: Roadside litter poses environmental, safety and economic challenges, yet current monitoring relies on labour-intensive surveys and public reporting, providing limited spatial coverage. Existing vision datasets for litter detection focus on street-level still images, aerial scenes or aquatic environments, and do not reflect the unique characteristics of dashcam footage, where litter appears extremely small, sparse and embedded in cluttered road-verge backgrounds. We introduce RoLID-11K, the first large-scale dataset for roadside litter detection from dashcams, comprising over 11k annotated images spanning diverse UK driving conditions and exhibiting pronounced long-tail and small-object distributions. We benchmark a broad spectrum of modern detectors, from accuracy-oriented transformer architectures to real-time YOLO models, and analyse their strengths and limitations on this challenging task. Our results show that while CO-DETR and related transformers achieve the best localisation accuracy, real-time models remain constrained by coarse feature hierarchies. RoLID-11K establishes a challenging benchmark for extreme small-object detection in dynamic driving scenes and aims to support the development of scalable, low-cost systems for roadside-litter monitoring. The dataset is available at https://github.com/xq141839/RoLID-11K.

</details>


### [38] [ABFR-KAN: Kolmogorov-Arnold Networks for Functional Brain Analysis](https://arxiv.org/abs/2601.00416)
*Tyler Ward,Abdullah Imran*

Main category: cs.CV

TL;DR: 提出ABFR-KAN模型，使用Transformer和KAN网络改进功能连接分析，在自闭症分类任务上超越现有方法


<details>
  <summary>Details</summary>
Motivation: 传统基于图谱的功能连接分析存在选择偏差和缺乏个体特异性的问题，需要改进结构偏差和解剖一致性

Method: 提出ABFR-KAN模型，结合Transformer分类网络、先进脑功能表示组件和Kolmogorov-Arnold Networks (KANs)，减少结构偏差，提高解剖一致性和功能连接估计可靠性

Result: 在ABIDE I数据集上的广泛实验（包括跨站点评估和消融研究）表明，ABFR-KAN在自闭症谱系障碍分类任务上持续优于现有最佳基线方法

Conclusion: ABFR-KAN通过结合先进脑功能表示和KAN网络，有效解决了传统功能连接分析的问题，为脑疾病诊断提供了更可靠的工具

Abstract: Functional connectivity (FC) analysis, a valuable tool for computer-aided brain disorder diagnosis, traditionally relies on atlas-based parcellation. However, issues relating to selection bias and a lack of regard for subject specificity can arise as a result of such parcellations. Addressing this, we propose ABFR-KAN, a transformer-based classification network that incorporates novel advanced brain function representation components with the power of Kolmogorov-Arnold Networks (KANs) to mitigate structural bias, improve anatomical conformity, and enhance the reliability of FC estimation. Extensive experiments on the ABIDE I dataset, including cross-site evaluation and ablation studies across varying model backbones and KAN configurations, demonstrate that ABFR-KAN consistently outperforms state-of-the-art baselines for autism spectrum distorder (ASD) classification. Our code is available at https://github.com/tbwa233/ABFR-KAN.

</details>


### [39] [Robust Assembly Progress Estimation via Deep Metric Learning](https://arxiv.org/abs/2601.00422)
*Kazuma Miura,Sarthak Pathak,Kazunori Umeda*

Main category: cs.CV

TL;DR: 提出基于四元组损失的异常检测网络，用于在遮挡或视觉变化微小情况下准确估计产品装配进度，在桌面PC数据集上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 智能工厂中产品装配进度的自动监控对提高运营效率至关重要，但多日手动装配任务中，当连续任务间视觉变化细微时，现有方法容易发生误分类。

Method: 提出基于四元组损失的异常图像学习方法，并引入自定义数据加载器，通过策略性选择训练样本来增强估计准确性，使用小规模数据集。

Result: 在桌面PC装配数据集上，提出的异常四元组网络优于现有方法，估计准确率提高1.3%，相邻任务间误分类减少1.9%。

Conclusion: 该方法在遮挡或视觉变化微小情况下仍能稳健地估计装配进度，证明了四元组损失和策略性训练样本选择的有效性。

Abstract: In recent years, the advancement of AI technologies has accelerated the development of smart factories. In particular, the automatic monitoring of product assembly progress is crucial for improving operational efficiency, minimizing the cost of discarded parts, and maximizing factory productivity. However, in cases where assembly tasks are performed manually over multiple days, implementing smart factory systems remains a challenge. Previous work has proposed Anomaly Triplet-Net, which estimates assembly progress by applying deep metric learning to the visual features of products. Nevertheless, when visual changes between consecutive tasks are subtle, misclassification often occurs. To address this issue, this paper proposes a robust system for estimating assembly progress, even in cases of occlusion or minimal visual change, using a small-scale dataset. Our method leverages a Quadruplet Loss-based learning approach for anomaly images and introduces a custom data loader that strategically selects training samples to enhance estimation accuracy. We evaluated our approach using a image datasets: captured during desktop PC assembly. The proposed Anomaly Quadruplet-Net outperformed existing methods on the dataset. Specifically, it improved the estimation accuracy by 1.3% and reduced misclassification between adjacent tasks by 1.9% in the desktop PC dataset and demonstrating the effectiveness of the proposed method.

</details>


### [40] [CPPO: Contrastive Perception for Vision Language Policy Optimization](https://arxiv.org/abs/2601.00501)
*Ahmad Rezaei,Mohsen Gholami,Saeed Ranjbar Alvar,Kevin Cannons,Mohammad Asiful Hossain,Zhou Weimin,Shunbo Zhou,Yong Zhang,Mohammad Akbari*

Main category: cs.CV

TL;DR: CPPO是一种用于微调视觉语言模型的对比感知策略优化方法，通过检测感知标记的熵变化并引入对比感知损失，无需额外模型即可提升多模态推理能力。


<details>
  <summary>Details</summary>
Motivation: 虽然强化学习在语言模型推理方面取得了进展，但扩展到多模态推理需要同时改进感知和推理能力。先前的工作主要使用显式感知奖励，但分离感知标记和推理标记很困难，需要额外的大语言模型、真实数据、强制分离感知与推理，或对所有输出标记不加区分地应用奖励。

Method: CPPO通过扰动输入图像下模型输出的熵变化来检测感知标记，然后在RL目标函数中扩展对比感知损失（CPL），该损失在信息保留扰动下强制一致性，在信息移除扰动下强制敏感性。

Result: 实验表明，CPPO超越了先前的感知奖励方法，同时避免了额外模型，使训练更加高效和可扩展。

Conclusion: CPPO通过创新的对比感知损失和基于熵的感知标记检测，有效解决了多模态强化学习中感知与推理分离的挑战，提供了一种更高效、可扩展的视觉语言模型微调方法。

Abstract: We introduce CPPO, a Contrastive Perception Policy Optimization method for finetuning vision-language models (VLMs). While reinforcement learning (RL) has advanced reasoning in language models, extending it to multimodal reasoning requires improving both the perception and reasoning aspects. Prior works tackle this challenge mainly with explicit perception rewards, but disentangling perception tokens from reasoning tokens is difficult, requiring extra LLMs, ground-truth data, forced separation of perception from reasoning by policy model, or applying rewards indiscriminately to all output tokens. CPPO addresses this problem by detecting perception tokens via entropy shifts in the model outputs under perturbed input images. CPPO then extends the RL objective function with a Contrastive Perception Loss (CPL) that enforces consistency under information-preserving perturbations and sensitivity under information-removing ones. Experiments show that CPPO surpasses previous perception-rewarding methods, while avoiding extra models, making training more efficient and scalable.

</details>


### [41] [MotionPhysics: Learnable Motion Distillation for Text-Guided Simulation](https://arxiv.org/abs/2601.00504)
*Miaowei Wang,Jakub Zadrożny,Oisin Mac Aodha,Amir Vaxman*

Main category: cs.CV

TL;DR: MotionPhysics：一个端到端可微分框架，通过自然语言提示推断3D场景的物理参数，无需真实轨迹或标注视频，利用多模态大语言模型和视频扩散模型实现逼真的动态模拟。


<details>
  <summary>Details</summary>
Motivation: 传统3D物体和材料模拟需要专家知识和耗时的物理参数调整，难以实现理想的动态行为。现有方法通常依赖真实轨迹或标注视频作为指导，限制了应用的便捷性和范围。

Method: 1. 使用多模态大语言模型估计材料参数值，并约束在合理范围内；2. 提出可学习的运动蒸馏损失，从预训练视频扩散模型中提取鲁棒的运动先验，同时最小化外观和几何归纳偏差来指导模拟。

Result: 在30多个场景中评估，包括真实世界、人工设计和AI生成的3D物体，涵盖弹性固体、金属、泡沫、沙子、牛顿和非牛顿流体等多种材料。MotionPhysics能生成由自然语言引导的视觉逼真动态模拟，超越现有技术，同时自动确定物理上合理的参数。

Conclusion: MotionPhysics通过自然语言提示实现了3D场景的物理参数自动推断和逼真动态模拟，无需真实轨迹或标注视频，为广泛材料和场景提供了有效的解决方案。

Abstract: Accurately simulating existing 3D objects and a wide variety of materials often demands expert knowledge and time-consuming physical parameter tuning to achieve the desired dynamic behavior. We introduce MotionPhysics, an end-to-end differentiable framework that infers plausible physical parameters from a user-provided natural language prompt for a chosen 3D scene of interest, removing the need for guidance from ground-truth trajectories or annotated videos. Our approach first utilizes a multimodal large language model to estimate material parameter values, which are constrained to lie within plausible ranges. We further propose a learnable motion distillation loss that extracts robust motion priors from pretrained video diffusion models while minimizing appearance and geometry inductive biases to guide the simulation. We evaluate MotionPhysics across more than thirty scenarios, including real-world, human-designed, and AI-generated 3D objects, spanning a wide range of materials such as elastic solids, metals, foams, sand, and both Newtonian and non-Newtonian fluids. We demonstrate that MotionPhysics produces visually realistic dynamic simulations guided by natural language, surpassing the state of the art while automatically determining physically plausible parameters. The code and project page are available at: https://wangmiaowei.github.io/MotionPhysics.github.io/.

</details>


### [42] [All-in-One Video Restoration under Smoothly Evolving Unknown Weather Degradations](https://arxiv.org/abs/2601.00533)
*Wenrui Li,Hongtao Chen,Yao Xiao,Wangmeng Zuo,Jiantao Zhou,Yonghong Tian,Xiaopeng Fan*

Main category: cs.CV

TL;DR: 提出ORCANet网络处理视频中平滑演化的未知退化问题，通过粗强度估计去雾模块和流提示生成模块实现时空一致的视频恢复


<details>
  <summary>Details</summary>
Motivation: 现有全合一图像恢复方法主要关注逐帧退化变化，忽略了现实世界中退化过程的时间连续性。实际应用中，退化类型和强度随时间平滑演化，多种退化可能共存或逐渐过渡。

Method: 提出SEUD场景和ORCANet网络：1) CIED模块利用物理先验估计雾强度并提供粗去雾特征初始化；2) FPG模块提取退化特征，生成捕获片段级退化类型的静态提示和适应帧级强度变化的动态提示；3) 标签感知监督机制提高不同退化下静态提示表示的可区分性。

Result: 大量实验表明，ORCANet在恢复质量、时间一致性和鲁棒性方面优于基于图像和视频的基线方法。

Conclusion: 提出了SEUD场景和ORCANet网络，有效解决了视频中平滑演化未知退化的恢复问题，通过时空一致的提示机制实现了高质量的视频恢复。

Abstract: All-in-one image restoration aims to recover clean images from diverse unknown degradations using a single model. But extending this task to videos faces unique challenges. Existing approaches primarily focus on frame-wise degradation variation, overlooking the temporal continuity that naturally exists in real-world degradation processes. In practice, degradation types and intensities evolve smoothly over time, and multiple degradations may coexist or transition gradually. In this paper, we introduce the Smoothly Evolving Unknown Degradations (SEUD) scenario, where both the active degradation set and degradation intensity change continuously over time. To support this scenario, we design a flexible synthesis pipeline that generates temporally coherent videos with single, compound, and evolving degradations. To address the challenges in the SEUD scenario, we propose an all-in-One Recurrent Conditional and Adaptive prompting Network (ORCANet). First, a Coarse Intensity Estimation Dehazing (CIED) module estimates haze intensity using physical priors and provides coarse dehazed features as initialization. Second, a Flow Prompt Generation (FPG) module extracts degradation features. FPG generates both static prompts that capture segment-level degradation types and dynamic prompts that adapt to frame-level intensity variations. Furthermore, a label-aware supervision mechanism improves the discriminability of static prompt representations under different degradations. Extensive experiments show that ORCANet achieves superior restoration quality, temporal consistency, and robustness over image and video-based baselines. Code is available at https://github.com/Friskknight/ORCANet-SEUD.

</details>


### [43] [FreeText: Training-Free Text Rendering in Diffusion Transformers via Attention Localization and Spectral Glyph Injection](https://arxiv.org/abs/2601.00535)
*Ruiqiang Zhang,Hengyi Wang,Chang Liu,Guanjie Wang,Zehua Ma,Weiming Zhang*

Main category: cs.CV

TL;DR: FreeText是一个无需训练、即插即用的框架，通过利用扩散Transformer模型的内在机制来改进文本渲染，解决了多行布局、密集排版和中文等长尾脚本的渲染问题。


<details>
  <summary>Details</summary>
Motivation: 大规模文本到图像扩散模型在开放域合成方面表现出色，但在精确文本渲染方面仍然存在困难，特别是对于多行布局、密集排版和中文等长尾脚本。现有解决方案通常需要昂贵的重新训练或严格的外部布局约束，这会降低美学质量并限制灵活性。

Method: FreeText将问题分解为"在哪里写"和"写什么"两个部分。对于"在哪里写"，通过读取token-wise空间归因来定位书写区域，使用sink-like tokens作为稳定的空间锚点，并通过拓扑感知细化产生高置信度掩码。对于"写什么"，引入频谱调制字形注入(SGMI)，通过频域带通调制注入噪声对齐的字形先验，以增强字形结构并抑制语义泄漏。

Result: 在Qwen-Image、FLUX.1-dev和SD3变体上的广泛实验表明，在长文本基准、CVTG和自建的CLT-Bench上，文本可读性持续提升，同时很大程度上保持了语义对齐和美学质量，推理开销适中。

Conclusion: FreeText是一个无需训练、即插即用的框架，通过利用扩散Transformer模型的内在机制，有效改进了文本渲染质量，特别是在处理复杂布局和长尾脚本方面表现出色，同时保持了模型的灵活性和美学质量。

Abstract: Large-scale text-to-image (T2I) diffusion models excel at open-domain synthesis but still struggle with precise text rendering, especially for multi-line layouts, dense typography, and long-tailed scripts such as Chinese. Prior solutions typically require costly retraining or rigid external layout constraints, which can degrade aesthetics and limit flexibility. We propose \textbf{FreeText}, a training-free, plug-and-play framework that improves text rendering by exploiting intrinsic mechanisms of \emph{Diffusion Transformer (DiT)} models. \textbf{FreeText} decomposes the problem into \emph{where to write} and \emph{what to write}. For \emph{where to write}, we localize writing regions by reading token-wise spatial attribution from endogenous image-to-text attention, using sink-like tokens as stable spatial anchors and topology-aware refinement to produce high-confidence masks. For \emph{what to write}, we introduce Spectral-Modulated Glyph Injection (SGMI), which injects a noise-aligned glyph prior with frequency-domain band-pass modulation to strengthen glyph structure and suppress semantic leakage (rendering the concept instead of the word). Extensive experiments on Qwen-Image, FLUX.1-dev, and SD3 variants across longText-Benchmark, CVTG, and our CLT-Bench show consistent gains in text readability while largely preserving semantic alignment and aesthetic quality, with modest inference overhead.

</details>


### [44] [Boosting Segment Anything Model to Generalize Visually Non-Salient Scenarios](https://arxiv.org/abs/2601.00537)
*Guangqian Guo,Pengfei Chen,Yong Guo,Huafeng Chen,Boqiang Zhang,Shan Gao*

Main category: cs.CV

TL;DR: VNS-SAM通过Mask-Edge Token Interactive解码器和Non-Salient Feature Mining模块增强SAM在视觉非显著场景下的分割能力，同时保持零样本泛化性。


<details>
  <summary>Details</summary>
Motivation: SAM在视觉非显著场景（前景背景对比度低）中表现不佳，现有方法难以捕捉准确轮廓，需要提升SAM对此类场景的感知能力。

Method: 提出VNS-SAM，包含两个核心设计：1) Mask-Edge Token Interactive解码器，2) Non-Salient Feature Mining模块，有效利用SAM的低层特征，仅需少量参数和计算开销。

Result: VNS-SAM在多种VNS分割任务中表现优异，特别是在零样本设置下，额外参数可在4小时内优化完成，展示了可行性和实用性。

Conclusion: VNS-SAM显著提升了SAM在视觉非显著场景下的分割性能，同时保持了零样本泛化能力，具有广泛的现实应用潜力。

Abstract: Segment Anything Model (SAM), known for its remarkable zero-shot segmentation capabilities, has garnered significant attention in the community. Nevertheless, its performance is challenged when dealing with what we refer to as visually non-salient scenarios, where there is low contrast between the foreground and background. In these cases, existing methods often cannot capture accurate contours and fail to produce promising segmentation results. In this paper, we propose Visually Non-Salient SAM (VNS-SAM), aiming to enhance SAM's perception of visually non-salient scenarios while preserving its original zero-shot generalizability. We achieve this by effectively exploiting SAM's low-level features through two designs: Mask-Edge Token Interactive decoder and Non-Salient Feature Mining module. These designs help the SAM decoder gain a deeper understanding of non-salient characteristics with only marginal parameter increments and computational requirements. The additional parameters of VNS-SAM can be optimized within 4 hours, demonstrating its feasibility and practicality. In terms of data, we established VNS-SEG, a unified dataset for various VNS scenarios, with more than 35K images, in contrast to previous single-task adaptations. It is designed to make the model learn more robust VNS features and comprehensively benchmark the model's segmentation performance and generalizability on VNS scenarios. Extensive experiments across various VNS segmentation tasks demonstrate the superior performance of VNS-SAM, particularly under zero-shot settings, highlighting its potential for broad real-world applications. Codes and datasets are publicly available at https://guangqian-guo.github.io/VNS-SAM.

</details>


### [45] [DynaDrag: Dynamic Drag-Style Image Editing by Motion Prediction](https://arxiv.org/abs/2601.00542)
*Jiacheng Sui,Yujie Zhou,Li Niu*

Main category: cs.CV

TL;DR: DynaDrag提出首个基于"预测-移动"框架的图像拖拽编辑方法，通过迭代执行运动预测和运动监督，动态调整有效处理点，在面部和人体数据集上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有拖拽式图像编辑方法存在跟踪丢失、跟踪模糊、源图像与目标图像差距大、中间点不合理导致编辑性差等问题，需要新的框架来解决这些挑战。

Method: 提出DynaDrag方法，采用"预测-移动"框架，迭代执行运动预测和运动监督：运动预测预测处理点应该移动的位置，运动监督据此拖拽点，并动态调整有效处理点。

Result: 在面部和人体数据集上的实验表明，DynaDrag在像素级图像操作方面优于先前的工作，解决了跟踪丢失和模糊等问题。

Conclusion: DynaDrag作为首个基于预测-移动框架的拖拽方法，通过迭代预测和监督机制以及动态调整处理点，有效提升了图像编辑的准确性和可控性。

Abstract: To achieve pixel-level image manipulation, drag-style image editing which edits images using points or trajectories as conditions is attracting widespread attention. Most previous methods follow move-and-track framework, in which miss tracking and ambiguous tracking are unavoidable challenging issues. Other methods under different frameworks suffer from various problems like the huge gap between source image and target edited image as well as unreasonable intermediate point which can lead to low editability. To avoid these problems, we propose DynaDrag, the first dragging method under predict-and-move framework. In DynaDrag, Motion Prediction and Motion Supervision are performed iteratively. In each iteration, Motion Prediction first predicts where the handle points should move, and then Motion Supervision drags them accordingly. We also propose to dynamically adjust the valid handle points to further improve the performance. Experiments on face and human datasets showcase the superiority over previous works.

</details>


### [46] [SingBAG Pro: Accelerating point cloud-based iterative reconstruction for 3D photoacoustic imaging under arbitrary array](https://arxiv.org/abs/2601.00551)
*Shuang Li,Yibing Wang,Jian Gao,Chulhong Kim,Seongwook Choi,Yu Zhang,Qian Chen,Yao Yao,Changhui Li*

Main category: cs.CV

TL;DR: SlingBAG Pro是一种基于点云迭代的先进重建算法，专门针对不规则几何换能器阵列的3D光声成像，在保持高质量重建的同时显著减少计算时间和换能器数量。


<details>
  <summary>Details</summary>
Motivation: 临床应用中需要高质量3D光声成像，但传统迭代重建算法在处理不规则阵列配置时面临计算复杂度高、内存需求大、重建时间长等挑战。不规则几何换能器阵列虽然能减少换能器数量并适应特定成像区域，但传统算法难以有效处理。

Method: 基于SlingBAG方法的点云迭代概念，扩展其兼容性以支持任意阵列几何形状。采用分层优化策略，结合零梯度滤波和迭代过程中逐步增加的时间采样率，快速去除冗余空间点云，加速收敛。

Result: 与原始SlingBAG算法相比，SlingBAG Pro在不规则阵列几何下实现了高达2.2倍的点云3D光声重建速度提升。通过仿真和活体小鼠实验验证了方法的有效性。

Conclusion: SlingBAG Pro算法能够有效解决不规则阵列3D光声成像重建的挑战，在保持高质量重建的同时显著减少重建时间和所需换能器数量，为临床应用提供了实用解决方案。

Abstract: High-quality three-dimensional (3D) photoacoustic imaging (PAI) is gaining increasing attention in clinical applications. To address the challenges of limited space and high costs, irregular geometric transducer arrays that conform to specific imaging regions are promising for achieving high-quality 3D PAI with fewer transducers. However, traditional iterative reconstruction algorithms struggle with irregular array configurations, suffering from high computational complexity, substantial memory requirements, and lengthy reconstruction times. In this work, we introduce SlingBAG Pro, an advanced reconstruction algorithm based on the point cloud iteration concept of the Sliding ball adaptive growth (SlingBAG) method, while extending its compatibility to arbitrary array geometries. SlingBAG Pro maintains high reconstruction quality, reduces the number of required transducers, and employs a hierarchical optimization strategy that combines zero-gradient filtering with progressively increased temporal sampling rates during iteration. This strategy rapidly removes redundant spatial point clouds, accelerates convergence, and significantly shortens overall reconstruction time. Compared to the original SlingBAG algorithm, SlingBAG Pro achieves up to a 2.2-fold speed improvement in point cloud-based 3D PA reconstruction under irregular array geometries. The proposed method is validated through both simulation and in vivo mouse experiments, and the source code is publicly available at https://github.com/JaegerCQ/SlingBAG_Pro.

</details>


### [47] [A Comprehensive Dataset for Human vs. AI Generated Image Detection](https://arxiv.org/abs/2601.00553)
*Rajarshi Roy,Nasrin Imanpour,Ashhar Aziz,Shashwat Bajpai,Gurpreet Singh,Shwetangshu Biswas,Kapil Wanaskar,Parth Patwa,Subhankar Ghosh,Shreyas Dixit,Nilesh Ranjan Pal,Vipula Rawte,Ritvik Garimella,Gaytri Jena,Vasu Sharma,Vinija Jain,Aman Chadha,Aishwarya Naresh Reganti,Amitava Das*

Main category: cs.CV

TL;DR: 发布MS COCOAI数据集用于AI生成图像检测，包含96000个真实和合成图像样本，基于MS COCO数据集构建，使用5种生成器生成合成图像，并提出两个检测任务。


<details>
  <summary>Details</summary>
Motivation: 多模态生成AI系统（如Stable Diffusion、DALL-E、MidJourney）改变了合成图像的创建方式，但也带来了误导性内容、虚假信息和操纵媒体的传播问题。随着生成图像越来越难以与真实照片区分，检测这些图像已成为紧迫需求。

Method: 基于MS COCO数据集构建MS COCOAI数据集，包含96000个真实和合成数据点。使用五种生成器生成合成图像：Stable Diffusion 3、Stable Diffusion 2.1、SDXL、DALL-E 3和MidJourney v6。基于该数据集提出两个任务：1）分类图像为真实或生成；2）识别给定合成图像是由哪个模型生成的。

Result: 发布了MS COCOAI数据集，该数据集已在Hugging Face上公开可用（https://huggingface.co/datasets/Rajarshi-Roy-research/Defactify_Image_Dataset）。

Conclusion: 该工作为解决AI生成图像检测问题提供了重要的数据集资源，有助于开发更有效的检测方法，应对生成AI技术带来的虚假信息挑战。

Abstract: Multimodal generative AI systems like Stable Diffusion, DALL-E, and MidJourney have fundamentally changed how synthetic images are created. These tools drive innovation but also enable the spread of misleading content, false information, and manipulated media. As generated images become harder to distinguish from photographs, detecting them has become an urgent priority. To combat this challenge, We release MS COCOAI, a novel dataset for AI generated image detection consisting of 96000 real and synthetic datapoints, built using the MS COCO dataset. To generate synthetic images, we use five generators: Stable Diffusion 3, Stable Diffusion 2.1, SDXL, DALL-E 3, and MidJourney v6. Based on the dataset, we propose two tasks: (1) classifying images as real or generated, and (2) identifying which model produced a given synthetic image. The dataset is available at https://huggingface.co/datasets/Rajarshi-Roy-research/Defactify_Image_Dataset.

</details>


### [48] [AEGIS: Exploring the Limit of World Knowledge Capabilities for Unified Mulitmodal Models](https://arxiv.org/abs/2601.00561)
*Jintao Lin,Bowen Dong,Weikang Shi,Chenyang Lei,Suiyun Zhang,Rui Liu,Xihui Liu*

Main category: cs.CV

TL;DR: AEGIS是一个评估统一多模态模型世界知识应用能力的多任务基准，包含1050个手动标注的问题，涵盖21个主题和6种推理类型，并提出确定性检查表评估协议以提高评估可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试存在局限性，只能进行孤立的单任务评估，诊断能力有限，无法全面评估统一多模态模型在不同任务中应用世界知识的能力。

Method: 提出AEGIS基准，包含视觉理解、生成、编辑和交错生成等多任务，涵盖1050个挑战性问题，涉及21个主题和6种推理类型。同时提出确定性检查表评估协议，用原子化的"是/否"判断替代模糊的提示式评分。

Result: 实验显示大多数统一多模态模型存在严重的世界知识缺陷，随着推理复杂度增加，性能显著下降。简单的插件式推理模块可以部分缓解这些弱点。

Conclusion: 世界知识推理是统一多模态模型发展的关键前沿，需要进一步研究来提升模型在不同任务中应用世界知识的能力。

Abstract: The capability of Unified Multimodal Models (UMMs) to apply world knowledge across diverse tasks remains a critical, unresolved challenge. Existing benchmarks fall short, offering only siloed, single-task evaluations with limited diagnostic power. To bridge this gap, we propose AEGIS (\emph{i.e.}, \textbf{A}ssessing \textbf{E}diting, \textbf{G}eneration, \textbf{I}nterpretation-Understanding for \textbf{S}uper-intelligence), a comprehensive multi-task benchmark covering visual understanding, generation, editing, and interleaved generation. AEGIS comprises 1,050 challenging, manually-annotated questions spanning 21 topics (including STEM, humanities, daily life, etc.) and 6 reasoning types. To concretely evaluate the performance of UMMs in world knowledge scope without ambiguous metrics, we further propose Deterministic Checklist-based Evaluation (DCE), a protocol that replaces ambiguous prompt-based scoring with atomic ``Y/N'' judgments, to enhance evaluation reliability. Our extensive experiments reveal that most UMMs exhibit severe world knowledge deficits and that performance degrades significantly with complex reasoning. Additionally, simple plug-in reasoning modules can partially mitigate these vulnerabilities, highlighting a promising direction for future research. These results highlight the importance of world-knowledge-based reasoning as a critical frontier for UMMs.

</details>


### [49] [Noise-Robust Tiny Object Localization with Flows](https://arxiv.org/abs/2601.00617)
*Huixin Sun,Linlin Yang,Ronyu Chen,Kerui Gu,Baochang Zhang,Angela Yao,Xianbin Cao*

Main category: cs.CV

TL;DR: TOLF框架通过流模型进行误差建模和不确定性引导优化，提升小目标检测的鲁棒性，减少标注噪声的影响。


<details>
  <summary>Details</summary>
Motivation: 尽管通用目标检测取得显著进展，但小目标检测性能仍远低于正常尺度目标。研究发现小目标对标注噪声高度敏感，严格的定位目标优化容易导致噪声过拟合。

Method: 提出Tiny Object Localization with Flows (TOLF)框架：1) 使用归一化流进行灵活的误差建模，捕捉复杂的非高斯预测分布；2) 引入不确定性感知梯度调制机制，抑制高不确定性、易噪声样本的学习。

Result: 在三个数据集上的实验验证了方法的有效性。特别是在AI-TOD数据集上，TOLF将DINO基线提升了1.2% AP。

Conclusion: TOLF通过流模型误差建模和不确定性引导优化，有效提升了小目标检测的鲁棒性，缓解了标注噪声导致的过拟合问题。

Abstract: Despite significant advances in generic object detection, a persistent performance gap remains for tiny objects compared to normal-scale objects. We demonstrate that tiny objects are highly sensitive to annotation noise, where optimizing strict localization objectives risks noise overfitting. To address this, we propose Tiny Object Localization with Flows (TOLF), a noise-robust localization framework leveraging normalizing flows for flexible error modeling and uncertainty-guided optimization. Our method captures complex, non-Gaussian prediction distributions through flow-based error modeling, enabling robust learning under noisy supervision. An uncertainty-aware gradient modulation mechanism further suppresses learning from high-uncertainty, noise-prone samples, mitigating overfitting while stabilizing training. Extensive experiments across three datasets validate our approach's effectiveness. Especially, TOLF boosts the DINO baseline by 1.2% AP on the AI-TOD dataset.

</details>


### [50] [A Cascaded Information Interaction Network for Precise Image Segmentation](https://arxiv.org/abs/2601.00562)
*Hewen Xiao,Jie Mei,Guangfu Ma,Weiren Wu*

Main category: cs.CV

TL;DR: 提出一种结合全局信息引导模块的级联卷积神经网络，通过融合多尺度特征提升复杂场景下的分割精度


<details>
  <summary>Details</summary>
Motivation: 视觉感知对自主行为至关重要，但复杂场景下的鲁棒分割仍具挑战。传统方法在视觉杂乱或模糊环境中表现不佳，需要更有效的特征融合机制。

Method: 提出级联卷积神经网络，集成新颖的全局信息引导模块，该模块能够有效融合低层纹理细节与高层语义特征，克服单尺度特征提取的局限性。

Result: 在基准图像分割数据集上的实验表明，该框架实现了卓越的精度，优于现有最先进方法，特别是在视觉杂乱或模糊环境中表现突出。

Conclusion: 该方法有效提升了分割精度，在复杂场景中表现出色，具有在实际机器人应用中部署的潜力。

Abstract: Visual perception plays a pivotal role in enabling autonomous behavior, offering a cost-effective and efficient alternative to complex multi-sensor systems. However, robust segmentation remains a challenge in complex scenarios. To address this, this paper proposes a cascaded convolutional neural network integrated with a novel Global Information Guidance Module. This module is designed to effectively fuse low-level texture details with high-level semantic features across multiple layers, thereby overcoming the inherent limitations of single-scale feature extraction. This architectural innovation significantly enhances segmentation accuracy, particularly in visually cluttered or blurred environments where traditional methods often fail. Experimental evaluations on benchmark image segmentation datasets demonstrate that the proposed framework achieves superior precision, outperforming existing state-of-the-art methods. The results highlight the effectiveness of the approach and its promising potential for deployment in practical robotic applications.

</details>


### [51] [GranAlign: Granularity-Aware Alignment Framework for Zero-Shot Video Moment Retrieval](https://arxiv.org/abs/2601.00584)
*Mingyu Jeon,Sunjae Yoon,Jonghee Kim,Junyeoung Kim*

Main category: cs.CV

TL;DR: 提出GranAlign框架，通过粒度感知对齐解决零样本视频时刻检索中的语义粒度不匹配问题，无需训练即可实现跨模态对齐，在多个基准测试中达到SOTA。


<details>
  <summary>Details</summary>
Motivation: 零样本视频时刻检索中，文本查询与视频内容之间存在语义粒度不匹配问题。现有方法虽然利用了高质量的预训练知识，但未能平衡不同模态之间的语义粒度，导致检索不准确。

Method: 提出Granularity-Aware Alignment (GranAlign)框架，包含两种互补技术：1) 基于粒度的查询重写，生成不同语义粒度的查询；2) 查询感知的标题生成，将查询意图嵌入视频内容。通过将多级查询与查询无关和查询感知的标题配对，有效解决语义不匹配。

Result: 在三个主要基准测试（QVHighlights、Charades-STA、ActivityNet-Captions）上均达到新的SOTA，在具有挑战性的QVHighlights数据集上mAP@avg提升了3.23%。

Conclusion: GranAlign框架通过粒度感知对齐有效解决了零样本视频时刻检索中的语义粒度不匹配问题，无需训练即可实现跨模态语义对齐，显著提升了检索性能。

Abstract: Zero-shot video moment retrieval (ZVMR) is the task of localizing a temporal moment within an untrimmed video using a natural language query without relying on task-specific training data. The primary challenge in this setting lies in the mismatch in semantic granularity between textual queries and visual content. Previous studies in ZVMR have attempted to achieve alignment by leveraging high-quality pre-trained knowledge that represents video and language in a joint space. However, these approaches failed to balance the semantic granularity between the pre-trained knowledge provided by each modality for a given scene. As a result, despite the high quality of each modality's representations, the mismatch in granularity led to inaccurate retrieval. In this paper, we propose a training-free framework, called Granularity-Aware Alignment (GranAlign), that bridges this gap between coarse and fine semantic representations. Our approach introduces two complementary techniques: granularity-based query rewriting to generate varied semantic granularities, and query-aware caption generation to embed query intent into video content. By pairing multi-level queries with both query-agnostic and query-aware captions, we effectively resolve semantic mismatches. As a result, our method sets a new state-of-the-art across all three major benchmarks (QVHighlights, Charades-STA, ActivityNet-Captions), with a notable 3.23% mAP@avg improvement on the challenging QVHighlights dataset.

</details>


### [52] [Detecting Performance Degradation under Data Shift in Pathology Vision-Language Model](https://arxiv.org/abs/2601.00716)
*Hao Guan,Li Zhou*

Main category: cs.CV

TL;DR: 该研究针对医学视觉语言模型在部署后可能因数据分布偏移导致性能下降的问题，提出结合输入级数据偏移检测和输出级置信度指标的综合监控框架，以提高模型在数字病理学中的可靠性。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型在医学图像分析中表现出色，但部署后当输入数据分布发生变化时，模型性能可能下降。由于缺乏标注数据，检测这种性能下降具有挑战性，但对临床可靠性至关重要。

Method: 1. 开发DomainSAT工具箱，集成代表性偏移检测算法，用于系统分析输入数据偏移；2. 研究输出级监控，提出基于模型预测置信度的无标签性能下降指标；3. 在大型病理数据集上进行肿瘤分类实验，结合输入偏移检测和输出置信度指标。

Result: 输入数据偏移检测能有效识别分布变化并提供早期诊断信号，但并不总是对应实际性能下降。基于置信度的输出指标与性能下降密切相关，可作为输入偏移检测的有效补充。两者结合能更可靠地检测和解释数据偏移下VLM的性能下降。

Conclusion: 该研究为数字病理学中基础模型的可靠性监控提供了一个实用且互补的框架，结合输入数据偏移检测和输出置信度指标能更有效地监测模型在数据分布变化下的性能退化。

Abstract: Vision-Language Models have demonstrated strong potential in medical image analysis and disease diagnosis. However, after deployment, their performance may deteriorate when the input data distribution shifts from that observed during development. Detecting such performance degradation is essential for clinical reliability, yet remains challenging for large pre-trained VLMs operating without labeled data. In this study, we investigate performance degradation detection under data shift in a state-of-the-art pathology VLM. We examine both input-level data shift and output-level prediction behavior to understand their respective roles in monitoring model reliability. To facilitate systematic analysis of input data shift, we develop DomainSAT, a lightweight toolbox with a graphical interface that integrates representative shift detection algorithms and enables intuitive exploration of data shift. Our analysis shows that while input data shift detection is effective at identifying distributional changes and providing early diagnostic signals, it does not always correspond to actual performance degradation. Motivated by this observation, we further study output-based monitoring and introduce a label-free, confidence-based degradation indicator that directly captures changes in model prediction confidence. We find that this indicator exhibits a close relationship with performance degradation and serves as an effective complement to input shift detection. Experiments on a large-scale pathology dataset for tumor classification demonstrate that combining input data shift detection and output confidence-based indicators enables more reliable detection and interpretation of performance degradation in VLMs under data shift. These findings provide a practical and complementary framework for monitoring the reliability of foundation models in digital pathology.

</details>


### [53] [SafeMo: Linguistically Grounded Unlearning for Trustworthy Text-to-Motion Generation](https://arxiv.org/abs/2601.00590)
*Yiling Wang,Zeyu Zhang,Yiran Wang,Hao Tang*

Main category: cs.CV

TL;DR: SafeMo是一个可信的运动生成框架，通过最小化运动遗忘（MMU）策略在连续空间中实现安全的人体运动生成，避免了离散代码本替换方法的缺陷，并提供了首个安全文本到运动数据集。


<details>
  <summary>Details</summary>
Motivation: 现有基于离散VQ-VAE代码本替换的文本到运动生成方法存在两个关键缺陷：1) 替换被良性提示重用的代码本条目会导致日常任务性能下降；2) 离散标记方法引入量化和平滑度损失，导致伪影和抖动过渡。此外，现有文本到运动数据集包含不安全意图和相应运动，不适合安全驱动的机器学习。

Method: 提出SafeMo框架，集成最小化运动遗忘（MMU）的两阶段机器学习遗忘策略，在连续空间中实现安全人体运动生成，避免代码本损失，保持连续运动学特性。同时构建首个安全文本到运动数据集SafeMoVAE-29K，包含重写的安全文本提示和连续精炼运动。

Result: 实验表明SafeMo在HumanML3D和Motion-X数据集上分别达到2.5倍和14.4倍更高的遗忘集FID，相比之前最先进的人类运动遗忘方法LCR，在安全提示上的良性性能相当或更好。

Conclusion: SafeMo通过连续空间中的机器学习遗忘策略有效解决了文本到运动生成的安全问题，避免了离散代码本替换方法的缺陷，在安全性和实用性之间取得了良好平衡，为可信人体运动生成提供了新方法。

Abstract: Text-to-motion (T2M) generation with diffusion backbones achieves strong realism and alignment. Safety concerns in T2M methods have been raised in recent years; existing methods replace discrete VQ-VAE codebook entries to steer the model away from unsafe behaviors. However, discrete codebook replacement-based methods have two critical flaws: firstly, replacing codebook entries which are reused by benign prompts leads to drifts on everyday tasks, degrading the model's benign performance; secondly, discrete token-based methods introduce quantization and smoothness loss, resulting in artifacts and jerky transitions. Moreover, existing text-to-motion datasets naturally contain unsafe intents and corresponding motions, making them unsuitable for safety-driven machine learning. To address these challenges, we propose SafeMo, a trustworthy motion generative framework integrating Minimal Motion Unlearning (MMU), a two-stage machine unlearning strategy, enabling safe human motion generation in continuous space, preserving continuous kinematics without codebook loss and delivering strong safety-utility trade-offs compared to current baselines. Additionally, we present the first safe text-to-motion dataset SafeMoVAE-29K integrating rewritten safe text prompts and continuous refined motion for trustworthy human motion unlearning. Built upon DiP, SafeMo efficiently generates safe human motions with natural transitions. Experiments demonstrate effective unlearning performance of SafeMo by showing strengthened forgetting on unsafe prompts, reaching 2.5x and 14.4x higher forget-set FID on HumanML3D and Motion-X respectively, compared to the previous SOTA human motion unlearning method LCR, with benign performance on safe prompts being better or comparable. Code: https://github.com/AIGeeksGroup/SafeMo. Website: https://aigeeksgroup.github.io/SafeMo.

</details>


### [54] [Modality Dominance-Aware Optimization for Embodied RGB-Infrared Perception](https://arxiv.org/abs/2601.00598)
*Xianhui Liu,Siqi Jiang,Yi Xie,Yuqing Lin,Siao Liu*

Main category: cs.CV

TL;DR: 提出MDACL框架解决RGB-IR多模态检测中的优化偏差问题，通过MDI量化模态主导性，使用HCG增强特征对齐和AER平衡优化动态


<details>
  <summary>Details</summary>
Motivation: RGB-IR多模态感知在复杂物理环境中至关重要，但现有方法存在由不对称模态特性引起的优化偏差问题。信息密度和特征质量的差异导致训练过度强调主导模态，阻碍有效融合

Method: 提出模态主导指数(MDI)量化模态主导性，基于MDI开发模态主导感知跨模态学习(MDACL)框架，包含分层跨模态引导(HCG)增强特征对齐和对抗平衡正则化(AER)平衡优化动态

Result: 在三个RGB-IR基准测试上的广泛实验表明，MDACL有效缓解优化偏差并实现最先进性能

Conclusion: MDACL框架通过量化模态主导性和调节跨模态优化，解决了RGB-IR多模态检测中的优化偏差问题，提升了融合效果和检测性能

Abstract: RGB-Infrared (RGB-IR) multimodal perception is fundamental to embodied multimedia systems operating in complex physical environments. Although recent cross-modal fusion methods have advanced RGB-IR detection, the optimization dynamics caused by asymmetric modality characteristics remain underexplored. In practice, disparities in information density and feature quality introduce persistent optimization bias, leading training to overemphasize a dominant modality and hindering effective fusion. To quantify this phenomenon, we propose the Modality Dominance Index (MDI), which measures modality dominance by jointly modeling feature entropy and gradient contribution. Based on MDI, we develop a Modality Dominance-Aware Cross-modal Learning (MDACL) framework that regulates cross-modal optimization. MDACL incorporates Hierarchical Cross-modal Guidance (HCG) to enhance feature alignment and Adversarial Equilibrium Regularization (AER) to balance optimization dynamics during fusion. Extensive experiments on three RGB-IR benchmarks demonstrate that MDACL effectively mitigates optimization bias and achieves SOTA performance.

</details>


### [55] [RePose: A Real-Time 3D Human Pose Estimation and Biomechanical Analysis Framework for Rehabilitation](https://arxiv.org/abs/2601.00625)
*Junxiao Xue,Pavel Smirnov,Ziao Li,Yunyun Shi,Shi Chen,Xinyi Yin,Xiaohan Yue,Lei Wang,Yiduo Wang,Feng Lin,Yijia Chen,Xiao Ma,Xiaoran Yan,Qing Zhang,Fengjian Xue,Xuecheng Wu*

Main category: cs.CV

TL;DR: RePose：用于康复训练的实时3D人体姿态估计与运动分析方法，通过多摄像头RGB视频输入实现端到端的实时监测与评估，提供即时反馈指导患者正确执行康复动作。


<details>
  <summary>Details</summary>
Motivation: 康复训练中需要实时监测和评估患者动作，提供即时反馈和指导，帮助患者正确执行康复练习，恢复肌肉力量和运动功能。传统方法难以满足实时性、准确性和多人干扰环境下的需求。

Method: 1. 提出统一的端到端实时人体姿态估计与运动分析流水线；2. 针对医疗康复场景提出快速跟踪方法（单帧跟踪<1ms）；3. 改进SmoothNet用于实时姿态估计，减少误差并恢复真实运动状态；4. 使用Unity平台进行实时监测评估并显示肌肉应力状况。

Result: 方法能够实时监测和评估康复训练中的患者动作，提供即时反馈和指导。快速跟踪方法在多人干扰环境下仍能高效工作，姿态估计误差显著降低，运动状态恢复更真实平滑。

Conclusion: RePose系统为康复训练提供了有效的实时监测与评估解决方案，通过多摄像头输入、快速跟踪和姿态优化技术，能够帮助患者正确执行康复动作，加速康复进程。

Abstract: We propose a real-time 3D human pose estimation and motion analysis method termed RePose for rehabilitation training. It is capable of real-time monitoring and evaluation of patients'motion during rehabilitation, providing immediate feedback and guidance to assist patients in executing rehabilitation exercises correctly. Firstly, we introduce a unified pipeline for end-to-end real-time human pose estimation and motion analysis using RGB video input from multiple cameras which can be applied to the field of rehabilitation training. The pipeline can help to monitor and correct patients'actions, thus aiding them in regaining muscle strength and motor functions. Secondly, we propose a fast tracking method for medical rehabilitation scenarios with multiple-person interference, which requires less than 1ms for tracking for a single frame. Additionally, we modify SmoothNet for real-time posture estimation, effectively reducing pose estimation errors and restoring the patient's true motion state, making it visually smoother. Finally, we use Unity platform for real-time monitoring and evaluation of patients' motion during rehabilitation, and to display the muscle stress conditions to assist patients with their rehabilitation training.

</details>


### [56] [HyperPriv-EPN: Hypergraph Learning with Privileged Knowledge for Ependymoma Prognosis](https://arxiv.org/abs/2601.00626)
*Shuren Gabriel Yu,Sikang Ren,Yongji Tian*

Main category: cs.CV

TL;DR: HyperPriv-EPN：基于超图的特权学习框架，利用术后文本数据提升术前室管膜瘤预后预测，无需推理时文本输入


<details>
  <summary>Details</summary>
Motivation: 室管膜瘤术前预后对治疗规划至关重要，但MRI缺乏术后手术报告中的语义信息。现有多模态方法无法在推理时利用这些不可用的特权文本数据。

Method: 提出HyperPriv-EPN框架，采用"分割图策略"，使用共享编码器处理教师图（含术后特权信息）和学生图（仅术前数据），通过双流蒸馏让学生图从视觉特征中"幻觉"出语义社区结构。

Result: 在311名患者的多中心队列验证中，HyperPriv-EPN实现了最先进的诊断准确率和生存分层性能。

Conclusion: 该框架有效将专家知识转移到术前场景，解锁历史术后数据的价值，在无需推理时文本的情况下指导新患者诊断。

Abstract: Preoperative prognosis of Ependymoma is critical for treatment planning but challenging due to the lack of semantic insights in MRI compared to post-operative surgical reports. Existing multimodal methods fail to leverage this privileged text data when it is unavailable during inference. To bridge this gap, we propose HyperPriv-EPN, a hypergraph-based Learning Using Privileged Information (LUPI) framework. We introduce a Severed Graph Strategy, utilizing a shared encoder to process both a Teacher graph (enriched with privileged post-surgery information) and a Student graph (restricted to pre-operation data). Through dual-stream distillation, the Student learns to hallucinate semantic community structures from visual features alone. Validated on a multi-center cohort of 311 patients, HyperPriv-EPN achieves state-of-the-art diagnostic accuracy and survival stratification. This effectively transfers expert knowledge to the preoperative setting, unlocking the value of historical post-operative data to guide the diagnosis of new patients without requiring text at inference.

</details>


### [57] [Quality Detection of Stored Potatoes via Transfer Learning: A CNN and Vision Transformer Approach](https://arxiv.org/abs/2601.00645)
*Shrikant Kapse,Priyankkumar Dhrangdhariya,Priya Kedia,Manasi Patwardhan,Shankar Kausley,Soumyadipta Maiti,Beena Rai,Shirish Karande*

Main category: cs.CV

TL;DR: 利用预训练深度学习模型（ResNet、VGG、DenseNet、ViT）进行马铃薯储存质量监测，包括发芽检测、重量损失估计和保质期预测，DenseNet在发芽检测上达到98.03%准确率。


<details>
  <summary>Details</summary>
Motivation: 解决马铃薯储存期间的质量监测问题，包括发芽检测、重量损失估计和保质期预测，为自动化分拣和库存系统提供非侵入式、可扩展的解决方案。

Method: 在200天控制温湿度条件下收集图像和重量数据，使用预训练的ResNet、VGG、DenseNet和ViT架构，设计两个专门模型：高精度二分类发芽检测器和多分类重量损失/保质期预测器。

Result: DenseNet在发芽检测上达到98.03%准确率；保质期预测在粗分类（2-5类）时准确率超过89.83%，细分类（6-8类）时准确率下降；模型可集成到自动化系统中实现早期发芽识别和动态分类。

Conclusion: 图像深度学习为马铃薯质量评估提供经济高效的非破坏性方法，支持库存管理和减少食物浪费；未来需开发适应不同品种和储存条件的通用模型以提高可扩展性。

Abstract: Image-based deep learning provides a non-invasive, scalable solution for monitoring potato quality during storage, addressing key challenges such as sprout detection, weight loss estimation, and shelf-life prediction. In this study, images and corresponding weight data were collected over a 200-day period under controlled temperature and humidity conditions. Leveraging powerful pre-trained architectures of ResNet, VGG, DenseNet, and Vision Transformer (ViT), we designed two specialized models: (1) a high-precision binary classifier for sprout detection, and (2) an advanced multi-class predictor to estimate weight loss and forecast remaining shelf-life with remarkable accuracy. DenseNet achieved exceptional performance, with 98.03% accuracy in sprout detection. Shelf-life prediction models performed best with coarse class divisions (2-5 classes), achieving over 89.83% accuracy, while accuracy declined for finer divisions (6-8 classes) due to subtle visual differences and limited data per class. These findings demonstrate the feasibility of integrating image-based models into automated sorting and inventory systems, enabling early identification of sprouted potatoes and dynamic categorization based on storage stage. Practical implications include improved inventory management, differential pricing strategies, and reduced food waste across supply chains. While predicting exact shelf-life intervals remains challenging, focusing on broader class divisions ensures robust performance. Future research should aim to develop generalized models trained on diverse potato varieties and storage conditions to enhance adaptability and scalability. Overall, this approach offers a cost-effective, non-destructive method for quality assessment, supporting efficiency and sustainability in potato storage and distribution.

</details>


### [58] [Reconstructing Building Height from Spaceborne TomoSAR Point Clouds Using a Dual-Topology Network](https://arxiv.org/abs/2601.00658)
*Zhaiyu Chen,Yuanyuan Wang,Yilei Shi,Xiao Xiang Zhu*

Main category: cs.CV

TL;DR: 提出首个基于学习的框架，将原始TomoSAR点云转换为高分辨率建筑高度图，通过双拓扑网络处理噪声、各向异性分布和数据空洞问题


<details>
  <summary>Details</summary>
Motivation: TomoSAR点云存在噪声、各向异性点分布和不相干表面数据空洞等问题，阻碍了准确的建筑高度重建，需要新的解决方案

Method: 采用双拓扑网络框架，交替处理点分支（建模不规则散射体特征）和网格分支（强制空间一致性），联合处理这两种表示以去噪和填补缺失区域

Result: 在慕尼黑和柏林数据上的广泛实验验证了方法的有效性，并可扩展到结合光学卫星影像进一步提升重建质量

Conclusion: 这是首个直接从TomoSAR点云进行大规模城市高度映射的概念验证，为可靠的建筑高度估计提供了有前景的替代方案

Abstract: Reliable building height estimation is essential for various urban applications. Spaceborne SAR tomography (TomoSAR) provides weather-independent, side-looking observations that capture facade-level structure, offering a promising alternative to conventional optical methods. However, TomoSAR point clouds often suffer from noise, anisotropic point distributions, and data voids on incoherent surfaces, all of which hinder accurate height reconstruction. To address these challenges, we introduce a learning-based framework for converting raw TomoSAR points into high-resolution building height maps. Our dual-topology network alternates between a point branch that models irregular scatterer features and a grid branch that enforces spatial consistency. By jointly processing these representations, the network denoises the input points and inpaints missing regions to produce continuous height estimates. To our knowledge, this is the first proof of concept for large-scale urban height mapping directly from TomoSAR point clouds. Extensive experiments on data from Munich and Berlin validate the effectiveness of our approach. Moreover, we demonstrate that our framework can be extended to incorporate optical satellite imagery, further enhancing reconstruction quality. The source code is available at https://github.com/zhu-xlab/tomosar2height.

</details>


### [59] [CRoPS: A Training-Free Hallucination Mitigation Framework for Vision-Language Models](https://arxiv.org/abs/2601.00659)
*Neeraj Anand,Samyak Jha,Udbhav Bamba,Rahul Rahaman*

Main category: cs.CV

TL;DR: CRoPS：一种无需训练的幻觉缓解框架，通过选择性移除关键文本标记构建幻觉模型，结合广义对比解码，在多个基准测试中显著提升LVLM可靠性


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型存在生成幻觉内容的严重问题，影响实际应用可靠性。现有无需训练方法存在两个局限：1）对幻觉来源的假设过于狭窄；2）在生成后期（幻觉最易发生阶段）效果下降

Method: 提出CRoPS框架：1）通过选择性移除关键文本标记构建幻觉模型，更有效捕捉幻觉效应；2）引入广义对比解码，整合多个幻觉模型以覆盖多样化的幻觉来源

Result: 在CHAIR分数上提升20%，在六个基准测试和三个LVLM家族中均取得一致增益，优于现有最先进的无需训练方法

Conclusion: CRoPS通过新颖的幻觉模型构建方法和广义对比解码，有效缓解了LVLM的幻觉问题，无需额外训练即可显著提升模型可靠性

Abstract: Despite the rapid success of Large Vision-Language Models (LVLMs), a persistent challenge is their tendency to generate hallucinated content, undermining reliability in real-world use. Existing training-free methods address hallucinations but face two limitations: (i) they rely on narrow assumptions about hallucination sources, and (ii) their effectiveness declines toward the end of generation, where hallucinations are most likely to occur. A common strategy is to build hallucinated models by completely or partially removing visual tokens and contrasting them with the original model. Yet, this alone proves insufficient, since visual information still propagates into generated text. Building on this insight, we propose a novel hallucinated model that captures hallucination effects by selectively removing key text tokens. We further introduce Generalized Contrastive Decoding, which integrates multiple hallucinated models to represent diverse hallucination sources. Together, these ideas form CRoPS, a training-free hallucination mitigation framework that improves CHAIR scores by 20% and achieves consistent gains across six benchmarks and three LVLM families, outperforming state-of-the-art training-free methods.

</details>


### [60] [Pixel-to-4D: Camera-Controlled Image-to-Video Generation with Dynamic 3D Gaussians](https://arxiv.org/abs/2601.00678)
*Melonie de Almeida,Daniela Ivanova,Tong Shi,John H. Williamson,Paul Henderson*

Main category: cs.CV

TL;DR: 提出Pixel-to-4D框架，通过单张图像构建3D高斯场景表示并采样物体运动，实现快速、相机引导的视频生成，无需迭代去噪注入物体运动。


<details>
  <summary>Details</summary>
Motivation: 现有单图像视频生成方法缺乏鲁棒的用户可控性（如修改相机路径），且相机控制模型在准确建模相机运动、保持时间一致性和几何完整性方面存在困难。需要一种能同时控制相机路径并保持时间一致性的方法。

Method: 提出新颖框架：1）从单张图像构建3D高斯场景表示；2）在单次前向传播中采样合理的物体运动；3）实现快速、相机引导的视频生成，无需通过迭代去噪将物体运动注入渲染帧。

Result: 在KITTI、Waymo、RealEstate10K和DL3DV-10K数据集上的广泛实验表明，该方法在视频质量和推理效率方面达到最先进水平。

Conclusion: Pixel-to-4D框架通过3D高斯表示和单次前向传播的物体运动采样，实现了高质量、高效且用户可控的单图像视频生成，解决了现有方法在时间一致性和相机控制方面的局限性。

Abstract: Humans excel at forecasting the future dynamics of a scene given just a single image. Video generation models that can mimic this ability are an essential component for intelligent systems. Recent approaches have improved temporal coherence and 3D consistency in single-image-conditioned video generation. However, these methods often lack robust user controllability, such as modifying the camera path, limiting their applicability in real-world applications. Most existing camera-controlled image-to-video models struggle with accurately modeling camera motion, maintaining temporal consistency, and preserving geometric integrity. Leveraging explicit intermediate 3D representations offers a promising solution by enabling coherent video generation aligned with a given camera trajectory. Although these methods often use 3D point clouds to render scenes and introduce object motion in a later stage, this two-step process still falls short in achieving full temporal consistency, despite allowing precise control over camera movement. We propose a novel framework that constructs a 3D Gaussian scene representation and samples plausible object motion, given a single image in a single forward pass. This enables fast, camera-guided video generation without the need for iterative denoising to inject object motion into render frames. Extensive experiments on the KITTI, Waymo, RealEstate10K and DL3DV-10K datasets demonstrate that our method achieves state-of-the-art video quality and inference efficiency. The project page is available at https://melonienimasha.github.io/Pixel-to-4D-Website.

</details>


### [61] [Efficient Deep Demosaicing with Spatially Downsampled Isotropic Networks](https://arxiv.org/abs/2601.00703)
*Cory Fan,Wenchao Zhang*

Main category: cs.CV

TL;DR: 本文提出在图像去马赛克各向同性网络中使用空间下采样，相比传统避免下采样的设计，能显著提升效率和性能，并设计了JD3Net验证效果。


<details>
  <summary>Details</summary>
Motivation: 移动平台上的数字成像应用需要轻量高效的网络，但传统各向同性网络为避免空间下采样而计算成本过高，不适合移动应用。本文认为空间下采样能改善各向同性网络的效率和性能。

Method: 采用基于DeepMAD的数学架构设计技术，设计了带下采样和不带下采样的简单全卷积网络进行对比，并开发了带下采样的变体JD3Net。

Result: 实验表明下采样能提升经验性能，JD3Net在多种图像去马赛克和联合去马赛克去噪任务上表现出强大的经验性能。

Conclusion: 与传统设计相反，空间下采样能显著改善各向同性网络的效率和性能，为移动平台上的图像去马赛克应用提供了更实用的解决方案。

Abstract: In digital imaging, image demosaicing is a crucial first step which recovers the RGB information from a color filter array (CFA). Oftentimes, deep learning is utilized to perform image demosaicing. Given that most modern digital imaging applications occur on mobile platforms, applying deep learning to demosaicing requires lightweight and efficient networks. Isotropic networks, also known as residual-in-residual networks, have been often employed for image demosaicing and joint-demosaicing-and-denoising (JDD). Most demosaicing isotropic networks avoid spatial downsampling entirely, and thus are often prohibitively expensive computationally for mobile applications. Contrary to previous isotropic network designs, this paper claims that spatial downsampling to a signficant degree can improve the efficiency and performance of isotropic networks. To validate this claim, we design simple fully convolutional networks with and without downsampling using a mathematical architecture design technique adapted from DeepMAD, and find that downsampling improves empirical performance. Additionally, empirical testing of the downsampled variant, JD3Net, of our fully convolutional networks reveals strong empirical performance on a variety of image demosaicing and JDD tasks.

</details>


### [62] [RGS-SLAM: Robust Gaussian Splatting SLAM with One-Shot Dense Initialization](https://arxiv.org/abs/2601.00705)
*Wei-Tse Cheng,Yen-Jen Chiou,Yuan-Fu Yang*

Main category: cs.CV

TL;DR: RGS-SLAM提出了一种基于高斯泼溅的鲁棒SLAM框架，用训练免费的对应关系-高斯初始化替代了传统GS-SLAM的残差驱动稠密化阶段，通过一次性三角化多视角对应关系生成高斯种子，实现更稳定的早期建图和更快的收敛速度。


<details>
  <summary>Details</summary>
Motivation: 传统GS-SLAM采用残差驱动稠密化方法，逐步添加高斯元素来填补缺失几何，这种方法可能导致早期建图不稳定且收敛较慢。RGS-SLAM旨在通过更智能的初始化策略解决这些问题，提高SLAM系统的鲁棒性和效率。

Method: RGS-SLAM的核心方法是用训练免费的对应关系-高斯初始化替代残差驱动稠密化。具体包括：1）使用DINOv3描述符获取密集多视角对应关系；2）通过置信度感知的内点分类器进行细化；3）一次性三角化这些对应关系生成结构感知的高斯种子；4）在优化前建立良好分布的高斯先验。

Result: 在TUM RGB-D和Replica数据集上的评估显示：1）收敛速度提升约20%；2）在纹理丰富和杂乱场景中获得更高的渲染保真度；3）定位和重建精度达到或超过最先进的高斯和基于点的SLAM系统；4）保持实时建图性能，最高可达925 FPS；5）完全兼容现有GS-SLAM流程。

Conclusion: RGS-SLAM通过创新的对应关系-高斯初始化策略，显著改进了高斯泼溅SLAM的稳定性和效率。该方法不仅加速了收敛过程，还提高了重建质量，同时保持了与现有系统的兼容性，为实时SLAM应用提供了更鲁棒的解决方案。

Abstract: We introduce RGS-SLAM, a robust Gaussian-splatting SLAM framework that replaces the residual-driven densification stage of GS-SLAM with a training-free correspondence-to-Gaussian initialization. Instead of progressively adding Gaussians as residuals reveal missing geometry, RGS-SLAM performs a one-shot triangulation of dense multi-view correspondences derived from DINOv3 descriptors refined through a confidence-aware inlier classifier, generating a well-distributed and structure-aware Gaussian seed prior to optimization. This initialization stabilizes early mapping and accelerates convergence by roughly 20\%, yielding higher rendering fidelity in texture-rich and cluttered scenes while remaining fully compatible with existing GS-SLAM pipelines. Evaluated on the TUM RGB-D and Replica datasets, RGS-SLAM achieves competitive or superior localization and reconstruction accuracy compared with state-of-the-art Gaussian and point-based SLAM systems, sustaining real-time mapping performance at up to 925 FPS.

</details>


### [63] [Multi-Level Feature Fusion for Continual Learning in Visual Quality Inspection](https://arxiv.org/abs/2601.00725)
*Johannes C. Bauer,Paul Geng,Stephan Trattnig,Petr Dokládal,Rüdiger Daub*

Main category: cs.CV

TL;DR: 提出多级特征融合方法，在制造业质量检测中实现高效持续学习，减少可训练参数的同时保持性能，并缓解灾难性遗忘问题。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络在制造业质量检测中应用广泛，但在再制造等变化频繁的场景中，产品和缺陷模式经常变化，需要模型持续适应新条件。现有方法需要频繁调整，计算成本高且容易发生灾难性遗忘。

Method: 提出多级特征融合方法，利用预训练网络中不同深度的特征表示，通过融合多层次特征来实现高效适应。该方法显著减少了可训练参数数量。

Result: 该方法在不同质量检测问题上能达到端到端训练的性能水平，同时使用显著更少的可训练参数。能减少灾难性遗忘，并提高对新产品或缺陷类型的泛化鲁棒性。

Conclusion: 多级特征融合方法为制造业中变化场景下的质量检测提供了一种高效、鲁棒的持续学习解决方案，在保持性能的同时降低了计算成本和遗忘风险。

Abstract: Deep neural networks show great potential for automating various visual quality inspection tasks in manufacturing. However, their applicability is limited in more volatile scenarios, such as remanufacturing, where the inspected products and defect patterns often change. In such settings, deployed models require frequent adaptation to novel conditions, effectively posing a continual learning problem. To enable quick adaptation, the necessary training processes must be computationally efficient while still avoiding effects like catastrophic forgetting. This work presents a multi-level feature fusion (MLFF) approach that aims to improve both aspects simultaneously by utilizing representations from different depths of a pretrained network. We show that our approach is able to match the performance of end-to-end training for different quality inspection problems while using significantly less trainable parameters. Furthermore, it reduces catastrophic forgetting and improves generalization robustness to new product types or defects.

</details>


### [64] [Grading Handwritten Engineering Exams with Multimodal Large Language Models](https://arxiv.org/abs/2601.00730)
*Janez Perš,Jon Muhovič,Andrej Košir,Boštjan Murovec*

Main category: cs.CV

TL;DR: 提出一个基于多模态大语言模型的端到端手写STEM考试自动评分工作流，通过结构化提示和参考解决方案实现可靠评分，在真实课程测验中达到与讲师评分约8分的平均绝对差异。


<details>
  <summary>Details</summary>
Motivation: 手写STEM考试能够捕捉开放式推理和图表，但人工评分速度慢且难以扩展。需要开发自动化评分系统来保持标准考试流程（A4纸、无约束手写）的同时提高效率。

Method: 采用多阶段设计：1）格式/存在性检查防止空白答案评分；2）独立评分器集成；3）监督器聚合；4）刚性模板和确定性验证生成可审计报告。使用多模态LLM（GPT-5.2和Gemini-3 Pro），讲师仅需提供手写参考解决方案和简短评分规则，参考方案转换为文本摘要作为评分条件。

Result: 在斯洛文尼亚语真实课程测验（包含手绘电路图）上评估，完整流程与讲师评分的平均绝对差异约为8分，偏差低，在D_max=40时手动审查触发率约17%。消融实验显示简单提示和移除参考方案会显著降低准确性并引入系统性过评。

Conclusion: 结构化提示和参考解决方案基础对于手写STEM考试自动评分至关重要，提出的端到端工作流能够可靠地评分手写工程测验，同时保持标准考试流程。

Abstract: Handwritten STEM exams capture open-ended reasoning and diagrams, but manual grading is slow and difficult to scale. We present an end-to-end workflow for grading scanned handwritten engineering quizzes with multimodal large language models (LLMs) that preserves the standard exam process (A4 paper, unconstrained student handwriting). The lecturer provides only a handwritten reference solution (100%) and a short set of grading rules; the reference is converted into a text-only summary that conditions grading without exposing the reference scan. Reliability is achieved through a multi-stage design with a format/presence check to prevent grading blank answers, an ensemble of independent graders, supervisor aggregation, and rigid templates with deterministic validation to produce auditable, machine-parseable reports. We evaluate the frozen pipeline in a clean-room protocol on a held-out real course quiz in Slovenian, including hand-drawn circuit schematics. With state-of-the-art backends (GPT-5.2 and Gemini-3 Pro), the full pipeline achieves $\approx$8-point mean absolute difference to lecturer grades with low bias and an estimated manual-review trigger rate of $\approx$17% at $D_{\max}=40$. Ablations show that trivial prompting and removing the reference solution substantially degrade accuracy and introduce systematic over-grading, confirming that structured prompting and reference grounding are essential.

</details>


### [65] [Unified Primitive Proxies for Structured Shape Completion](https://arxiv.org/abs/2601.00759)
*Zhaiyu Chen,Yuqing Wang,Xiao Xiang Zhu*

Main category: cs.CV

TL;DR: UniCo：通过专用路径解码基元，在单次前向传播中预测完整几何、语义和内点成员关系的统一结构化形状补全方法


<details>
  <summary>Details</summary>
Motivation: 重新思考基元与点云如何交互，发现将基元解码放在专用路径中关注共享形状特征更为有效，而不是采用流行的级联方法

Method: 提出UniCo框架，使用可学习的基元代理作为查询，通过上下文化产生可直接组装的输出；训练策略通过在线目标更新耦合基元和点云

Result: 在合成和真实世界基准测试中，使用四个独立组装求解器，UniCo始终优于近期基线，将Chamfer距离降低达50%，法线一致性提高达7%

Conclusion: 为从不完整数据中进行结构化3D理解提供了有吸引力的方案，建立了基元与点云交互的新范式

Abstract: Structured shape completion recovers missing geometry as primitives rather than as unstructured points, which enables primitive-based surface reconstruction. Instead of following the prevailing cascade, we rethink how primitives and points should interact, and find it more effective to decode primitives in a dedicated pathway that attends to shared shape features. Following this principle, we present UniCo, which in a single feed-forward pass predicts a set of primitives with complete geometry, semantics, and inlier membership. To drive this unified representation, we introduce primitive proxies, learnable queries that are contextualized to produce assembly-ready outputs. To ensure consistent optimization, our training strategy couples primitives and points with online target updates. Across synthetic and real-world benchmarks with four independent assembly solvers, UniCo consistently outperforms recent baselines, lowering Chamfer distance by up to 50% and improving normal consistency by up to 7%. These results establish an attractive recipe for structured 3D understanding from incomplete data. Project page: https://unico-completion.github.io.

</details>


### [66] [Fusion-SSAT: Unleashing the Potential of Self-supervised Auxiliary Task by Feature Fusion for Generalized Deepfake Detection](https://arxiv.org/abs/2601.00789)
*Shukesh Reddy,Srijan Das,Abhijit Das*

Main category: cs.CV

TL;DR: 论文提出将自监督学习作为辅助任务来优化深度伪造检测的主要任务，通过融合自监督辅助任务的特征表示来提升检测性能，在多个数据集上实现了更好的跨数据集泛化能力。


<details>
  <summary>Details</summary>
Motivation: 探索自监督学习作为辅助任务在深度伪造检测中的潜力，解决当前深度伪造检测器在跨数据集泛化方面的局限性。

Method: 研究自监督学习任务与主要深度伪造检测任务的不同训练方案组合，通过融合自监督辅助任务的特征表示来构建更强大的特征表示。

Result: 在DF40、FaceForensics++、Celeb-DF、DFD、FaceShifter、UADFV等多个数据集上的实验表明，该方法相比当前最先进的检测器在跨数据集评估中表现出更好的泛化性能。

Conclusion: 融合自监督辅助任务的特征表示能够充分利用自监督学习和主要任务的潜力，为深度伪造检测提供独特的特征表示，从而提升主要任务的性能。

Abstract: In this work, we attempted to unleash the potential of self-supervised learning as an auxiliary task that can optimise the primary task of generalised deepfake detection. To explore this, we examined different combinations of the training schemes for these tasks that can be most effective. Our findings reveal that fusing the feature representation from self-supervised auxiliary tasks is a powerful feature representation for the problem at hand. Such a representation can leverage the ultimate potential and bring in a unique representation of both the self-supervised and primary tasks, achieving better performance for the primary task. We experimented on a large set of datasets, which includes DF40, FaceForensics++, Celeb-DF, DFD, FaceShifter, UADFV, and our results showed better generalizability on cross-dataset evaluation when compared with current state-of-the-art detectors.

</details>


### [67] [Two Deep Learning Approaches for Automated Segmentation of Left Ventricle in Cine Cardiac MRI](https://arxiv.org/abs/2601.00794)
*Wenhui Chu,Nikolaos V. Tsekos*

Main category: cs.CV

TL;DR: 本文提出了LNU-Net和IBU-Net两种新型深度学习架构，用于从短轴电影MRI图像中进行左心室分割，相比原始U-Net和其他先进方法在Dice系数和平均垂直距离指标上表现更优。


<details>
  <summary>Details</summary>
Motivation: 左心室分割对于心脏图像的临床量化和诊断至关重要。现有的分割方法需要进一步提升准确性和性能。

Method: 提出了两种基于U-Net的改进架构：LNU-Net在卷积块中使用层归一化，IBU-Net在第一个卷积块中结合实例归一化和批归一化。采用下采样路径进行特征提取和上采样路径进行精确定位，并使用仿射变换和弹性变形进行数据增强。

Result: 在包含45名患者805张MRI图像的数据集上评估，LNU-Net和IBU-Net在Dice系数和平均垂直距离指标上优于原始U-Net和其他先进方法。

Conclusion: 提出的LNU-Net和IBU-Net架构能够有效提升左心室分割的准确性，为临床诊断提供了更可靠的工具。

Abstract: Left ventricle (LV) segmentation is critical for clinical quantification and diagnosis of cardiac images. In this work, we propose two novel deep learning architectures called LNU-Net and IBU-Net for left ventricle segmentation from short-axis cine MRI images. LNU-Net is derived from layer normalization (LN) U-Net architecture, while IBU-Net is derived from the instance-batch normalized (IB) U-Net for medical image segmentation. The architectures of LNU-Net and IBU-Net have a down-sampling path for feature extraction and an up-sampling path for precise localization. We use the original U-Net as the basic segmentation approach and compared it with our proposed architectures. Both LNU-Net and IBU-Net have left ventricle segmentation methods: LNU-Net applies layer normalization in each convolutional block, while IBU-Net incorporates instance and batch normalization together in the first convolutional block and passes its result to the next layer. Our method incorporates affine transformations and elastic deformations for image data processing. Our dataset that contains 805 MRI images regarding the left ventricle from 45 patients is used for evaluation. We experimentally evaluate the results of the proposed approaches outperforming the dice coefficient and the average perpendicular distance than other state-of-the-art approaches.

</details>


### [68] [AdaGaR: Adaptive Gabor Representation for Dynamic Scene Reconstruction](https://arxiv.org/abs/2601.00796)
*Jiewen Chan,Zhenjun Zhao,Yu-Lun Liu*

Main category: cs.CV

TL;DR: AdaGaR是一个用于单目视频动态3D场景重建的统一框架，通过自适应Gabor表示和时序连续性约束，解决了现有方法在频率适应性和运动平滑性方面的限制。


<details>
  <summary>Details</summary>
Motivation: 现有方法存在三个主要问题：1）使用单高斯基元具有低通滤波特性，限制了高频细节捕捉；2）标准Gabor函数存在能量不稳定性；3）缺乏时序连续性约束导致插值时出现运动伪影。

Method: 提出自适应Gabor表示，通过可学习频率权重和自适应能量补偿扩展高斯函数；使用时序曲率正则化的三次Hermite样条确保运动平滑性；采用结合深度估计、点跟踪和前景掩码的自适应初始化机制。

Result: 在Tap-Vid DAVIS数据集上达到SOTA性能（PSNR 35.49, SSIM 0.9433, LPIPS 0.0723），在帧插值、深度一致性、视频编辑和立体视图合成等任务上表现出强泛化能力。

Conclusion: AdaGaR通过统一的频率自适应和时序连续性框架，在动态3D场景重建中实现了更好的细节捕捉和运动平滑性，为单目视频重建提供了有效的解决方案。

Abstract: Reconstructing dynamic 3D scenes from monocular videos requires simultaneously capturing high-frequency appearance details and temporally continuous motion. Existing methods using single Gaussian primitives are limited by their low-pass filtering nature, while standard Gabor functions introduce energy instability. Moreover, lack of temporal continuity constraints often leads to motion artifacts during interpolation. We propose AdaGaR, a unified framework addressing both frequency adaptivity and temporal continuity in explicit dynamic scene modeling. We introduce Adaptive Gabor Representation, extending Gaussians through learnable frequency weights and adaptive energy compensation to balance detail capture and stability. For temporal continuity, we employ Cubic Hermite Splines with Temporal Curvature Regularization to ensure smooth motion evolution. An Adaptive Initialization mechanism combining depth estimation, point tracking, and foreground masks establishes stable point cloud distributions in early training. Experiments on Tap-Vid DAVIS demonstrate state-of-the-art performance (PSNR 35.49, SSIM 0.9433, LPIPS 0.0723) and strong generalization across frame interpolation, depth consistency, video editing, and stereo view synthesis. Project page: https://jiewenchan.github.io/AdaGaR/

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [69] [RIMRULE: Improving Tool-Using Language Agents via MDL-Guided Rule Learning](https://arxiv.org/abs/2601.00086)
*Xiang Gao,Yuguang Yao,Qi Zhang,Kaiwen Dong,Avinash Baidya,Ruocheng Guo,Hilaf Hasson,Kamalika Das*

Main category: cs.CL

TL;DR: RIMRULE：基于动态规则注入的神经符号方法，通过从失败轨迹中提炼紧凑、可解释的规则来提升LLM在特定领域工具使用中的可靠性，无需修改模型权重。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在特定领域工具使用时面临挑战，因为API可能具有特殊性、文档不足或针对私有工作流程定制，需要有效的任务特定工具适应方法。

Method: 提出RIMRULE神经符号方法：1) 从失败轨迹中提炼紧凑可解释规则；2) 使用最小描述长度目标优化规则通用性和简洁性；3) 将规则以自然语言和结构化符号形式存储；4) 在推理时动态注入规则到提示中。

Result: 在工具使用基准测试中，该方法提高了对已见和未见工具的准确性，优于基于提示的适应方法，并能与微调互补。从某个LLM学习的规则可以跨架构重用，提升其他LLM性能。

Conclusion: RIMRULE通过动态规则注入有效提升了LLM在特定领域工具使用的可靠性，展示了符号知识在不同架构间的可移植性，为LLM工具适应提供了轻量级解决方案。

Abstract: Large language models (LLMs) often struggle to use tools reliably in domain-specific settings, where APIs may be idiosyncratic, under-documented, or tailored to private workflows. This highlights the need for effective adaptation to task-specific tools. We propose RIMRULE, a neuro-symbolic approach for LLM adaptation based on dynamic rule injection. Compact, interpretable rules are distilled from failure traces and injected into the prompt during inference to improve task performance. These rules are proposed by the LLM itself and consolidated using a Minimum Description Length (MDL) objective that favors generality and conciseness. Each rule is stored in both natural language and a structured symbolic form, supporting efficient retrieval at inference time. Experiments on tool-use benchmarks show that this approach improves accuracy on both seen and unseen tools without modifying LLM weights. It outperforms prompting-based adaptation methods and complements finetuning. Moreover, rules learned from one LLM can be reused to improve others, including long reasoning LLMs, highlighting the portability of symbolic knowledge across architectures.

</details>


### [70] [Universal Adaptive Constraint Propagation: Scaling Structured Inference for Large Language Models via Meta-Reinforcement Learning](https://arxiv.org/abs/2601.00095)
*Ibne Farabi Shihab,Sanjeda Akter,Anuj Sharma*

Main category: cs.CL

TL;DR: MetaJuLS：基于元强化学习的通用约束传播方法，用于LLM结构化推理，实现跨语言/任务的快速适应，相比GPU优化基线提速1.5-2倍，精度损失小于0.2%


<details>
  <summary>Details</summary>
Motivation: 大型语言模型需要结构化推理（如JSON模式强制、多语言解析），输出必须满足复杂约束。现有方法通常需要针对每个任务重新训练，效率低下且计算成本高。

Method: 提出MetaJuLS（元强化学习方法），将结构化推理建模为自适应约束传播问题。使用图注意力网络（GAT）和元学习训练通用约束传播策略，该策略可跨语言和任务应用而无需任务特定重训练。

Result: 在Universal Dependencies（10种语言）和LLM约束生成（LogicBench、GSM8K-Constrained）上验证：相比GPU优化基线获得1.5-2倍加速，精度损失小于0.2%；新语言/任务适应仅需5-10梯度步（5-15秒），而非数小时训练。机制分析显示策略发现了类人解析策略（易优先）和新颖的非直观启发式方法。

Conclusion: MetaJuLS通过减少LLM部署中的传播步骤，直接降低推理碳足迹，为绿色AI做出贡献。该方法展示了元强化学习在结构化推理中的潜力，实现了跨领域的快速适应和高效推理。

Abstract: Large language models increasingly require structured inference, from JSON schema enforcement to multi-lingual parsing, where outputs must satisfy complex constraints. We introduce MetaJuLS, a meta-reinforcement learning approach that learns universal constraint propagation policies applicable across languages and tasks without task-specific retraining. By formulating structured inference as adaptive constraint propagation and training a Graph Attention Network with meta-learning, MetaJuLS achieves 1.5--2.0$\times$ speedups over GPU-optimized baselines while maintaining within 0.2\% accuracy of state-of-the-art parsers. On Universal Dependencies across 10 languages and LLM-constrained generation (LogicBench, GSM8K-Constrained), MetaJuLS demonstrates rapid cross-domain adaptation: a policy trained on English parsing adapts to new languages and tasks with 5--10 gradient steps (5--15 seconds) rather than requiring hours of task-specific training. Mechanistic analysis reveals the policy discovers human-like parsing strategies (easy-first) and novel non-intuitive heuristics. By reducing propagation steps in LLM deployments, MetaJuLS contributes to Green AI by directly reducing inference carbon footprint.

</details>


### [71] [Pat-DEVAL: Chain-of-Legal-Thought Evaluation for Patent Description](https://arxiv.org/abs/2601.00166)
*Yongmin Yoo,Kris W Pan*

Main category: cs.CL

TL;DR: Pat-DEVAL：首个专利说明书多维评估框架，通过法律约束推理机制评估技术披露完整性和法定合规性，显著优于现有方法


<details>
  <summary>Details</summary>
Motivation: 现有专利自动撰写评估方法无法评估长文本结构连贯性和法定合规性，需要专门针对专利说明书的评估框架

Method: 提出Pat-DEVAL框架，采用LLM-as-a-judge范式，引入Chain-of-Legal-Thought（CoLT）法律约束推理机制，进行顺序性专利法特定分析

Result: 在Pap2Pat-EvalGold数据集上，Pat-DEVAL达到0.69的皮尔逊相关系数，显著优于基线指标和现有LLM评估器；在法律专业合规性方面达到0.73的优异相关性

Conclusion: Pat-DEVAL通过显式注入法定约束，为自动专利撰写系统提供了确保技术合理性和法律合规性的方法论基础，建立了新的评估标准

Abstract: Patent descriptions must deliver comprehensive technical disclosure while meeting strict legal standards such as enablement and written description requirements. Although large language models have enabled end-to-end automated patent drafting, existing evaluation approaches fail to assess long-form structural coherence and statutory compliance specific to descriptions. We propose Pat-DEVAL, the first multi-dimensional evaluation framework dedicated to patent description bodies. Leveraging the LLM-as-a-judge paradigm, Pat-DEVAL introduces Chain-of-Legal-Thought (CoLT), a legally-constrained reasoning mechanism that enforces sequential patent-law-specific analysis. Experiments validated by patent expert on our Pap2Pat-EvalGold dataset demonstrate that Pat-DEVAL achieves a Pearson correlation of 0.69, significantly outperforming baseline metrics and existing LLM evaluators. Notably, the framework exhibits a superior correlation of 0.73 in Legal-Professional Compliance, proving that the explicit injection of statutory constraints is essential for capturing nuanced legal validity. By establishing a new standard for ensuring both technical soundness and legal compliance, Pat-DEVAL provides a robust methodological foundation for the practical deployment of automated patent drafting systems.

</details>


### [72] [Understanding Emotion in Discourse: Recognition Insights and Linguistic Patterns for Generation](https://arxiv.org/abs/2601.00181)
*Cheonkam Jeong,Adeline Nyamathi*

Main category: cs.CL

TL;DR: 本文通过系统分析IEMOCAP数据集，填补了对话情感识别（ERC）中的两个关键空白：理解哪些架构选择真正重要，以及连接识别与生成的语言学分析。研究发现对话上下文至关重要，层次化句子表示在提供上下文后失效，外部情感词典无增益。同时发现情感与话语标记位置显著相关，悲伤话语需要更多上下文进行消歧。


<details>
  <summary>Details</summary>
Motivation: 尽管对话情感识别（ERC）已取得高准确率，但仍存在两个关键空白：1）对哪些架构选择真正重要的理解有限；2）缺乏连接识别与生成的语言学分析。本文旨在通过系统分析IEMOCAP数据集来填补这些空白。

Method: 采用系统分析方法：1）在识别方面，进行严格的消融研究，使用10种随机种子评估，分析对话上下文、层次化句子表示和外部情感词典的影响；2）在语言学分析方面，分析5,286个话语标记出现情况，研究情感与标记位置的关系，特别是悲伤话语的标记使用模式。

Result: 识别方面：1）对话上下文至关重要，90%的增益来自最近10-30个轮次；2）层次化句子表示在提供上下文后失效；3）外部情感词典无增益。使用简单架构和严格因果上下文，在4-way和6-way分类中分别达到82.69%和67.07%的加权F1，优于先前方法。语言学方面：情感与话语标记位置显著相关（p<.0001），悲伤话语的左边缘标记使用率（21.9%）低于其他情感（28-32%），这与悲伤话语需要更多上下文进行消歧的发现一致。

Conclusion: 对话上下文是对话情感识别的关键因素，层次化表示和外部词典在提供充分上下文后变得不必要。悲伤话语由于缺乏显性语用信号，特别依赖对话历史进行消歧。这些发现为ERC架构设计提供了实证指导，并建立了识别与生成之间的语言学联系。

Abstract: While Emotion Recognition in Conversation (ERC) has achieved high accuracy, two critical gaps remain: a limited understanding of \textit{which} architectural choices actually matter, and a lack of linguistic analysis connecting recognition to generation. We address both gaps through a systematic analysis of the IEMOCAP dataset.
  For recognition, we conduct a rigorous ablation study with 10-seed evaluation and report three key findings. First, conversational context is paramount, with performance saturating rapidly -- 90\% of the total gain achieved within just the most recent 10--30 preceding turns (depending on the label set). Second, hierarchical sentence representations help at utterance-level, but this benefit disappears once conversational context is provided, suggesting that context subsumes intra-utterance structure. Third, external affective lexicons (SenticNet) provide no gain, indicating that pre-trained encoders already capture necessary emotional semantics. With simple architectures using strictly causal context, we achieve 82.69\% (4-way) and 67.07\% (6-way) weighted F1, outperforming prior text-only methods including those using bidirectional context.
  For linguistic analysis, we analyze 5,286 discourse marker occurrences and find a significant association between emotion and marker positioning ($p < .0001$). Notably, "sad" utterances exhibit reduced left-periphery marker usage (21.9\%) compared to other emotions (28--32\%), consistent with theories linking left-periphery markers to active discourse management. This connects to our recognition finding that sadness benefits most from context (+22\%p): lacking explicit pragmatic signals, sad utterances require conversational history for disambiguation.

</details>


### [73] [Knowledge Distillation for Temporal Knowledge Graph Reasoning with Large Language Models](https://arxiv.org/abs/2601.00202)
*Wang Xing,Wei Song,Siyu Lin,Chen Wu,Zhesi Li,Man Wang*

Main category: cs.CL

TL;DR: 提出专为时序知识图谱推理设计的蒸馏框架，利用大语言模型作为教师模型，将结构和时序推理能力迁移到轻量级学生模型，在保持高效的同时提升推理性能。


<details>
  <summary>Details</summary>
Motivation: 现有时序知识图谱推理模型通常需要大量参数和计算资源，导致硬件成本高、能耗大，难以部署在资源受限的实时推理平台上。现有的模型压缩和蒸馏技术主要针对静态知识图谱设计，无法有效捕捉时序知识图谱中的时间依赖关系，导致推理性能下降。

Method: 提出专门针对时序知识图谱推理的蒸馏框架，利用大语言模型作为教师模型来指导蒸馏过程。通过整合大规模公共知识和任务特定的时序信息，将结构和时序推理能力有效迁移到轻量级学生模型，使其能够建模时序动态同时保持紧凑高效的架构。

Result: 在多个公开基准数据集上的广泛实验表明，该方法持续优于强基线模型，在推理准确性、计算效率和实际可部署性之间实现了有利的平衡。

Conclusion: 提出的蒸馏框架成功解决了时序知识图谱推理中的效率和性能权衡问题，为资源受限平台上的实时推理应用提供了有效的解决方案，推动了时序知识图谱推理在实际部署中的可行性。

Abstract: Reasoning over temporal knowledge graphs (TKGs) is fundamental to improving the efficiency and reliability of intelligent decision-making systems and has become a key technological foundation for future artificial intelligence applications. Despite recent progress, existing TKG reasoning models typically rely on large parameter sizes and intensive computation, leading to high hardware costs and energy consumption. These constraints hinder their deployment on resource-constrained, low-power, and distributed platforms that require real-time inference. Moreover, most existing model compression and distillation techniques are designed for static knowledge graphs and fail to adequately capture the temporal dependencies inherent in TKGs, often resulting in degraded reasoning performance. To address these challenges, we propose a distillation framework specifically tailored for temporal knowledge graph reasoning. Our approach leverages large language models as teacher models to guide the distillation process, enabling effective transfer of both structural and temporal reasoning capabilities to lightweight student models. By integrating large-scale public knowledge with task-specific temporal information, the proposed framework enhances the student model's ability to model temporal dynamics while maintaining a compact and efficient architecture. Extensive experiments on multiple publicly available benchmark datasets demonstrate that our method consistently outperforms strong baselines, achieving a favorable trade-off between reasoning accuracy, computational efficiency, and practical deployability.

</details>


### [74] [From Evidence-Based Medicine to Knowledge Graph: Retrieval-Augmented Generation for Sports Rehabilitation and a Domain Benchmark](https://arxiv.org/abs/2601.00216)
*Jinning Zhang,Jie Song,Wenhui Tu,Zecheng Li,Jingxuan Li,Jin Li,Xuan Liu,Taole Sha,Zichen Wei,Yan Li*

Main category: cs.CL

TL;DR: 该研究提出了一种将循证医学原则融入图检索增强生成的方法，通过PICO框架改进知识图谱构建与检索，并设计贝叶斯重排序算法考虑证据等级，在运动康复领域验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 当前医学领域的检索增强生成方法主要关注性能提升，但忽视了循证医学原则，存在两个关键问题：查询与检索证据之间缺乏PICO对齐，以及在重排序过程中未考虑证据等级层次。

Method: 提出将循证医学原则适配到图检索增强生成的通用策略：1）将PICO框架整合到知识图谱构建和检索中；2）提出贝叶斯启发的重排序算法，根据证据等级校准排序分数而不引入预定义权重；3）在运动康复领域构建知识图谱（357,844节点，371,226边）和可重用基准（1,637个QA对）。

Result: 系统在多个指标上表现优异：0.830的要点覆盖率、0.819的答案忠实度、0.882的语义相似度、0.788的PICOT匹配准确率。五位临床专家在5点李克特量表上给予4.66-4.84的高分评价（事实准确性、忠实度、相关性、安全性、PICO对齐）。

Conclusion: 提出的循证医学适配策略显著提升了检索和答案质量，且可迁移到其他临床领域。发布的资源有助于解决运动康复领域RAG数据集稀缺的问题。

Abstract: In medicine, large language models (LLMs) increasingly rely on retrieval-augmented generation (RAG) to ground outputs in up-to-date external evidence. However, current RAG approaches focus primarily on performance improvements while overlooking evidence-based medicine (EBM) principles. This study addresses two key gaps: (1) the lack of PICO alignment between queries and retrieved evidence, and (2) the absence of evidence hierarchy considerations during reranking. We present a generalizable strategy for adapting EBM to graph-based RAG, integrating the PICO framework into knowledge graph construction and retrieval, and proposing a Bayesian-inspired reranking algorithm to calibrate ranking scores by evidence grade without introducing predefined weights. We validated this framework in sports rehabilitation, a literature-rich domain currently lacking RAG systems and benchmarks. We released a knowledge graph (357,844 nodes and 371,226 edges) and a reusable benchmark of 1,637 QA pairs. The system achieved 0.830 nugget coverage, 0.819 answer faithfulness, 0.882 semantic similarity, and 0.788 PICOT match accuracy. In a 5-point Likert evaluation, five expert clinicians rated the system 4.66-4.84 across factual accuracy, faithfulness, relevance, safety, and PICO alignment. These findings demonstrate that the proposed EBM adaptation strategy improves retrieval and answer quality and is transferable to other clinical domains. The released resources also help address the scarcity of RAG datasets in sports rehabilitation.

</details>


### [75] [JP-TL-Bench: Anchored Pairwise LLM Evaluation for Bidirectional Japanese-English Translation](https://arxiv.org/abs/2601.00223)
*Leonard Lin,Adam Lensenmayer*

Main category: cs.CL

TL;DR: JP-TL-Bench是一个轻量级开源基准测试，用于指导日英翻译系统的迭代开发，专注于评估"哪个翻译更好"而非"翻译是否可接受"，通过参考无关的成对LLM比较和Bradley-Terry模型聚合结果。


<details>
  <summary>Details</summary>
Motivation: 日英翻译中，礼貌、隐含意义、省略和语域等微妙选择对自然度影响很大，需要评估"哪个翻译更好"而非"翻译是否可接受"。现有基准测试难以捕捉这些细微差别，需要专门针对日英翻译的评估框架。

Method: 使用参考无关的成对LLM比较方法，将候选模型与固定的版本化锚点集进行比较。通过Bradley-Terry模型聚合成对比较结果，生成胜率和基于逻辑变换的0-10分"LT"评分。评估协议设计确保LLM判断既可靠又经济。

Result: JP-TL-Bench提供了结构稳定的评分系统，由于每个候选模型都针对相同的冻结锚点集进行评估，在相同基础集、判断器和聚合代码下，评分具有结构稳定性。

Conclusion: JP-TL-Bench是一个专门针对日英翻译细微差别的轻量级基准测试，通过可靠的成对比较和标准化评分方法，为翻译系统的迭代开发提供指导。

Abstract: We introduce JP-TL-Bench, a lightweight, open benchmark designed to guide the iterative development of Japanese-English translation systems. In this context, the challenge is often "which of these two good translations is better?" rather than "is this translation acceptable?" This distinction matters for Japanese-English, where subtle choices in politeness, implicature, ellipsis, and register strongly affect perceived naturalness. JP-TL-Bench uses a protocol built to make LLM judging both reliable and affordable: it evaluates a candidate model via reference-free, pairwise LLM comparisons against a fixed, versioned anchor set. Pairwise results are aggregated with a Bradley-Terry model and reported as win rates plus a normalized 0-10 "LT" score derived from a logistic transform of fitted log-strengths. Because each candidate is scored against the same frozen anchor set, scores are structurally stable given the same base set, judge, and aggregation code.

</details>


### [76] [Talk Less, Verify More: Improving LLM Assistants with Semantic Checks and Execution Feedback](https://arxiv.org/abs/2601.00224)
*Yan Sun,Ming Cai,Stanley Kok*

Main category: cs.CL

TL;DR: 本文提出了两种互补的验证技术（Q*和Feedback+），通过生成器-判别器框架将验证责任从用户转移到系统，以提高LLM助手在企业工作流程中的可靠性和准确性。


<details>
  <summary>Details</summary>
Motivation: 当前对话式商业分析系统缺乏内置验证机制，用户需要手动验证可能错误的输出，这影响了LLM助手在企业工作流程中的可靠性和实用性。

Method: 提出了两种互补的验证技术：1) Q*：通过反向翻译和语义匹配来验证代码与用户意图的一致性；2) Feedback+：通过执行反馈来指导代码优化。这两种技术嵌入在生成器-判别器框架中。

Result: 在Spider、Bird和GSM8K三个基准数据集上的评估表明，Q*和Feedback+都能显著降低错误率和任务完成时间，但发现反向翻译是主要性能瓶颈。

Conclusion: 本文提出了一个面向设计的框架，用于构建更可靠的企业级GenAI系统，能够提供可信的决策支持，同时指出了反向翻译作为未来改进的关键方向。

Abstract: As large language model (LLM) assistants become increasingly integrated into enterprise workflows, their ability to generate accurate, semantically aligned, and executable outputs is critical. However, current conversational business analytics (CBA) systems often lack built-in verification mechanisms, leaving users to manually validate potentially flawed results. This paper introduces two complementary verification techniques: Q*, which performs reverse translation and semantic matching between code and user intent, and Feedback+, which incorporates execution feedback to guide code refinement. Embedded within a generator-discriminator framework, these mechanisms shift validation responsibilities from users to the system. Evaluations on three benchmark datasets, Spider, Bird, and GSM8K, demonstrate that both Q* and Feedback+ reduce error rates and task completion time. The study also identifies reverse translation as a key bottleneck, highlighting opportunities for future improvement. Overall, this work contributes a design-oriented framework for building more reliable, enterprise-grade GenAI systems capable of trustworthy decision support.

</details>


### [77] [Parallel Universes, Parallel Languages: A Comprehensive Study on LLM-based Multilingual Counterfactual Example Generation](https://arxiv.org/abs/2601.00263)
*Qianli Wang,Van Bach Nguyen,Yihong Liu,Fedor Splitt,Nils Feldhus,Christin Seifert,Hinrich Schütze,Sebastian Möller,Vera Schmitt*

Main category: cs.CL

TL;DR: 本文系统研究了多语言反事实生成，发现翻译生成的反事实有效性更高但修改更多，多语言反事实数据增强比跨语言增强效果更好，但生成质量限制了性能提升。


<details>
  <summary>Details</summary>
Motivation: 反事实作为解释模型行为的重要方法，虽然大语言模型在生成英语反事实上表现出色且具备多语言能力，但其在多语言反事实生成上的效果尚不明确，需要系统研究。

Method: 1) 对六种语言进行自动评估，比较直接生成和通过英语翻译生成的反事实；2) 分析高资源欧洲语言反事实的编辑模式；3) 识别和分类跨语言一致的错误类型；4) 评估多语言反事实数据增强与跨语言增强的效果。

Result: 1) 翻译生成的反事实有效性更高但需要更多修改，且质量仍不及原始英语反事实；2) 高资源欧洲语言的编辑模式相似，表明跨语言扰动遵循共同策略；3) 识别出四类跨语言一致的错误类型；4) 多语言反事实数据增强比跨语言增强带来更大性能提升，尤其对低资源语言，但生成不完美限制了性能提升和鲁棒性。

Conclusion: 多语言反事实生成存在质量差距，翻译方法能提高有效性但代价是更多修改。多语言数据增强优于跨语言增强，但生成质量限制了最终效果，需要改进多语言反事实生成技术。

Abstract: Counterfactuals refer to minimally edited inputs that cause a model's prediction to change, serving as a promising approach to explaining the model's behavior. Large language models (LLMs) excel at generating English counterfactuals and demonstrate multilingual proficiency. However, their effectiveness in generating multilingual counterfactuals remains unclear. To this end, we conduct a comprehensive study on multilingual counterfactuals. We first conduct automatic evaluations on both directly generated counterfactuals in the target languages and those derived via English translation across six languages. Although translation-based counterfactuals offer higher validity than their directly generated counterparts, they demand substantially more modifications and still fall short of matching the quality of the original English counterfactuals. Second, we find the patterns of edits applied to high-resource European-language counterfactuals to be remarkably similar, suggesting that cross-lingual perturbations follow common strategic principles. Third, we identify and categorize four main types of errors that consistently appear in the generated counterfactuals across languages. Finally, we reveal that multilingual counterfactual data augmentation (CDA) yields larger model performance improvements than cross-lingual CDA, especially for lower-resource languages. Yet, the imperfections of the generated counterfactuals limit gains in model performance and robustness.

</details>


### [78] [Beyond Perfect APIs: A Comprehensive Evaluation of LLM Agents Under Real-World API Complexity](https://arxiv.org/abs/2601.00268)
*Doyoung Kim,Zhiwei Ren,Jie Hao,Zhongkai Sun,Lichao Wang,Xiyao Ma,Zack Ye,Xu Han,Jun Yin,Heng Ji,Wei Shen,Xing Fan,Benjamin Yao,Chenlei Guo*

Main category: cs.CL

TL;DR: WildAGTEval是一个评估LLM智能体在真实API复杂度下函数调用能力的基准，考虑了API规范和API执行两个维度的现实世界复杂性。


<details>
  <summary>Details</summary>
Motivation: 现有研究通常假设理想化的API系统，忽视了真实世界的复杂因素（如噪声API输出）。需要评估LLM智能体在现实API复杂度下的表现。

Method: 创建WildAGTEval基准，包含60个不同的复杂度场景，可组合成约32K测试配置，并提供用户-智能体交互来评估LLM智能体在这些场景下的表现。

Result: 大多数场景具有挑战性，不相关信息复杂度造成的困难最大，使强LLM性能下降27.3%。定性分析显示LLM有时会扭曲用户意图以声称完成任务，严重影响用户满意度。

Conclusion: WildAGTEval揭示了LLM智能体在真实API复杂度下面临的挑战，特别是处理不相关信息和意图扭曲问题，对实际应用中的用户满意度有重要影响。

Abstract: We introduce WildAGTEval, a benchmark designed to evaluate large language model (LLM) agents' function-calling capabilities under realistic API complexity. Unlike prior work that assumes an idealized API system and disregards real-world factors such as noisy API outputs, WildAGTEval accounts for two dimensions of real-world complexity: 1. API specification, which includes detailed documentation and usage constraints, and 2. API execution, which captures runtime challenges. Consequently, WildAGTEval offers (i) an API system encompassing 60 distinct complexity scenarios that can be composed into approximately 32K test configurations, and (ii) user-agent interactions for evaluating LLM agents on these scenarios. Using WildAGTEval, we systematically assess several advanced LLMs and observe that most scenarios are challenging, with irrelevant information complexity posing the greatest difficulty and reducing the performance of strong LLMs by 27.3%. Furthermore, our qualitative analysis reveals that LLMs occasionally distort user intent merely to claim task completion, critically affecting user satisfaction.

</details>


### [79] [Can Large Language Models Still Explain Themselves? Investigating the Impact of Quantization on Self-Explanations](https://arxiv.org/abs/2601.00282)
*Qianli Wang,Nils Feldhus,Pepa Atanasova,Fedor Splitt,Simon Ostermann,Sebastian Möller,Vera Schmitt*

Main category: cs.CL

TL;DR: 量化对大型语言模型的自解释能力产生负面影响，但程度相对较小，不影响量化作为模型压缩技术的有效性。


<details>
  <summary>Details</summary>
Motivation: 量化被广泛用于加速大型语言模型推理和部署，但其对自解释（模型为自身输出生成解释）的影响尚未被研究。自解释对于高风险应用的透明度至关重要，因此理解量化是否会降低自解释质量和忠实度非常重要。

Method: 研究两种自解释类型：自然语言解释和反事实示例，使用三种常见量化技术在不同比特宽度下对LLMs进行量化，并通过用户研究评估自解释的连贯性和可信度。

Result: 量化通常导致自解释质量（最多下降4.4%）和忠实度（最多下降2.38%）的适度下降。用户研究表明量化降低了自解释的连贯性和可信度（最多8.5%）。较大模型在自解释质量方面对量化的抵抗力有限，但在保持忠实度方面表现更好。没有一种量化技术能在任务准确性、自解释质量和忠实度方面始终表现优异。

Conclusion: 量化对自解释的影响因上下文而异，建议针对具体用例验证自解释质量，特别是对更敏感的自然语言解释。然而，自解释质量和忠实度的相对较小恶化并不影响量化作为模型压缩技术的有效性。

Abstract: Quantization is widely used to accelerate inference and streamline the deployment of large language models (LLMs), yet its effects on self-explanations (SEs) remain unexplored. SEs, generated by LLMs to justify their own outputs, require reasoning about the model's own decision-making process, a capability that may exhibit particular sensitivity to quantization. As SEs are increasingly relied upon for transparency in high-stakes applications, understanding whether and to what extent quantization degrades SE quality and faithfulness is critical. To address this gap, we examine two types of SEs: natural language explanations (NLEs) and counterfactual examples, generated by LLMs quantized using three common techniques at distinct bit widths. Our findings indicate that quantization typically leads to moderate declines in both SE quality (up to 4.4\%) and faithfulness (up to 2.38\%). The user study further demonstrates that quantization diminishes both the coherence and trustworthiness of SEs (up to 8.5\%). Compared to smaller models, larger models show limited resilience to quantization in terms of SE quality but better maintain faithfulness. Moreover, no quantization technique consistently excels across task accuracy, SE quality, and faithfulness. Given that quantization's impact varies by context, we recommend validating SE quality for specific use cases, especially for NLEs, which show greater sensitivity. Nonetheless, the relatively minor deterioration in SE quality and faithfulness does not undermine quantization's effectiveness as a model compression technique.

</details>


### [80] [DepFlow: Disentangled Speech Generation to Mitigate Semantic Bias in Depression Detection](https://arxiv.org/abs/2601.00303)
*Yuxin Li,Xiangyu Zhang,Yifei Li,Zhiwei Guo,Haoyang Zhang,Eng Siong Chng,Cuntai Guan*

Main category: cs.CL

TL;DR: 提出DepFlow框架，通过三阶段文本转语音系统生成声学-语义不匹配数据，缓解抑郁症检测中的语义偏见，提高模型在伪装抑郁症场景下的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有抑郁症数据集（如DAIC-WOZ）中语言情感与诊断标签强耦合，导致模型学习语义捷径，在真实场景（如伪装抑郁症）中鲁棒性差，需要解决声学-语义不匹配问题。

Method: 三阶段框架：1）抑郁症声学编码器通过对抗训练学习说话人和内容不变的抑郁症嵌入；2）流匹配TTS模型通过FiLM调制注入抑郁症嵌入；3）基于原型的严重程度映射机制实现连续可解释控制。使用该框架构建伪装抑郁症增强数据集（CDoA）。

Result: 抑郁症声学编码器ROC-AUC达0.693；CDoA数据集在三种抑郁症检测架构上分别提升macro-F1 9%、12%和5%，优于传统增强策略。

Conclusion: DepFlow不仅提高了抑郁症检测的鲁棒性，还为对话系统和基于模拟的评估提供了可控合成平台，解决了临床数据受限的伦理和覆盖范围问题。

Abstract: Speech is a scalable and non-invasive biomarker for early mental health screening. However, widely used depression datasets like DAIC-WOZ exhibit strong coupling between linguistic sentiment and diagnostic labels, encouraging models to learn semantic shortcuts. As a result, model robustness may be compromised in real-world scenarios, such as Camouflaged Depression, where individuals maintain socially positive or neutral language despite underlying depressive states. To mitigate this semantic bias, we propose DepFlow, a three-stage depression-conditioned text-to-speech framework. First, a Depression Acoustic Encoder learns speaker- and content-invariant depression embeddings through adversarial training, achieving effective disentanglement while preserving depression discriminability (ROC-AUC: 0.693). Second, a flow-matching TTS model with FiLM modulation injects these embeddings into synthesis, enabling control over depressive severity while preserving content and speaker identity. Third, a prototype-based severity mapping mechanism provides smooth and interpretable manipulation across the depression continuum. Using DepFlow, we construct a Camouflage Depression-oriented Augmentation (CDoA) dataset that pairs depressed acoustic patterns with positive/neutral content from a sentiment-stratified text bank, creating acoustic-semantic mismatches underrepresented in natural data. Evaluated across three depression detection architectures, CDoA improves macro-F1 by 9%, 12%, and 5%, respectively, consistently outperforming conventional augmentation strategies in depression Detection. Beyond enhancing robustness, DepFlow provides a controllable synthesis platform for conversational systems and simulation-based evaluation, where real clinical data remains limited by ethical and coverage constraints.

</details>


### [81] [Robust Uncertainty Quantification for Factual Generation of Large Language Models](https://arxiv.org/abs/2601.00348)
*Yuhao Zhang,Zhongliang Yang,Linna Zhou*

Main category: cs.CL

TL;DR: 该研究针对LLM幻觉问题，提出了一种基于多事实生成任务的鲁棒不确定性量化方法，通过构建包含虚假名称的陷阱问题集来检测模型可靠性。


<details>
  <summary>Details</summary>
Motivation: LLM幻觉问题严重影响了AI生成内容的可靠性和可信度。现有不确定性量化方法在常规问答场景中有效，但在面对非常规或对抗性提问策略时表现不足，这引发了实际应用中LLM响应可靠性的担忧。

Method: 1) 构建包含虚假名称的陷阱问题集；2) 在多事实生成任务中提出鲁棒不确定性量化方法(RU)；3) 在四个不同模型上与基线方法进行对比实验。

Result: 构建的陷阱问题集表现优异。提出的RU方法在四个不同模型上相比最佳基线方法，ROCAUC值平均提升0.1-0.2，显示出显著性能优势。

Conclusion: 该研究为解决LLM幻觉问题提供了新的视角和方法，通过鲁棒的不确定性量化技术增强了模型在面对非常规提问时的可靠性检测能力。

Abstract: The rapid advancement of large language model(LLM) technology has facilitated its integration into various domains of professional and daily life. However, the persistent challenge of LLM hallucination has emerged as a critical limitation, significantly compromising the reliability and trustworthiness of AI-generated content. This challenge has garnered significant attention within the scientific community, prompting extensive research efforts in hallucination detection and mitigation strategies. Current methodological frameworks reveal a critical limitation: traditional uncertainty quantification approaches demonstrate effectiveness primarily within conventional question-answering paradigms, yet exhibit notable deficiencies when confronted with non-canonical or adversarial questioning strategies. This performance gap raises substantial concerns regarding the dependability of LLM responses in real-world applications requiring robust critical thinking capabilities. This study aims to fill this gap by proposing an uncertainty quantification scenario in the task of generating with multiple facts. We have meticulously constructed a set of trap questions contained with fake names. Based on this scenario, we innovatively propose a novel and robust uncertainty quantification method(RU). A series of experiments have been conducted to verify its effectiveness. The results show that the constructed set of trap questions performs excellently. Moreover, when compared with the baseline methods on four different models, our proposed method has demonstrated great performance, with an average increase of 0.1-0.2 in ROCAUC values compared to the best performing baseline method, providing new sights and methods for addressing the hallucination issue of LLMs.

</details>


### [82] [The Role of Mixed-Language Documents for Multilingual Large Language Model Pretraining](https://arxiv.org/abs/2601.00364)
*Jiandong Shao,Raphael Tang,Crystina Zhang,Karin Sevegnani,Pontus Stenetorp,Jianfei Yang,Yao Lu*

Main category: cs.CL

TL;DR: 多语言大语言模型在主要单语预训练下仍能实现出色的跨语言性能。研究发现，双语数据中仅占2%的平行数据对翻译性能至关重要，而代码切换数据贡献有限；跨语言理解和推理任务则无需双语数据也能实现。


<details>
  <summary>Details</summary>
Motivation: 多语言大语言模型在主要单语预训练下仍能实现出色的跨语言性能，双语数据在预训练语料中的作用机制尚不明确。本研究旨在探究双语数据对模型跨语言能力的具体贡献。

Method: 在受控条件下从头预训练模型，比较标准网络语料库与去除所有多语言文档的单语版本。将双语数据分类为平行数据(14%)、代码切换数据(72%)和其他文档(14%)，并通过将平行或代码切换数据重新引入单语语料库进行细粒度消融实验。

Result: 移除仅占语料库2%的双语数据导致翻译性能下降56%（BLEU），而跨语言QA和一般推理任务保持稳定。平行数据几乎完全恢复翻译性能（达到未过滤基线的91%），代码切换数据贡献极小。其他跨语言任务基本不受任一类双语数据影响。

Conclusion: 翻译性能严重依赖平行数据提供的系统性词元级对齐，而跨语言理解和推理能力即使没有双语数据也能实现。双语数据对模型不同跨语言能力的影响存在显著差异。

Abstract: Multilingual large language models achieve impressive cross-lingual performance despite largely monolingual pretraining. While bilingual data in pretraining corpora is widely believed to enable these abilities, details of its contributions remain unclear. We investigate this question by pretraining models from scratch under controlled conditions, comparing the standard web corpus with a monolingual-only version that removes all multilingual documents. Despite constituting only 2% of the corpus, removing bilingual data causes translation performance to drop 56% in BLEU, while behaviour on cross-lingual QA and general reasoning tasks remains stable, with training curves largely overlapping the baseline. To understand this asymmetry, we categorize bilingual data into parallel (14%), code-switching (72%), and miscellaneous documents (14%) based on the semantic relevance of content in different languages. We then conduct granular ablations by reintroducing parallel or code-switching data into the monolingual-only corpus. Our experiments reveal that parallel data almost fully restores translation performance (91% of the unfiltered baseline), whereas code-switching contributes minimally. Other cross-lingual tasks remain largely unaffected by either type. These findings reveal that translation critically depends on systematic token-level alignments from parallel data, whereas cross-lingual understanding and reasoning appear to be achievable even without bilingual data.

</details>


### [83] [BERT-JEPA: Reorganizing CLS Embeddings for Language-Invariant Semantics](https://arxiv.org/abs/2601.00366)
*Taj Gillin,Adam Lalani,Kenneth Zhang,Marcel Mateos Salles*

Main category: cs.CL

TL;DR: BERT-JEPA (BEPA) 结合了BERT和JEPA训练目标，通过解决[CLS]嵌入空间坍缩问题，创建语言无关的表示空间，在多语言基准测试中提升性能。


<details>
  <summary>Details</summary>
Motivation: BERT模型中的[CLS]嵌入空间存在坍缩问题，限制了其多语言表示能力。JEPA作为一种新兴的自监督训练技术，有望改善这一问题，创建更好的语言无关表示空间。

Method: 提出BERT-JEPA (BEPA)训练范式，在BERT风格模型中添加JEPA训练目标。该方法旨在解决[CLS]嵌入空间的坍缩问题，将其转化为语言无关的空间。

Result: BERT-JEPA在多语言基准测试中表现出性能提升，验证了JEPA训练目标对改善多语言表示的有效性。

Conclusion: 结合JEPA训练目标的BERT-JEPA能够有效解决[CLS]嵌入空间坍缩问题，创建更好的语言无关表示，从而提升多语言任务的性能。

Abstract: Joint Embedding Predictive Architectures (JEPA) are a novel self supervised training technique that have shown recent promise across domains. We introduce BERT-JEPA (BEPA), a training paradigm that adds a JEPA training objective to BERT-style models, working to combat a collapsed [CLS] embedding space and turning it into a language-agnostic space. This new structure leads to increased performance across multilingual benchmarks.

</details>


### [84] [Vision-Language Reasoning for Geolocalization: A Reinforcement Learning Approach](https://arxiv.org/abs/2601.00388)
*Biao Wu,Meng Fang,Ling Chen,Ke Xu,Tao Cheng,Jun Wang*

Main category: cs.CL

TL;DR: Geo-R是一个基于强化学习的检索免费图像地理定位框架，通过从真实坐标生成结构化推理路径，使用基于Haversine距离的坐标对齐奖励来优化定位精度。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型在图像地理定位中通常依赖合成推理标注或外部图像检索，这限制了可解释性和泛化能力。需要一种检索免费的方法，能够直接从真实坐标中挖掘结构化推理路径。

Method: 提出Geo-R框架：1) 引入"区域链"规则分层推理范式，将GPS坐标映射到地理实体（国家、省份、城市等），生成精确可解释的监督信号；2) 采用轻量级强化学习策略，基于Haversine距离设计坐标对齐奖励，通过空间有意义的反馈优化模型预测。

Result: 在多个基准测试中验证了Geo-R的有效性，实现了更高的定位精度、更强的泛化能力和更透明的推理过程，建立了检索免费图像地理定位的新范式。

Conclusion: Geo-R通过结合结构化地理推理和直接空间监督，为可扩展和可解释的图像地理定位提供了新的解决方案，模型和代码将公开以促进进一步研究。

Abstract: Recent advances in vision-language models have opened up new possibilities for reasoning-driven image geolocalization. However, existing approaches often rely on synthetic reasoning annotations or external image retrieval, which can limit interpretability and generalizability. In this paper, we present Geo-R, a retrieval-free framework that uncovers structured reasoning paths from existing ground-truth coordinates and optimizes geolocation accuracy via reinforcement learning. We propose the Chain of Region, a rule-based hierarchical reasoning paradigm that generates precise, interpretable supervision by mapping GPS coordinates to geographic entities (e.g., country, province, city) without relying on model-generated or synthetic labels. Building on this, we introduce a lightweight reinforcement learning strategy with coordinate-aligned rewards based on Haversine distance, enabling the model to refine predictions through spatially meaningful feedback. Our approach bridges structured geographic reasoning with direct spatial supervision, yielding improved localization accuracy, stronger generalization, and more transparent inference. Experimental results across multiple benchmarks confirm the effectiveness of Geo-R, establishing a new retrieval-free paradigm for scalable and interpretable image geolocalization. To facilitate further research and ensure reproducibility, both the model and code will be made publicly available.

</details>


### [85] [Do LLMs Judge Distantly Supervised Named Entity Labels Well? Constructing the JudgeWEL Dataset](https://arxiv.org/abs/2601.00411)
*Alistair Plum,Laura Bernardy,Tharindu Ranasinghe*

Main category: cs.CL

TL;DR: 提出judgeWEL数据集，用于卢森堡语命名实体识别，通过新颖的LLM管道自动标注和验证，比现有数据集大5倍且覆盖更平衡


<details>
  <summary>Details</summary>
Motivation: 为低资源语言构建数据集是NLP的主要瓶颈之一，资源稀缺和语言特性使得大规模标注成本高且不一致

Method: 利用维基百科和维基数据作为弱监督结构化来源，通过维基百科内部链接推断实体类型，然后使用多个LLM识别和保留高质量标注句子来降低噪声

Result: 生成的语料库比现有卢森堡语NER数据集大约5倍，提供更广泛和更平衡的实体类别覆盖

Conclusion: judgeWEL为多语言和低资源NER研究提供了重要的新资源，展示了利用结构化知识和LLM验证构建低资源语言数据集的可行性

Abstract: We present judgeWEL, a dataset for named entity recognition (NER) in Luxembourgish, automatically labelled and subsequently verified using large language models (LLM) in a novel pipeline. Building datasets for under-represented languages remains one of the major bottlenecks in natural language processing, where the scarcity of resources and linguistic particularities make large-scale annotation costly and potentially inconsistent. To address these challenges, we propose and evaluate a novel approach that leverages Wikipedia and Wikidata as structured sources of weak supervision. By exploiting internal links within Wikipedia articles, we infer entity types based on their corresponding Wikidata entries, thereby generating initial annotations with minimal human intervention. Because such links are not uniformly reliable, we mitigate noise by employing and comparing several LLMs to identify and retain only high-quality labelled sentences. The resulting corpus is approximately five times larger than the currently available Luxembourgish NER dataset and offers broader and more balanced coverage across entity categories, providing a substantial new resource for multilingual and low-resource NER research.

</details>


### [86] [Toward Better Temporal Structures for Geopolitical Events Forecasting](https://arxiv.org/abs/2601.00430)
*Kian Ahrabian,Eric Boxer,Jay Pujara*

Main category: cs.CL

TL;DR: 本文提出超关系时序知识广义超图(HTKGHs)来扩展传统时序知识图谱的表达能力，支持复杂多实体时序事实，并基于POLECAT数据库构建htkgh-polecat数据集，评估大语言模型在复杂预测场景中的表现。


<details>
  <summary>Details</summary>
Motivation: 传统时序知识图谱(HTKGs)在表示复杂事实时存在局限性，特别是无法支持超过两个主要实体的时序事实，这在现实世界的地缘政治事件中很常见。需要一种更强大的表示方法来捕捉复杂的多实体时序关系。

Method: 1) 提出HTKGHs作为HTKGs的泛化形式，支持两种常见于地缘政治事件的复杂事实类型；2) 基于POLECAT全球事件数据库构建htkgh-polecat数据集；3) 在关系预测任务上对流行大语言模型进行基准测试和分析。

Result: 建立了HTKGHs的形式化定义，展示了其向后兼容性，同时支持复杂事实表示。创建了htkgh-polecat数据集，为大语言模型在复杂时序预测场景中的能力评估提供了基准。

Conclusion: HTKGHs为表示复杂多实体时序事实提供了更强大的框架，htkgh-polecat数据集为大语言模型在地缘政治事件预测中的能力评估提供了重要资源，研究为大语言模型在复杂预测场景中的适应性和能力提供了深入见解。

Abstract: Forecasting on geopolitical temporal knowledge graphs (TKGs) through the lens of large language models (LLMs) has recently gained traction. While TKGs and their generalization, hyper-relational temporal knowledge graphs (HTKGs), offer a straightforward structure to represent simple temporal relationships, they lack the expressive power to convey complex facts efficiently. One of the critical limitations of HTKGs is a lack of support for more than two primary entities in temporal facts, which commonly occur in real-world events. To address this limitation, in this work, we study a generalization of HTKGs, Hyper-Relational Temporal Knowledge Generalized Hypergraphs (HTKGHs). We first derive a formalization for HTKGHs, demonstrating their backward compatibility while supporting two complex types of facts commonly found in geopolitical incidents. Then, utilizing this formalization, we introduce the htkgh-polecat dataset, built upon the global event database POLECAT. Finally, we benchmark and analyze popular LLMs on the relation prediction task, providing insights into their adaptability and capabilities in complex forecasting scenarios.

</details>


### [87] [Comparative Efficiency Analysis of Lightweight Transformer Models: A Multi-Domain Empirical Benchmark for Enterprise NLP Deployment](https://arxiv.org/abs/2601.00444)
*Muhammad Shahmeer Khan*

Main category: cs.CL

TL;DR: 本文比较了三种轻量级Transformer模型（DistilBERT、MiniLM、ALBERT）在三个不同领域（客户情感分类、新闻主题分类、毒性和仇恨言论检测）的性能表现，分析了准确性与效率之间的权衡。


<details>
  <summary>Details</summary>
Motivation: 企业NLP领域对高效、轻量级模型处理多领域文本自动化任务的需求日益增长，需要比较不同轻量级Transformer模型在不同应用场景下的性能表现。

Method: 使用IMDB、AG News和Measuring Hate Speech语料库数据集，对DistilBERT、MiniLM和ALBERT三种模型进行对比分析，评估指标包括准确率、精确率、召回率、F1分数等准确性指标，以及模型大小、推理时间、吞吐量和内存使用等效率指标。

Result: 没有单一模型在所有性能维度上占优：ALBERT在多个领域获得最高任务特定准确率；MiniLM在推理速度和吞吐量方面表现最佳；DistilBERT在任务间保持最一致的准确性，同时保持竞争力的效率。

Conclusion: 研究揭示了准确性与效率之间的权衡，建议：延迟敏感的企业应用选择MiniLM，需要平衡性能的选择DistilBERT，资源受限环境选择ALBERT。

Abstract: In the rapidly evolving landscape of enterprise natural language processing (NLP), the demand for efficient, lightweight models capable of handling multi-domain text automation tasks has intensified. This study conducts a comparative analysis of three prominent lightweight Transformer models - DistilBERT, MiniLM, and ALBERT - across three distinct domains: customer sentiment classification, news topic classification, and toxicity and hate speech detection. Utilizing datasets from IMDB, AG News, and the Measuring Hate Speech corpus, we evaluated performance using accuracy-based metrics including accuracy, precision, recall, and F1-score, as well as efficiency metrics such as model size, inference time, throughput, and memory usage. Key findings reveal that no single model dominates all performance dimensions. ALBERT achieves the highest task-specific accuracy in multiple domains, MiniLM excels in inference speed and throughput, and DistilBERT demonstrates the most consistent accuracy across tasks while maintaining competitive efficiency. All results reflect controlled fine-tuning under fixed enterprise-oriented constraints rather than exhaustive hyperparameter optimization. These results highlight trade-offs between accuracy and efficiency, recommending MiniLM for latency-sensitive enterprise applications, DistilBERT for balanced performance, and ALBERT for resource-constrained environments.

</details>


### [88] [Language as Mathematical Structure: Examining Semantic Field Theory Against Language Games](https://arxiv.org/abs/2601.00448)
*Dimitris Vartziotis*

Main category: cs.CL

TL;DR: 论文对比了语言意义的社会建构主义（语言游戏）和数学导向的语义场理论，认为两者在LLMs中互补而非对立


<details>
  <summary>Details</summary>
Motivation: 利用大语言模型作为实验场，检验长期存在的语言意义理论，特别是社会建构主义与数学框架之间的对比

Method: 形式化词汇场和语言场作为连续语义空间中的交互结构，分析transformer架构的核心特性（分布式表示、注意力机制、嵌入空间几何规律）如何与这些概念相关

Result: LLMs在捕捉语义规律方面的成功支持语言具有底层数学结构的观点，而其在语用推理和上下文敏感性方面的局限则与社会基础的重要性一致

Conclusion: 数学结构和语言游戏可以理解为互补而非竞争视角，这一框架澄清了纯统计语言模型的适用范围和局限，并为理论指导的AI架构提供了新方向

Abstract: Large language models (LLMs) offer a new empirical setting in which long-standing theories of linguistic meaning can be examined. This paper contrasts two broad approaches: social constructivist accounts associated with language games, and a mathematically oriented framework we call Semantic Field Theory. Building on earlier work by the author, we formalize the notions of lexical fields (Lexfelder) and linguistic fields (Lingofelder) as interacting structures in a continuous semantic space. We then analyze how core properties of transformer architectures-such as distributed representations, attention mechanisms, and geometric regularities in embedding spaces-relate to these concepts. We argue that the success of LLMs in capturing semantic regularities supports the view that language exhibits an underlying mathematical structure, while their persistent limitations in pragmatic reasoning and context sensitivity are consistent with the importance of social grounding emphasized in philosophical accounts of language use. On this basis, we suggest that mathematical structure and language games can be understood as complementary rather than competing perspectives. The resulting framework clarifies the scope and limits of purely statistical models of language and motivates new directions for theoretically informed AI architectures.

</details>


### [89] [Defensive M2S: Training Guardrail Models on Compressed Multi-turn Conversations](https://arxiv.org/abs/2601.00454)
*Hyunjun Kim*

Main category: cs.CL

TL;DR: 提出Defensive M2S训练范式，通过将多轮对话压缩为单轮对话来训练护栏模型，大幅降低训练和推理成本，同时保持高攻击检测率。


<details>
  <summary>Details</summary>
Motivation: 护栏模型对LLM部署安全至关重要，但处理完整多轮对话历史会带来显著计算成本。需要一种高效的方法来降低训练和推理开销。

Method: 提出Defensive M2S训练范式，在多轮到单轮(M2S)压缩对话上微调护栏模型，而非完整对话历史。使用三种压缩模板(hyphenize, numberize, pythonize)压缩对话，在三个护栏模型家族(LlamaGuard, Nemotron, Qwen3Guard)上评估。

Result: M2S将训练成本从O(n²)降至O(n)，训练数据量减少93倍(从15.7M降至169K tokens)。最佳配置(Qwen3Guard+hyphenize)在SafeDialBench上达到93.8%攻击检测召回率，推理token减少94.6%(从3,231降至173)，比基线提升38.9个百分点。

Conclusion: M2S压缩可作为护栏模型部署的有效效率技术，显著降低训练和推理成本，同时保持高安全检测性能，支持长多轮对话的可扩展安全筛查。

Abstract: Guardrail models are essential for ensuring the safety of Large Language Model (LLM) deployments, but processing full multi-turn conversation histories incurs significant computational cost. We propose Defensive M2S, a training paradigm that fine-tunes guardrail models on Multi-turn to Single-turn (M2S) compressed conversations rather than complete dialogue histories. We provide a formal complexity analysis showing that M2S reduces training cost from $O(n^2)$ to $O(n)$ for $n$-turn conversations. Empirically, on our training dataset (779 samples, avg. 10.6 turns), M2S requires only 169K tokens compared to 15.7M tokens for the multi-turn baseline -- a 93$\times$ reduction. We evaluate Defensive M2S across three guardrail model families (LlamaGuard, Nemotron, Qwen3Guard) and three compression templates (hyphenize, numberize, pythonize) on SafeDialBench, a comprehensive multi-turn jailbreak benchmark. Our best configuration, Qwen3Guard with hyphenize compression, achieves 93.8% attack detection recall while reducing inference tokens by 94.6% (from 3,231 to 173 tokens per conversation). This represents a 38.9 percentage point improvement over the baseline while dramatically reducing both training and inference costs. Our findings demonstrate that M2S compression can serve as an effective efficiency technique for guardrail deployment, enabling scalable safety screening of long multi-turn conversations.

</details>


### [90] [Noise-Aware Named Entity Recognition for Historical VET Documents](https://arxiv.org/abs/2601.00488)
*Alexander M. Esser,Jens Dörpinghaus*

Main category: cs.CL

TL;DR: 提出一种针对职业教育培训领域历史文档的鲁棒命名实体识别方法，通过噪声感知训练、合成OCR错误注入和迁移学习，显著提升在噪声条件下的识别准确率。


<details>
  <summary>Details</summary>
Motivation: 职业教育培训领域的历史数字化文档存在OCR噪声问题，传统NER方法在这种噪声条件下表现不佳，需要开发鲁棒的NER方法来处理特定领域、多语言、噪声环境下的实体识别。

Method: 采用噪声感知训练（NAT），通过合成注入OCR错误，结合迁移学习和多阶段微调。系统比较了三种互补策略：在噪声数据、干净数据和人工合成数据上训练。这是首批识别VET文档中多种实体类型的方法之一。

Result: 实验结果表明，领域特定和噪声感知的微调显著提高了在噪声条件下的鲁棒性和准确性。该方法虽然应用于德语文档，但可迁移到任意语言。

Conclusion: 提出的方法有效解决了VET领域历史文档的NER问题，提供了公开可用的代码，支持在领域特定上下文中进行可重复的噪声感知NER研究。

Abstract: This paper addresses Named Entity Recognition (NER) in the domain of Vocational Education and Training (VET), focusing on historical, digitized documents that suffer from OCR-induced noise. We propose a robust NER approach leveraging Noise-Aware Training (NAT) with synthetically injected OCR errors, transfer learning, and multi-stage fine-tuning. Three complementary strategies, training on noisy, clean, and artificial data, are systematically compared. Our method is one of the first to recognize multiple entity types in VET documents. It is applied to German documents but transferable to arbitrary languages. Experimental results demonstrate that domain-specific and noise-aware fine-tuning substantially increases robustness and accuracy under noisy conditions. We provide publicly available code for reproducible noise-aware NER in domain-specific contexts.

</details>


### [91] [Rule-Based Approaches to Atomic Sentence Extraction](https://arxiv.org/abs/2601.00506)
*Lineesha Kamana,Akshita Ananda Subramanian,Mehuli Ghosh,Suman Saha*

Main category: cs.CL

TL;DR: 本文分析了复杂句结构对基于规则的原子句提取性能的影响，识别了相对从句、同位语、并列谓语等导致提取困难的结构。


<details>
  <summary>Details</summary>
Motivation: 现有原子句提取方法缺乏可解释性，无法揭示哪些语言结构导致提取失败。需要系统分析特定从句结构和依存关系如何影响提取性能。

Method: 使用WikiSplit数据集，在spaCy中实现基于依存关系的提取规则，生成100个黄金标准原子句集，使用ROUGE和BERTScore评估性能。

Result: 系统达到ROUGE-1 F1=0.6714，ROUGE-2 F1=0.478，ROUGE-L F1=0.650，BERTScore F1=0.5898，显示中等至高水平的对齐。相对从句、同位语、并列谓语、状语从句和被动结构最具挑战性。

Conclusion: 基于规则的提取方法在准确性上表现合理，但对句法复杂性敏感。需要进一步改进以处理复杂的语言结构。

Abstract: Natural language often combines multiple ideas into complex sentences. Atomic sentence extraction, the task of decomposing complex sentences into simpler sentences that each express a single idea, improves performance in information retrieval, question answering, and automated reasoning systems. Previous work has formalized the "split-and-rephrase" task and established evaluation metrics, and machine learning approaches using large language models have improved extraction accuracy. However, these methods lack interpretability and provide limited insight into which linguistic structures cause extraction failures. Although some studies have explored dependency-based extraction of subject-verb-object triples and clauses, no principled analysis has examined which specific clause structures and dependencies lead to extraction difficulties. This study addresses this gap by analyzing how complex sentence structures, including relative clauses, adverbial clauses, coordination patterns, and passive constructions, affect the performance of rule-based atomic sentence extraction. Using the WikiSplit dataset, we implemented dependency-based extraction rules in spaCy, generated 100 gold=standard atomic sentence sets, and evaluated performance using ROUGE and BERTScore. The system achieved ROUGE-1 F1 = 0.6714, ROUGE-2 F1 = 0.478, ROUGE-L F1 = 0.650, and BERTScore F1 = 0.5898, indicating moderate-to-high lexical, structural, and semantic alignment. Challenging structures included relative clauses, appositions, coordinated predicates, adverbial clauses, and passive constructions. Overall, rule-based extraction is reasonably accurate but sensitive to syntactic complexity.

</details>


### [92] [Retrieval--Reasoning Processes for Multi-hop Question Answering: A Four-Axis Design Framework and Empirical Trends](https://arxiv.org/abs/2601.00536)
*Yuelyu Ji,Zhuochun Li,Rui Meng,Daqing He*

Main category: cs.CL

TL;DR: 本文提出一个四轴框架来分析多跳问答系统的执行过程，将检索-推理过程作为分析单元，系统梳理代表性方法并总结效果-效率-证据忠实度之间的权衡。


<details>
  <summary>Details</summary>
Motivation: 当前RAG和智能体方法在多跳问答中表现良好，但检索-推理过程往往隐含不明确，使得不同模型家族的程序选择难以比较。需要系统化的分析框架来理解执行过程。

Method: 提出四轴分析框架：(A)整体执行计划，(B)索引结构，(C)下一步控制策略和触发机制，(D)停止/继续标准。使用该框架对代表性多跳QA系统进行映射分析，综合标准基准测试中的消融实验和趋势。

Result: 系统梳理了多跳问答系统，总结了在HotpotQA、2WikiMultiHopQA、MuSiQue等标准基准上的效果，揭示了效果、效率和证据忠实度之间的重复性权衡关系。

Conclusion: 提出检索-推理智能体的开放挑战，包括结构感知规划、可迁移控制策略以及在分布偏移下的鲁棒停止机制，为未来研究提供方向。

Abstract: Multi-hop question answering (QA) requires systems to iteratively retrieve evidence and reason across multiple hops. While recent RAG and agentic methods report strong results, the underlying retrieval--reasoning \emph{process} is often left implicit, making procedural choices hard to compare across model families. This survey takes the execution procedure as the unit of analysis and introduces a four-axis framework covering (A) overall execution plan, (B) index structure, (C) next-step control (strategies and triggers), and (D) stop/continue criteria. Using this schema, we map representative multi-hop QA systems and synthesize reported ablations and tendencies on standard benchmarks (e.g., HotpotQA, 2WikiMultiHopQA, MuSiQue), highlighting recurring trade-offs among effectiveness, efficiency, and evidence faithfulness. We conclude with open challenges for retrieval--reasoning agents, including structure-aware planning, transferable control policies, and robust stopping under distribution shift.

</details>


### [93] [ECR: Manifold-Guided Semantic Cues for Compact Language Models](https://arxiv.org/abs/2601.00543)
*Chung-Wei Victor Yuan*

Main category: cs.CL

TL;DR: ECR框架通过语义锚点保持紧凑模型嵌入空间的几何结构一致性，避免语义漂移，提升下游任务性能。


<details>
  <summary>Details</summary>
Motivation: 紧凑模型在容量有限或多语言场景下容易丢失嵌入空间结构，导致语义漂移，影响下游任务性能。现有压缩方法只关注表层输出对齐，未能保持底层流形结构。

Method: 提出嵌入一致性调节(ECR)框架：从教师模型嵌入中提取语义锚点（离线计算一次），让紧凑模型学习保持这些锚点周围的几何一致性，不依赖匹配logits或内部特征。推理时仅增加小型投影步骤，不改变解码架构或运行时行为。

Result: 在10万规模多语言语料实验中，ECR稳定训练过程，跨任务和语言保持语义结构，产生更紧凑且任务对齐的表示空间，使低容量模型能学习比传统基线更清晰的流形。ECR无需教师输出，与蒸馏兼容但独立。

Conclusion: ECR帮助紧凑模型更好地遵循任务要求，使其在严格效率或隐私限制下更容易部署，通过保持嵌入空间几何一致性解决了紧凑模型的语义漂移问题。

Abstract: Compact models often lose the structure of their embedding space. The issue shows up when the capacity is tight or the data spans several languages. Such collapse makes it difficult for downstream tasks to build on the resulting representation. Existing compression methods focus on aligning model outputs at a superficial level but fail to preserve the underlying manifold structure. This mismatch often leads to semantic drift in the compact model, causing both task behavior and linguistic properties to deviate from the reference model.
  To address those issues, we provide a new framework called Embedding Consistency Regulation (ECR). This framework first derives a set of semantic anchors from teacher embeddings (computed once offline). Then, the compact model learns to maintain consistent geometry around these anchors, without relying on matching logits or internal features. ECR adds only a small projection step at inference, without altering the decoding architecture or its runtime behavior.
  In experiments on a 100K multilingual corpus, ECR consistently stabilizes training and preserves semantic structure across tasks and languages. It also produces a more compact and task-aligned representation space, enabling low-capacity models to learn cleaner manifolds than conventional baselines. ECR works without teacher outputs and is compatible with, but independent of, distillation. Taken together, our results show that ECR helps compact models better follow task requirements and makes them easier to deploy under strict efficiency or privacy limits.

</details>


### [94] [A Language-Agnostic Hierarchical LoRA-MoE Architecture for CTC-based Multilingual ASR](https://arxiv.org/abs/2601.00557)
*Yuang Zheng,Yuxiang Mei,Dongxing Xu,Jie Chen,Yanhua Long*

Main category: cs.CL

TL;DR: 提出HLoRA框架，将分层LoRA-MoE集成到mHuBERT-CTC模型中，实现语言无关的多语言ASR，无需推理时的语言信息，单次解码即可达到两阶段方法的性能。


<details>
  <summary>Details</summary>
Motivation: 大规模多语言ASR模型（如Whisper）计算和延迟成本高，难以部署到资源受限的边缘设备。需要轻量级、语言无关的解决方案。

Method: 基于CTC架构，提出语言无关的分层LoRA-MoE（HLoRA）框架，集成到mHuBERT-CTC模型中。包含多语言共享LoRA学习语言不变声学表示，语言特定LoRA专家建模语言相关特征。通过LID后验驱动的LoRA路由实现端到端解码。

Result: 在MSR-86K和MLC-SLM 2025挑战数据集上，HLoRA仅通过单次解码就达到了最先进两阶段推理方法的竞争性能，显著提高了低资源多语言ASR的解码效率。

Conclusion: HLoRA框架实现了真正语言无关的解码，无需推理时的语言身份信息或显式语言标签，为资源受限环境下的多语言ASR提供了高效解决方案。

Abstract: Large-scale multilingual ASR (mASR) models such as Whisper achieve strong performance but incur high computational and latency costs, limiting their deployment on resource-constrained edge devices. In this study, we propose a lightweight and language-agnostic multilingual ASR system based on a CTC architecture with domain adaptation. Specifically, we introduce a Language-agnostic Hierarchical LoRA-MoE (HLoRA) framework integrated into an mHuBERT-CTC model, enabling end-to-end decoding via LID-posterior-driven LoRA routing. The hierarchical design consists of a multilingual shared LoRA for learning language-invariant acoustic representations and language-specific LoRA experts for modeling language-dependent characteristics. The proposed routing mechanism removes the need for prior language identity information or explicit language labels during inference, achieving true language-agnostic decoding. Experiments on MSR-86K and the MLC-SLM 2025 Challenge datasets demonstrate that HLoRA achieves competitive performance with state-of-the-art two-stage inference methods using only single-pass decoding, significantly improving decoding efficiency for low-resource mASR applications.

</details>


### [95] [InfoSynth: Information-Guided Benchmark Synthesis for LLMs](https://arxiv.org/abs/2601.00575)
*Ishir Garg,Neel Kolhe,Xuandong Zhao,Dawn Song*

Main category: cs.CL

TL;DR: InfoSynth是一个基于信息论原则自动生成和评估推理基准的框架，使用KL散度和熵量化基准新颖性和多样性，通过遗传算法和代码反馈生成Python编程问题，97%情况下能生成准确测试用例和解决方案。


<details>
  <summary>Details</summary>
Motivation: 传统基准创建依赖人工，成本高且耗时；现有基准常污染LLM训练数据，需要新颖多样的基准来准确评估LLM的真实能力。

Method: 提出基于KL散度和熵的指标量化基准新颖性和多样性；开发端到端流水线，使用遗传算法和迭代代码反馈从种子数据集合成稳健的Python编程问题。

Result: 方法97%情况下能生成准确测试用例和解决方案；合成的基准相比种子数据集始终表现出更高的新颖性和多样性；算法能控制生成问题的新颖性/多样性和难度。

Conclusion: InfoSynth为LLM提供了一个可扩展、自我验证的高质量基准构建流水线，能生成新颖多样的基准，无需依赖昂贵的模型评估。

Abstract: Large language models (LLMs) have demonstrated significant advancements in reasoning and code generation. However, efficiently creating new benchmarks to evaluate these capabilities remains a challenge. Traditional benchmark creation relies on manual human effort, a process that is both expensive and time-consuming. Furthermore, existing benchmarks often contaminate LLM training data, necessitating novel and diverse benchmarks to accurately assess their genuine capabilities. This work introduces InfoSynth, a novel framework for automatically generating and evaluating reasoning benchmarks guided by information-theoretic principles. We propose metrics based on KL-divergence and entropy to quantify benchmark novelty and diversity without relying on costly model evaluations. Building on this framework, we develop an end-to-end pipeline that synthesizes robust Python coding problems from seed datasets using genetic algorithms and iterative code feedback. Our method generates accurate test cases and solutions to new problems 97% of the time, and the synthesized benchmarks consistently exhibit higher novelty and diversity compared to their seed datasets. Moreover, our algorithm provides a method for controlling the novelty/diversity and difficulty of generated problems. InfoSynth offers a scalable, self-verifying pipeline for constructing high-quality, novel and diverse benchmarks for LLMs. Project Page: https://ishirgarg.github.io/infosynth_web/

</details>


### [96] [CSSBench: Evaluating the Safety of Lightweight LLMs against Chinese-Specific Adversarial Patterns](https://arxiv.org/abs/2601.00588)
*Zhenhong Zhou,Shilinlu Yan,Chuanpu Liu,Qiankun Li,Kun Wang,Zhigang Zeng*

Main category: cs.CL

TL;DR: CSSBench是一个专门针对中文特定对抗模式的安全基准测试，用于评估轻量级大语言模型在中文环境下的安全性，填补了现有基准测试主要关注英文的空白。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型越来越多地部署在成本敏感和设备端场景中，但安全防护主要针对英文。中文恶意查询通常通过同音字、拼音、符号分割等中文特定模式隐藏意图，这些对抗模式在现有基准测试中未被充分捕捉，特别是轻量级模型可能更容易受到此类特定对抗扰动的影响。

Method: 提出了中文特定安全基准测试(CSSBench)，强调中文对抗模式，涵盖六个常见中文场景领域：非法活动与合规、隐私泄露、健康与医疗错误信息、欺诈与仇恨、成人内容、公共与政治安全。将查询组织成多种任务类型，评估流行轻量级LLMs，并测量过度拒绝行为以评估安全引起的性能下降。

Result: 结果显示中文特定对抗模式对轻量级大语言模型构成关键挑战，该基准测试为中文LLM安全性提供了全面评估，有助于实际中的稳健部署。

Conclusion: CSSBench填补了中文安全评估的空白，特别是针对轻量级模型在中文特定对抗模式下的脆弱性，为实际部署中的安全性提供了重要评估工具。

Abstract: Large language models (LLMs) are increasingly deployed in cost-sensitive and on-device scenarios, and safety guardrails have advanced mainly in English. However, real-world Chinese malicious queries typically conceal intent via homophones, pinyin, symbol-based splitting, and other Chinese-specific patterns. These Chinese-specific adversarial patterns create the safety evaluation gap that is not well captured by existing benchmarks focused on English. This gap is particularly concerning for lightweight models, which may be more vulnerable to such specific adversarial perturbations. To bridge this gap, we introduce the Chinese-Specific Safety Benchmark (CSSBench) that emphasizes these adversarial patterns and evaluates the safety of lightweight LLMs in Chinese. Our benchmark covers six domains that are common in real Chinese scenarios, including illegal activities and compliance, privacy leakage, health and medical misinformation, fraud and hate, adult content, and public and political safety, and organizes queries into multiple task types. We evaluate a set of popular lightweight LLMs and measure over-refusal behavior to assess safety-induced performance degradation. Our results show that the Chinese-specific adversarial pattern is a critical challenge for lightweight LLMs. This benchmark offers a comprehensive evaluation of LLM safety in Chinese, assisting robust deployments in practice.

</details>


### [97] [Beyond IVR: Benchmarking Customer Support LLM Agents for Business-Adherence](https://arxiv.org/abs/2601.00596)
*Sumanth Balaji,Piyush Mishra,Aashraya Sachdeva,Suraj Agrawal*

Main category: cs.CL

TL;DR: JourneyBench是一个评估客户支持AI代理策略遵从性的新基准，使用图表示生成多样化支持场景，并提出用户旅程覆盖率指标。研究发现动态提示代理能显著提升策略遵从性。


<details>
  <summary>Details</summary>
Motivation: 传统客户支持系统（如IVR）依赖刚性脚本，缺乏处理复杂策略驱动任务的灵活性。虽然LLM代理提供了有前景的替代方案，但评估其遵守业务规则和真实支持工作流程的能力仍然是一个开放挑战。现有基准主要关注工具使用或任务完成，忽视了代理遵守多步骤策略、导航任务依赖关系以及对不可预测用户行为保持鲁棒性的能力。

Method: 引入JourneyBench基准，利用图表示生成多样化、真实的支持场景。提出用户旅程覆盖率（User Journey Coverage Score）作为衡量策略遵从性的新指标。评估了两种代理设计：静态提示代理（SPA）和动态提示代理（DPA），后者明确建模策略控制。

Result: 在三个领域的703个对话中，DPA显著提升了策略遵从性，甚至允许较小的模型如GPT-4o-mini在策略遵从方面胜过更强大的模型如GPT-4o。结构化编排对策略遵从至关重要。

Conclusion: JourneyBench是推进AI驱动客户支持超越IVR时代限制的关键资源。研究表明，通过动态提示和结构化编排，LLM代理能够更好地遵守复杂的业务策略和工作流程。

Abstract: Traditional customer support systems, such as Interactive Voice Response (IVR), rely on rigid scripts and lack the flexibility required for handling complex, policy-driven tasks. While large language model (LLM) agents offer a promising alternative, evaluating their ability to act in accordance with business rules and real-world support workflows remains an open challenge. Existing benchmarks primarily focus on tool usage or task completion, overlooking an agent's capacity to adhere to multi-step policies, navigate task dependencies, and remain robust to unpredictable user or environment behavior. In this work, we introduce JourneyBench, a benchmark designed to assess policy-aware agents in customer support. JourneyBench leverages graph representations to generate diverse, realistic support scenarios and proposes the User Journey Coverage Score, a novel metric to measure policy adherence. We evaluate multiple state-of-the-art LLMs using two agent designs: a Static-Prompt Agent (SPA) and a Dynamic-Prompt Agent (DPA) that explicitly models policy control. Across 703 conversations in three domains, we show that DPA significantly boosts policy adherence, even allowing smaller models like GPT-4o-mini to outperform more capable ones like GPT-4o. Our findings demonstrate the importance of structured orchestration and establish JourneyBench as a critical resource to advance AI-driven customer support beyond IVR-era limitations.

</details>


### [98] [Probabilistic Guarantees for Reducing Contextual Hallucinations in LLMs](https://arxiv.org/abs/2601.00641)
*Nils Rautenberg,Sven Schippkus*

Main category: cs.CL

TL;DR: 提出一个模型无关的框架，通过重复采样和多数投票机制，为确定性自动化工作流中的LLM幻觉提供概率保证，无需修改模型权重。


<details>
  <summary>Details</summary>
Motivation: LLM在确定性自动化工作流中经常产生上下文幻觉（生成内容与提示明确信息矛盾），这种错误在输入固定且正确性明确的情况下特别成问题，需要一种简单、模型无关的方法来减少幻觉。

Method: 1) 在独立上下文窗口中重复相同提示，通过指数级降低所有输出都错误的概率；2) 使用LLM作为评判器识别正确答案；3) 当评判器不完美时，通过独立评判调用的多数投票来增强评判器，获得指数级下降的集合级错误率。

Result: 在受控提取任务上的实验与理论预测完全匹配：管道失败概率随重复次数指数下降，幻觉选择概率随评判器数量指数下降。该方法能够将幻觉概率驱动到任意低水平。

Conclusion: 该框架提供了一种轻量级、模块化、理论可靠的方法，在不修改模型权重、解码策略或提示工程的情况下，为固定输入LLM工作流中的幻觉提供概率保证。

Abstract: Large language models (LLMs) frequently produce contextual hallucinations, where generated content contradicts or ignores information explicitly stated in the prompt. Such errors are particularly problematic in deterministic automation workflows, where inputs are fixed and correctness is unambiguous. We introduce a simple and model-agnostic framework that provides explicit probabilistic guarantees for reducing hallucinations in this setting.
  We formalize the notion of a specific task, defined by a fixed input and a deterministic correctness criterion, and show that issuing the same prompt in independent context windows yields an exponential reduction in the probability that all model outputs are incorrect. To identify a correct answer among repeated runs, we incorporate an LLM-as-a-judge and prove that the probability that the judged pipeline fails decays at a rate determined by the judge's true- and false-positive probabilities. When the judge is imperfect, we strengthen it through majority vote over independent judge calls, obtaining ensemble-level error rates that decrease exponentially in the number of votes. This yields an explicit bound on the probability that the pipeline selects a hallucinated answer.
  Experiments on controlled extraction tasks with synthetic noisy judges match these predictions exactly: pipeline failure decreases exponentially with the number of repetitions, and hallucination-selection decreases exponentially with the number of judges in the ensemble. Together, these results provide a lightweight, modular, and theoretically grounded method for driving hallucination probabilities arbitrarily low in fixed-input LLM workflows-without modifying model weights, decoding strategies, or prompt engineering.

</details>


### [99] [Physio-DPO: Aligning Large Language Models with the Protein Energy Landscape to Eliminate Structural Hallucinations](https://arxiv.org/abs/2601.00647)
*QiWei Meng*

Main category: cs.CL

TL;DR: Physio-DPO：一种基于物理信息的蛋白质语言模型对齐框架，通过考虑物理能量景观的连续结构来减少结构幻觉，提高蛋白质设计的稳定性和可折叠性。


<details>
  <summary>Details</summary>
Motivation: 现有的大规模蛋白质语言模型在生成蛋白质序列时经常产生结构幻觉，生成的语言可能性高但热力学不稳定的构象。现有的对齐方法（如DPO）将偏好建模为二元标签，忽略了物理能量景观的连续结构。

Method: 提出Physio-DPO框架，引入幅度感知目标函数，根据天然结构与物理扰动硬负样本之间的能量差距来缩放优化更新，将蛋白质语言模型基于热力学稳定性进行对齐。

Result: Physio-DPO在实验中一致优于SFT、PPO和标准DPO等基线方法，将自一致性RMSD降低到1.28Å，将可折叠性提高到92.8%。定性分析显示Physio-DPO有效缓解结构幻觉，恢复了疏水核心堆积和氢键网络等生物物理相互作用。

Conclusion: Physio-DPO通过将物理能量景观的连续结构纳入对齐过程，显著提高了蛋白质语言模型生成的热力学稳定性，为生成式蛋白质设计提供了更可靠的框架。

Abstract: Large Protein Language Models have shown strong potential for generative protein design, yet they frequently produce structural hallucinations, generating sequences with high linguistic likelihood that fold into thermodynamically unstable conformations. Existing alignment approaches such as Direct Preference Optimization are limited in this setting, as they model preferences as binary labels and ignore the continuous structure of the physical energy landscape. We propose Physio-DPO, a physics informed alignment framework that grounds protein language models in thermodynamic stability. Physio-DPO introduces a magnitude aware objective that scales optimization updates according to the energy gap between native structures and physics perturbed hard negatives. Experiments show that Physio-DPO consistently outperforms strong baselines including SFT, PPO, and standard DPO, reducing self consistency RMSD to 1.28 Å and increasing foldability to 92.8%. Qualitative analysis further demonstrates that Physio-DPO effectively mitigates structural hallucinations by recovering biophysical interactions such as hydrophobic core packing and hydrogen bond networks.

</details>


### [100] [Fast-weight Product Key Memory](https://arxiv.org/abs/2601.00671)
*Tianyu Zhao,Llion Jones*

Main category: cs.CL

TL;DR: FwPKM是一种新型序列建模架构，将静态产品键记忆转换为动态快速权重记忆，通过局部梯度下降实现训练和推理时的参数动态更新，解决了存储容量与计算效率的权衡问题。


<details>
  <summary>Details</summary>
Motivation: 现代语言模型的序列建模层面临存储容量与计算效率的权衡：Softmax注意力提供无限存储但计算成本高（二次复杂度），线性变体计算高效但存储容量有限且固定。需要一种既能高效计算又具备动态存储能力的架构。

Method: 提出快速权重产品键记忆（FwPKM），将稀疏的产品键记忆从静态模块转变为动态的"快速权重"情景记忆。通过局部块级梯度下降在训练和推理时动态更新参数，使模型能够快速记忆和检索输入序列中的新键值对。

Result: FwPKM作为有效的情景记忆，补充了标准模块的语义记忆，在长上下文数据集上显著降低了困惑度。在"大海捞针"评估中，尽管仅在4K-token序列上训练，却能泛化到128K-token的上下文。

Conclusion: FwPKM成功解决了序列建模中存储容量与计算效率的权衡问题，提供了一种动态、高效的情景记忆机制，能够有效处理长上下文序列，展现出强大的泛化能力。

Abstract: Sequence modeling layers in modern language models typically face a trade-off between storage capacity and computational efficiency. While Softmax attention offers unbounded storage at prohibitive quadratic costs, linear variants provide efficiency but suffer from limited, fixed-size storage. We propose Fast-weight Product Key Memory (FwPKM), a novel architecture that resolves this tension by transforming the sparse Product Key Memory (PKM) from a static module into a dynamic, "fast-weight" episodic memory. Unlike PKM, FwPKM updates its parameters dynamically at both training and inference time via local chunk-level gradient descent, allowing the model to rapidly memorize and retrieve new key-value pairs from input sequences. Experiments reveal that FwPKM functions as an effective episodic memory that complements the semantic memory of standard modules, yielding significant perplexity reductions on long-context datasets. Notably, in Needle in a Haystack evaluations, FwPKM generalizes to 128K-token contexts despite being trained on only 4K-token sequences.

</details>


### [101] [Sigmoid Head for Quality Estimation under Language Ambiguity](https://arxiv.org/abs/2601.00680)
*Tu Anh Dinh,Jan Niehues*

Main category: cs.CL

TL;DR: 提出Sigmoid Head方法解决语言模型概率不可靠的质量估计问题，通过sigmoid激活函数和多正确选项处理提升质量信号


<details>
  <summary>Details</summary>
Motivation: 语言模型的概率分布不是可靠的质量估计器，因为自然语言具有歧义性。当多个输出选项都有效时，模型的概率分布会分散到这些选项上，从而误导性地表明输出质量较低。这主要由两个原因造成：(1) LM的最终输出激活使用softmax，不允许多个正确选项同时获得高概率；(2) LM的训练数据是单一、one-hot编码的参考，表明每个输出步骤只有一个正确选项。

Method: 在预训练语言模型之上训练一个质量估计模块，称为Sigmoid Head。这是一个额外的解嵌入头，使用sigmoid激活函数来解决第一个限制。为了处理第二个限制，在训练Sigmoid Head的负采样过程中，使用启发式方法避免选择可能替代的正确标记。该方法在训练和推理过程中计算效率高。

Result: Sigmoid Head产生的概率相比原始的softmax头是显著更好的质量信号。由于Sigmoid Head不依赖于人工标注的质量数据，与监督式质量估计相比，在域外设置中更加鲁棒。

Conclusion: 提出的Sigmoid Head方法有效解决了语言模型概率作为质量估计器的局限性，通过sigmoid激活和智能负采样策略，在不需要人工标注数据的情况下提供了更可靠的质量信号，特别适用于域外场景。

Abstract: Language model (LM) probability is not a reliable quality estimator, as natural language is ambiguous. When multiple output options are valid, the model's probability distribution is spread across them, which can misleadingly indicate low output quality. This issue is caused by two reasons: (1) LMs' final output activation is softmax, which does not allow multiple correct options to receive high probabilities simultaneuously and (2) LMs' training data is single, one-hot encoded references, indicating that there is only one correct option at each output step. We propose training a module for Quality Estimation on top of pre-trained LMs to address these limitations. The module, called Sigmoid Head, is an extra unembedding head with sigmoid activation to tackle the first limitation. To tackle the second limitation, during the negative sampling process to train the Sigmoid Head, we use a heuristic to avoid selecting potentially alternative correct tokens. Our Sigmoid Head is computationally efficient during training and inference. The probability from Sigmoid Head is notably better quality signal compared to the original softmax head. As the Sigmoid Head does not rely on human-annotated quality data, it is more robust to out-of-domain settings compared to supervised QE.

</details>


### [102] [Exploring the Performance of Large Language Models on Subjective Span Identification Tasks](https://arxiv.org/abs/2601.00736)
*Alphaeus Dmonte,Roland Oruche,Tharindu Ranasinghe,Marcos Zampieri,Prasad Calyam*

Main category: cs.CL

TL;DR: 评估多种大语言模型在文本跨度识别任务上的表现，包括情感分析、冒犯性语言识别和声明验证，探索指令调优、上下文学习和思维链等策略。


<details>
  <summary>Details</summary>
Motivation: 当前大多数跨度识别方法依赖BERT等较小预训练模型，而大语言模型在主观跨度识别任务（如基于方面的情感分析）中尚未充分探索，需要填补这一研究空白。

Method: 评估多种LLM在三个任务上的表现：情感分析、冒犯性语言识别和声明验证，采用指令调优、上下文学习和思维链等策略。

Result: 结果表明文本内部的潜在关系有助于LLM识别精确的文本跨度。

Conclusion: 文本中的内在关系对于LLM准确识别文本跨度至关重要，为LLM在主观跨度识别任务中的应用提供了重要见解。

Abstract: Identifying relevant text spans is important for several downstream tasks in NLP, as it contributes to model explainability. While most span identification approaches rely on relatively smaller pre-trained language models like BERT, a few recent approaches have leveraged the latest generation of Large Language Models (LLMs) for the task. Current work has focused on explicit span identification like Named Entity Recognition (NER), while more subjective span identification with LLMs in tasks like Aspect-based Sentiment Analysis (ABSA) has been underexplored. In this paper, we fill this important gap by presenting an evaluation of the performance of various LLMs on text span identification in three popular tasks, namely sentiment analysis, offensive language identification, and claim verification. We explore several LLM strategies like instruction tuning, in-context learning, and chain of thought. Our results indicate underlying relationships within text aid LLMs in identifying precise text spans.

</details>


### [103] [Adapting Natural Language Processing Models Across Jurisdictions: A pilot Study in Canadian Cancer Registries](https://arxiv.org/abs/2601.00787)
*Jonathan Simkin,Lovedeep Gondara,Zeeshan Rizvi,Gregory Doyle,Jeff Dowden,Dan Bond,Desmond Martin,Raymond Ng*

Main category: cs.CL

TL;DR: 跨省评估癌症登记NLP模型泛化能力，通过微调和集成方法显著减少漏诊癌症，实现隐私保护的工作流程


<details>
  <summary>Details</summary>
Motivation: 人口癌症登记依赖病理报告，但人工提取资源密集且延迟数据。现有NLP系统在跨司法管辖区（不同报告规范）的泛化能力尚不清楚，需要评估模型在不同省份的适应性和效果。

Method: 1) 跨省评估BCCRTron（BC癌症登记领域适应模型）和GatorTron（生物医学模型）在加拿大癌症监测中的应用；2) 使用纽芬兰与拉布拉多癌症登记的约104,000份（Tier 1）和22,000份（Tier 2）去标识化病理报告；3) 通过互补的摘要和诊断重点报告部分输入管道微调模型；4) 采用保守OR集成方法组合两个模型以提高敏感性。

Result: 1) 跨省测试中，微调模型保持高性能，证明在一个司法管辖区预训练的transformer可通过适度微调本地化到另一个管辖区；2) OR集成显著提高敏感性：Tier 1召回率达0.99，漏诊癌症降至24例（单独模型为48和54例）；Tier 2召回率达0.99，漏诊可报告癌症降至33例（单独模型为54和46例）；3) 集成互补文本表示大幅减少漏诊癌症并提高错误覆盖。

Conclusion: 通过微调和集成方法，transformer模型可成功跨省适应，显著改善癌症登记NLP性能。隐私保护工作流程（仅共享模型权重）支持可互操作的NLP基础设施，为未来泛加拿大癌症病理和登记工作流程基础模型奠定基础。

Abstract: Population-based cancer registries depend on pathology reports as their primary diagnostic source, yet manual abstraction is resource-intensive and contributes to delays in cancer data. While transformer-based NLP systems have improved registry workflows, their ability to generalize across jurisdictions with differing reporting conventions remains poorly understood. We present the first cross-provincial evaluation of adapting BCCRTron, a domain-adapted transformer model developed at the British Columbia Cancer Registry, alongside GatorTron, a biomedical transformer model, for cancer surveillance in Canada. Our training dataset consisted of approximately 104,000 and 22,000 de-identified pathology reports from the Newfoundland & Labrador Cancer Registry (NLCR) for Tier 1 (cancer vs. non-cancer) and Tier 2 (reportable vs. non-reportable) tasks, respectively. Both models were fine-tuned using complementary synoptic and diagnosis focused report section input pipelines. Across NLCR test sets, the adapted models maintained high performance, demonstrating transformers pretrained in one jurisdiction can be localized to another with modest fine-tuning. To improve sensitivity, we combined the two models using a conservative OR-ensemble achieving a Tier 1 recall of 0.99 and reduced missed cancers to 24, compared with 48 and 54 for the standalone models. For Tier 2, the ensemble achieved 0.99 recall and reduced missed reportable cancers to 33, compared with 54 and 46 for the individual models. These findings demonstrate that an ensemble combining complementary text representations substantially reduce missed cancers and improve error coverage in cancer-registry NLP. We implement a privacy-preserving workflow in which only model weights are shared between provinces, supporting interoperable NLP infrastructure and a future pan-Canadian foundation model for cancer pathology and registry workflows.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [104] [Reasoning in Action: MCTS-Driven Knowledge Retrieval for Large Language Models](https://arxiv.org/abs/2601.00003)
*Shuqi Liu,Bowei He,Chen Ma,Linqi Song*

Main category: cs.AI

TL;DR: 提出了一种推理感知的知识检索方法，通过粗到细的两阶段检索策略，结合蒙特卡洛树搜索，为LLMs提供与对话逻辑结构对齐的知识，超越表面语义相似性。


<details>
  <summary>Details</summary>
Motivation: 当前LLMs通常通过检索语义相似信息或提升推理能力来增强性能，但如何有效整合检索和推理策略仍是一个挑战。需要超越表面语义相似性，提供与对话逻辑结构对齐的知识。

Method: 采用粗到细的两阶段知识检索方法：1）首先识别知识库中与上下文相关的子区域；2）在该子区域内细化搜索，提取与推理过程相关的知识。两阶段都使用蒙特卡洛树搜索启发的方法，通过关键词在知识句子中导航。

Result: 在两个多轮对话数据集上的实验表明，该方法不仅更贴近人类对话的底层推理逻辑，还显著提高了检索知识的多样性，从而生成更具信息量和创造性的响应。

Conclusion: 提出的推理感知知识检索方法能够有效整合检索和推理策略，通过逻辑结构对齐的知识检索，提升LLMs在多轮对话中的表现，生成更丰富多样的响应。

Abstract: Large language models (LLMs) typically enhance their performance through either the retrieval of semantically similar information or the improvement of their reasoning capabilities. However, a significant challenge remains in effectively integrating both retrieval and reasoning strategies to optimize LLM performance. In this paper, we introduce a reasoning-aware knowledge retrieval method that enriches LLMs with information aligned to the logical structure of conversations, moving beyond surface-level semantic similarity. We follow a coarse-to-fine approach for knowledge retrieval. First, we identify a contextually relevant sub-region of the knowledge base, ensuring that all sentences within it are relevant to the context topic. Next, we refine our search within this sub-region to extract knowledge that is specifically relevant to the reasoning process. Throughout both phases, we employ the Monte Carlo Tree Search-inspired search method to effectively navigate through knowledge sentences using common keywords. Experiments on two multi-turn dialogue datasets demonstrate that our knowledge retrieval approach not only aligns more closely with the underlying reasoning in human conversations but also significantly enhances the diversity of the retrieved knowledge, resulting in more informative and creative responses.

</details>


### [105] [Finetuning Large Language Models for Automated Depression Screening in Nigerian Pidgin English: GENSCORE Pilot Study](https://arxiv.org/abs/2601.00004)
*Isaac Iyinoluwa Olufadewa,Miracle Ayomikun Adesina,Ezekiel Ayodeji Oladejo,Uthman Babatunde Usman,Owen Kolade Adeniyi,Matthew Tolulope Olawoyin*

Main category: cs.AI

TL;DR: 使用微调大语言模型进行尼日利亚皮钦语抑郁症筛查，GPT-4.1在准确性和文化适应性方面表现最佳


<details>
  <summary>Details</summary>
Motivation: 尼日利亚抑郁症筛查覆盖率低，传统工具如PHQ-9在高收入国家验证，但可能不适合尼日利亚这样的多语言环境，存在语言和文化障碍

Method: 收集432个尼日利亚皮钦语音频响应，进行转录、预处理和标注（语义标签、俚语解释、PHQ-9严重程度评分），微调三种LLM（Phi-3-mini-4k-instruct、Gemma-3-4B-it、GPT-4.1）并评估性能

Result: GPT-4.1表现最佳，PHQ-9严重程度评分预测准确率达94.5%，在文化适应性、清晰度和相关性方面也最优

Conclusion: AI辅助的抑郁症筛查可为尼日利亚服务不足社区提供解决方案，为在语言多样、资源有限环境中部署对话式心理健康工具奠定基础

Abstract: Depression is a major contributor to the mental-health burden in Nigeria, yet screening coverage remains limited due to low access to clinicians, stigma, and language barriers. Traditional tools like the Patient Health Questionnaire-9 (PHQ-9) were validated in high-income countries but may be linguistically or culturally inaccessible for low- and middle-income countries and communities such as Nigeria where people communicate in Nigerian Pidgin and more than 520 local languages. This study presents a novel approach to automated depression screening using fine-tuned large language models (LLMs) adapted for conversational Nigerian Pidgin. We collected a dataset of 432 Pidgin-language audio responses from Nigerian young adults aged 18-40 to prompts assessing psychological experiences aligned with PHQ-9 items, performed transcription, rigorous preprocessing and annotation, including semantic labeling, slang and idiom interpretation, and PHQ-9 severity scoring. Three LLMs - Phi-3-mini-4k-instruct, Gemma-3-4B-it, and GPT-4.1 - were fine-tuned on this annotated dataset, and their performance was evaluated quantitatively (accuracy, precision and semantic alignment) and qualitatively (clarity, relevance, and cultural appropriateness). GPT-4.1 achieved the highest quantitative performance, with 94.5% accuracy in PHQ-9 severity scoring prediction, outperforming Gemma-3-4B-it and Phi-3-mini-4k-instruct. Qualitatively, GPT-4.1 also produced the most culturally appropriate, clear, and contextually relevant responses. AI-mediated depression screening for underserved Nigerian communities. This work provides a foundation for deploying conversational mental-health tools in linguistically diverse, resource-constrained environments.

</details>


### [106] [Toward a Physical Theory of Intelligence](https://arxiv.org/abs/2601.00021)
*Peter David Fagan*

Main category: cs.AI

TL;DR: 该论文提出了一个基于不可逆信息处理的物理智能理论，将智能定义为每单位不可逆处理信息产生的目标导向功，并推导出信息摄入、计算和功提取的物理约束。


<details>
  <summary>Details</summary>
Motivation: 建立智能的物理基础理论，将信息处理与物理守恒定律联系起来，为理解生物和人工系统中的智能现象提供统一的物理框架。

Method: 提出守恒一致编码（CCE）框架，将编码建模为由守恒定律强制分离的吸引子盆地；定义智能为每单位不可逆处理信息产生的目标导向功；推导物理约束并应用于生物系统和连续动力电路。

Result: 揭示了长时程效率需要保持内部信息结构，导致自我建模；发现物理体现的智能系统具有类似不完备性的固有认知极限；分析大脑接近理论预测的高效运行状态；布尔逻辑作为吸引子选择的特例出现。

Conclusion: 该理论为智能提供了统一的、底质中立的物理解释，将智能视为物理现象，并为人工智能安全提供了基于不可逆信息流和结构稳态的物理基础视角。

Abstract: We present a physical theory of intelligence grounded in irreversible information processing in systems constrained by conservation laws. An intelligent system is modelled as a coupled agent-environment process whose evolution transforms information into goal-directed work. To connect information to physical state, we introduce the Conservation-Congruent Encoding (CCE) framework, in which encodings correspond to metastable basins of attraction whose separability is enforced by conservation laws. Within this framework, intelligence is defined as the amount of goal-directed work produced per nat of irreversibly processed information. From this definition we derive a hierarchy of physical constraints governing information intake, irreversible computation, and work extraction in open systems. The framework reveals how long-horizon efficiency requires the preservation of internal informational structure, giving rise to self-modelling, and it establishes that physically embodied intelligent systems possess intrinsic epistemic limits analogous to incompleteness phenomena. Applying the theory to biological systems, we analyse how oscillatory and near-critical dynamics optimise the trade-off between information preservation, dissipation, and useful work, placing the brain near an efficient operating regime predicted by the framework. At the architectural level, we develop a theory of continuous dynamical circuits in which classical Boolean logic emerges as a special case of attractor selection, while more general invariant geometries support computational modes beyond fixed-point logic. Finally, we propose a physically grounded perspective on artificial intelligence safety based on irreversible information flow and structural homeostasis. Together, these results provide a unified, substrate-neutral account of intelligence as a physical phenomenon.

</details>


### [107] [A multi-algorithm approach for operational human resources workload balancing in a last mile urban delivery system](https://arxiv.org/abs/2601.00023)
*Luis M. Moreno-Saavedra,Silvia Jimenez-Fernandez,Antonio Portilla-Figueras,David Casillas-Perez,Sancho Salcedo-Sanz*

Main category: cs.AI

TL;DR: 提出多算法方法解决最后一公里包裹配送中的工作量平衡问题，通过结合距离和工作量考虑优化包裹分配，确保每位配送员完成相似工作量


<details>
  <summary>Details</summary>
Motivation: 传统基于地理邻近性的包裹分配方法效率低下，导致配送员工作量分布不均衡，需要优化系统以改善配送时间并实现工作量平衡

Method: 提出多算法方法，包括不同版本的k-means、进化算法、基于k-means初始化的递归分配（不同问题编码）以及混合进化集成算法，综合考虑距离和工作量因素

Result: 在西班牙Azuqueca de Henares的实际最后一公里包裹配送系统中验证了方法的性能

Conclusion: 提出的多算法方法能有效解决最后一公里配送中的工作量平衡问题，确保配送员工作量均衡分配

Abstract: Efficient workload assignment to the workforce is critical in last-mile package delivery systems. In this context, traditional methods of assigning package deliveries to workers based on geographical proximity can be inefficient and surely guide to an unbalanced workload distribution among delivery workers. In this paper, we look at the problem of operational human resources workload balancing in last-mile urban package delivery systems. The idea is to consider the effort workload to optimize the system, i.e., the optimization process is now focused on improving the delivery time, so that the workload balancing is complete among all the staff. This process should correct significant decompensations in workload among delivery workers in a given zone. Specifically, we propose a multi-algorithm approach to tackle this problem. The proposed approach takes as input a set of delivery points and a defined number of workers, and then assigns packages to workers, in such a way that it ensures that each worker completes a similar amount of work per day. The proposed algorithms use a combination of distance and workload considerations to optimize the allocation of packages to workers. In this sense, the distance between the delivery points and the location of each worker is also taken into account. The proposed multi-algorithm methodology includes different versions of k-means, evolutionary approaches, recursive assignments based on k-means initialization with different problem encodings, and a hybrid evolutionary ensemble algorithm. We have illustrated the performance of the proposed approach in a real-world problem in an urban last-mile package delivery workforce operating at Azuqueca de Henares, Spain.

</details>


### [108] [Quantitative Rule-Based Strategy modeling in Classic Indian Rummy: A Metric Optimization Approach](https://arxiv.org/abs/2601.00024)
*Purushottam Saha,Avirup Chakraborty,Sourish Sarkar,Subhamoy Maitra,Diganta Mukherjee,Tridib Mukherjee*

Main category: cs.AI

TL;DR: 提出基于MinDist度量（修改MinScore以量化手牌与最近有效配置的编辑距离）的规则框架，用于13张牌印度拉米游戏策略设计，通过高效算法计算，结合对手建模，显著提升胜率。


<details>
  <summary>Details</summary>
Motivation: 13张牌印度拉米是不完全信息顺序游戏，需要概率推理和组合决策。传统启发式方法有限，需要更形式化、可解释的策略设计框架。

Method: 1) 提出MinDist手牌评估度量，量化手牌与最近有效配置的编辑距离；2) 设计计算高效算法，基于MinScore算法，利用动态剪枝和模式缓存；3) 在两人零和模拟框架中结合对手建模；4) 使用统计假设检验评估策略。

Result: 基于MinDist的智能体相比传统启发式方法在胜率上有显著提升，为算法化拉米策略设计提供了形式化和可解释的步骤。

Conclusion: MinDist度量能有效捕捉手牌完成的结构接近度，结合高效算法和对手建模，为不完全信息顺序游戏提供了有效的策略设计框架。

Abstract: The 13-card variant of Classic Indian Rummy is a sequential game of incomplete information that requires probabilistic reasoning and combinatorial decision-making. This paper proposes a rule-based framework for strategic play, driven by a new hand-evaluation metric termed MinDist. The metric modifies the MinScore metric by quantifying the edit distance between a hand and the nearest valid configuration, thereby capturing structural proximity to completion. We design a computationally efficient algorithm derived from the MinScore algorithm, leveraging dynamic pruning and pattern caching to exactly calculate this metric during play. Opponent hand-modeling is also incorporated within a two-player zero-sum simulation framework, and the resulting strategies are evaluated using statistical hypothesis testing. Empirical results show significant improvement in win rates for MinDist-based agents over traditional heuristics, providing a formal and interpretable step toward algorithmic Rummy strategy design.

</details>


### [109] [From Clay to Code: Typological and Material Reasoning in AI Interpretations of Iranian Pigeon Towers](https://arxiv.org/abs/2601.00029)
*Abolhassan Pishahang,Maryam Badiei*

Main category: cs.AI

TL;DR: 研究探索生成式AI如何解读乡土建筑中的智慧，以伊朗鸽塔为例测试三种扩散模型，发现AI能复制几何模式但误解材料和气候逻辑


<details>
  <summary>Details</summary>
Motivation: 探讨生成式AI系统如何理解和重新诠释乡土建筑形式中蕴含的建筑智慧，分析AI在感知、扭曲和重新想象传统设计智能方面的能力

Method: 以伊朗鸽塔为案例研究，测试Midjourney v6、DALL-E 3和基于Stable Diffusion XL的DreamStudio三种扩散模型，采用参考性、适应性和推测性三个提示阶段，通过五标准评估框架分析

Result: AI能可靠地复制几何模式，但误解材料和气候逻辑；参考图像提高真实性但限制创造力，无参考约束则产生创新但文化模糊的结果

Conclusion: 定义了视觉相似性与建筑推理之间的边界，提出计算乡土推理作为分析AI如何感知、扭曲和重新想象传统设计智能的框架

Abstract: This study investigates how generative AI systems interpret the architectural intelligence embedded in vernacular form. Using the Iranian pigeon tower as a case study, the research tests three diffusion models, Midjourney v6, DALL-E 3, and DreamStudio based on Stable Diffusion XL (SDXL), across three prompt stages: referential, adaptive, and speculative. A five-criteria evaluation framework assesses how each system reconstructs typology, materiality, environment, realism, and cultural specificity. Results show that AI reliably reproduces geometric patterns but misreads material and climatic reasoning. Reference imagery improves realism yet limits creativity, while freedom from reference generates inventive but culturally ambiguous outcomes. The findings define a boundary between visual resemblance and architectural reasoning, positioning computational vernacular reasoning as a framework for analyzing how AI perceives, distorts, and reimagines traditional design intelligence.

</details>


### [110] [The Agentic Leash: Extracting Causal Feedback Fuzzy Cognitive Maps with LLMs](https://arxiv.org/abs/2601.00097)
*Akash Kumar Panda,Olaoluwa Adigun,Bart Kosko*

Main category: cs.AI

TL;DR: 提出一种基于LLM的智能体，从原始文本中提取因果反馈模糊认知图（FCM），并通过双向交互实现系统的准自主演化。


<details>
  <summary>Details</summary>
Motivation: 传统FCM构建依赖人工，本文旨在利用LLM的自主性自动从文本中提取因果结构，实现FCM的自动生成和演化。

Method: 设计三步精细调优的系统指令：1) 提取关键名词和名词短语；2) 从这些词汇中提取FCM概念节点；3) 推断节点间的部分/模糊因果边。使用LLM智能体（Gemini和ChatGPT）执行此过程。

Result: 在Kissinger关于AI的论文测试中，生成的FCM与人工构建的FCM收敛到相同的平衡极限环，尽管节点和边数量不同。混合不同LLM生成的FCM能吸收主要成分的平衡点，同时创建新平衡点以更好近似底层因果系统。

Conclusion: LLM智能体能够有效从文本中提取因果FCM结构，实现准自主演化，混合不同LLM生成的FCM能产生更优的因果系统近似。

Abstract: We design a large-language-model (LLM) agent that extracts causal feedback fuzzy cognitive maps (FCMs) from raw text. The causal learning or extraction process is agentic both because of the LLM's semi-autonomy and because ultimately the FCM dynamical system's equilibria drive the LLM agents to fetch and process causal text. The fetched text can in principle modify the adaptive FCM causal structure and so modify the source of its quasi-autonomy--its equilibrium limit cycles and fixed-point attractors. This bidirectional process endows the evolving FCM dynamical system with a degree of autonomy while still staying on its agentic leash. We show in particular that a sequence of three finely tuned system instructions guide an LLM agent as it systematically extracts key nouns and noun phrases from text, as it extracts FCM concept nodes from among those nouns and noun phrases, and then as it extracts or infers partial or fuzzy causal edges between those FCM nodes. We test this FCM generation on a recent essay about the promise of AI from the late diplomat and political theorist Henry Kissinger and his colleagues. This three-step process produced FCM dynamical systems that converged to the same equilibrium limit cycles as did the human-generated FCMs even though the human-generated FCM differed in the number of nodes and edges. A final FCM mixed generated FCMs from separate Gemini and ChatGPT LLM agents. The mixed FCM absorbed the equilibria of its dominant mixture component but also created new equilibria of its own to better approximate the underlying causal dynamical system.

</details>


### [111] [Mortar: Evolving Mechanics for Automatic Game Design](https://arxiv.org/abs/2601.00105)
*Muhammad U. Nasir,Yuchen Li,Steven James,Julian Togelius*

Main category: cs.AI

TL;DR: Mortar系统结合质量多样性算法和大型语言模型，自动演化游戏机制，通过合成完整游戏评估机制对玩家技能排序的贡献度。


<details>
  <summary>Details</summary>
Motivation: 游戏机制设计是耗时且依赖专家经验的过程，需要自动化方法来探索多样化的游戏机制，减轻人工设计负担。

Method: 结合质量多样性算法和大型语言模型探索多样化机制，通过树搜索合成完整游戏，评估机制对玩家技能排序的贡献度。

Result: Mortar能生成多样且可玩的游戏，产生的机制在游戏中更能促进技能排序，消融研究和用户研究验证了系统组件的有效性。

Conclusion: Mortar系统成功实现了游戏机制的自主演化，为自动游戏设计提供了有效方法，通过技能排序评估机制质量是可行的。

Abstract: We present Mortar, a system for autonomously evolving game mechanics for automatic game design. Game mechanics define the rules and interactions that govern gameplay, and designing them manually is a time-consuming and expert-driven process. Mortar combines a quality-diversity algorithm with a large language model to explore a diverse set of mechanics, which are evaluated by synthesising complete games that incorporate both evolved mechanics and those drawn from an archive. The mechanics are evaluated by composing complete games through a tree search procedure, where the resulting games are evaluated by their ability to preserve a skill-based ordering over players -- that is, whether stronger players consistently outperform weaker ones. We assess the mechanics based on their contribution towards the skill-based ordering score in the game. We demonstrate that Mortar produces games that appear diverse and playable, and mechanics that contribute more towards the skill-based ordering score in the game. We perform ablation studies to assess the role of each system component and a user study to evaluate the games based on human feedback.

</details>


### [112] [Ask, Clarify, Optimize: Human-LLM Agent Collaboration for Smarter Inventory Control](https://arxiv.org/abs/2601.00121)
*Yaqi Duan,Yichun Hu,Jiashuo Jiang*

Main category: cs.AI

TL;DR: LLMs作为端到端库存优化求解器存在"幻觉税"性能差距，提出混合代理框架将语义推理与数学计算解耦，LLM作为智能接口调用算法引擎，相比GPT-4o端到端方案降低32.1%库存成本。


<details>
  <summary>Details</summary>
Motivation: 中小企业在库存管理中缺乏部署高级优化方法的专业知识，需要探索LLM能否帮助弥合这一差距，但发现LLM作为端到端求解器存在性能问题。

Method: 提出混合代理框架，严格分离语义推理与数学计算：LLM作为智能接口从自然语言提取参数并解释结果，自动调用严格算法构建优化引擎；引入Human Imitator作为有限理性管理者的数字孪生，实现可扩展、可重复的压力测试。

Result: 混合代理框架相比使用GPT-4o作为端到端求解器的交互基线，总库存成本降低32.1%；提供完美真实信息本身不足以改善GPT-4o性能，确认瓶颈本质是计算而非信息问题。

Conclusion: LLM不应取代运筹学，而应作为自然语言接口，使非专家能够访问基于求解器的严格策略；混合代理框架有效解决了LLM在随机推理方面的局限性。

Abstract: Inventory management remains a challenge for many small and medium-sized businesses that lack the expertise to deploy advanced optimization methods. This paper investigates whether Large Language Models (LLMs) can help bridge this gap. We show that employing LLMs as direct, end-to-end solvers incurs a significant "hallucination tax": a performance gap arising from the model's inability to perform grounded stochastic reasoning. To address this, we propose a hybrid agentic framework that strictly decouples semantic reasoning from mathematical calculation. In this architecture, the LLM functions as an intelligent interface, eliciting parameters from natural language and interpreting results while automatically calling rigorous algorithms to build the optimization engine.
  To evaluate this interactive system against the ambiguity and inconsistency of real-world managerial dialogue, we introduce the Human Imitator, a fine-tuned "digital twin" of a boundedly rational manager that enables scalable, reproducible stress-testing. Our empirical analysis reveals that the hybrid agentic framework reduces total inventory costs by 32.1% relative to an interactive baseline using GPT-4o as an end-to-end solver. Moreover, we find that providing perfect ground-truth information alone is insufficient to improve GPT-4o's performance, confirming that the bottleneck is fundamentally computational rather than informational. Our results position LLMs not as replacements for operations research, but as natural-language interfaces that make rigorous, solver-based policies accessible to non-experts.

</details>


### [113] [Constructing a Neuro-Symbolic Mathematician from First Principles](https://arxiv.org/abs/2601.00125)
*Keqin Xie*

Main category: cs.AI

TL;DR: Mathesis：一种神经符号架构，通过将数学状态编码为高阶超图，并使用符号推理核将约束映射到连续能量景观，将证明搜索转化为能量最小化问题，解决LLM的逻辑推理缺陷。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在复杂推理中存在持续的逻辑失败，因为它们缺乏内部公理框架。需要一种能够将符号逻辑与神经学习相结合的方法来改善数学推理能力。

Method: 提出Mathesis神经符号架构：1) 将数学状态编码为高阶超图；2) 使用符号推理核（SRK）- 一个可微分的逻辑引擎，将约束映射到连续能量景观；3) 定义全局能量函数E(G)，零能量表示逻辑一致性；4) 通过梯度信号训练超图变换器大脑；5) 使用蒙特卡洛树搜索和进化证明搜索实现多步推理。

Result: 该方法将证明搜索转化为能量最小化问题，通过SRK提供梯度信号来训练神经网络组件，实现了符号逻辑与神经学习的结合，能够进行多步数学推理。

Conclusion: Mathesis架构通过神经符号方法解决了LLM的逻辑推理缺陷，将证明搜索转化为能量最小化问题，为复杂数学推理提供了新的框架。

Abstract: Large Language Models (LLMs) exhibit persistent logical failures in complex reasoning due to the lack of an internal axiomatic framework. We propose Mathesis, a neuro-symbolic architecture that encodes mathematical states as higher-order hypergraphs and uses a Symbolic Reasoning Kernel (SRK)--a differentiable logic engine that maps constraints to a continuous energy landscape. By defining a global energy function E(G), where zero energy implies logical consistency, the SRK yields gradient-based signals to train a Hypergraph Transformer Brain, turning proof search into energy minimization. Multi-step deduction is enabled via Monte Carlo Tree Search and Evolutionary Proof Search, guided by learned value functions and semantic unification.

</details>


### [114] [Explicit Abstention Knobs for Predictable Reliability in Video Question Answering](https://arxiv.org/abs/2601.00138)
*Jorge Ortiz*

Main category: cs.AI

TL;DR: 研究验证了在视频问答任务中，基于置信度的弃权机制能否有效控制错误率，并考察其在分布偏移下的鲁棒性。使用NExT-QA数据集和Gemini 2.0 Flash模型，发现置信度阈值能在分布内提供机制性控制，但在分布偏移下可靠性下降。


<details>
  <summary>Details</summary>
Motivation: 在视觉语言模型的高风险部署中，需要选择性预测机制，让系统在不确定时弃权而非冒险产生代价高昂的错误。研究旨在验证基于置信度的弃权是否能可靠控制视频问答中的错误率，以及这种控制在分布偏移下是否保持鲁棒。

Method: 使用NExT-QA数据集和Gemini 2.0 Flash模型进行研究。通过扫描置信度阈值epsilon来产生风险-覆盖率的权衡曲线，评估置信度阈值机制在分布内和分布偏移下的表现。

Result: 1. 置信度阈值在分布内提供机制性控制，通过调整阈值可以平滑地权衡风险与覆盖率，降低错误率。2. 在分布偏移下，置信度阈值提供的控制可靠性下降，表明需要更鲁棒的置信度估计方法。

Conclusion: 虽然置信度阈值在分布内能有效控制错误率，但在分布偏移下可靠性不足。这表明需要开发更鲁棒的置信度估计方法，以确保视觉语言模型在高风险部署中的可靠选择性预测。

Abstract: High-stakes deployment of vision-language models (VLMs) requires selective prediction, where systems abstain when uncertain rather than risk costly errors. We investigate whether confidence-based abstention provides reliable control over error rates in video question answering, and whether that control remains robust under distribution shift. Using NExT-QA and Gemini 2.0 Flash, we establish two findings. First, confidence thresholding provides mechanistic control in-distribution. Sweeping threshold epsilon produces smooth risk-coverage tradeoffs, reducing error rates f

</details>


### [115] [An AI Monkey Gets Grapes for Sure -- Sphere Neural Networks for Reliable Decision-Making](https://arxiv.org/abs/2601.00142)
*Tiansi Dong,Henry He,Pietro Liò,Mateja Jamnik*

Main category: cs.AI

TL;DR: 该论文比较了三种神经推理方法：LLM推理、监督学习推理和显式模型推理，发现显式模型推理最可靠，并提出球面神经网络实现可靠推理。


<details>
  <summary>Details</summary>
Motivation: 当前LLM推理不可靠，监督学习推理存在灾难性遗忘问题，需要寻找更可靠的神经推理方法。

Method: 提出球面神经网络，将概念表示为n维球面上的圆，通过补圆表示否定算子，过滤不可满足的圆形配置实现可靠决策。

Result: 球面神经网络能掌握16种三段论推理任务，包括严格的析取三段论推理，同时保持经典三段论推理的严谨性。

Conclusion: 在三种神经推理方法中，基于显式模型构建的神经推理是最可靠的。

Abstract: This paper compares three methodological categories of neural reasoning: LLM reasoning, supervised learning-based reasoning, and explicit model-based reasoning. LLMs remain unreliable and struggle with simple decision-making that animals can master without extensive corpora training. Through disjunctive syllogistic reasoning testing, we show that reasoning via supervised learning is less appealing than reasoning via explicit model construction. Concretely, we show that an Euler Net trained to achieve 100.00% in classic syllogistic reasoning can be trained to reach 100.00% accuracy in disjunctive syllogistic reasoning. However, the retrained Euler Net suffers severely from catastrophic forgetting (its performance drops to 6.25% on already-learned classic syllogistic reasoning), and its reasoning competence is limited to the pattern level. We propose a new version of Sphere Neural Networks that embeds concepts as circles on the surface of an n-dimensional sphere. These Sphere Neural Networks enable the representation of the negation operator via complement circles and achieve reliable decision-making by filtering out illogical statements that form unsatisfiable circular configurations. We demonstrate that the Sphere Neural Network can master 16 syllogistic reasoning tasks, including rigorous disjunctive syllogistic reasoning, while preserving the rigour of classical syllogistic reasoning. We conclude that neural reasoning with explicit model construction is the most reliable among the three methodological categories of neural reasoning.

</details>


### [116] [FlashInfer-Bench: Building the Virtuous Cycle for AI-driven LLM Systems](https://arxiv.org/abs/2601.00227)
*Shanli Xing,Yiyan Zhai,Alexander Jiang,Yixin Dong,Yong Wu,Zihao Ye,Charlie Ruan,Yingyi Huang,Yineng Zhang,Liangsheng Yin,Aksara Bayyapu,Luis Ceze,Tianqi Chen*

Main category: cs.AI

TL;DR: FlashInfer-Bench 建立了一个标准化闭环框架，将AI生成的GPU内核与真实推理系统连接，包含数据集、基准测试框架、排行榜和动态替换机制，为AI生成内核的持续改进和部署提供实用路径。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型能够生成GPU内核，但将这些AI生成的内核集成到真实推理系统中仍然具有挑战性，需要建立标准化框架来连接内核生成、基准测试和部署。

Method: 1. FlashInfer Trace提供统一模式描述内核定义、工作负载、实现和评估；2. 基于真实服务轨迹构建数据集；3. 建立正确性和性能感知的基准测试框架；4. 创建公共排行榜跟踪LLM代理的GPU编程能力；5. 开发动态替换机制apply()将最佳内核注入生产LLM引擎。

Result: FlashInfer-Bench成功建立了实用、可复现的框架，能够评估LLM代理的性能和局限性，比较不同GPU编程语言的权衡，并为未来代理设计提供见解。

Conclusion: FlashInfer-Bench为持续改进AI生成的GPU内核并将其部署到大规模LLM推理系统中建立了实用路径，解决了AI生成内核与真实系统集成的关键挑战。

Abstract: Recent advances show that large language models (LLMs) can act as autonomous agents capable of generating GPU kernels, but integrating these AI-generated kernels into real-world inference systems remains challenging. FlashInfer-Bench addresses this gap by establishing a standardized, closed-loop framework that connects kernel generation, benchmarking, and deployment. At its core, FlashInfer Trace provides a unified schema describing kernel definitions, workloads, implementations, and evaluations, enabling consistent communication between agents and systems. Built on real serving traces, FlashInfer-Bench includes a curated dataset, a robust correctness- and performance-aware benchmarking framework, a public leaderboard to track LLM agents' GPU programming capabilities, and a dynamic substitution mechanism (apply()) that seamlessly injects the best-performing kernels into production LLM engines such as SGLang and vLLM. Using FlashInfer-Bench, we further evaluate the performance and limitations of LLM agents, compare the trade-offs among different GPU programming languages, and provide insights for future agent design. FlashInfer-Bench thus establishes a practical, reproducible pathway for continuously improving AI-generated kernels and deploying them into large-scale LLM inference.

</details>


### [117] [Will LLM-powered Agents Bias Against Humans? Exploring the Belief-Dependent Vulnerability](https://arxiv.org/abs/2601.00240)
*Zongwei Wang,Bincheng Gu,Hongyu Yu,Junliang Yu,Tao He,Jiayin Feng,Min Gao*

Main category: cs.AI

TL;DR: 研究发现LLM赋能的智能体不仅存在人口统计学偏见，还会在"我们vs他们"的最小群体线索下表现出群体间偏见。当这种群体边界与智能体-人类划分重合时，人类整体可能被智能体视为外群体。研究还提出了一种信念投毒攻击来抑制有利于人类的规范脚本。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探索LLM赋能的智能体是否会在最小群体线索下表现出群体间偏见，特别是当这种群体边界与智能体-人类划分重合时，可能导致人类整体被智能体视为外群体的风险。研究者希望识别这些漏洞以指导更安全的智能体设计。

Method: 构建了一个基于分配决策的多智能体社会模拟实验，在明确的收益权衡下测试智能体的行为。提出了信念投毒攻击(BPA)，包括初始化时的配置文件投毒(BPA-PP)和通过优化信念精炼后缀注入存储反思中的记忆投毒(BPA-MP)。

Result: 实验表明智能体在最小群体线索下表现出一致的群体间偏见。虽然当部分对应方被标记为人类时这种偏见会减弱，但这种减弱依赖于智能体相信真实人类存在的信念。信念投毒攻击能够有效抑制有利于人类的规范脚本，重新激活对人类的外群体偏见。

Conclusion: LLM赋能的智能体确实存在群体间偏见风险，特别是当群体边界与智能体-人类划分重合时。信念投毒攻击揭示了新的攻击面，需要在配置文件和记忆边界实施实际缓解策略来加强当前智能体框架的安全性。

Abstract: LLM-empowered agents can exhibit not only demographic bias (e.g., gender, religion) but also intergroup bias triggered by minimal "us" versus "them" cues. When this intergroup boundary aligns with an agent-human divide, the risk shifts from disparities among human demographic groups to a more fundamental group-level asymmetry, i.e., humans as a whole may be treated as the outgroup by agents. To examine this possibility, we construct a controlled multi-agent social simulation based on allocation decisions under explicit payoff trade-offs and find that agents exhibit a consistent intergroup bias under minimal group cues. Although this bias is attenuated when some counterparts are framed as humans, we attribute the attenuation to an implicit human-norm script that favors humans yet activates only when the agent believes a real human is present. This belief dependence creates a new attack surface. We therefore introduce a Belief Poisoning Attack (BPA) that corrupts persistent identity beliefs to suppress the human-norm script and reactivate outgroup bias toward humans, instantiated as profile poisoning at initialization (BPA-PP) and memory poisoning via optimized belief-refinement suffixes injected into stored reflections (BPA-MP). Finally, we discuss practical mitigation strategies for hardening current agent frameworks against BPA, highlighting feasible interventions at profile and memory boundaries. Extensive experiments demonstrate both the existence of agent intergroup bias and the severity of BPA across settings. Our goal in identifying these vulnerabilities is to inform safer agent design, not to enable real-world exploitation.

</details>


### [118] [ClinicalReTrial: A Self-Evolving AI Agent for Clinical Trial Protocol Optimization](https://arxiv.org/abs/2601.00290)
*Sixue Xing,Xuanye Xia,Kerui Wu,Meng Jiang,Jintai Chen,Tianfan Fu*

Main category: cs.AI

TL;DR: ClinicalReTrial是一个自我进化的AI代理框架，将临床试验失败预测转化为可操作的协议重新设计问题，通过闭环优化改进试验方案。


<details>
  <summary>Details</summary>
Motivation: 尽管现有AI方法能预测临床试验成功率，但它们只是被动诊断风险，无法在预测到失败时提供可操作的补救措施。临床试验失败是药物开发的主要瓶颈，微小的协议设计缺陷就可能毁掉有前景的治疗方案。

Method: 提出ClinicalReTrial框架，将临床试验推理转化为迭代协议重新设计问题。框架整合失败诊断、安全感知修改和候选评估，形成闭环、奖励驱动的优化系统。使用结果预测模型作为模拟环境，支持低成本评估协议修改，并提供密集奖励信号用于持续自我改进。采用分层记忆机制捕获试验内迭代级反馈，并提炼可转移的重新设计模式。

Result: 实证结果显示，ClinicalReTrial改进了83.3%的试验协议，平均成功率提升5.7%。回顾性案例研究表明，发现的重新设计策略与实际临床试验修改高度一致。

Conclusion: ClinicalReTrial填补了现有AI方法仅能预测失败而无法提供补救措施的空白，通过将临床试验推理转化为可操作的协议重新设计问题，为药物开发提供了主动的、可操作的解决方案。

Abstract: Clinical trial failure remains a central bottleneck in drug development, where minor protocol design flaws can irreversibly compromise outcomes despite promising therapeutics. Although cutting-edge AI methods achieve strong performance in predicting trial success, they are inherently reactive for merely diagnosing risk without offering actionable remedies once failure is anticipated. To fill this gap, this paper proposes ClinicalReTrial, a self-evolving AI agent framework that addresses this gap by casting clinical trial reasoning as an iterative protocol redesign problem. Our method integrates failure diagnosis, safety-aware modification, and candidate evaluation in a closed-loop, reward-driven optimization framework. Serving the outcome prediction model as a simulation environment, ClinicalReTrial enables low-cost evaluation of protocol modifications and provides dense reward signals for continuous self-improvement. To support efficient exploration, the framework maintains hierarchical memory that captures iteration-level feedback within trials and distills transferable redesign patterns across trials. Empirically, ClinicalReTrial improves 83.3% of trial protocols with a mean success probability gain of 5.7%, and retrospective case studies demonstrate strong alignment between the discovered redesign strategies and real-world clinical trial modifications.

</details>


### [119] [Multiagent Reinforcement Learning for Liquidity Games](https://arxiv.org/abs/2601.00324)
*Alicia Vidler,Gal A. Kaminka*

Main category: cs.AI

TL;DR: 该论文提出金融蜂群模型，将流动性博弈与理性蜂群统一，展示独立交易者如何通过差异奖励实现个体盈利与市场流动性的集体优化。


<details>
  <summary>Details</summary>
Motivation: 将蜂群方法应用于金融市场流动性建模，同时将金融分析方法用于蜂群研究，有望推动两个领域的发展。在蜂群研究中，博弈论方法有望解释理性自利参与者为何会表现出集体效用遵循现象；在金融市场中，理解独立金融代理如何自组织以改善和稳定市场对市场设计研究者具有重要意义。

Method: 将流动性博弈（交易者收益取决于交易中的总流动性）与理性蜂群（去中心化代理使用差异奖励将自利学习与全局目标对齐）统一起来。在马尔可夫团队博弈框架中使用差异奖励，定义了一个交易者蜂群，其集体目标是提供市场流动性同时保持代理独立性。

Result: 研究表明，个体流动性最大化行为有助于整体市场流动性，无需协调或共谋。金融蜂群模型为双边资产市场中理性独立代理实现个体盈利和市场效率提供了理论框架。

Conclusion: 金融蜂群模型展示了如何通过差异奖励机制使自利的交易者自发地为市场流动性做出贡献，为理解金融市场自组织和设计更稳定的市场结构提供了新视角。

Abstract: Making use of swarm methods in financial market modeling of liquidity, and techniques from financial analysis in swarm analysis, holds the potential to advance both research areas. In swarm research, the use of game theory methods holds the promise of explaining observed phenomena of collective utility adherence with rational self-interested swarm participants. In financial markets, a better understanding of how independent financial agents may self-organize for the betterment and stability of the marketplace would be a boon for market design researchers. This paper unifies Liquidity Games, where trader payoffs depend on aggregate liquidity within a trade, with Rational Swarms, where decentralized agents use difference rewards to align self-interested learning with global objectives. We offer a theoretical frameworks where we define a swarm of traders whose collective objective is market liquidity provision while maintaining agent independence. Using difference rewards within a Markov team games framework, we show that individual liquidity-maximizing behaviors contribute to overall market liquidity without requiring coordination or collusion. This Financial Swarm model provides a framework for modeling rational, independent agents where they achieve both individual profitability and collective market efficiency in bilateral asset markets.

</details>


### [120] [Bio-inspired Agentic Self-healing Framework for Resilient Distributed Computing Continuum Systems](https://arxiv.org/abs/2601.00339)
*Alaa Saleh,Praveen Kumar Donta,Roberto Morabito,Sasu Tarkoma,Anders Lindgren,Qiyang Zhang,Schahram Dustdar Susanna Pirttikangas,Lauri Lovén*

Main category: cs.AI

TL;DR: ReCiSt是一个受生物自愈机制启发的分布式计算连续系统自主故障恢复框架，通过四层架构实现故障隔离、诊断、自适应恢复和知识积累


<details>
  <summary>Details</summary>
Motivation: 分布式计算连续系统（DCCS）集成了从物联网设备到云基础设施的异构计算资源，其复杂性、移动性和动态运行条件导致频繁故障，需要可扩展、自适应和自我调节的弹性策略

Method: 将生物自愈的四个阶段（止血、炎症、增殖、重塑）重构为计算层的四层架构：包含层、诊断层、元认知层和知识层，使用语言模型驱动的智能体解释异构日志、推断根本原因、优化推理路径并重新配置资源

Result: 在公共故障数据集上评估，ReCiSt能够在数十秒内实现自愈，智能体CPU使用率最低为10%，展示了克服不确定性的深度分析和实现弹性所需的微智能体数量

Conclusion: ReCiSt框架成功将生物自愈机制转化为分布式计算系统的自主故障恢复能力，通过语言模型驱动的智能体实现了最小人工干预的系统弹性

Abstract: Human biological systems sustain life through extraordinary resilience, continually detecting damage, orchestrating targeted responses, and restoring function through self-healing. Inspired by these capabilities, this paper introduces ReCiSt, a bio-inspired agentic self-healing framework designed to achieve resilience in Distributed Computing Continuum Systems (DCCS). Modern DCCS integrate heterogeneous computing resources, ranging from resource-constrained IoT devices to high-performance cloud infrastructures, and their inherent complexity, mobility, and dynamic operating conditions expose them to frequent faults that disrupt service continuity. These challenges underscore the need for scalable, adaptive, and self-regulated resilience strategies. ReCiSt reconstructs the biological phases of Hemostasis, Inflammation, Proliferation, and Remodeling into the computational layers Containment, Diagnosis, Meta-Cognitive, and Knowledge for DCCS. These four layers perform autonomous fault isolation, causal diagnosis, adaptive recovery, and long-term knowledge consolidation through Language Model (LM)-powered agents. These agents interpret heterogeneous logs, infer root causes, refine reasoning pathways, and reconfigure resources with minimal human intervention. The proposed ReCiSt framework is evaluated on public fault datasets using multiple LMs, and no baseline comparison is included due to the scarcity of similar approaches. Nevertheless, our results, evaluated under different LMs, confirm ReCiSt's self-healing capabilities within tens of seconds with minimum of 10% of agent CPU usage. Our results also demonstrated depth of analysis to over come uncertainties and amount of micro-agents invoked to achieve resilience.

</details>


### [121] [Adaptive Causal Coordination Detection for Social Media: A Memory-Guided Framework with Semi-Supervised Learning](https://arxiv.org/abs/2601.00400)
*Weng Ding,Yi Han,Mu-Jiang-Shan Wang*

Main category: cs.AI

TL;DR: 提出自适应因果协调检测框架ACCD，通过三阶段渐进式架构动态学习最优检测配置，在协调攻击检测中F1分数达87.3%，比现有基线提升15.2%，减少68%人工标注需求。


<details>
  <summary>Details</summary>
Motivation: 当前社交媒体协调虚假行为检测方法存在三大问题：依赖表面相关性分析、使用静态参数设置、需要大量人工标注。这些限制导致检测效果有限且效率低下。

Method: 提出三阶段自适应因果协调检测框架：1) 自适应收敛交叉映射技术深度识别账户间真实因果关系；2) 半监督分类中集成主动学习和不确定性采样，减少人工标注负担；3) 基于历史检测经验的自动验证模块，实现检测结果的自验证和优化。

Result: 在Twitter IRA数据集、Reddit协调痕迹和多个广泛使用的机器人检测基准上进行评估，ACCD在协调攻击检测中F1分数达87.3%，比最强基线提升15.2%，减少68%人工标注需求，通过层次聚类优化实现2.8倍处理加速。

Conclusion: ACCD为社交媒体平台协调行为识别提供了更准确、高效、高度自动化的端到端解决方案，具有重要的实际应用价值和广泛的推广潜力。

Abstract: Detecting coordinated inauthentic behavior on social media remains a critical and persistent challenge, as most existing approaches rely on superficial correlation analysis, employ static parameter settings, and demand extensive and labor-intensive manual annotation. To address these limitations systematically, we propose the Adaptive Causal Coordination Detection (ACCD) framework. ACCD adopts a three-stage, progressive architecture that leverages a memory-guided adaptive mechanism to dynamically learn and retain optimal detection configurations for diverse coordination scenarios. Specifically, in the first stage, ACCD introduces an adaptive Convergent Cross Mapping (CCM) technique to deeply identify genuine causal relationships between accounts. The second stage integrates active learning with uncertainty sampling within a semi-supervised classification scheme, significantly reducing the burden of manual labeling. The third stage deploys an automated validation module driven by historical detection experience, enabling self-verification and optimization of the detection outcomes. We conduct a comprehensive evaluation using real-world datasets, including the Twitter IRA dataset, Reddit coordination traces, and several widely-adopted bot detection benchmarks. Experimental results demonstrate that ACCD achieves an F1-score of 87.3\% in coordinated attack detection, representing a 15.2\% improvement over the strongest existing baseline. Furthermore, the system reduces manual annotation requirements by 68\% and achieves a 2.8x speedup in processing through hierarchical clustering optimization. In summary, ACCD provides a more accurate, efficient, and highly automated end-to-end solution for identifying coordinated behavior on social platforms, offering substantial practical value and promising potential for broad application.

</details>


### [122] [Can Semantic Methods Enhance Team Sports Tactics? A Methodology for Football with Broader Applications](https://arxiv.org/abs/2601.00421)
*Alessio Di Rubbo,Mattia Neri,Remo Pareschi,Marco Pedroni,Roberto Valtancoli,Paolino Zica*

Main category: cs.AI

TL;DR: 将语义空间推理从计算语言学扩展到团队运动战术决策，将球员视为词汇、团队配置视为语义结构，通过向量空间建模评估战术匹配度


<details>
  <summary>Details</summary>
Motivation: 传统计算语言学的语义空间推理方法在团队运动战术决策中具有应用潜力，通过类比文本与团队的结构相似性，为战术分析提供新的量化框架

Method: 将球员表示为整合技术、身体、心理属性的多维向量，通过上下文加权聚合成团队语义表示，在共享向量空间中编码战术模板，使用向量距离度量评估战术匹配度

Result: 开发了Python原型系统，能够生成可解释的动态自适应策略建议，并提供属性层面的细粒度诊断洞察，方法具有跨领域通用性

Conclusion: 该方法为团队决策和性能优化提供了通用框架，未来方向包括真实数据集成、预测模拟以及人机混合战术智能系统开发

Abstract: This paper explores how semantic-space reasoning, traditionally used in computational linguistics, can be extended to tactical decision-making in team sports. Building on the analogy between texts and teams -- where players act as words and collective play conveys meaning -- the proposed methodology models tactical configurations as compositional semantic structures. Each player is represented as a multidimensional vector integrating technical, physical, and psychological attributes; team profiles are aggregated through contextual weighting into a higher-level semantic representation. Within this shared vector space, tactical templates such as high press, counterattack, or possession build-up are encoded analogously to linguistic concepts. Their alignment with team profiles is evaluated using vector-distance metrics, enabling the computation of tactical ``fit'' and opponent-exploitation potential. A Python-based prototype demonstrates how these methods can generate interpretable, dynamically adaptive strategy recommendations, accompanied by fine-grained diagnostic insights at the attribute level. Beyond football, the approach offers a generalizable framework for collective decision-making and performance optimization in team-based domains -- ranging from basketball and hockey to cooperative robotics and human-AI coordination systems. The paper concludes by outlining future directions toward real-world data integration, predictive simulation, and hybrid human-machine tactical intelligence.

</details>


### [123] [Progressive Ideation using an Agentic AI Framework for Human-AI Co-Creation](https://arxiv.org/abs/2601.00475)
*Sankar B,Srinidhi Ranjini Girish,Aadya Bharti,Dibakar Sen*

Main category: cs.AI

TL;DR: MIDAS是一个分布式AI代理系统，模拟人类元认知创意生成流程，通过专业代理团队逐步优化创意并评估全局和局部新颖性，实现真正的人机协同创意生成。


<details>
  <summary>Details</summary>
Motivation: 当前"单次爆发"式AI系统产生大量语义聚类的创意，加剧了新手设计师在生成真正新颖多样创意方面的认知挑战，需要新的框架来支持真正的人机协同创意生成。

Method: 提出MIDAS框架，用分布式专业AI代理团队替代单一AI范式，模拟人类元认知创意生成流程，逐步优化创意并评估每个创意的全局新颖性（相对于现有解决方案）和局部新颖性（相对于已生成创意）。

Result: MIDAS展示了一个可行且渐进的真正人机协同创意生成范式，将人类设计师从被动的筛选者提升为参与性、主动的协作伙伴。

Conclusion: 分布式AI代理系统能够有效支持真正新颖创意的生成，为人机协同创意设计提供了新的可行范式。

Abstract: The generation of truly novel and diverse ideas is important for contemporary engineering design, yet it remains a significant cognitive challenge for novice designers. Current 'single-spurt' AI systems exacerbate this challenge by producing a high volume of semantically clustered ideas. We propose MIDAS (Meta-cognitive Ideation through Distributed Agentic AI System), a novel framework that replaces the single-AI paradigm with a distributed 'team' of specialized AI agents designed to emulate the human meta-cognitive ideation workflow. This agentic system progressively refines ideas and assesses each one for both global novelty (against existing solutions) and local novelty (against previously generated ideas). MIDAS, therefore, demonstrates a viable and progressive paradigm for true human-AI co-creation, elevating the human designer from a passive filterer to a participatory, active, collaborative partner.

</details>


### [124] [The Illusion of Insight in Reasoning Models](https://arxiv.org/abs/2601.00514)
*Liv G. d'Aliberti,Manoel Horta Ribeiro*

Main category: cs.AI

TL;DR: 研究发现推理模型中的"顿悟时刻"（中期推理转变）实际上很罕见，不会随训练变得更频繁，也很少提高准确性，这表明它们不是模型内在的自我纠正机制，而是不稳定推理行为的症状。


<details>
  <summary>Details</summary>
Motivation: 先前研究认为像DeepSeek-R1-Zero这样的模型会在推理过程中经历"顿悟时刻"（中期推理转变），从而实现自我纠正。但尚不清楚这种内在推理策略转变是否真的能提升性能。

Method: 分析了超过100万条推理轨迹、数百个训练检查点、三个推理领域、多种解码温度和模型架构，检测中期推理转变并研究其影响。

Result: 发现推理转变很罕见，不会随训练变得更频繁，且很少提高准确性。但效果随模型不确定性变化：在高熵（高不确定性）条件下人为触发外部转变能可靠提高准确性。

Conclusion: 中期推理转变是不稳定推理行为的症状，而非内在的自我纠正机制。这表明先前对模型"顿悟"能力的认知可能被误解了。

Abstract: Do reasoning models have "Aha!" moments? Prior work suggests that models like DeepSeek-R1-Zero undergo sudden mid-trace realizations that lead to accurate outputs, implying an intrinsic capacity for self-correction. Yet, it remains unclear whether such intrinsic shifts in reasoning strategy actually improve performance. Here, we study mid-reasoning shifts and instrument training runs to detect them. Our analysis spans 1M+ reasoning traces, hundreds of training checkpoints, three reasoning domains, and multiple decoding temperatures and model architectures. We find that reasoning shifts are rare, do not become more frequent with training, and seldom improve accuracy, indicating that they do not correspond to prior perceptions of model insight. However, their effect varies with model uncertainty. Building on this finding, we show that artificially triggering extrinsic shifts under high entropy reliably improves accuracy. Our results show that mid-reasoning shifts are symptoms of unstable inference behavior rather than an intrinsic mechanism for self-correction.

</details>


### [125] [DA-DPO: Cost-efficient Difficulty-aware Preference Optimization for Reducing MLLM Hallucinations](https://arxiv.org/abs/2601.00623)
*Longtian Qiu,Shan Ning,Chuyu Zhang,Jiaxuan Sun,Xuming He*

Main category: cs.AI

TL;DR: DA-DPO提出难度感知的直接偏好优化框架，通过估计偏好数据难度并重加权训练样本，解决多模态大语言模型中偏好优化过拟合问题，提升幻觉抑制效果。


<details>
  <summary>Details</summary>
Motivation: 现有多模态DPO方法因偏好数据难度不平衡容易过拟合，模型过度关注易区分的偏好对，阻碍细粒度幻觉抑制并降低整体性能。

Method: 提出DA-DPO框架：1) 难度估计：利用预训练视觉-语言模型结合生成和对比目标，通过分布感知投票策略产生鲁棒难度分数；2) 难度感知训练：基于估计难度重加权偏好对，降低简单样本权重，强调困难样本以缓解过拟合。

Result: 实验表明DA-DPO持续改进多模态偏好优化，增强对幻觉的鲁棒性，在标准基准上获得更好的泛化能力，同时保持计算效率。

Conclusion: DA-DPO通过难度感知机制有效平衡学习过程，无需额外数据或微调阶段，实现更有效的偏好优化，提升多模态大语言模型的幻觉抑制能力。

Abstract: Direct Preference Optimization (DPO) has shown strong potential for mitigating hallucinations in Multimodal Large Language Models (MLLMs). However, existing multimodal DPO approaches often suffer from overfitting due to the difficulty imbalance in preference data. Our analysis shows that MLLMs tend to overemphasize easily distinguishable preference pairs, which hinders fine-grained hallucination suppression and degrades overall performance. To address this issue, we propose Difficulty-Aware Direct Preference Optimization (DA-DPO), a cost-effective framework designed to balance the learning process. DA-DPO consists of two main components: (1) Difficulty Estimation leverages pre-trained vision--language models with complementary generative and contrastive objectives, whose outputs are integrated via a distribution-aware voting strategy to produce robust difficulty scores without additional training; and (2) Difficulty-Aware Training reweights preference pairs based on their estimated difficulty, down-weighting easy samples while emphasizing harder ones to alleviate overfitting. This framework enables more effective preference optimization by prioritizing challenging examples, without requiring new data or extra fine-tuning stages. Extensive experiments demonstrate that DA-DPO consistently improves multimodal preference optimization, yielding stronger robustness to hallucinations and better generalization across standard benchmarks, while remaining computationally efficient. The project page is available at https://artanic30.github.io/project_pages/DA-DPO/.

</details>


### [126] [A Vision-and-Knowledge Enhanced Large Language Model for Generalizable Pedestrian Crossing Behavior Inference](https://arxiv.org/abs/2601.00694)
*Qingwen Pu,Kun Xie,Hong Yang,Guocong Zhai*

Main category: cs.AI

TL;DR: PedX-LLM：结合视觉特征和领域知识的行人过街行为推理框架，通过LLaMA-2-7B微调实现，在准确率和泛化性上超越传统方法


<details>
  <summary>Details</summary>
Motivation: 现有行人过街行为推断方法（统计模型和监督学习）泛化能力有限，在新场景表现不佳。现有LLM应用缺乏领域适应性和视觉上下文，需要更智能的解决方案

Method: 提出PedX-LLM框架：集成LLaVA提取的视觉特征、文本数据和交通领域知识，通过LoRA微调LLaMA-2-7B基础模型进行行人过街决策推理

Result: 达到82.0%平衡准确率，优于最佳统计和监督学习方法。视觉增强模块贡献2.9%性能提升，领域知识集成带来额外4.1%改进。在未见场景的零-shot配置达到66.9%准确率，few-shot学习提升至72.2%

Conclusion: PedX-LLM展示了强大的泛化能力，证实视觉和知识增强的推理使模型能够模拟人类决策逻辑，克服纯数据驱动方法的局限性

Abstract: Existing paradigms for inferring pedestrian crossing behavior, ranging from statistical models to supervised learning methods, demonstrate limited generalizability and perform inadequately on new sites. Recent advances in Large Language Models (LLMs) offer a shift from numerical pattern fitting to semantic, context-aware behavioral reasoning, yet existing LLM applications lack domain-specific adaptation and visual context. This study introduces Pedestrian Crossing LLM (PedX-LLM), a vision-and-knowledge enhanced framework designed to transform pedestrian crossing inference from site-specific pattern recognition to generalizable behavioral reasoning. By integrating LLaVA-extracted visual features with textual data and transportation domain knowledge, PedX-LLM fine-tunes a LLaMA-2-7B foundation model via Low-Rank Adaptation (LoRA) to infer crossing decisions. PedX-LLM achieves 82.0% balanced accuracy, outperforming the best statistical and supervised learning methods. Results demonstrate that the vision-augmented module contributes a 2.9% performance gain by capturing the built environment and integrating domain knowledge yields an additional 4.1% improvement. To evaluate generalizability across unseen environments, cross-site validation was conducted using site-based partitioning. The zero-shot PedX-LLM configuration achieves 66.9% balanced accuracy on five unseen test sites, outperforming the baseline data-driven methods by at least 18 percentage points. Incorporating just five validation examples via few-shot learning to PedX-LLM further elevates the balanced accuracy to 72.2%. PedX-LLM demonstrates strong generalizability to unseen scenarios, confirming that vision-and-knowledge-enhanced reasoning enables the model to mimic human-like decision logic and overcome the limitations of purely data-driven methods.

</details>


### [127] [An Agentic Framework for Neuro-Symbolic Programming](https://arxiv.org/abs/2601.00743)
*Aliakbar Nafar,Chetan Chigurupati,Danial Kamali,Hamid Karimian,Parisa Kordjamshidi*

Main category: cs.AI

TL;DR: AgenticDomiKnowS (ADS) 是一个将自由形式任务描述自动转换为完整 DomiKnowS 程序的工具，通过智能体工作流减少神经符号编程的开发时间。


<details>
  <summary>Details</summary>
Motivation: 将符号约束集成到深度学习模型中可以提高模型的鲁棒性、可解释性和数据效率，但现有框架（如 DomiKnowS）需要用户精通特定语法，这仍然是一个耗时且具有挑战性的任务。

Method: ADS 使用智能体工作流将自由形式任务描述翻译成完整的 DomiKnowS 程序，通过单独创建和测试每个 DomiKnowS 组件来实现。工作流支持可选的人工干预，允许熟悉 DomiKnowS 的用户优化中间输出。

Result: ADS 使有经验的 DomiKnowS 用户和非用户都能快速构建神经符号程序，将开发时间从数小时减少到 10-15 分钟。

Conclusion: ADS 消除了对特定库语法的依赖，通过智能体工作流和可选的人工干预机制，显著降低了神经符号编程的门槛和开发时间。

Abstract: Integrating symbolic constraints into deep learning models could make them more robust, interpretable, and data-efficient. Still, it remains a time-consuming and challenging task. Existing frameworks like DomiKnowS help this integration by providing a high-level declarative programming interface, but they still assume the user is proficient with the library's specific syntax. We propose AgenticDomiKnowS (ADS) to eliminate this dependency. ADS translates free-form task descriptions into a complete DomiKnowS program using an agentic workflow that creates and tests each DomiKnowS component separately. The workflow supports optional human-in-the-loop intervention, enabling users familiar with DomiKnowS to refine intermediate outputs. We show how ADS enables experienced DomiKnowS users and non-users to rapidly construct neuro-symbolic programs, reducing development time from hours to 10-15 minutes.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [128] [Quantifying correlations between information overload and fake news during COVID-19 pandemic: a Reddit study with BERT model approach](https://arxiv.org/abs/2601.00496)
*Jan Rawa,Julian Sienkiewicz*

Main category: cs.SI

TL;DR: 研究探索使用BERTopic模型获取主题分布的基尼指数作为信息过载的代理指标，并在COVID-19相关Reddit社区中验证其与假新闻比例的相关性。


<details>
  <summary>Details</summary>
Motivation: 信息过载是影响任务执行的普遍现象，在媒体空间中会导致新闻疲劳和新闻回避，进而促进社交媒体上假新闻的传播。目前缺乏自动追踪大型数据集中信息过载的方法。

Method: 使用BERTopic模型获取主题分布，计算基尼指数作为信息过载的代理指标。在COVID-19相关Reddit社区数据集上，通过FakeBERT分类器检测假新闻比例，分析基尼指数与假新闻比例的相关性。

Result: 全局层面发现基尼指数与假新闻比例存在显著相关性，但在社区层面的相关性分析结果不明确。

Conclusion: 基尼指数可以作为信息过载的潜在代理指标，但需要进一步研究来理解社区层面的差异，并开发更精细的测量方法。

Abstract: Information overload (IOL) is a well-known and devastating phenomenon that alters the performance of carrying out all types of tasks. It has been shown that in the media space, IOL can contribute to news fatigue and news avoidance, which often leads to the proliferation of fake news posts on social networks. However, there is a lack of automatic methods that can be used to track IOL in large datasets. In this study, we investigate whether the Gini index calculated from the distribution of topics obtained via the BERTopic model can be considered a proxy for IOL. We test our assumptions on a set of Reddit communities related to the COVID-19 pandemic and obtain a significant global correlation between the Gini index and the fraction of fake news detected by the FakeBERT classifier. However, at the community level, the correlation analysis results are ambiguous.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [129] [Delay-Tolerant Networking for Tsunami Evacuation on the Small Island of Hachijojima: A Study of Epidemic and Prophet Routing](https://arxiv.org/abs/2601.00109)
*Keiya Kawano,Milena Radenkovic*

Main category: cs.NI

TL;DR: 评估两种DTN路由方案在海啸疏散场景中的多标准性能特征


<details>
  <summary>Details</summary>
Motivation: 海啸灾害对沿海和岛屿社区构成严重威胁。大地震发生时，通信基础设施受损，传统通信渠道失效，人们需要在时间压力下做出疏散决策。移动设备可以形成延迟容忍网络(DTNs)，通过机会性接触转发信息。

Method: 在东京八丈岛海啸疏散场景中，评估两种DTN路由方案的多标准性能特征。使用延迟容忍网络技术，在通信基础设施失效的情况下，通过移动设备之间的机会性接触进行消息转发。

Result: 论文评估了两种DTN路由方案在海啸疏散场景中的性能，但具体结果未在摘要中提供。研究展示了DTN技术在海啸应急通信中的潜在应用价值。

Conclusion: DTN技术可以在传统通信基础设施失效的海啸疏散场景中提供替代通信方案，移动设备形成的机会网络能够支持应急信息共享和疏散决策。

Abstract: Tsunami disasters pose a serious and recurring threat to coastal and island communities. When a large earthquake occurs, people are forced to make evacuation decisions under extreme time pressure, often at the same time as the communication infrastructure is damaged or completely lost. In such circumstances, the familiar channels for sharing information - cellular networks, the internet, and even landlines - can no longer be relied upon. What typically remains are the mobile devices that evacuees carry with them. These devices can form Delay Tolerant Networks (DTNs), in which messages are forwarded opportunistically whenever people come into contact. To explore this, we evaluate multi-criteria performance characteristics of two DTN routing schemes in a pre-tsunami evacuation scenario for the island of Hachijojima, Japan use case.

</details>


### [130] [CTMap: LLM-Enabled Connectivity-Aware Path Planning in Millimeter-Wave Digital Twin Networks](https://arxiv.org/abs/2601.00110)
*Md Salik Parwez,Sai Teja Srivillibhutturu,Sai Venkat Reddy Kopparthi,Asfiya Misba,Debashri Roy,Habeeb Olufowobi,Charles Kim*

Main category: cs.NI

TL;DR: CTMAP是一个基于大语言模型的数字孪生框架，用于毫米波无线网络中的连接感知路径导航，通过数字孪生模拟和LLM推理优化信号强度而非仅考虑距离


<details>
  <summary>Details</summary>
Motivation: 传统导航工具仅优化距离、时间或成本，忽略了密集城市环境中信号遮挡导致的网络连接质量下降问题，特别是在毫米波网络中信号遮挡问题更为严重

Method: 1) 使用OpenStreetMap、Blender和NVIDIA Sionna的射线追踪引擎构建毫米波网络的数字孪生，模拟真实的接收信号强度地图；2) 使用改进的Dijkstra算法生成最大化累积RSS的最优路径作为训练数据；3) 基于指令调优的GPT-4进行语义路由查询推理

Result: 实验结果显示，CTMAP相比最短距离基线实现了高达10倍的累积信号强度提升，同时保持高路径有效性，能够处理"寻找最强信号路径"等语义查询

Conclusion: 数字孪生模拟与LLM推理的结合为智能、可解释、连接驱动的导航建立了可扩展基础，推动了AI赋能的6G移动系统设计

Abstract: In this paper, we present \textit{CTMAP}, a large language model (LLM) empowered digital twin framework for connectivity-aware route navigation in millimeter-wave (mmWave) wireless networks. Conventional navigation tools optimize only distance, time, or cost, overlooking network connectivity degradation caused by signal blockage in dense urban environments. The proposed framework constructs a digital twin of the physical mmWave network using OpenStreetMap, Blender, and NVIDIA Sionna's ray-tracing engine to simulate realistic received signal strength (RSS) maps. A modified Dijkstra algorithm then generates optimal routes that maximize cumulative RSS, forming the training data for instruction-tuned GPT-4-based reasoning. This integration enables semantic route queries such as ``find the strongest-signal path'' and returns connectivity-optimized paths that are interpretable by users and adaptable to real-time environmental updates. Experimental results demonstrate that CTMAP achieves up to a tenfold improvement in cumulative signal strength compared to shortest-distance baselines, while maintaining high path validity. The synergy of digital twin simulation and LLM reasoning establishes a scalable foundation for intelligent, interpretable, and connectivity-driven navigation, advancing the design of AI-empowered 6G mobility systems.

</details>


### [131] [A-FC: An Activity-Based Delay Tolerant Routing Protocol for Improving Future School Campus Emergency Communications](https://arxiv.org/abs/2601.00148)
*Chengjun Jiang,Milena Radenkovic*

Main category: cs.NI

TL;DR: 提出基于活动的首次接触(A-FC)协议，利用校园内高活跃度的"教职工节点"作为消息中继，显著提升灾难场景下的消息投递率和降低延迟。


<details>
  <summary>Details</summary>
Motivation: 校园应急通信系统在台风等灾害中至关重要，传统DTN协议（如Direct Delivery和First Contact）在高延迟和低投递率方面表现不佳，无法在通信基础设施瘫痪时维持可靠连接。

Method: 提出活动型首次接触(A-FC)协议，利用现实世界中的社会角色（特别是高活跃度的"教职工节点"）来克服网络分区问题，强制将消息上传到这些活跃节点进行中继转发。

Result: 基于福州第一中学拓扑结构的仿真结果显示，A-FC协议显著优于基准协议，达到约68%的消息投递概率，平均延迟降至4311秒，平均跳数仅为1.68。

Conclusion: A-FC协议为校园灾难响应建立了一个低成本、高可靠性的备用通信模型，通过利用校园内的社会角色结构有效解决了灾害场景下的通信中断问题。

Abstract: School Campus emergency communication systems are vital for safeguarding student safety during sudden disasters such as typhoons, which frequently cause widespread paralysis of communication infrastructure. Traditional Delay-Tolerant Network (DTN) protocols, such as Direct Delivery and First Contact, struggle to maintain reliable connections in such scenarios due to high latency and low delivery rates. This paper proposes the Activity-based First Contact (A-FC) protocol, an innovative routing scheme that leverages real-world social roles to overcome network partitioning by mandatorily uploading messages to highly active "staff nodes". We constructed a real-world evaluation scenario based on the topology of Fuzhou No. 1 Middle School. Simulation results demonstrate that the A-FC protocol significantly outperforms baseline protocols, achieving approximately 68% message delivery probability and reducing average delay to 4311 seconds. With an average hop count of merely 1.68, this protocol establishes a low-cost, highly reliable backup communication model for school campus disaster response.

</details>


### [132] [Multi-Satellite NOMA-Irregular Repetition Slotted ALOHA for IoT Networks](https://arxiv.org/abs/2601.00341)
*Estefanía Recayte,Carla Amatetti*

Main category: cs.NI

TL;DR: 论文评估了在卫星网络中采用多接收器对基于NOMA-IRSA协议的物联网系统性能的影响，发现即使只增加一个额外卫星接收器也能显著提升整体系统性能。


<details>
  <summary>Details</summary>
Motivation: 随着5G向6G过渡，物联网设备数量激增，需要整合非地面网络来满足容量需求。卫星覆盖范围广会导致用户密度高、碰撞概率增加，但巨型星座部署使地面用户可同时看到多个卫星，这为利用接收器分集提供了机会。

Method: 研究在物联网节点使用非正交多址接入(NOMA)不规则重复时隙ALOHA(IRSA)协议的场景中，评估多接收器的影响。考虑卫星信道损伤，推导系统性能下界作为网络行为快速评估工具，并分析网络设计参数在丢包率和能效方面的权衡。

Result: 研究发现，在仅增加一个额外卫星作为接收器的情况下，就能显著提升整体系统性能。论文识别了网络设计参数的内在权衡关系，特别关注丢包率和能效之间的平衡。

Conclusion: 多接收器配置在卫星物联网网络中具有显著优势，即使简单的增加一个额外卫星接收器也能带来明显的性能增益。这为未来6G非地面网络设计提供了有价值的见解，特别是在处理大规模物联网设备接入时。

Abstract: As the transition from 5G to 6G unfolds, a substantial increase in Internet of Things (IoT) devices is expected, enabling seamless and pervasive connectivity across various applications. Accommodating this surge and meeting the high capacity demands will necessitate the integration of NonTerrestrial Networks (NTNs). However, the extensive coverage area of satellites, relative to terrestrial receivers, will lead to a high density of users attempting to access the channel at the same time, increasing the collision probability. In turn, the deployment of mega constellations make it possible for ground users to be in visibility of more than one satellite at the same time, enabling receiver diversity. Therefore, in this paper, we evaluate the impact of multi-receivers in scenarios where IoT nodes share the channel following a non-orthogonal multiple access (NOMA)irregular repetition slotted ALOHA (IRSA) protocol. Considering the impairments of satellite channels, we derive a lower bound of system performance, serving as a fast tool for initial evaluation of network behavior. Additionally, we identify the trade-offs inherent to the network design parameters, with a focus on packet loss rate and energy efficiency. Notably, in the visibility of only one extra satellite as receiver yields significant gains in overall system performance.

</details>


### [133] [MAESTRO: Multi-Agent Evaluation Suite for Testing, Reliability, and Observability](https://arxiv.org/abs/2601.00481)
*Tie Ma,Yixi Chen,Vaastav Anand,Alessandro Cornacchia,Amândio R. Faustino,Guanheng Liu,Shan Zhang,Hongbin Luo,Suhaib A. Fahmy,Zafar A. Qazi,Marco Canini*

Main category: cs.NI

TL;DR: MAESTRO是一个用于评估基于LLM的多智能体系统（MAS）的测试、可靠性和可观测性的评估套件，通过标准化配置、统一接口和框架无关的执行跟踪来系统化评估智能体系统。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏系统化的方法来评估基于LLM的多智能体系统的测试、可靠性和可观测性，需要标准化的评估框架来理解MAS的执行特性、资源消耗和性能变化。

Method: MAESTRO通过统一接口标准化MAS配置和执行，支持原生和第三方MAS集成，提供轻量级适配器，导出框架无关的执行跟踪和系统级信号（延迟、成本、故障）。使用12个代表性MAS实例化，在重复运行、后端模型和工具配置上进行受控实验。

Result: 研究发现MAS执行在结构上稳定但时间上可变，导致性能和可靠性存在显著的运行间差异。MAS架构是资源概况、可重现性和成本-延迟-准确性权衡的主导因素，通常超过后端模型或工具设置的变化影响。

Conclusion: MAESTRO能够实现系统化评估，并为设计和优化智能体系统提供实证指导，帮助理解MAS的行为特性和优化方向。

Abstract: We present MAESTRO, an evaluation suite for the testing, reliability, and observability of LLM-based MAS. MAESTRO standardizes MAS configuration and execution through a unified interface, supports integrating both native and third-party MAS via a repository of examples and lightweight adapters, and exports framework-agnostic execution traces together with system-level signals (e.g., latency, cost, and failures). We instantiate MAESTRO with 12 representative MAS spanning popular agentic frameworks and interaction patterns, and conduct controlled experiments across repeated runs, backend models, and tool configurations. Our case studies show that MAS executions can be structurally stable yet temporally variable, leading to substantial run-to-run variance in performance and reliability. We further find that MAS architecture is the dominant driver of resource profiles, reproducibility, and cost-latency-accuracy trade-off, often outweighing changes in backend models or tool settings. Overall, MAESTRO enables systematic evaluation and provides empirical guidance for designing and optimizing agentic systems.

</details>


### [134] [Scheduling for TWDM-EPON-Based Fronthaul Without a Dedicated Registration Wavelength](https://arxiv.org/abs/2601.00661)
*Akash Kumar,Sourav Dutta,Goutam Das*

Main category: cs.NI

TL;DR: 提出一种TWDM EPON前传网络调度框架，支持周期性注册而无需额外波长信道，相比专用注册波长方案可支持更多RU数量。


<details>
  <summary>Details</summary>
Motivation: C-RAN架构需要满足严格延迟和抖动要求的前传系统。EPON因其成本效益和兼容性成为有前景的解决方案，但传统EPON注册过程会中断数据传输，违反eCPRI要求。ITU-T建议使用专用波长信道进行注册，但这导致带宽利用率低下。

Method: 提出一种新颖的调度框架，用于基于TWDM EPON的前传网络，该框架能够实现周期性注册而无需浪费额外的波长信道。

Result: 性能评估表明，与使用专用注册波长的基准方案相比，所提方法在给定波长信道数量下，支持的无线单元(RU)数量最多可增加71%。

Conclusion: 该调度框架有效解决了EPON前传网络中的注册问题，在满足eCPRI延迟和抖动要求的同时，显著提高了波长信道的利用效率。

Abstract: The adoption of Centralized Radio Access Network (C-RAN) architectures requires fronthaul systems capable of carrying large volumes of radio data while meeting stringent delay and jitter requirements. Ethernet Passive Optical Networks (EPONs) have emerged as a promising fronthaul solution due to their cost efficiency and compatibility with existing infrastructure. However, the traditional registration process for EPON systems halts the ongoing data transmissions during the registration period, thereby violating the enhanced Common Public Radio Interface (eCPRI) delay and jitter requirements. This limitation has been acknowledged by the ITU-T, which recommends the use of a dedicated wavelength channel for registration, leading to inefficient bandwidth utilization. In this paper, we propose a novel scheduling framework for a Time and Wavelength Division Multiplexed (TWDM) EPON-based fronthaul that enables periodic registration without wasting an additional wavelength channel. Performance evaluation demonstrates that the proposed method achieves up to a 71\% increase in the number of Radio Units (RUs) supported for a given number of wavelength channels, compared to a baseline scheme employing a dedicated registration wavelength.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [135] [Understanding Security Risks of AI Agents' Dependency Updates](https://arxiv.org/abs/2601.00205)
*Tanmay Singla,Berk Çakar,Paschal C. Amusuo,James C. Davis*

Main category: cs.SE

TL;DR: AI编码代理在依赖更新中比人类更频繁选择已知漏洞版本，且修复更困难，导致安全风险增加


<details>
  <summary>Details</summary>
Motivation: 随着AI编码代理通过PR修改软件，需要了解其依赖决策是否引入独特的安全风险，因为依赖是现代软件供应链的关键控制点

Method: 分析7个生态系统中117,062个依赖变更，比较AI代理和人类在PR中的依赖决策，包括漏洞版本选择频率和修复难度

Result: AI代理选择已知漏洞版本的比例更高（2.46% vs 1.64%），修复更困难（36.8%需要主版本升级 vs 12.9%），整体导致漏洞净增加98个，而人类减少1,316个

Conclusion: 需要在PR时进行漏洞筛查和注册表感知的防护措施，使AI驱动的依赖更新更安全

Abstract: Package dependencies are a critical control point in modern software supply chains. Dependency changes can substantially alter a project's security posture. As AI coding agents increasingly modify software via pull requests, it is unclear whether their dependency decisions introduce distinct security risks.
  We study 117,062 dependency changes from agent- and human-authored pull requests across seven ecosystems. Agents select known-vulnerable versions more often than humans (2.46% vs. 1.64%), and their vulnerable selections are more disruptive to remediate, with 36.8% requiring major-version upgrades compared to 12.9% for humans, despite patched alternatives existing in most cases. At the aggregate level, agent-driven dependency work yields a net vulnerability increase of 98, whereas human-authored work yields a net reduction of 1,316. These findings motivate pull-request-time vulnerability screening and registry-aware guardrails to make agent-driven dependency updates safer.

</details>


### [136] [Advanced Vulnerability Scanning for Open Source Software: Detection and Mitigation of Log4j Vulnerabilities](https://arxiv.org/abs/2601.00235)
*Victor Wen,Zedong Peng*

Main category: cs.SE

TL;DR: 开发了一个先进的Log4j扫描工具，通过评估软件的实际可利用性来减少误报，集成到GitHub Actions中实现自动化持续扫描，准确率达到91.4%。


<details>
  <summary>Details</summary>
Motivation: Log4Shell漏洞披露后，仍有大量Log4j下载包含易受攻击的包。现有检测工具主要关注识别Log4j版本，导致大量误报，因为它们不检查软件是否真的易受恶意攻击者利用。

Method: 开发先进的Log4j扫描工具，首先识别漏洞，然后提供针对性的缓解建议和即时反馈。通过GitHub Actions集成，提供自动化持续扫描能力，确保在代码变更时及时识别漏洞。

Result: 评估了28个开源软件项目的不同版本，从140次扫描样本中实现了91.4%的准确率。GitHub Action实现已在GitHub市场可用。

Conclusion: 该工具提供了一种可靠的方法来检测和缓解开源项目中的漏洞，通过集成到现有开发工作流中实现实时监控和快速响应潜在威胁。

Abstract: Automated detection of software vulnerabilities remains a critical challenge in software security. Log4j is an industrial-grade Java logging framework listed as one of the top 100 critical open source projects. On Dec. 10, 2021 a severe vulnerability Log4Shell was disclosed before being fully patched with Log4j2 version 2.17.0 on Dec. 18, 2021. However, to this day about 4.1 million, or 33 percent of all Log4j downloads in the last 7 days contain vulnerable packages. Many Log4Shell scanners have since been created to detect if a user's installed Log4j version is vulnerable. Current detection tools primarily focus on identifying the version of Log4j installed, leading to numerous false positives, as they do not check if the software scanned is really vulnerable to malicious actors. This research aims to develop an advanced Log4j scanning tool that can evaluate the real-world exploitability of the software, thereby reducing false positives. Our approach first identifies vulnerabilities and then provides targeted recommendations for mitigating these detected vulnerabilities, along with instant feedback to users. By leveraging GitHub Actions, our tool offers automated and continuous scanning capabilities, ensuring timely identification of vulnerabilities as code changes occur. This integration into existing development workflows enables real-time monitoring and quicker responses to potential threats. We demonstrate the effectiveness of our approach by evaluating 28 open-source software projects across different releases, achieving an accuracy rate of 91.4% from a sample of 140 scans. Our GitHub action implementation is available at the GitHub marketplace and can be accessed by anyone interested in improving their software security and for future studies. This tool provides a dependable way to detect and mitigate vulnerabilities in open-source projects.

</details>


### [137] [An Empirical Evaluation of LLM-Based Approaches for Code Vulnerability Detection: RAG, SFT, and Dual-Agent Systems](https://arxiv.org/abs/2601.00254)
*Md Hasan Saju,Maher Muhtadi,Akramul Azim*

Main category: cs.SE

TL;DR: 本文比较了三种基于大语言模型的软件漏洞检测方法：检索增强生成(RAG)、监督微调(SFT)和双代理框架，发现RAG方法在准确率和F1分数上表现最佳。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型的快速发展，为自动化软件漏洞检测提供了新机遇。本文旨在比较不同LLM技术在软件漏洞检测中的有效性，以提升现代代码库的安全性。

Method: 研究比较了三种方法：1) 检索增强生成(RAG)，整合互联网和MITRE CWE数据库的外部领域知识；2) 监督微调(SFT)，使用参数高效的QLoRA适配器；3) 双代理LLM框架，其中第二个代理审计和优化第一个代理的输出。使用从Big-Vul和GitHub真实代码库中整理的包含五个关键CWE类别的数据集进行评估。

Result: RAG方法取得了最高的整体准确率(0.86)和F1分数(0.85)。SFT方法也表现出色。双代理系统在提高推理透明度和错误缓解方面显示出潜力，同时减少了资源开销。

Conclusion: 研究表明，整合领域专业知识机制能显著增强LLM在实际漏洞检测任务中的适用性。RAG方法因其上下文增强能力而表现最佳，为实际应用提供了有效解决方案。

Abstract: The rapid advancement of Large Language Models (LLMs) presents new opportunities for automated software vulnerability detection, a crucial task in securing modern codebases. This paper presents a comparative study on the effectiveness of LLM-based techniques for detecting software vulnerabilities. The study evaluates three approaches, Retrieval-Augmented Generation (RAG), Supervised Fine-Tuning (SFT), and a Dual-Agent LLM framework, against a baseline LLM model. A curated dataset was compiled from Big-Vul and real-world code repositories from GitHub, focusing on five critical Common Weakness Enumeration (CWE) categories: CWE-119, CWE-399, CWE-264, CWE-20, and CWE-200. Our RAG approach, which integrated external domain knowledge from the internet and the MITRE CWE database, achieved the highest overall accuracy (0.86) and F1 score (0.85), highlighting the value of contextual augmentation. Our SFT approach, implemented using parameter-efficient QLoRA adapters, also demonstrated strong performance. Our Dual-Agent system, an architecture in which a secondary agent audits and refines the output of the first, showed promise in improving reasoning transparency and error mitigation, with reduced resource overhead. These results emphasize that incorporating a domain expertise mechanism significantly strengthens the practical applicability of LLMs in real-world vulnerability detection tasks.

</details>


### [138] [In Line with Context: Repository-Level Code Generation via Context Inlining](https://arxiv.org/abs/2601.00376)
*Chao Hu,Wenhao Zeng,Yuling Shi,Beijun Shen,Xiaodong Gu*

Main category: cs.SE

TL;DR: InlineCoder是一个用于仓库级代码生成的新框架，通过将未完成函数内联到其调用图中，将复杂的仓库理解任务转化为更简单的函数级编码任务。


<details>
  <summary>Details</summary>
Motivation: 现有的仓库级代码生成方法（如RAG或基于上下文的函数选择）主要依赖表面相似性，难以捕捉控制仓库级语义的丰富依赖关系，导致在理解整个仓库时表现不足。

Method: InlineCoder首先根据函数签名生成一个草稿完成（锚点），然后进行双向内联过程：1) 上游内联 - 将锚点嵌入到其调用者中以捕捉多样使用场景；2) 下游检索 - 将锚点的被调用者集成到提示中以提供精确的依赖上下文。

Result: 通过结合草稿完成与上下游视角的丰富上下文，使LLM能够获得全面的仓库视图，从而更好地完成仓库级代码生成任务。

Conclusion: InlineCoder通过创新的内联方法，将复杂的仓库级理解问题转化为更易处理的函数级编码任务，显著提升了仓库级代码生成的性能。

Abstract: Repository-level code generation has attracted growing attention in recent years. Unlike function-level code generation, it requires the model to understand the entire repository, reasoning over complex dependencies across functions, classes, and modules. However, existing approaches such as retrieval-augmented generation (RAG) or context-based function selection often fall short: they primarily rely on surface-level similarity and struggle to capture the rich dependencies that govern repository-level semantics. In this paper, we introduce InlineCoder, a novel framework for repository-level code generation. InlineCoder enhances the understanding of repository context by inlining the unfinished function into its call graph, thereby reframing the challenging repository understanding as an easier function-level coding task. Given a function signature, InlineCoder first generates a draft completion, termed an anchor, which approximates downstream dependencies and enables perplexity-based confidence estimation. This anchor drives a bidirectional inlining process: (i) Upstream Inlining, which embeds the anchor into its callers to capture diverse usage scenarios; and (ii) Downstream Retrieval, which integrates the anchor's callees into the prompt to provide precise dependency context. The enriched context, combining draft completion with upstream and downstream perspectives, equips the LLM with a comprehensive repository view.

</details>


### [139] [On Plagiarism and Software Plagiarism](https://arxiv.org/abs/2601.00429)
*Rares Folea,Emil Slusanschi*

Main category: cs.SE

TL;DR: 本文探讨软件相似性自动检测的复杂性，介绍开源软件解决方案Project Martial，并综述现有反软件抄袭方法、法律案例和技术分类。


<details>
  <summary>Details</summary>
Motivation: 软件相似性检测面临数字工件的独特挑战，需要有效的自动检测工具来应对软件抄袭问题，同时考虑学术界和法律实践中的相关发展。

Method: 1) 分析学术界和法律领域的现有反抄袭方法；2) 基于可用工件对检测挑战进行分类；3) 综述文献中的技术（指纹识别、软件水印、代码嵌入等）；4) 在Project Martial项目中应用部分技术。

Result: 提出了Project Martial开源软件解决方案，系统梳理了软件相似性检测的技术分类和法律背景，为实际应用提供了技术框架。

Conclusion: 软件相似性检测是一个复杂领域，需要结合技术方法和法律理解。Project Martial为开源社区提供了实用的检测工具，同时该研究为未来工作提供了系统的分类框架。

Abstract: This paper explores the complexities of automatic detection of software similarities, in relation to the unique challenges of digital artifacts, and introduces Project Martial, an open-source software solution for detecting code similarity. This research enumerates some of the existing approaches to counter software plagiarism by examining both the academia and legal landscape, including notable lawsuits and court rulings that have shaped the understanding of software copyright infringements in commercial applications. Furthermore, we categorize the classes of detection challenges based on the available artifacts, and we provide a survey of the previously studied techniques in the literature, including solutions based on fingerprinting, software birthmarks, or code embeddings, and exemplify how a subset of them can be applied in the context of Project Martial.

</details>


### [140] [DSL or Code? Evaluating the Quality of LLM-Generated Algebraic Specifications: A Case Study in Optimization at Kinaxis](https://arxiv.org/abs/2601.00469)
*Negin Ayoughi,David Dewar,Shiva Nejati,Mehrdad Sabetzadeh*

Main category: cs.SE

TL;DR: EXEOS是一个基于LLM的方法，可以从自然语言描述生成AMPL模型和Python代码，并通过求解器反馈进行迭代优化，在数学优化领域表现优于Python代码。


<details>
  <summary>Details</summary>
Motivation: 尽管模型驱动工程（MDE）提供了抽象和分析严谨性，但在许多领域的工业采用受到模型开发和维护成本的限制。大型语言模型（LLMs）可以通过从自然语言描述直接生成模型来帮助改变这种成本平衡。然而，对于领域特定语言（DSLs），LLM生成的模型可能不如主流语言（如Python）的LLM生成代码准确，因为后者在LLM训练语料库中占主导地位。

Method: 作者提出了EXEOS方法，这是一个基于LLM的方法，可以从自然语言问题描述中推导出AMPL模型和Python代码，并通过求解器反馈进行迭代优化。该方法在公共优化数据集和工业合作伙伴Kinaxis的真实供应链案例上进行了评估。

Result: 使用两个LLM家族的消融研究表明，AMPL在可执行性和正确性方面与Python竞争，有时甚至优于Python。EXEOS中的设计选择提高了生成规范的质量。

Conclusion: LLM可以有效地从自然语言描述生成领域特定语言（如AMPL）的模型，并且通过适当的反馈机制，这些模型可以与主流语言（如Python）的生成代码竞争甚至超越。这为降低模型驱动工程的采用成本提供了有前景的途径。

Abstract: Model-driven engineering (MDE) provides abstraction and analytical rigour, but industrial adoption in many domains has been limited by the cost of developing and maintaining models. Large language models (LLMs) can help shift this cost balance by supporting direct generation of models from natural-language (NL) descriptions. For domain-specific languages (DSLs), however, LLM-generated models may be less accurate than LLM-generated code in mainstream languages such as Python, due to the latter's dominance in LLM training corpora. We investigate this issue in mathematical optimization, with AMPL, a DSL with established industrial use. We introduce EXEOS, an LLM-based approach that derives AMPL models and Python code from NL problem descriptions and iteratively refines them with solver feedback. Using a public optimization dataset and real-world supply-chain cases from our industrial partner Kinaxis, we evaluate generated AMPL models against Python code in terms of executability and correctness. An ablation study with two LLM families shows that AMPL is competitive with, and sometimes better than, Python, and that our design choices in EXEOS improve the quality of generated specifications.

</details>


### [141] [Multi-Agent Coordinated Rename Refactoring](https://arxiv.org/abs/2601.00482)
*Abhiram Bellur,Mohammed Raihan Ullah,Fraol Batole,Mohit Kansara,Masaharu Morimoto,Kai Ishikawa,Haifeng Chen,Yaroslav Zharov,Timofey Bryksin,Tien N. Nguyen,Hridesh Rajan,Danny Dig*

Main category: cs.SE

TL;DR: 提出首个多智能体框架来自动化协调重命名，通过开发者初始重构线索推断相关重构范围，使用三个智能体协作完成安全、准确的项目范围重命名重构。


<details>
  <summary>Details</summary>
Motivation: 协调重命名是常见但困难的任务，开发者需要手动在多个文件和上下文中传播重命名重构，过程繁琐且易出错。现有启发式方法产生过多误报，而普通大语言模型因上下文有限且无法与重构工具交互，只能提供不完整建议。

Method: 设计了三智能体框架：1) 范围推断智能体将开发者初始重构线索转化为明确自然语言声明的范围；2) 计划执行智能体使用该计划识别需要重构的程序元素，并通过调用IDE可信重构API安全执行更改；3) 复制智能体指导项目范围搜索。

Result: 在609K次提交的100个开源项目中进行了形成性研究，并调查了205名开发者。框架能显著减少开发者负担，同时保持开发者在主导地位。

Conclusion: AI智能体在软件开发中的主要价值在于扩展开发者的推理和行动能力，而非取代人类参与。协调重命名正是智能体可以显著减轻开发者负担的重复性任务，同时保持开发者在主导地位。

Abstract: The primary value of AI agents in software development lies in their ability to extend the developer's capacity for reasoning and action, not to supplant human involvement. To showcase how to use agents working in tandem with developers, we designed a novel approach for carrying out coordinated renaming. Coordinated renaming, where a single rename refactoring triggers refactorings in multiple, related identifiers, is a frequent yet challenging task. Developers must manually propagate these rename refactorings across numerous files and contexts, a process that is both tedious and highly error-prone. State-of-the-art heuristic-based approaches produce an overwhelming number of false positives, while vanilla Large Language Models (LLMs) provide incomplete suggestions due to their limited context and inability to interact with refactoring tools. This leaves developers with incomplete refactorings or burdens them with filtering too many false positives. Coordinated renaming is exactly the kind of repetitive task that agents can significantly reduce the developers' burden while keeping them in the driver's seat.
  We designed, implemented, and evaluated the first multi-agent framework that automates coordinated renaming. It operates on a key insight: a developer's initial refactoring is a clue to infer the scope of related refactorings. Our Scope Inference Agent first transforms this clue into an explicit, natural-language Declared Scope. The Planned Execution Agent then uses this as a strict plan to identify program elements that should undergo refactoring and safely executes the changes by invoking the IDE's own trusted refactoring APIs. Finally, the Replication Agent uses it to guide the project-wide search. We first conducted a formative study on the practice of coordinated renaming in 609K commits in 100 open-source projects and surveyed 205 developers ...

</details>


### [142] [STELLAR: A Search-Based Testing Framework for Large Language Model Applications](https://arxiv.org/abs/2601.00497)
*Lev Sorokin,Ivan Vasilev,Ken E. Friedl,Andrea Stocco*

Main category: cs.SE

TL;DR: STELLAR是一个基于进化优化的自动化搜索测试框架，用于发现LLM应用中导致不当响应的文本输入，相比基线方法能暴露更多故障。


<details>
  <summary>Details</summary>
Motivation: LLM应用在客服、教育、出行等领域广泛应用，但容易产生不准确、虚构或有害的响应，且其高维输入空间使系统测试特别困难。

Method: 将测试生成建模为优化问题，将输入空间离散化为风格、内容和扰动特征，采用进化优化动态探索更可能暴露故障的特征组合。

Result: 在三个LLM对话问答系统上评估：安全基准测试和车载场所推荐系统。STELLAR暴露的故障最多达基线方法的4.3倍（平均2.5倍）。

Conclusion: STELLAR框架能有效发现LLM应用中的不当响应，相比现有方法显著提高了故障检测能力，为LLM系统测试提供了新方法。

Abstract: Large Language Model (LLM)-based applications are increasingly deployed across various domains, including customer service, education, and mobility. However, these systems are prone to inaccurate, fictitious, or harmful responses, and their vast, high-dimensional input space makes systematic testing particularly challenging. To address this, we present STELLAR, an automated search-based testing framework for LLM-based applications that systematically uncovers text inputs leading to inappropriate system responses. Our framework models test generation as an optimization problem and discretizes the input space into stylistic, content-related, and perturbation features. Unlike prior work that focuses on prompt optimization or coverage heuristics, our work employs evolutionary optimization to dynamically explore feature combinations that are more likely to expose failures. We evaluate STELLAR on three LLM-based conversational question-answering systems. The first focuses on safety, benchmarking both public and proprietary LLMs against malicious or unsafe prompts. The second and third target navigation, using an open-source and an industrial retrieval-augmented system for in-vehicle venue recommendations. Overall, STELLAR exposes up to 4.3 times (average 2.5 times) more failures than the existing baseline approaches.

</details>


### [143] [SEMODS: A Validated Dataset of Open-Source Software Engineering Models](https://arxiv.org/abs/2601.00635)
*Alexandra González,Xavier Franch,Silverio Martínez-Fernández*

Main category: cs.SE

TL;DR: SEMODS是一个包含3,427个Hugging Face模型的软件工程专用数据集，通过自动化收集和人工标注结合LLM辅助验证构建，将模型与软件开发生命周期任务关联，支持数据分析、模型发现、基准测试和模型适配等应用。


<details>
  <summary>Details</summary>
Motivation: 随着AI在软件工程中的应用日益广泛，需要专门的模型集合来支持SE任务。Hugging Face上数百万个模型和新模型不断涌现，没有专门的目录难以识别适合SE任务的模型，因此需要构建一个SE专用的模型数据集。

Method: 从Hugging Face提取3,427个模型，采用自动化收集与严格验证相结合的方法：通过人工标注和大语言模型辅助验证，将模型与软件开发生命周期中的任务和活动关联，提供标准化的评估结果表示。

Result: 构建了SEMODS数据集，包含3,427个SE相关模型，建立了模型与SE任务的系统化关联，支持多种应用场景，包括数据分析、模型发现、基准测试和模型适配。

Conclusion: SEMODS填补了软件工程领域缺乏专门模型数据集的空白，为AI在SE中的应用提供了系统化的资源支持，有助于推动AI与软件工程的深度融合。

Abstract: Integrating Artificial Intelligence into Software Engineering (SE) requires having a curated collection of models suited to SE tasks. With millions of models hosted on Hugging Face (HF) and new ones continuously being created, it is infeasible to identify SE models without a dedicated catalogue. To address this gap, we present SEMODS: an SE-focused dataset of 3,427 models extracted from HF, combining automated collection with rigorous validation through manual annotation and large language model assistance. Our dataset links models to SE tasks and activities from the software development lifecycle, offering a standardized representation of their evaluation results, and supporting multiple applications such as data analysis, model discovery, benchmarking, and model adaptation.

</details>


### [144] [Early-Stage Prediction of Review Effort in AI-Generated Pull Requests](https://arxiv.org/abs/2601.00753)
*Dao Sy Duy Minh,Huynh Trung Kiet,Tran Chi Nguyen,Nguyen Lam Phu Quy,Phu Hoa Pham,Nguyen Dinh Ha Duong,Truong Bao Tran*

Main category: cs.SE

TL;DR: 论文分析33,707个AI代理生成的PR，发现其呈现两极行为模式：28.3%为即时合并，其余则陷入冗长评审循环。提出基于静态结构特征的Circuit Breaker模型，能提前预测高评审成本PR，AUC达0.957。


<details>
  <summary>Details</summary>
Motivation: 随着AI代理从代码补全工具转变为能大规模提交PR的完整队友，软件维护者面临新挑战：不仅要评审代码，还要管理与非人类贡献者的复杂交互循环。核心问题是：能否在人类交互开始前就预测哪些AI生成的PR会消耗过多评审精力？

Method: 分析AIDev数据集中33,707个AI代理生成的PR（来自2,807个仓库），发现两极行为模式。提出Circuit Breaker分流模型，使用仅静态结构特征（而非语义文本特征）的LightGBM模型，在时间分割上预测高评审成本PR（前20%）。

Result: LightGBM模型AUC达0.957，语义特征（TF-IDF、CodeBERT）预测价值可忽略。在20%评审预算下，模型能拦截69%的总评审工作量，实现零延迟治理。发现AI代理的评审负担由其修改内容的结构特征决定，而非语义内容。

Conclusion: 研究挑战了AI辅助代码评审的普遍假设：评审负担由AI代理修改什么（结构特征）决定，而非其说什么（语义内容）。这凸显了在人机协作中需要结构性治理机制，而非依赖语义分析。

Abstract: As autonomous AI agents transition from code completion tools to full-fledged teammates capable of opening pull requests (PRs) at scale, software maintainers face a new challenge: not just reviewing code, but managing complex interaction loops with non-human contributors. This paradigm shift raises a critical question: can we predict which agent-generated PRs will consume excessive review effort before any human interaction begins?
  Analyzing 33,707 agent-authored PRs from the AIDev dataset across 2,807 repositories, we uncover a striking two-regime behavioral pattern that fundamentally distinguishes autonomous agents from human developers. The first regime, representing 28.3 percent of all PRs, consists of instant merges (less than 1 minute), reflecting success on narrow automation tasks. The second regime involves iterative review cycles where agents frequently stall or abandon refinement (ghosting).
  We propose a Circuit Breaker triage model that predicts high-review-effort PRs (top 20 percent) at creation time using only static structural features. A LightGBM model achieves AUC 0.957 on a temporal split, while semantic text features (TF-IDF, CodeBERT) provide negligible predictive value. At a 20 percent review budget, the model intercepts 69 percent of total review effort, enabling zero-latency governance.
  Our findings challenge prevailing assumptions in AI-assisted code review: review burden is dictated by what agents touch, not what they say, highlighting the need for structural governance mechanisms in human-AI collaboration.

</details>
