<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 43]
- [cs.CL](#cs.CL) [Total: 27]
- [cs.SI](#cs.SI) [Total: 1]
- [cs.SE](#cs.SE) [Total: 10]
- [cs.NI](#cs.NI) [Total: 4]
- [cs.AI](#cs.AI) [Total: 10]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [KPM-Bench: A Kinematic Parsing Motion Benchmark for Fine-grained Motion-centric Video Understanding](https://arxiv.org/abs/2602.17768)
*Boda Lin,Yongjie Zhu,Xiaocheng Gong,Wenyu Qin,Meng Wang*

Main category: cs.CV

TL;DR: 该论文提出了KPM-Bench数据集和MoPE算法，用于解决视频描述中细粒度运动细节不足和幻觉问题，通过运动解析和提取技术提升运动中心视频描述的准确性。


<details>
  <summary>Details</summary>
Motivation: 当前视频描述模型在准确描述细粒度运动细节方面存在局限，且存在严重幻觉问题，特别是在运动中心视频中，对复杂肢体动态的精确描述至关重要但常被忽视。

Method: 1) 提出自动化标注流程，结合运动学计算和语言解析；2) 构建KPM-Bench数据集，包含细粒度视频-描述对、运动理解问答对和幻觉评估集；3) 提出MoPE算法从文本描述中提取运动属性；4) 基于MoPE设计独立幻觉评估指标；5) 将MoPE集成到GRPO后训练框架中。

Result: 开发了KPM-Bench开源数据集，提出了MoPE算法和相应评估指标，有效缓解了运动描述中的幻觉问题，显著提升了运动中心视频描述模型的可靠性。

Conclusion: 通过KPM-Bench数据集和MoPE算法的结合，系统性地解决了视频描述中的细粒度运动理解和幻觉问题，为运动中心视频理解提供了新的基准和方法。

Abstract: Despite recent advancements, video captioning models still face significant limitations in accurately describing fine-grained motion details and suffer from severe hallucination issues. These challenges become particularly prominent when generating captions for motion-centric videos, where precise depiction of intricate movements and limb dynamics is crucial yet often neglected. To alleviate this gap, we introduce an automated annotation pipeline that integrates kinematic-based motion computation with linguistic parsing, enabling detailed decomposition and description of complex human motions. Based on this pipeline, we construct and release the Kinematic Parsing Motion Benchmark (KPM-Bench), a novel open-source dataset designed to facilitate fine-grained motion understanding. KPM-Bench consists of (i) fine-grained video-caption pairs that comprehensively illustrate limb-level dynamics in complex actions, (ii) diverse and challenging question-answer pairs focusing specifically on motion understanding, and (iii) a meticulously curated evaluation set specifically designed to assess hallucination phenomena associated with motion descriptions. Furthermore, to address hallucination issues systematically, we propose the linguistically grounded Motion Parsing and Extraction (MoPE) algorithm, capable of accurately extracting motion-specific attributes directly from textual captions. Leveraging MoPE, we introduce a precise hallucination evaluation metric that functions independently of large-scale vision-language or language-only models. By integrating MoPE into the GRPO post-training framework, we effectively mitigate hallucination problems, significantly improving the reliability of motion-centric video captioning models.

</details>


### [2] [CLUTCH: Contextualized Language model for Unlocking Text-Conditioned Hand motion modelling in the wild](https://arxiv.org/abs/2602.17770)
*Balamurugan Thambiraja,Omid Taheri,Radek Danecek,Giorgio Becherini,Gerard Pons-Moll,Justus Thies*

Main category: cs.CV

TL;DR: 提出3D-HIW数据集和CLUTCH系统，用于野外场景的文本-手部动作生成与描述，解决现有方法在真实场景中动作有限和对齐不足的问题。


<details>
  <summary>Details</summary>
Motivation: 手部动作在日常生活中至关重要，但现有方法依赖工作室采集的有限数据集，难以扩展到真实野外场景，且文本-动作对齐效果不佳。

Method: (1) 构建3D-HIW数据集：结合视觉语言模型和3D手部追踪器，从大量第一人称动作视频中标注32K个3D手部动作序列和对应文本；(2) 提出CLUTCH系统：包含SHIFT（基于VQ-VAE的手部动作分词架构）和几何精炼阶段（通过重建损失微调LLM）。

Result: 在文本到手部动作生成和动作到文本描述任务上达到最先进性能，建立了可扩展的野外手部动作建模的首个基准。

Conclusion: 通过3D-HIW数据集和CLUTCH系统，首次实现了对野外场景手部动作的高质量建模，为文本-手部动作交互提供了可扩展的解决方案。

Abstract: Hands play a central role in daily life, yet modeling natural hand motions remains underexplored. Existing methods that tackle text-to-hand-motion generation or hand animation captioning rely on studio-captured datasets with limited actions and contexts, making them costly to scale to "in-the-wild" settings. Further, contemporary models and their training schemes struggle to capture animation fidelity with text-motion alignment. To address this, we (1) introduce '3D Hands in the Wild' (3D-HIW), a dataset of 32K 3D hand-motion sequences and aligned text, and (2) propose CLUTCH, an LLM-based hand animation system with two critical innovations: (a) SHIFT, a novel VQ-VAE architecture to tokenize hand motion, and (b) a geometric refinement stage to finetune the LLM. To build 3D-HIW, we propose a data annotation pipeline that combines vision-language models (VLMs) and state-of-the-art 3D hand trackers, and apply it to a large corpus of egocentric action videos covering a wide range of scenarios. To fully capture motion in-the-wild, CLUTCH employs SHIFT, a part-modality decomposed VQ-VAE, which improves generalization and reconstruction fidelity. Finally, to improve animation quality, we introduce a geometric refinement stage, where CLUTCH is co-supervised with a reconstruction loss applied directly to decoded hand motion parameters. Experiments demonstrate state-of-the-art performance on text-to-motion and motion-to-text tasks, establishing the first benchmark for scalable in-the-wild hand motion modelling. Code, data and models will be released.

</details>


### [3] [Multi-Modal Monocular Endoscopic Depth and Pose Estimation with Edge-Guided Self-Supervision](https://arxiv.org/abs/2602.17785)
*Xinwei Ju,Rema Daher,Danail Stoyanov,Sophia Bano,Francisco Vasconcelos*

Main category: cs.CV

TL;DR: PRISM：一种用于结肠镜导航的自监督单目深度与姿态估计框架，通过边缘检测和亮度解耦利用解剖和光照先验指导几何学习。


<details>
  <summary>Details</summary>
Motivation: 结肠镜辅助导航中的单目深度和姿态估计对改善筛查效果很重要，但面临纹理缺失表面、复杂光照模式、变形以及缺乏可靠真实值数据集的挑战。

Method: 提出PRISM框架，结合边缘检测（使用学习型边缘检测器如DexiNed或HED）和亮度解耦（通过内在分解模块分离着色和反射），利用解剖和光照先验指导几何学习。

Result: 在多个真实和合成数据集上实现最先进性能。消融研究发现：1）真实数据的自监督训练优于真实幻影数据的监督训练；2）视频帧率对模型性能极为重要。

Conclusion: PRISM通过结合边缘检测和亮度解耦有效解决了结肠镜深度估计的挑战，为结肠镜导航提供了实用的训练策略和最佳实践。

Abstract: Monocular depth and pose estimation play an important role in the development of colonoscopy-assisted navigation, as they enable improved screening by reducing blind spots, minimizing the risk of missed or recurrent lesions, and lowering the likelihood of incomplete examinations. However, this task remains challenging due to the presence of texture-less surfaces, complex illumination patterns, deformation, and a lack of in-vivo datasets with reliable ground truth. In this paper, we propose **PRISM** (Pose-Refinement with Intrinsic Shading and edge Maps), a self-supervised learning framework that leverages anatomical and illumination priors to guide geometric learning. Our approach uniquely incorporates edge detection and luminance decoupling for structural guidance. Specifically, edge maps are derived using a learning-based edge detector (e.g., DexiNed or HED) trained to capture thin and high-frequency boundaries, while luminance decoupling is obtained through an intrinsic decomposition module that separates shading and reflectance, enabling the model to exploit shading cues for depth estimation. Experimental results on multiple real and synthetic datasets demonstrate state-of-the-art performance. We further conduct a thorough ablation study on training data selection to establish best practices for pose and depth estimation in colonoscopy. This analysis yields two practical insights: (1) self-supervised training on real-world data outperforms supervised training on realistic phantom data, underscoring the superiority of domain realism over ground truth availability; and (2) video frame rate is an extremely important factor for model performance, where dataset-specific video frame sampling is necessary for generating high quality training data.

</details>


### [4] [LGD-Net: Latent-Guided Dual-Stream Network for HER2 Scoring with Task-Specific Domain Knowledge](https://arxiv.org/abs/2602.17793)
*Peide Zhu,Linbin Lu,Zhiqin Chen,Xiong Chen*

Main category: cs.CV

TL;DR: 提出LGD-Net框架，通过跨模态特征幻觉而非像素级图像生成，直接从H&E切片预测HER2表达水平，避免重建伪影，提高计算效率


<details>
  <summary>Details</summary>
Motivation: 标准IHC染色资源密集、昂贵且耗时，许多地区无法获得。从H&E切片直接预测HER2水平成为潜在替代方案，但现有像素级虚拟染色方法计算昂贵且易产生重建伪影，可能导致诊断错误

Method: 提出Latent-Guided Dual-Stream Network (LGD-Net)，采用跨模态特征幻觉而非显式像素级图像生成。学习将形态学H&E特征直接映射到分子潜在空间，训练时由教师IHC编码器引导。通过轻量级辅助正则化任务，利用特定领域知识（核分布和膜染色强度）正则化模型训练

Result: 在公开BCI数据集上的广泛实验表明，LGD-Net达到最先进性能，显著优于基线方法，同时支持使用单模态H&E输入进行高效推理

Conclusion: LGD-Net通过特征级而非像素级的跨模态映射，有效解决了传统虚拟染色方法的计算负担和伪影问题，为从H&E切片准确预测HER2表达水平提供了高效可靠的解决方案

Abstract: It is a critical task to evalaute HER2 expression level accurately for breast cancer evaluation and targeted treatment therapy selection. However, the standard multi-step Immunohistochemistry (IHC) staining is resource-intensive, expensive, and time-consuming, which is also often unavailable in many areas. Consequently, predicting HER2 levels directly from H&E slides has emerged as a potential alternative solution. It has been shown to be effective to use virtual IHC images from H&E images for automatic HER2 scoring. However, the pixel-level virtual staining methods are computationally expensive and prone to reconstruction artifacts that can propagate diagnostic errors. To address these limitations, we propose the Latent-Guided Dual-Stream Network (LGD-Net), a novel framework that employes cross-modal feature hallucination instead of explicit pixel-level image generation. LGD-Net learns to map morphological H&E features directly to the molecular latent space, guided by a teacher IHC encoder during training. To ensure the hallucinated features capture clinically relevant phenotypes, we explicitly regularize the model training with task-specific domain knowledge, specifically nuclei distribution and membrane staining intensity, via lightweight auxiliary regularization tasks. Extensive experiments on the public BCI dataset demonstrate that LGD-Net achieves state-of-the-art performance, significantly outperforming baseline methods while enabling efficient inference using single-modality H&E inputs.

</details>


### [5] [Enabling Training-Free Text-Based Remote Sensing Segmentation](https://arxiv.org/abs/2602.17799)
*Jose Sosa,Danila Rukhovich,Anis Kacem,Djamila Aouada*

Main category: cs.CV

TL;DR: 提出无需额外训练即可实现遥感图像文本引导分割的方法，结合对比式和生成式视觉语言模型与SAM，在19个遥感基准测试中表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型和视觉基础模型为零样本遥感图像分割提供了新机会，但大多数方法仍需额外可训练组件，限制了泛化能力和实际应用。本研究探索如何仅依赖现有基础模型实现文本引导的遥感分割。

Method: 提出两种方法：1) 对比式方法使用CLIP作为SAM网格提议的掩码选择器；2) 生成式方法使用GPT-5和LoRA调优的Qwen-VL模型为SAM生成点击提示。两种方法都实现了完全无需训练或轻量级LoRA调优的流程。

Result: 在19个遥感基准测试（包括开放词汇、指代和基于推理的任务）中展示了强大能力。对比式方法在完全零样本设置下实现了最先进的开放词汇语义分割，生成式方法中LoRA调优的Qwen-VL模型表现最佳。

Conclusion: 证明了仅依赖现有基础模型即可实现有效的遥感图像文本引导分割，无需额外训练，为实际应用提供了更通用的解决方案。

Abstract: Recent advances in Vision Language Models (VLMs) and Vision Foundation Models (VFMs) have opened new opportunities for zero-shot text-guided segmentation of remote sensing imagery. However, most existing approaches still rely on additional trainable components, limiting their generalisation and practical applicability. In this work, we investigate to what extent text-based remote sensing segmentation can be achieved without additional training, by relying solely on existing foundation models. We propose a simple yet effective approach that integrates contrastive and generative VLMs with the Segment Anything Model (SAM), enabling a fully training-free or lightweight LoRA-tuned pipeline. Our contrastive approach employs CLIP as mask selector for SAM's grid-based proposals, achieving state-of-the-art open-vocabulary semantic segmentation (OVSS) in a completely zero-shot setting. In parallel, our generative approach enables reasoning and referring segmentation by generating click prompts for SAM using GPT-5 in a zero-shot setting and a LoRA-tuned Qwen-VL model, with the latter yielding the best results. Extensive experiments across 19 remote sensing benchmarks, including open-vocabulary, referring, and reasoning-based tasks, demonstrate the strong capabilities of our approach. Code will be released at https://github.com/josesosajs/trainfree-rs-segmentation.

</details>


### [6] [VidEoMT: Your ViT is Secretly Also a Video Segmentation Model](https://arxiv.org/abs/2602.17807)
*Narges Norouzi,Idil Esen Zulfikar,Niccol`o Cavagnero,Tommie Kerssies,Bastian Leibe,Gijs Dubbelman,Daan de Geus*

Main category: cs.CV

TL;DR: VidEoMT是一个仅使用编码器的视频分割模型，通过轻量级查询传播机制实现跨帧信息传递，无需专用跟踪模块，在保持竞争力的同时达到5-10倍速度提升。


<details>
  <summary>Details</summary>
Motivation: 现有在线视频分割模型通常结合逐帧分割器和复杂的专用跟踪模块，虽然有效但引入了显著的架构复杂性和计算开销。受ViT编码器在大规模预训练下无需专用模块即可进行准确图像分割的启发，希望开发一个简单且高效的视频分割模型。

Method: 提出Video Encoder-only Mask Transformer (VidEoMT)，采用纯编码器架构。引入轻量级查询传播机制，通过重用前一帧的查询来跨帧传递信息。同时采用查询融合策略，将传播查询与一组时间无关的学习查询相结合，平衡信息传递与新内容适应性。

Result: VidEoMT在保持竞争力的准确率的同时，实现了5-10倍的速度提升，使用ViT-L骨干网络时运行速度可达160 FPS，达到了跟踪器的效果而无需额外复杂性。

Conclusion: VidEoMT证明了纯编码器架构在视频分割任务中的有效性，通过简单的查询传播和融合机制实现了高效的时间建模，为视频分割提供了一种更简单、更快速的解决方案。

Abstract: Existing online video segmentation models typically combine a per-frame segmenter with complex specialized tracking modules. While effective, these modules introduce significant architectural complexity and computational overhead. Recent studies suggest that plain Vision Transformer (ViT) encoders, when scaled with sufficient capacity and large-scale pre-training, can conduct accurate image segmentation without requiring specialized modules. Motivated by this observation, we propose the Video Encoder-only Mask Transformer (VidEoMT), a simple encoder-only video segmentation model that eliminates the need for dedicated tracking modules. To enable temporal modeling in an encoder-only ViT, VidEoMT introduces a lightweight query propagation mechanism that carries information across frames by reusing queries from the previous frame. To balance this with adaptability to new content, it employs a query fusion strategy that combines the propagated queries with a set of temporally-agnostic learned queries. As a result, VidEoMT attains the benefits of a tracker without added complexity, achieving competitive accuracy while being 5x--10x faster, running at up to 160 FPS with a ViT-L backbone. Code: https://www.tue-mps.org/videomt/

</details>


### [7] [VQPP: Video Query Performance Prediction Benchmark](https://arxiv.org/abs/2602.17814)
*Adrian Catalin Lutu,Eduard Poesina,Radu Tudor Ionescu*

Main category: cs.CV

TL;DR: 论文提出了首个视频查询性能预测（VQPP）基准，包含两个文本到视频检索数据集和两个CBVR系统，共56K文本查询和51K视频，探索了多种预检索和后检索性能预测器，并展示了VQPP在查询重写任务中的应用。


<details>
  <summary>Details</summary>
Motivation: 查询性能预测（QPP）在文本和图像检索中已有广泛研究，但在基于内容的视频检索（CBVR）领域仍未被充分探索。为了填补这一空白，需要建立一个专门的视频查询性能预测基准。

Method: 创建了包含两个文本到视频检索数据集和两个CBVR系统的VQPP基准，包含56K文本查询和51K视频，提供官方训练、验证和测试划分。探索了多种预检索和后检索性能预测器，并使用最佳预检索预测器作为奖励模型，通过直接偏好优化（DPO）训练大型语言模型进行查询重写。

Result: 预检索预测器取得了有竞争力的性能，能够在检索步骤之前实现应用。VQPP基准为视频领域的QPP研究提供了可复现比较的基础，并成功应用于查询重写任务。

Conclusion: 该研究填补了视频查询性能预测领域的空白，建立了首个VQPP基准，展示了预检索预测器的有效性，并为视频检索系统的性能优化提供了新工具。代码和基准已开源。

Abstract: Query performance prediction (QPP) is an important and actively studied information retrieval task, having various applications, such as query reformulation, query expansion, and retrieval system selection, among many others. The task has been primarily studied in the context of text and image retrieval, whereas QPP for content-based video retrieval (CBVR) remains largely underexplored. To this end, we propose the first benchmark for video query performance prediction (VQPP), comprising two text-to-video retrieval datasets and two CBVR systems, respectively. VQPP contains a total of 56K text queries and 51K videos, and comes with official training, validation and test splits, fostering direct comparisons and reproducible results. We explore multiple pre-retrieval and post-retrieval performance predictors, creating a representative benchmark for future exploration of QPP in the video domain. Our results show that pre-retrieval predictors obtain competitive performance, enabling applications before performing the retrieval step. We also demonstrate the applicability of VQPP by employing the best performing pre-retrieval predictor as reward model for training a large language model (LLM) on the query reformulation task via direct preference optimization (DPO). We release our benchmark and code at https://github.com/AdrianLutu/VQPP.

</details>


### [8] [On the Evaluation Protocol of Gesture Recognition for UAV-based Rescue Operation based on Deep Learning: A Subject-Independence Perspective](https://arxiv.org/abs/2602.17854)
*Domonkos Varga*

Main category: cs.CV

TL;DR: 该论文分析了Liu和Szirányi提出的手势识别方法，指出其评估协议存在严重的数据泄露问题，导致报告的高准确率无法反映模型对未见个体的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 针对Liu和Szirányi提出的手势识别方法，作者发现其评估协议存在缺陷，特别是帧级别的随机训练-测试分割会导致同一受试者的样本同时出现在训练集和测试集中，造成数据泄露，无法真实评估模型对未见个体的泛化能力。

Method: 通过分析已发布的混淆矩阵、学习曲线和数据集构建方式，作者系统性地证明了评估协议的问题。具体来说，他们展示了帧级别的随机分割如何不可避免地混合同一受试者的样本，导致严重的数据泄露。

Result: 研究发现，报告的高准确率指标（接近完美）是由于数据泄露造成的，而非模型真正的泛化能力。评估协议未能测量模型对未见个体的识别能力，这在无人机-人交互等实际应用中至关重要。

Conclusion: 该分析强调了在基于视觉的手势识别研究中，采用独立于受试者的数据划分方法的重要性。特别是对于需要可靠识别未见个体手势的应用（如无人机-人交互），必须确保评估协议能够真实反映模型的泛化能力。

Abstract: This paper presents a methodological analysis of the gesture-recognition approach proposed by Liu and Szirányi, with a particular focus on the validity of their evaluation protocol. We show that the reported near-perfect accuracy metrics result from a frame-level random train-test split that inevitably mixes samples from the same subjects across both sets, causing severe data leakage. By examining the published confusion matrix, learning curves, and dataset construction, we demonstrate that the evaluation does not measure generalization to unseen individuals. Our findings underscore the importance of subject-independent data partitioning in vision-based gesture-recognition research, especially for applications - such as UAV-human interaction - that require reliable recognition of gestures performed by previously unseen people.

</details>


### [9] [Learning Compact Video Representations for Efficient Long-form Video Understanding in Large Multimodal Models](https://arxiv.org/abs/2602.17869)
*Yuxiao Chen,Jue Wang,Zhikang Zhang,Jingru Yi,Xu Zhang,Yang Zou,Zhaowei Cai,Jianbo Yuan,Xinyu Li,Hao Yang,Davide Modolo*

Main category: cs.CV

TL;DR: 提出一个用于长视频理解的新框架，包含自适应视频采样器和时空视频压缩器，结合多模态大语言模型，有效处理长视频冗余问题


<details>
  <summary>Details</summary>
Motivation: 随着视频骨干架构和大型语言模型的发展，分析长达数十分钟的长视频变得可行且普遍。但视频序列固有的冗余性给现有模型带来两大挑战：1) 在内存限制内高效处理更多帧；2) 从大量输入数据中提取判别性信息。

Method: 提出端到端的长视频理解框架，包含基于信息密度的自适应视频采样器(AVS)和基于自动编码器的时空视频压缩器(SVC)，与多模态大语言模型(MLLM)集成。

Result: 该框架在多个基准测试中表现优异，既擅长长视频理解任务，也在标准视频理解基准上表现出色，证明了其处理长视频复杂性的有效性和通用性。

Conclusion: 提出的系统能自适应有效地从不同时长视频中捕获关键信息，实现高压缩率的同时保留重要判别信息，为解决长视频理解中的冗余问题提供了有效方案。

Abstract: With recent advancements in video backbone architectures, combined with the remarkable achievements of large language models (LLMs), the analysis of long-form videos spanning tens of minutes has become both feasible and increasingly prevalent. However, the inherently redundant nature of video sequences poses significant challenges for contemporary state-of-the-art models. These challenges stem from two primary aspects: 1) efficiently incorporating a larger number of frames within memory constraints, and 2) extracting discriminative information from the vast volume of input data. In this paper, we introduce a novel end-to-end schema for long-form video understanding, which includes an information-density-based adaptive video sampler (AVS) and an autoencoder-based spatiotemporal video compressor (SVC) integrated with a multimodal large language model (MLLM). Our proposed system offers two major advantages: it adaptively and effectively captures essential information from video sequences of varying durations, and it achieves high compression rates while preserving crucial discriminative information. The proposed framework demonstrates promising performance across various benchmarks, excelling in both long-form video understanding tasks and standard video understanding benchmarks. These results underscore the versatility and efficacy of our approach, particularly in managing the complexities of prolonged video sequences.

</details>


### [10] [Understanding the Fine-Grained Knowledge Capabilities of Vision-Language Models](https://arxiv.org/abs/2602.17871)
*Dhruba Ghosh,Yuhui Zhang,Ludwig Schmidt*

Main category: cs.CV

TL;DR: 研究发现当前视觉语言模型在细粒度图像分类任务上表现不佳，通过实验发现更好的视觉编码器和预训练阶段对提升细粒度分类性能至关重要。


<details>
  <summary>Details</summary>
Motivation: 虽然视觉语言模型在各种视觉问答基准测试中取得了显著进展，但近期研究表明这些模型在传统的图像分类基准测试（特别是细粒度分类）上表现落后。本文旨在探究视觉语言模型在细粒度视觉知识理解方面存在差距的原因。

Method: 对大量最新的视觉语言模型在细粒度分类基准上进行测试，通过一系列消融实验分析影响性能的因素，包括不同LLM和视觉编码器的效果，以及预训练阶段的重要性。

Result: 实验发现：1）使用更好的LLM对所有基准测试都有同等提升；2）更好的视觉编码器对细粒度分类性能有不成比例的显著提升；3）预训练阶段对细粒度性能至关重要，特别是在语言模型权重未冻结的情况下。

Conclusion: 这些发现为增强视觉语言模型的细粒度视觉理解和视觉中心能力提供了方向，强调了视觉编码器质量和预训练策略在提升细粒度分类性能中的关键作用。

Abstract: Vision-language models (VLMs) have made substantial progress across a wide range of visual question answering benchmarks, spanning visual reasoning, document understanding, and multimodal dialogue. These improvements are evident in a wide range of VLMs built on a variety of base models, alignment architectures, and training data. However, recent works show that these models trail behind in traditional image classification benchmarks, which test fine-grained visual knowledge. We test a large number of recent VLMs on fine-grained classification benchmarks and identify potential factors in the disconnect between fine-grained knowledge and other vision benchmarks. Through a series of ablation experiments, we find that using a better LLM improves all benchmark scores equally, while a better vision encoder disproportionately improves fine-grained classification performance. Furthermore, we find that the pretraining stage is also vital to fine-grained performance, particularly when the language model weights are unfrozen during pretraining. These insights pave the way for enhancing fine-grained visual understanding and vision-centric capabilities in VLMs.

</details>


### [11] [A Single Image and Multimodality Is All You Need for Novel View Synthesis](https://arxiv.org/abs/2602.17909)
*Amirhosein Javadi,Chi-Shiang Gau,Konstantinos D. Polyzos,Tara Javidi*

Main category: cs.CV

TL;DR: 该论文提出了一种利用稀疏多模态测距数据（如雷达或激光雷达）改进扩散模型单图像新视角合成的方法，通过高斯过程重建稠密深度图来替代单目深度估计，显著提升了几何一致性和视觉质量。


<details>
  <summary>Details</summary>
Motivation: 当前基于扩散模型的单图像新视角合成方法依赖于单目深度估计，但在低纹理、恶劣天气和遮挡严重的真实场景中，深度估计的可靠性有限，导致合成视图的质量和一致性受到限制。

Method: 提出多模态深度重建框架，利用极稀疏的测距传感数据（如汽车雷达或激光雷达），采用局部高斯过程公式在角度域建模深度，实现高效计算并显式量化观测有限区域的不确定性。重建的深度和不确定性可直接替换现有扩散渲染流程中的单目深度估计器。

Result: 在真实多模态驾驶场景实验中，用稀疏测距重建深度替代纯视觉深度，显著提升了单图像新视角视频生成的几何一致性和视觉质量。

Conclusion: 研究强调了可靠几何先验对基于扩散的视角合成的重要性，并证明了即使在极端稀疏情况下，多模态传感也能带来实际益处。

Abstract: Diffusion-based approaches have recently demonstrated strong performance for single-image novel view synthesis by conditioning generative models on geometry inferred from monocular depth estimation. However, in practice, the quality and consistency of the synthesized views are fundamentally limited by the reliability of the underlying depth estimates, which are often fragile under low texture, adverse weather, and occlusion-heavy real-world conditions. In this work, we show that incorporating sparse multimodal range measurements provides a simple yet effective way to overcome these limitations. We introduce a multimodal depth reconstruction framework that leverages extremely sparse range sensing data, such as automotive radar or LiDAR, to produce dense depth maps that serve as robust geometric conditioning for diffusion-based novel view synthesis. Our approach models depth in an angular domain using a localized Gaussian Process formulation, enabling computationally efficient inference while explicitly quantifying uncertainty in regions with limited observations. The reconstructed depth and uncertainty are used as a drop-in replacement for monocular depth estimators in existing diffusion-based rendering pipelines, without modifying the generative model itself. Experiments on real-world multimodal driving scenes demonstrate that replacing vision-only depth with our sparse range-based reconstruction substantially improves both geometric consistency and visual quality in single-image novel-view video generation. These results highlight the importance of reliable geometric priors for diffusion-based view synthesis and demonstrate the practical benefits of multimodal sensing even at extreme levels of sparsity.

</details>


### [12] [ZACH-ViT: Regime-Dependent Inductive Bias in Compact Vision Transformers for Medical Imaging](https://arxiv.org/abs/2602.17929)
*Athanasios Angelakis*

Main category: cs.CV

TL;DR: ZACH-ViT是一种紧凑型视觉Transformer，移除了位置嵌入和[CLS]标记，通过全局平均池化实现排列不变性，在医学图像分类任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 传统Vision Transformer依赖位置嵌入和类别标记编码固定空间先验，这在医学成像等空间布局信息较弱或不一致的场景中可能阻碍泛化能力。

Method: 提出ZACH-ViT，移除位置嵌入和[CLS]标记，通过全局平均池化实现排列不变性，使用自适应残差投影保持训练稳定性，在紧凑参数预算下运行。

Result: 在7个MedMNIST数据集上评估，ZACH-ViT（0.25M参数）在BloodMNIST上表现最佳，在PathMNIST上与TransMIL竞争，在具有强解剖先验的数据集上优势减弱。

Conclusion: 将架构归纳偏置与数据结构对齐比追求通用基准主导更重要。ZACH-ViT在资源受限的临床环境中具有部署潜力，支持亚秒级推理时间。

Abstract: Vision Transformers rely on positional embeddings and class tokens that encode fixed spatial priors. While effective for natural images, these priors may hinder generalization when spatial layout is weakly informative or inconsistent, a frequent condition in medical imaging and edge-deployed clinical systems. We introduce ZACH-ViT (Zero-token Adaptive Compact Hierarchical Vision Transformer), a compact Vision Transformer that removes both positional embeddings and the [CLS] token, achieving permutation invariance through global average pooling over patch representations. The term "Zero-token" specifically refers to removing the dedicated [CLS] aggregation token and positional embeddings; patch tokens remain unchanged and are processed normally. Adaptive residual projections preserve training stability in compact configurations while maintaining a strict parameter budget.
  Evaluation is performed across seven MedMNIST datasets spanning binary and multi-class tasks under a strict few-shot protocol (50 samples per class, fixed hyperparameters, five random seeds). The empirical analysis demonstrates regime-dependent behavior: ZACH-ViT (0.25M parameters, trained from scratch) achieves its strongest advantage on BloodMNIST and remains competitive with TransMIL on PathMNIST, while its relative advantage decreases on datasets with strong anatomical priors (OCTMNIST, OrganAMNIST), consistent with the architectural hypothesis. These findings support the view that aligning architectural inductive bias with data structure can be more important than pursuing universal benchmark dominance. Despite its minimal size and lack of pretraining, ZACH-ViT achieves competitive performance while maintaining sub-second inference times, supporting deployment in resource-constrained clinical environments. Code and models are available at https://github.com/Bluesman79/ZACH-ViT.

</details>


### [13] [ROCKET: Residual-Oriented Multi-Layer Alignment for Spatially-Aware Vision-Language-Action Models](https://arxiv.org/abs/2602.17951)
*Guoheng Sun,Tingting Du,Kaixi Feng,Chenxiang Luo,Xingguo Ding,Zheyu Shen,Ziyao Wang,Yexiao He,Ang Li*

Main category: cs.CV

TL;DR: ROCKET提出了一种残差导向的多层表示对齐框架，通过共享投影器将VLA模型的多个层与3D视觉基础模型对齐，显著提升机器人操作性能并大幅降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 现有的Vision-Language-Action模型通常在2D数据上预训练，缺乏3D空间理解能力。现有表示对齐方法通常只在单层进行监督，无法充分利用深度分布信息，而简单的多层对齐会导致梯度干扰。

Method: 提出ROCKET框架：1）将多层对齐形式化为将一个残差流对齐到另一个残差流；2）使用共享投影器通过层不变映射将VLA骨干的多个层与强大的3D视觉基础模型的多个层对齐；3）提出Matryoshka风格的稀疏激活方案来平衡多个对齐损失；4）结合免训练层选择策略。

Result: 在LIBERO数据集上仅需约4%的计算预算就达到98.5%的SOTA成功率；在LIBERO-Plus和RoboTwin上均表现出优越性能；适用于多种VLA模型。

Conclusion: ROCKET通过残差导向的多层表示对齐有效解决了现有VLA模型缺乏3D空间理解的问题，在显著降低计算成本的同时实现了优越的性能，为机器人操作任务提供了高效解决方案。

Abstract: Vision-Language-Action (VLA) models enable instruction-following robotic manipulation, but they are typically pretrained on 2D data and lack 3D spatial understanding. An effective approach is representation alignment, where a strong vision foundation model is used to guide a 2D VLA model. However, existing methods usually apply supervision at only a single layer, failing to fully exploit the rich information distributed across depth; meanwhile, naïve multi-layer alignment can cause gradient interference. We introduce ROCKET, a residual-oriented multi-layer representation alignment framework that formulates multi-layer alignment as aligning one residual stream to another. Concretely, ROCKET employs a shared projector to align multiple layers of the VLA backbone with multiple layers of a powerful 3D vision foundation model via a layer-invariant mapping, which reduces gradient conflicts. We provide both theoretical justification and empirical analyses showing that a shared projector is sufficient and outperforms prior designs, and further propose a Matryoshka-style sparse activation scheme for the shared projector to balance multiple alignment losses. Our experiments show that, combined with a training-free layer selection strategy, ROCKET requires only about 4% of the compute budget while achieving 98.5% state-of-the-art success rate on LIBERO. We further demonstrate the superior performance of ROCKET across LIBERO-Plus and RoboTwin, as well as multiple VLA models. The code and model weights can be found at https://github.com/CASE-Lab-UMD/ROCKET-VLA.

</details>


### [14] [Image Quality Assessment: Exploring Quality Awareness via Memory-driven Distortion Patterns Matching](https://arxiv.org/abs/2602.18000)
*Xuting Lan,Mingliang Zhou,Xuekai Wei,Jielu Yan,Yueting Huang,Huayan Pu,Jun Luo,Weijia Jia*

Main category: cs.CV

TL;DR: 提出基于记忆驱动的质量感知框架MQAF，通过建立存储失真模式的记忆库，在有无参考图像时动态切换双模式质量评估策略，减少对高质量参考图像的依赖。


<details>
  <summary>Details</summary>
Motivation: 现有全参考图像质量评估方法依赖参考图像质量，限制了在理想参考源不可得的实际应用。受人类视觉系统积累视觉记忆能力的启发，希望建立类似生物记忆机制的评估框架。

Method: 提出记忆驱动的质量感知框架MQAF，建立存储失真模式的记忆库，采用双模式策略：有参考图像时，自适应加权参考信息并与记忆库中的失真模式比较；无参考图像时，依赖记忆库中的失真模式推断图像质量。

Result: 实验结果表明，该方法在多个数据集上优于现有最先进方法，同时能够适应无参考和全参考两种任务。

Conclusion: MQAF通过模拟人类视觉记忆机制，有效减少了对高质量参考图像的依赖，实现了在有无参考图像情况下的灵活图像质量评估，具有更好的实际应用价值。

Abstract: Existing full-reference image quality assessment (FR-IQA) methods achieve high-precision evaluation by analysing feature differences between reference and distorted images. However, their performance is constrained by the quality of the reference image, which limits real-world applications where ideal reference sources are unavailable. Notably, the human visual system has the ability to accumulate visual memory, allowing image quality assessment on the basis of long-term memory storage. Inspired by this biological memory mechanism, we propose a memory-driven quality-aware framework (MQAF), which establishes a memory bank for storing distortion patterns and dynamically switches between dual-mode quality assessment strategies to reduce reliance on high-quality reference images. When reference images are available, MQAF obtains reference-guided quality scores by adaptively weighting reference information and comparing the distorted image with stored distortion patterns in the memory bank. When the reference image is absent, the framework relies on distortion patterns in the memory bank to infer image quality, enabling no-reference quality assessment (NR-IQA). The experimental results show that our method outperforms state-of-the-art approaches across multiple datasets while adapting to both no-reference and full-reference tasks.

</details>


### [15] [MUOT_3M: A 3 Million Frame Multimodal Underwater Benchmark and the MUTrack Tracking Method](https://arxiv.org/abs/2602.18006)
*Ahsan Baidar Bakht,Mohamad Alansari,Muhayy Ud Din,Muzammal Naseer,Sajid Javed,Irfan Hussain,Jiri Matas,Arif Mahmood*

Main category: cs.CV

TL;DR: 提出了首个伪多模态水下目标跟踪基准MUOT_3M（300万帧）和基于SAM的多模态到单模态跟踪器MUTrack，在五个基准上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 水下目标跟踪对海洋机器人、生态监测和海洋探索至关重要，但现有基准规模小且仅限RGB模态，限制了在颜色失真、浑浊和低能见度条件下的鲁棒性。

Method: 1) 构建MUOT_3M基准：包含300万帧、3030个视频，具有RGB、增强RGB、深度和语言四种模态；2) 提出MUTrack跟踪器：基于SAM架构，采用视觉几何对齐、视觉语言融合和四级知识蒸馏，将多模态知识转移到单模态学生模型。

Result: MUTrack在五个UOT基准上比最强SOTA基线高出8.40% AUC和7.80%精度，运行速度达24 FPS。MUOT_3M基准包含32个跟踪属性、677个细粒度类别。

Conclusion: MUOT_3M和MUTrack为可扩展、多模态训练但实际可部署的水下跟踪建立了新基础，解决了数据稀缺和模态限制问题。

Abstract: Underwater Object Tracking (UOT) is crucial for efficient marine robotics, large scale ecological monitoring, and ocean exploration; however, progress has been hindered by the scarcity of large, multimodal, and diverse datasets. Existing benchmarks remain small and RGB only, limiting robustness under severe color distortion, turbidity, and low visibility conditions. We introduce MUOT_3M, the first pseudo multimodal UOT benchmark comprising 3 million frames from 3,030 videos (27.8h) annotated with 32 tracking attributes, 677 fine grained classes, and synchronized RGB, estimated enhanced RGB, estimated depth, and language modalities validated by a marine biologist. Building upon MUOT_3M, we propose MUTrack, a SAM-based multimodal to unimodal tracker featuring visual geometric alignment, vision language fusion, and four level knowledge distillation that transfers multimodal knowledge into a unimodal student model. Extensive evaluations across five UOT benchmarks demonstrate that MUTrack achieves up to 8.40% higher AUC and 7.80% higher precision than the strongest SOTA baselines while running at 24 FPS. MUOT_3M and MUTrack establish a new foundation for scalable, multimodally trained yet practically deployable underwater tracking.

</details>


### [16] [Towards LLM-centric Affective Visual Customization via Efficient and Precise Emotion Manipulating](https://arxiv.org/abs/2602.18016)
*Jiamin Luo,Xuqian Gu,Jingjing Wang,Jiahong Lu*

Main category: cs.CV

TL;DR: 提出L-AVC任务，通过多模态LLM编辑图像的主观情感，并提出EPEM方法，包含EIC模块高效对齐情感语义转换和PER模块精确保留情感无关内容。


<details>
  <summary>Details</summary>
Motivation: 现有视觉定制研究主要关注控制信号（如语言、布局、边缘检测）与编辑图像的客观对齐，忽略了主观情感内容，且缺乏通用的情感视觉定制基础模型。

Method: 提出EPEM方法：1) EIC模块使LLM在编辑前后高效对齐情感语义转换；2) PER模块精确保留情感无关内容。在构建的L-AVC数据集上进行评估。

Result: 在L-AVC数据集上的综合实验评估表明，EPEM方法在L-AVC任务上优于多个最先进的基线方法，证明了情感信息对L-AVC的重要性以及EPEM在高效精确操纵情感信息方面的有效性。

Conclusion: 本文提出的L-AVC任务和EPEM方法填补了情感视觉定制领域的空白，通过高效的情感语义转换和精确的情感无关内容保留，实现了对图像主观情感的有效编辑。

Abstract: Previous studies on visual customization primarily rely on the objective alignment between various control signals (e.g., language, layout and canny) and the edited images, which largely ignore the subjective emotional contents, and more importantly lack general-purpose foundation models for affective visual customization. With this in mind, this paper proposes an LLM-centric Affective Visual Customization (L-AVC) task, which focuses on generating images within modifying their subjective emotions via Multimodal LLM. Further, this paper contends that how to make the model efficiently align emotion conversion in semantics (named inter-emotion semantic conversion) and how to precisely retain emotion-agnostic contents (named exter-emotion semantic retaining) are rather important and challenging in this L-AVC task. To this end, this paper proposes an Efficient and Precise Emotion Manipulating approach for editing subjective emotions in images. Specifically, an Efficient Inter-emotion Converting (EIC) module is tailored to make the LLM efficiently align emotion conversion in semantics before and after editing, followed by a Precise Exter-emotion Retaining (PER) module to precisely retain the emotion-agnostic contents. Comprehensive experimental evaluations on our constructed L-AVC dataset demonstrate the great advantage of the proposed EPEM approach to the L-AVC task over several state-of-the-art baselines. This justifies the importance of emotion information for L-AVC and the effectiveness of EPEM in efficiently and precisely manipulating such information.

</details>


### [17] [DeepSVU: Towards In-depth Security-oriented Video Understanding via Unified Physical-world Regularized MoE](https://arxiv.org/abs/2602.18019)
*Yujie Jin,Wenxin Zhang,Jingjing Wang,Guodong Zhou*

Main category: cs.CV

TL;DR: 本文提出深度安全导向视频理解（DeepSVU）新任务，旨在不仅识别威胁，还要归因和评估威胁原因，并提出了统一物理世界正则化MoE（UPRM）方法来解决该任务。


<details>
  <summary>Details</summary>
Motivation: 现有安全导向视频理解研究主要关注检测和定位威胁，但缺乏生成和评估威胁原因的能力。为填补这一空白，本文提出了更深入的DeepSVU任务。

Method: 提出统一物理世界正则化MoE（UPRM）方法，包含两个关键组件：统一物理世界增强MoE（UPE）块用于建模粗到细的物理世界信息，物理世界权衡正则化器（PTR）用于自适应权衡这些因素。

Result: 在DeepSVU指令数据集（UCF-C指令和CUVA指令）上的实验表明，UPRM优于多个先进的视频LLM和非VLM方法，验证了物理世界信息的重要性以及UPRM的有效性。

Conclusion: 粗到细的物理世界信息对DeepSVU任务至关重要，提出的UPRM方法能有效捕捉此类信息，为安全导向视频理解提供了新的解决方案。

Abstract: In the literature, prior research on Security-oriented Video Understanding (SVU) has predominantly focused on detecting and localize the threats (e.g., shootings, robberies) in videos, while largely lacking the effective capability to generate and evaluate the threat causes. Motivated by these gaps, this paper introduces a new chat paradigm SVU task, i.e., In-depth Security-oriented Video Understanding (DeepSVU), which aims to not only identify and locate the threats but also attribute and evaluate the causes threatening segments. Furthermore, this paper reveals two key challenges in the proposed task: 1) how to effectively model the coarse-to-fine physical-world information (e.g., human behavior, object interactions and background context) to boost the DeepSVU task; and 2) how to adaptively trade off these factors. To tackle these challenges, this paper proposes a new Unified Physical-world Regularized MoE (UPRM) approach. Specifically, UPRM incorporates two key components: the Unified Physical-world Enhanced MoE (UPE) Block and the Physical-world Trade-off Regularizer (PTR), to address the above two challenges, respectively. Extensive experiments conduct on our DeepSVU instructions datasets (i.e., UCF-C instructions and CUVA instructions) demonstrate that UPRM outperforms several advanced Video-LLMs as well as non-VLM approaches. Such information.These justify the importance of the coarse-to-fine physical-world information in the DeepSVU task and demonstrate the effectiveness of our UPRM in capturing such information.

</details>


### [18] [UAOR: Uncertainty-aware Observation Reinjection for Vision-Language-Action Models](https://arxiv.org/abs/2602.18020)
*Jiabing Yang,Yixiang Chen,Yuan Xu,Peiyan Li,Xiangnan Wu,Zichen Wen,Bowen Fang,Tao Yu,Zhengbo Zhang,Yingda Li,Kai Wang,Jing Liu,Nianfeng Liu,Yan Huang,Liang Wang*

Main category: cs.CV

TL;DR: 提出UAOR（不确定性感知观测重注入）模块，无需训练即可提升VLA模型性能，通过注意力检索在不确定性高时将观测信息重注入到下一层FFN中。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型增强方法通常需要额外观测线索（如深度图、点云）或辅助模块（如目标检测器），这些方法需要昂贵的数据收集和额外训练。希望找到一种无需训练、即插即用的方法来提升VLA模型性能。

Method: 提出UAOR模块，当语言模型层表现出高不确定性（通过动作熵衡量）时，通过注意力检索将关键观测信息重注入到下一层的FFN中。这是一种训练免费、即插即用的机制。

Result: 综合实验表明，该方法能持续提升各种VLA模型在仿真和真实世界任务中的性能，且开销极小。特别地，UAOR无需额外观测线索或模块，成为现有VLA流程的通用实用插件。

Conclusion: UAOR是一种有效、无需训练、即插即用的VLA模型增强模块，通过不确定性感知的观测重注入机制，使模型在推理过程中更好地关注观测信息，生成更自信和可靠的动作。

Abstract: Vision-Language-Action (VLA) models leverage pretrained Vision-Language Models (VLMs) as backbones to map images and instructions to actions, demonstrating remarkable potential for generalizable robotic manipulation. To enhance performance, existing methods often incorporate extra observation cues (e.g., depth maps, point clouds) or auxiliary modules (e.g., object detectors, encoders) to enable more precise and reliable task execution, yet these typically require costly data collection and additional training. Inspired by the finding that Feed-Forward Network (FFN) in language models can act as "key-value memory", we propose Uncertainty-aware Observation Reinjection (UAOR), an effective, training-free and plug-and-play module for VLA models. Specifically, when the current language model layer exhibits high uncertainty, measured by Action Entropy, it reinjects key observation information into the next layer's Feed-Forward Network (FFN) through attention retrieval. This mechanism helps VLAs better attend to observations during inference, enabling more confident and faithful action generation. Comprehensive experiments show that our method consistently improves diverse VLA models across simulation and real-world tasks with minimal overhead. Notably, UAOR eliminates the need for additional observation cues or modules, making it a versatile and practical plug-in for existing VLA pipelines. The project page is at https://uaor.jiabingyang.cn.

</details>


### [19] [Dual-Channel Attention Guidance for Training-Free Image Editing Control in Diffusion Transformers](https://arxiv.org/abs/2602.18022)
*Guandong Li,Mengxia Ye*

Main category: cs.CV

TL;DR: 提出Dual-Channel Attention Guidance (DCAG)框架，通过同时操纵DiT中的Key和Value通道实现无训练的编辑强度控制，相比仅操作Key的方法能更精确地平衡编辑效果与保真度。


<details>
  <summary>Details</summary>
Motivation: 现有基于DiT的扩散图像编辑模型需要无训练的编辑强度控制。当前注意力操纵方法仅关注Key空间来调节注意力路由，完全忽略了控制特征聚合的Value空间，限制了编辑效果的精确控制。

Method: 首先发现DiT多模态注意力层中的Key和Value投影都表现出明显的偏置-增量结构。基于此提出DCAG框架，同时操纵Key通道（控制注意力位置）和Value通道（控制特征聚合）。理论分析表明Key通道通过非线性softmax函数作为粗粒度控制，Value通道通过线性加权求和作为细粒度补充。

Result: 在PIE-Bench基准测试（700张图像，10个编辑类别）上，DCAG在所有保真度指标上均优于仅使用Key引导的方法。在局部编辑任务中改进最显著：对象删除（LPIPS减少4.9%）和对象添加（LPIPS减少3.2%）。

Conclusion: DCAG通过同时操纵Key和Value通道，在二维参数空间(δ_k, δ_v)中实现了比单通道方法更精确的编辑-保真度权衡，为基于DiT的图像编辑提供了更精细的控制能力。

Abstract: Training-free control over editing intensity is a critical requirement for diffusion-based image editing models built on the Diffusion Transformer (DiT) architecture. Existing attention manipulation methods focus exclusively on the Key space to modulate attention routing, leaving the Value space -- which governs feature aggregation -- entirely unexploited. In this paper, we first reveal that both Key and Value projections in DiT's multi-modal attention layers exhibit a pronounced bias-delta structure, where token embeddings cluster tightly around a layer-specific bias vector. Building on this observation, we propose Dual-Channel Attention Guidance (DCAG), a training-free framework that simultaneously manipulates both the Key channel (controlling where to attend) and the Value channel (controlling what to aggregate). We provide a theoretical analysis showing that the Key channel operates through the nonlinear softmax function, acting as a coarse control knob, while the Value channel operates through linear weighted summation, serving as a fine-grained complement. Together, the two-dimensional parameter space $(δ_k, δ_v)$ enables more precise editing-fidelity trade-offs than any single-channel method. Extensive experiments on the PIE-Bench benchmark (700 images, 10 editing categories) demonstrate that DCAG consistently outperforms Key-only guidance across all fidelity metrics, with the most significant improvements observed in localized editing tasks such as object deletion (4.9% LPIPS reduction) and object addition (3.2% LPIPS reduction).

</details>


### [20] [Spatio-temporal Decoupled Knowledge Compensator for Few-Shot Action Recognition](https://arxiv.org/abs/2602.18043)
*Hongyu Qu,Xiangbo Shu,Rui Yan,Hailiang Gao,Wenguan Wang,Jinhui Tang*

Main category: cs.CV

TL;DR: DiST提出了一种基于分解-融合的少样本动作识别框架，利用大语言模型提供的解耦空间和时间知识来学习多粒度原型，在五个标准数据集上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有少样本动作识别方法通常使用语义粗糙的类别名称作为辅助上下文，但这样的上下文信息有限，无法为捕捉动作中的新颖空间和时间概念提供足够的背景知识。

Method: 提出DiST框架：1）分解阶段：将原始动作名称解耦为多样化的时空属性描述；2）融合阶段：提出空间/时间知识补偿器（SKC/TKC）分别发现判别性的对象级和帧级原型，SKC在空间知识指导下自适应聚合重要补丁标记，TKC利用时间属性辅助帧间时序关系建模。

Result: 在五个标准少样本动作识别数据集上实现了最先进的性能，证明了该方法的有效性。

Conclusion: 通过利用大语言模型提供的解耦空间和时间知识，DiST能够学习表达性强的多粒度原型，为捕捉细粒度空间细节和多样化时间模式提供了透明度，显著提升了少样本动作识别性能。

Abstract: Few-Shot Action Recognition (FSAR) is a challenging task that requires recognizing novel action categories with a few labeled videos. Recent works typically apply semantically coarse category names as auxiliary contexts to guide the learning of discriminative visual features. However, such context provided by the action names is too limited to provide sufficient background knowledge for capturing novel spatial and temporal concepts in actions. In this paper, we propose DiST, an innovative Decomposition-incorporation framework for FSAR that makes use of decoupled Spatial and Temporal knowledge provided by large language models to learn expressive multi-granularity prototypes. In the decomposition stage, we decouple vanilla action names into diverse spatio-temporal attribute descriptions (action-related knowledge). Such commonsense knowledge complements semantic contexts from spatial and temporal perspectives. In the incorporation stage, we propose Spatial/Temporal Knowledge Compensators (SKC/TKC) to discover discriminative object-level and frame-level prototypes, respectively. In SKC, object-level prototypes adaptively aggregate important patch tokens under the guidance of spatial knowledge. Moreover, in TKC, frame-level prototypes utilize temporal attributes to assist in inter-frame temporal relation modeling. These learned prototypes thus provide transparency in capturing fine-grained spatial details and diverse temporal patterns. Experimental results show DiST achieves state-of-the-art results on five standard FSAR datasets.

</details>


### [21] [CityGuard: Graph-Aware Private Descriptors for Bias-Resilient Identity Search Across Urban Cameras](https://arxiv.org/abs/2602.18047)
*Rong Fu,Wenxin Zhang,Yibo Meng,Jia Yee Tan,Jiaxuan Lu,Rui Lu,Jiekai Wu,Zhaolu Kang,Simon Fong*

Main category: cs.CV

TL;DR: CityGuard：一种用于去中心化监控的拓扑感知Transformer框架，通过分散自适应度量学习、空间条件注意力和差分隐私嵌入映射，实现隐私保护的城市规模行人重识别。


<details>
  <summary>Details</summary>
Motivation: 城市规模行人重识别面临视角变化、遮挡和域偏移等挑战，同时需要遵守数据保护法规，防止原始图像共享。需要开发既能保护隐私又能有效进行身份检索的解决方案。

Method: 1. 分散自适应度量学习：根据特征分布调整实例级边界，增强类内紧凑性；2. 空间条件注意力：将粗略几何信息（如GPS或部署平面图）注入基于图的自注意力机制，实现投影一致的跨视角对齐；3. 差分隐私嵌入映射：结合紧凑近似索引，支持安全且成本高效的部署。

Result: 在Market-1501和其他公共基准测试中，检索精度和查询吞吐量均优于强基线方法，数据库规模检索研究也证实了框架的实际可行性。

Conclusion: CityGuard框架能够生成对视角变化、遮挡和域偏移具有鲁棒性的描述符，并在严格的差分隐私核算下实现隐私与效用的可调平衡，适用于隐私关键的城市身份匹配应用。

Abstract: City-scale person re-identification across distributed cameras must handle severe appearance changes from viewpoint, occlusion, and domain shift while complying with data protection rules that prevent sharing raw imagery. We introduce CityGuard, a topology-aware transformer for privacy-preserving identity retrieval in decentralized surveillance. The framework integrates three components. A dispersion-adaptive metric learner adjusts instance-level margins according to feature spread, increasing intra-class compactness. Spatially conditioned attention injects coarse geometry, such as GPS or deployment floor plans, into graph-based self-attention to enable projectively consistent cross-view alignment using only coarse geometric priors without requiring survey-grade calibration. Differentially private embedding maps are coupled with compact approximate indexes to support secure and cost-efficient deployment. Together these designs produce descriptors robust to viewpoint variation, occlusion, and domain shifts, and they enable a tunable balance between privacy and utility under rigorous differential-privacy accounting. Experiments on Market-1501 and additional public benchmarks, complemented by database-scale retrieval studies, show consistent gains in retrieval precision and query throughput over strong baselines, confirming the practicality of the framework for privacy-critical urban identity matching.

</details>


### [22] [Temporal Consistency-Aware Text-to-Motion Generation](https://arxiv.org/abs/2602.18057)
*Hongsong Wang,Wenjing Yan,Qiuxia Lai,Xin Geng*

Main category: cs.CV

TL;DR: TCA-T2M：一个时间一致性感知的文本到动作生成框架，通过跨序列时间对齐和运动约束提升动作生成的语义对齐和物理合理性


<details>
  <summary>Details</summary>
Motivation: 现有两阶段文本到动作生成框架通常忽略跨序列时间一致性（即相同动作在不同实例间的共享时间结构），导致语义错位和物理上不合理的动作

Method: 提出TCA-T2M框架：1）时间一致性感知空间VQ-VAE用于跨序列时间对齐；2）掩码运动变换器用于文本条件动作生成；3）运动学约束块减轻离散化伪影确保物理合理性

Result: 在HumanML3D和KIT-ML基准测试中达到最先进性能，证明了时间一致性对鲁棒和连贯文本到动作生成的重要性

Conclusion: TCA-T2M通过引入时间一致性感知机制显著提升了文本到动作生成的语义对齐和物理合理性，为动作生成研究提供了新方向

Abstract: Text-to-Motion (T2M) generation aims to synthesize realistic human motion sequences from natural language descriptions. While two-stage frameworks leveraging discrete motion representations have advanced T2M research, they often neglect cross-sequence temporal consistency, i.e., the shared temporal structures present across different instances of the same action. This leads to semantic misalignments and physically implausible motions. To address this limitation, we propose TCA-T2M, a framework for temporal consistency-aware T2M generation. Our approach introduces a temporal consistency-aware spatial VQ-VAE (TCaS-VQ-VAE) for cross-sequence temporal alignment, coupled with a masked motion transformer for text-conditioned motion generation. Additionally, a kinematic constraint block mitigates discretization artifacts to ensure physical plausibility. Experiments on HumanML3D and KIT-ML benchmarks demonstrate that TCA-T2M achieves state-of-the-art performance, highlighting the importance of temporal consistency in robust and coherent T2M generation.

</details>


### [23] [DohaScript: A Large-Scale Multi-Writer Dataset for Continuous Handwritten Hindi Text](https://arxiv.org/abs/2602.18089)
*Kunwar Arpit Singh,Ankush Prakash,Haroon R Lone*

Main category: cs.CV

TL;DR: DohaScript是一个大规模、多书写者的手写印地语数据集，包含531位贡献者书写的相同六首传统印地语对句，旨在解决德瓦纳格里文字手写文本在公开基准数据集中代表性不足的问题。


<details>
  <summary>Details</summary>
Motivation: 尽管德瓦纳格里文字有数亿使用者，但其手写文本在公开基准数据集中严重不足。现有资源规模有限，主要关注孤立字符或短词，缺乏受控词汇内容和书写者多样性，无法捕捉德瓦纳格里手写体连续、融合和结构复杂的特性。

Method: 创建DohaScript数据集，收集531位独特贡献者的手写印地语文本。数据集设计为平行风格语料库，所有书写者转录相同的六首传统印地语对句。包含去识别化的人口统计元数据，基于客观清晰度和分辨率标准的严格质量筛选，以及页面级布局难度标注。

Result: 基线实验显示了清晰的质量分离和对未见书写者的强泛化能力，突出了数据集的可靠性和实用价值。数据集支持手写识别、书写者识别、风格分析和生成建模等任务。

Conclusion: DohaScript旨在作为标准化、可复现的基准，推动低资源脚本环境下连续手写德瓦纳格里文本的研究进展。

Abstract: Despite having hundreds of millions of speakers, handwritten Devanagari text remains severely underrepresented in publicly available benchmark datasets. Existing resources are limited in scale, focus primarily on isolated characters or short words, and lack controlled lexical content and writer level diversity, which restricts their utility for modern data driven handwriting analysis. As a result, they fail to capture the continuous, fused, and structurally complex nature of Devanagari handwriting, where characters are connected through a shared shirorekha (horizontal headline) and exhibit rich ligature formations. We introduce DohaScript, a large scale, multi writer dataset of handwritten Hindi text collected from 531 unique contributors. The dataset is designed as a parallel stylistic corpus, in which all writers transcribe the same fixed set of six traditional Hindi dohas (couplets). This controlled design enables systematic analysis of writer specific variation independent of linguistic content, and supports tasks such as handwriting recognition, writer identification, style analysis, and generative modeling. The dataset is accompanied by non identifiable demographic metadata, rigorous quality curation based on objective sharpness and resolution criteria, and page level layout difficulty annotations that facilitate stratified benchmarking. Baseline experiments demonstrate clear quality separation and strong generalization to unseen writers, highlighting the dataset's reliability and practical value. DohaScript is intended to serve as a standardized and reproducible benchmark for advancing research on continuous handwritten Devanagari text in low resource script settings.

</details>


### [24] [3DMedAgent: Unified Perception-to-Understanding for 3D Medical Analysis](https://arxiv.org/abs/2602.18064)
*Ziyue Wang,Linghan Cai,Chang Han Low,Haofeng Liu,Junde Wu,Jingyu Wang,Rui Wang,Lei Song,Jiang Bian,Jingjing Fu,Yueming Jin*

Main category: cs.CV

TL;DR: 3DMedAgent：一种统一代理，使2D多模态大语言模型能够执行通用3D CT分析，无需3D特定微调，通过协调异构工具和结构化记忆实现从感知到理解的渐进分析。


<details>
  <summary>Details</summary>
Motivation: 现有3D分析方法采用孤立的任务特定建模或任务无关的端到端范式，阻碍了感知证据的系统积累。同时，多模态大语言模型主要面向2D设计，限制了其对体积医学数据的感知和分析能力。

Method: 3DMedAgent通过灵活的MLLM代理协调异构视觉和文本工具，将复杂3D分析逐步分解为可处理的子任务：从全局到局部视图、从3D体积到信息丰富的2D切片、从视觉证据到结构化文本表示。核心设计包括维护长期结构化记忆，聚合中间工具输出，支持查询自适应、证据驱动的多步推理。

Result: 在超过40个任务上的实验表明，3DMedAgent在3D胸部成像的DeepChestVQA基准测试中，持续优于通用、医学和3D特定的MLLMs，展示了向通用3D临床助手扩展的可行路径。

Conclusion: 3DMedAgent为2D MLLMs提供了一种无需3D特定微调即可执行通用3D CT分析的统一代理框架，通过工具协调和结构化记忆实现从低层感知到高层临床理解的系统分析，代表了向通用3D临床助手发展的可扩展路径。

Abstract: 3D CT analysis spans a continuum from low-level perception to high-level clinical understanding. Existing 3D-oriented analysis methods adopt either isolated task-specific modeling or task-agnostic end-to-end paradigms to produce one-hop outputs, impeding the systematic accumulation of perceptual evidence for downstream reasoning. In parallel, recent multimodal large language models (MLLMs) exhibit improved visual perception and can integrate visual and textual information effectively, yet their predominantly 2D-oriented designs fundamentally limit their ability to perceive and analyze volumetric medical data. To bridge this gap, we propose 3DMedAgent, a unified agent that enables 2D MLLMs to perform general 3D CT analysis without 3D-specific fine-tuning. 3DMedAgent coordinates heterogeneous visual and textual tools through a flexible MLLM agent, progressively decomposing complex 3D analysis into tractable subtasks that transition from global to regional views, from 3D volumes to informative 2D slices, and from visual evidence to structured textual representations. Central to this design, 3DMedAgent maintains a long-term structured memory that aggregates intermediate tool outputs and supports query-adaptive, evidence-driven multi-step reasoning. We further introduce the DeepChestVQA benchmark for evaluating unified perception-to-understanding capabilities in 3D thoracic imaging. Experiments across over 40 tasks demonstrate that 3DMedAgent consistently outperforms general, medical, and 3D-specific MLLMs, highlighting a scalable path toward general-purpose 3D clinical assistants.Code and data are available at \href{https://github.com/jinlab-imvr/3DMedAgent}{https://github.com/jinlab-imvr/3DMedAgent}.

</details>


### [25] [Faster Training, Fewer Labels: Self-Supervised Pretraining for Fine-Grained BEV Segmentation](https://arxiv.org/abs/2602.18066)
*Daniel Busch,Christian Bohn,Thomas Kurbiel,Klaus Friedrichs,Richard Meyes,Tobias Meisen*

Main category: cs.CV

TL;DR: 提出一种两阶段训练策略，通过自监督预训练减少对BEV标注数据的依赖，在nuScenes数据集上使用50%标注数据达到优于全监督基线的性能


<details>
  <summary>Details</summary>
Motivation: 当前多摄像头BEV语义地图方法依赖昂贵且标注不一致的BEV地面真值，需要减少对标注数据的依赖并提高可扩展性

Method: 两阶段训练：1) 自监督预训练：将BEVFormer预测可微分重投影到图像平面，使用Mask2Former生成的多视角语义伪标签训练，加入时序一致性损失；2) 监督微调：仅需50%数据集，利用预训练学到的丰富先验

Result: 在nuScenes数据集上性能提升达+2.5pp mIoU，同时减少50%标注数据使用，总训练时间减少三分之二

Conclusion: 可微分重投影加相机视角伪标签能产生可迁移的BEV特征，为减少标注的自动驾驶感知提供可扩展路径

Abstract: Dense Bird's Eye View (BEV) semantic maps are central to autonomous driving, yet current multi-camera methods depend on costly, inconsistently annotated BEV ground truth. We address this limitation with a two-phase training strategy for fine-grained road marking segmentation that removes full supervision during pretraining and halves the amount of training data during fine-tuning while still outperforming the comparable supervised baseline model. During the self-supervised pretraining, BEVFormer predictions are differentiably reprojected into the image plane and trained against multi-view semantic pseudo-labels generated by the widely used semantic segmentation model Mask2Former. A temporal loss encourages consistency across frames. The subsequent supervised fine-tuning phase requires only 50% of the dataset and significantly less training time. With our method, the fine-tuning benefits from rich priors learned during pretraining boosting the performance and BEV segmentation quality (up to +2.5pp mIoU over the fully supervised baseline) on nuScenes. It simultaneously halves the usage of annotation data and reduces total training time by up to two thirds. The results demonstrate that differentiable reprojection plus camera perspective pseudo labels yields transferable BEV features and a scalable path toward reduced-label autonomous perception.

</details>


### [26] [OODBench: Out-of-Distribution Benchmark for Large Vision-Language Models](https://arxiv.org/abs/2602.18094)
*Ling Lin,Yang Bai,Heng Su,Congcong Zhu,Yaoxing Wang,Yang Zhou,Huazhu Fu,Jingrun Chen*

Main category: cs.CV

TL;DR: OODBench：一个自动化构建的视觉语言模型（VLM）在分布外（OOD）数据上的评估基准，包含40K实例级OOD样本，揭示了现有VLM在OOD数据上性能显著下降的问题，并提出了一种可靠的自评估指标。


<details>
  <summary>Details</summary>
Motivation: 现实应用中数据往往不满足独立同分布（IID）假设，而分布外（OOD）对象处理不当可能带来安全风险（如自动驾驶、医疗辅助）。目前缺乏全面评估VLM处理OOD数据能力的有效基准。

Method: 提出OODBench，一种主要自动化、最小人工验证的方法，用于构建新基准并评估VLM处理OOD数据的能力。包含40K实例级OOD实例-类别对，并提出基于"基础到高级渐进式"提示问题的可靠自动化评估指标。

Result: 当前VLM在OODBench上表现出显著性能下降，即使底层图像类别很常见。提出的评估指标能更全面地评估OOD数据对不同难度问题的影响。

Conclusion: OODBench为VLM在OOD数据上的评估提供了有效基准，揭示了现有模型的局限性，提出的评估方法和发现为未来OOD数据获取和评估研究提供了重要见解。

Abstract: Existing Visual-Language Models (VLMs) have achieved significant progress by being trained on massive-scale datasets, typically under the assumption that data are independent and identically distributed (IID). However, in real-world scenarios, it is often impractical to expect that all data processed by an AI system satisfy this assumption. Furthermore, failure to appropriately handle out-of-distribution (OOD) objects may introduce safety risks in real-world applications (e.g., autonomous driving or medical assistance). Unfortunately, current research has not yet provided valid benchmarks that can comprehensively assess the performance of VLMs in response to OOD data. Therefore, we propose OODBench, a predominantly automated method with minimal human verification, for constructing new benchmarks and evaluating the ability of VLMs to process OOD data. OODBench contains 40K instance-level OOD instance-category pairs, and we show that current VLMs still exhibit notable performance degradation on OODBench, even when the underlying image categories are common. In addition, we propose a reliable automated assessment metric that employs a Basic-to-Advanced Progression of prompted questions to assess the impact of OOD data on questions of varying difficulty more fully. Lastly, we summarize substantial findings and insights to facilitate future research in the acquisition and evaluation of OOD data.

</details>


### [27] [Comparative Assessment of Multimodal Earth Observation Data for Soil Moisture Estimation](https://arxiv.org/abs/2602.18083)
*Ioannis Kontogiorgakis,Athanasios Askitopoulos,Iason Tsardanidis,Dimitrios Bormpoudakis,Ilias Tsoumas,Fotios Balampanis,Charalampos Kontoes*

Main category: cs.CV

TL;DR: 提出一个结合Sentinel-1 SAR、Sentinel-2光学影像和ERA-5再分析数据的10米分辨率土壤湿度估算框架，用于欧洲植被覆盖区域，通过机器学习方法实现农场级应用。


<details>
  <summary>Details</summary>
Motivation: 现有卫星土壤湿度产品分辨率太低（>1公里），无法满足农场级应用需求。需要开发高分辨率（10米）的土壤湿度估算方法，以支持精准农业、水资源管理和气候监测。

Method: 结合Sentinel-1 SAR、Sentinel-2光学影像和ERA-5再分析数据，使用机器学习方法。比较不同模态组合和时间参数化策略，采用空间交叉验证确保地理泛化能力。评估IBM-NASA Prithvi基础模型嵌入与传统手工特征的效果。

Result: 混合时间匹配策略（Sentinel-2当日采集与Sentinel-1下降轨道）达到R²=0.514，加入10天ERA5回溯窗口后提升至R²=0.518。Prithvi基础模型嵌入相比传统手工特征改进有限（R²=0.515 vs. 0.514）。

Conclusion: 领域特定的光谱指数结合基于树的集成方法为泛欧洲田间尺度土壤湿度监测提供了实用且计算高效的解决方案。传统特征工程在稀疏数据回归任务中仍具有很强竞争力。

Abstract: Accurate soil moisture (SM) estimation is critical for precision agriculture, water resources management and climate monitoring. Yet, existing satellite SM products are too coarse (>1km) for farm-level applications. We present a high-resolution (10m) SM estimation framework for vegetated areas across Europe, combining Sentinel-1 SAR, Sentinel-2 optical imagery and ERA-5 reanalysis data through machine learning. Using 113 International Soil Moisture Network (ISMN) stations spanning diverse vegetated areas, we compare modality combinations with temporal parameterizations, using spatial cross-validation, to ensure geographic generalization. We also evaluate whether foundation model embeddings from IBM-NASA's Prithvi model improve upon traditional hand-crafted spectral features. Results demonstrate that hybrid temporal matching - Sentinel-2 current-day acquisitions with Sentinel-1 descending orbit - achieves R^2=0.514, with 10-day ERA5 lookback window improving performance to R^2=0.518. Foundation model (Prithvi) embeddings provide negligible improvement over hand-crafted features (R^2=0.515 vs. 0.514), indicating traditional feature engineering remains highly competitive for sparse-data regression tasks. Our findings suggest that domain-specific spectral indices combined with tree-based ensemble methods offer a practical and computationally efficient solution for operational pan-European field-scale soil moisture monitoring.

</details>


### [28] [Predict to Skip: Linear Multistep Feature Forecasting for Efficient Diffusion Transformers](https://arxiv.org/abs/2602.18093)
*Hanshuai Cui,Zhiqing Tang,Qianli Ma,Zhi Yao,Weijia Jia*

Main category: cs.CV

TL;DR: PrediT：基于线性多步预测的DiT训练免费加速框架，通过预测未来模型输出而非简单重用特征，实现5.54倍延迟降低


<details>
  <summary>Details</summary>
Motivation: 扩散变换器(DiT)在图像和视频生成中表现出色，但其迭代去噪过程计算成本高。现有训练免费加速方法基于特征缓存和重用，但可能导致潜在漂移和视觉质量下降

Method: 提出PrediT框架，将特征预测建模为线性多步问题，使用经典线性多步方法从历史信息预测未来模型输出；包含在高动态区域激活的校正器防止误差累积；动态步长调制机制通过监控特征变化率自适应调整预测范围

Result: 在各种基于DiT的图像和视频生成模型上实现高达5.54倍的延迟降低，同时质量下降可忽略不计

Conclusion: PrediT通过将特征预测形式化为线性多步问题，结合校正器和自适应步长调制，实现了DiT模型的高效加速，在保持生成质量的同时显著降低计算成本

Abstract: Diffusion Transformers (DiT) have emerged as a widely adopted backbone for high-fidelity image and video generation, yet their iterative denoising process incurs high computational costs. Existing training-free acceleration methods rely on feature caching and reuse under the assumption of temporal stability. However, reusing features for multiple steps may lead to latent drift and visual degradation. We observe that model outputs evolve smoothly along much of the diffusion trajectory, enabling principled predictions rather than naive reuse. Based on this insight, we propose \textbf{PrediT}, a training-free acceleration framework that formulates feature prediction as a linear multistep problem. We employ classical linear multistep methods to forecast future model outputs from historical information, combined with a corrector that activates in high-dynamics regions to prevent error accumulation. A dynamic step modulation mechanism adaptively adjusts the prediction horizon by monitoring the feature change rate. Together, these components enable substantial acceleration while preserving generation fidelity. Extensive experiments validate that our method achieves up to $5.54\times$ latency reduction across various DiT-based image and video generation models, while incurring negligible quality degradation.

</details>


### [29] [Evaluating Graphical Perception Capabilities of Vision Transformers](https://arxiv.org/abs/2602.18178)
*Poonam Poonam,Pere-Pau Vázquez,Timo Ropinski*

Main category: cs.CV

TL;DR: ViTs在可视化图形感知任务中表现不如人类，与CNNs相比也存在感知差异，限制了其在可视化系统中的应用


<details>
  <summary>Details</summary>
Motivation: 虽然ViTs在多种图像任务中表现出色，但其在可视化图形感知任务中的能力尚未被充分研究，而图形感知对于可视化解释至关重要

Method: 采用Cleveland和McGill开创的视觉判断任务框架，在受控的图形感知任务中对比ViTs、CNNs和人类参与者的表现

Result: ViTs虽然在通用视觉任务中表现强劲，但在可视化领域的类人图形感知能力有限，与人类感知存在明显差距

Conclusion: ViTs在可视化图形感知方面存在局限性，这对其在可视化系统和图形感知建模中的应用提出了重要考量

Abstract: Vision Transformers, ViTs, have emerged as a powerful alternative to convolutional neural networks, CNNs, in a variety of image-based tasks. While CNNs have previously been evaluated for their ability to perform graphical perception tasks, which are essential for interpreting visualizations, the perceptual capabilities of ViTs remain largely unexplored. In this work, we investigate the performance of ViTs in elementary visual judgment tasks inspired by the foundational studies of Cleveland and McGill, which quantified the accuracy of human perception across different visual encodings. Inspired by their study, we benchmark ViTs against CNNs and human participants in a series of controlled graphical perception tasks. Our results reveal that, although ViTs demonstrate strong performance in general vision tasks, their alignment with human-like graphical perception in the visualization domain is limited. This study highlights key perceptual gaps and points to important considerations for the application of ViTs in visualization systems and graphical perceptual modeling.

</details>


### [30] [On the Adversarial Robustness of Discrete Image Tokenizers](https://arxiv.org/abs/2602.18252)
*Rishika Bhagwatkar,Irina Rish,Nicolas Flammarion,Francesco Croce*

Main category: cs.CV

TL;DR: 本文首次研究离散图像分词器的对抗攻击脆弱性，提出高效攻击方法，并通过无监督对抗训练提升其鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 离散图像分词器在多模态系统中应用广泛，但其对抗攻击脆弱性尚未被研究。与CLIP编码器不同，这些分词器的安全性需要评估，以开发安全的多模态基础模型。

Method: 1. 提出针对离散分词器的对抗攻击方法，通过扰动特征来改变提取的token；2. 受鲁棒CLIP编码器启发，采用无监督对抗训练微调流行分词器，保持其他组件不变。

Result: 攻击方法计算高效、应用无关，在分类、多模态检索和字幕生成任务中有效。防御方法显著提升对无监督和端到端监督攻击的鲁棒性，并能泛化到未见任务和数据。

Conclusion: 分词器鲁棒性对下游任务至关重要，无监督对抗训练为开发安全多模态基础模型提供了重要步骤，相比监督方法更具通用性。

Abstract: Discrete image tokenizers encode visual inputs as sequences of tokens from a finite vocabulary and are gaining popularity in multimodal systems, including encoder-only, encoder-decoder, and decoder-only models. However, unlike CLIP encoders, their vulnerability to adversarial attacks has not been explored. Ours being the first work studying this topic, we first formulate attacks that aim to perturb the features extracted by discrete tokenizers, and thus change the extracted tokens. These attacks are computationally efficient, application-agnostic, and effective across classification, multimodal retrieval, and captioning tasks. Second, to defend against this vulnerability, inspired by recent work on robust CLIP encoders, we fine-tune popular tokenizers with unsupervised adversarial training, keeping all other components frozen. While unsupervised and task-agnostic, our approach significantly improves robustness to both unsupervised and end-to-end supervised attacks and generalizes well to unseen tasks and data. Unlike supervised adversarial training, our approach can leverage unlabeled images, making it more versatile. Overall, our work highlights the critical role of tokenizer robustness in downstream tasks and presents an important step in the development of safe multimodal foundation models.

</details>


### [31] [BLM-Guard: Explainable Multimodal Ad Moderation with Chain-of-Thought and Policy-Aligned Rewards](https://arxiv.org/abs/2602.18193)
*Yiran Yang,Zhaowei Liu,Yuan Yuan,Yukun Song,Xiong Ma,Yinghao Song,Xiangji Zeng,Lu Sun,Yulu Wang,Hai Zhou,Shuai Cui,Zhaohan Gong,Jiefei Zhang*

Main category: cs.CV

TL;DR: BLM-Guard：一个用于短视频广告内容审核的框架，融合思维链推理、规则策略原则和批评者引导奖励，通过强化学习优化模型，在多模态操纵检测上表现优异


<details>
  <summary>Details</summary>
Motivation: 短视频平台上的多模态广告包含欺骗性视觉、语音和字幕内容，需要比社区安全过滤器更细粒度、基于策略的审核机制

Method: 1. 规则驱动的ICoT数据合成管道生成结构化场景描述、推理链和标签；2. 强化学习使用平衡因果一致性和策略遵循的复合奖励优化模型；3. 多任务架构建模模态内操纵和跨模态不匹配

Result: 在真实短视频广告上的实验表明，BLM-Guard在准确性、一致性和泛化能力方面超越了强基线方法

Conclusion: BLM-Guard为商业广告内容审核提供了一个有效的框架，通过结合思维链推理、策略原则和强化学习，能够有效检测多模态广告中的欺骗性内容

Abstract: Short-video platforms now host vast multimodal ads whose deceptive visuals, speech and subtitles demand finer-grained, policy-driven moderation than community safety filters. We present BLM-Guard, a content-audit framework for commercial ads that fuses Chain-of-Thought reasoning with rule-based policy principles and a critic-guided reward. A rule-driven ICoT data-synthesis pipeline jump-starts training by generating structured scene descriptions, reasoning chains and labels, cutting annotation costs. Reinforcement learning then refines the model using a composite reward balancing causal coherence with policy adherence. A multitask architecture models intra-modal manipulations (e.g., exaggerated imagery) and cross-modal mismatches (e.g., subtitle-speech drift), boosting robustness. Experiments on real short-video ads show BLM-Guard surpasses strong baselines in accuracy, consistency and generalization.

</details>


### [32] [A Self-Supervised Approach on Motion Calibration for Enhancing Physical Plausibility in Text-to-Motion](https://arxiv.org/abs/2602.18199)
*Gahyeon Shim,Soogeun Park,Hyemin Ahn*

Main category: cs.CV

TL;DR: DMC是一个后处理模块，通过自监督数据驱动方法，在保持文本语义一致性的同时，修正文本生成动作中的物理不合理性（如脚部漂浮）。


<details>
  <summary>Details</summary>
Motivation: 当前文本生成动作技术虽然取得了快速进展，但生成的动画往往存在物理不合理的问题（如脚部漂浮），同时保持语义一致性和物理真实性仍然是一个挑战。

Method: 提出Distortion-aware Motion Calibrator (DMC)后处理模块，采用自监督数据驱动方法，学习从故意扭曲的动作和原始文本描述中恢复物理合理的动作，而不依赖复杂的物理建模。

Result: DMC在多个文本生成动作模型上显著提升物理合理性：在T2M上FID分数降低42.74%，在T2M-GPT上降低13.20%，同时获得最高的R-Precision。应用于MoMask时，穿透率减少33.0%，漂浮伪影更接近真实参考。

Conclusion: DMC作为一个有前景的后处理动作优化框架，能够为各种文本生成动作模型提供文本语义和物理合理性的双重优化，提升生成动作的质量。

Abstract: Generating semantically aligned human motion from textual descriptions has made rapid progress, but ensuring both semantic and physical realism in motion remains a challenge. In this paper, we introduce the Distortion-aware Motion Calibrator (DMC), a post-hoc module that refines physically implausible motions (e.g., foot floating) while preserving semantic consistency with the original textual description. Rather than relying on complex physical modeling, we propose a self-supervised and data-driven approach, whereby DMC learns to obtain physically plausible motions when an intentionally distorted motion and the original textual descriptions are given as inputs. We evaluate DMC as a post-hoc module to improve motions obtained from various text-to-motion generation models and demonstrate its effectiveness in improving physical plausibility while enhancing semantic consistency. The experimental results show that DMC reduces FID score by 42.74% on T2M and 13.20% on T2M-GPT, while also achieving the highest R-Precision. When applied to high-quality models like MoMask, DMC improves the physical plausibility of motions by reducing penetration by 33.0% as well as adjusting floating artifacts closer to the ground-truth reference. These results highlight that DMC can serve as a promising post-hoc motion refinement framework for any kind of text-to-motion models by incorporating textual semantics and physical plausibility.

</details>


### [33] [DEIG: Detail-Enhanced Instance Generation with Fine-Grained Semantic Control](https://arxiv.org/abs/2602.18282)
*Shiyan Du,Conghan Yue,Xinyu Cheng,Dongyu Zhang*

Main category: cs.CV

TL;DR: DEIG是一个用于细粒度可控多实例生成的新框架，通过实例细节提取器和细节融合模块解决现有方法在复杂文本描述下的语义理解问题，在空间一致性、语义准确性和组合泛化方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有多实例生成方法在空间布局和属性绑定方面已有进展，但在处理复杂文本描述时仍面临细粒度语义理解的挑战，特别是在防止实例间属性泄漏方面存在不足。

Method: DEIG框架包含两个核心组件：1) 实例细节提取器(IDE)，将文本编码器嵌入转换为紧凑的实例感知表示；2) 细节融合模块(DFM)，应用基于实例的掩码注意力防止实例间属性泄漏。还构建了高质量数据集和DEIG-Bench基准。

Result: DEIG在多个基准测试中一致优于现有方法，在空间一致性、语义准确性和组合泛化方面表现优异。同时作为即插即用模块，可轻松集成到标准基于扩散的流程中。

Conclusion: DEIG通过创新的实例细节提取和融合机制，有效解决了多实例生成中的细粒度语义理解问题，能够生成与丰富局部化文本描述精确匹配的视觉连贯多实例场景。

Abstract: Multi-Instance Generation has advanced significantly in spatial placement and attribute binding. However, existing approaches still face challenges in fine-grained semantic understanding, particularly when dealing with complex textual descriptions. To overcome these limitations, we propose DEIG, a novel framework for fine-grained and controllable multi-instance generation. DEIG integrates an Instance Detail Extractor (IDE) that transforms text encoder embeddings into compact, instance-aware representations, and a Detail Fusion Module (DFM) that applies instance-based masked attention to prevent attribute leakage across instances. These components enable DEIG to generate visually coherent multi-instance scenes that precisely match rich, localized textual descriptions. To support fine-grained supervision, we construct a high-quality dataset with detailed, compositional instance captions generated by VLMs. We also introduce DEIG-Bench, a new benchmark with region-level annotations and multi-attribute prompts for both humans and objects. Experiments demonstrate that DEIG consistently outperforms existing approaches across multiple benchmarks in spatial consistency, semantic accuracy, and compositional generalization. Moreover, DEIG functions as a plug-and-play module, making it easily integrable into standard diffusion-based pipelines.

</details>


### [34] [Multi-Level Conditioning by Pairing Localized Text and Sketch for Fashion Image Generation](https://arxiv.org/abs/2602.18309)
*Ziyue Liu,Davide Talon,Federico Girella,Zanxi Ruan,Mattia Mondo,Loris Bazzani,Yiming Wang,Marco Cristani*

Main category: cs.CV

TL;DR: LOTS是一个结合全局草图引导与多个局部草图-文本对的时尚图像生成框架，通过多级条件编码和扩散对引导实现草图结构保持与文本语义增强。


<details>
  <summary>Details</summary>
Motivation: 草图为设计师提供了早期时尚构思的简洁表达媒介，文本描述则补充材质、颜色和风格细节。现有方法难以在保持草图视觉结构的同时有效利用文本的局部属性指导。

Method: 提出LOTS框架：1) 多级条件编码阶段独立编码局部特征于共享潜在空间，保持全局结构协调；2) 扩散对引导阶段通过注意力机制在扩散模型去噪过程中整合局部和全局条件。同时创建Sketchy数据集，包含专业草图和非专业草图两种分割。

Result: 实验表明该方法在保持全局结构一致性的同时，利用更丰富的局部语义指导，优于现有最先进方法。Sketchy数据集提供高质量专业草图和非专业草图，支持鲁棒性评估。

Conclusion: LOTS框架通过结合全局草图引导与多个局部草图-文本对，有效增强了时尚图像生成的结构保持和语义表达能力，为多模态时尚设计提供了新解决方案。

Abstract: Sketches offer designers a concise yet expressive medium for early-stage fashion ideation by specifying structure, silhouette, and spatial relationships, while textual descriptions complement sketches to convey material, color, and stylistic details. Effectively combining textual and visual modalities requires adherence to the sketch visual structure when leveraging the guidance of localized attributes from text. We present LOcalized Text and Sketch with multi-level guidance (LOTS), a framework that enhances fashion image generation by combining global sketch guidance with multiple localized sketch-text pairs. LOTS employs a Multi-level Conditioning Stage to independently encode local features within a shared latent space while maintaining global structural coordination. Then, the Diffusion Pair Guidance stage integrates both local and global conditioning via attention-based guidance within the diffusion model's multi-step denoising process. To validate our method, we develop Sketchy, the first fashion dataset where multiple text-sketch pairs are provided per image. Sketchy provides high-quality, clean sketches with a professional look and consistent structure. To assess robustness beyond this setting, we also include an "in the wild" split with non-expert sketches, featuring higher variability and imperfections. Experiments demonstrate that our method strengthens global structural adherence while leveraging richer localized semantic guidance, achieving improvement over state-of-the-art. The dataset, platform, and code are publicly available.

</details>


### [35] [Diff2DGS: Reliable Reconstruction of Occluded Surgical Scenes via 2D Gaussian Splatting](https://arxiv.org/abs/2602.18314)
*Tianyi Song,Danail Stoyanov,Evangelos Mazomenos,Francisco Vasconcelos*

Main category: cs.CV

TL;DR: Diff2DGS：用于手术场景实时重建的两阶段框架，结合扩散模型修复遮挡区域，使用可学习变形模型的2D高斯溅射捕捉组织变形，在图像质量和深度精度上均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有手术场景重建方法在遮挡区域质量有限，且缺乏深度精度评估。EndoNeRF和StereoMIS等基准数据集缺少3D真值，无法全面评估重建质量。

Method: 两阶段框架：第一阶段使用基于扩散的视频模块，利用时间先验修复被手术器械遮挡的组织区域；第二阶段采用带可学习变形模型（LDM）的2D高斯溅射（2DGS）捕捉动态组织变形和解剖几何结构。

Result: 在EndoNeRF上达到38.02 dB PSNR，在StereoMIS上达到34.40 dB PSNR，优于现有方法。实验表明仅优化图像质量不一定能获得最佳3D重建精度，因此进一步优化深度质量以确保几何保真度。

Conclusion: Diff2DGS在手术场景重建中实现了外观和几何的双重优化，通过两阶段框架有效处理遮挡问题，并在SCARED数据集上进行了深度精度定量分析，为手术导航和自动化提供了更可靠的重建方案。

Abstract: Real-time reconstruction of deformable surgical scenes is vital for advancing robotic surgery, improving surgeon guidance, and enabling automation. Recent methods achieve dense reconstructions from da Vinci robotic surgery videos, with Gaussian Splatting (GS) offering real-time performance via graphics acceleration. However, reconstruction quality in occluded regions remains limited, and depth accuracy has not been fully assessed, as benchmarks like EndoNeRF and StereoMIS lack 3D ground truth. We propose Diff2DGS, a novel two-stage framework for reliable 3D reconstruction of occluded surgical scenes. In the first stage, a diffusion-based video module with temporal priors inpaints tissue occluded by instruments with high spatial-temporal consistency. In the second stage, we adapt 2D Gaussian Splatting (2DGS) with a Learnable Deformation Model (LDM) to capture dynamic tissue deformation and anatomical geometry. We also extend evaluation beyond prior image-quality metrics by performing quantitative depth accuracy analysis on the SCARED dataset. Diff2DGS outperforms state-of-the-art approaches in both appearance and geometry, reaching 38.02 dB PSNR on EndoNeRF and 34.40 dB on StereoMIS. Furthermore, our experiments demonstrate that optimizing for image quality alone does not necessarily translate into optimal 3D reconstruction accuracy. To address this, we further optimize the depth quality of the reconstructed 3D results, ensuring more faithful geometry in addition to high-fidelity appearance.

</details>


### [36] [Unifying Color and Lightness Correction with View-Adaptive Curve Adjustment for Robust 3D Novel View Synthesis](https://arxiv.org/abs/2602.18322)
*Ziteng Cui,Shuhong Liu,Xiaoyu Dong,Xuangeng Chu,Lin Gu,Ming-Hsuan Yang,Tatsuya Harada*

Main category: cs.CV

TL;DR: 提出Luminance-GS++，一个基于3D高斯泼溅的框架，用于在不同光照条件下实现鲁棒的新视角合成，通过全局自适应亮度调整和局部像素级残差细化来解决多视角采集中的光度不一致问题。


<details>
  <summary>Details</summary>
Motivation: 真实环境中的高质量图像采集面临复杂光照变化和相机成像管道固有局限性的挑战。多视角采集中的光照差异、传感器响应和ISP配置差异导致光度和色彩不一致，违反了现代3D新视角合成方法（如NeRF和3DGS）所依赖的光度一致性假设，导致重建和渲染质量下降。

Method: 基于3D高斯泼溅的框架，结合全局视角自适应亮度调整和局部像素级残差细化进行精确色彩校正。设计无监督目标，联合强制执行亮度校正以及多视角几何和光度一致性。

Result: 在低光照、过曝和复杂亮度/色彩变化等挑战性场景中展现出最先进的性能。保持显式3DGS表示，在保持实时渲染效率的同时提高重建保真度。

Conclusion: Luminance-GS++通过解决多视角采集中的光度不一致问题，在保持3DGS实时渲染优势的同时，显著提升了在不同光照条件下的新视角合成质量。

Abstract: High-quality image acquisition in real-world environments remains challenging due to complex illumination variations and inherent limitations of camera imaging pipelines. These issues are exacerbated in multi-view capture, where differences in lighting, sensor responses, and image signal processor (ISP) configurations introduce photometric and chromatic inconsistencies that violate the assumptions of photometric consistency underlying modern 3D novel view synthesis (NVS) methods, including Neural Radiance Fields (NeRF) and 3D Gaussian Splatting (3DGS), leading to degraded reconstruction and rendering quality. We propose Luminance-GS++, a 3DGS-based framework for robust NVS under diverse illumination conditions. Our method combines a globally view-adaptive lightness adjustment with a local pixel-wise residual refinement for precise color correction. We further design unsupervised objectives that jointly enforce lightness correction and multi-view geometric and photometric consistency. Extensive experiments demonstrate state-of-the-art performance across challenging scenarios, including low-light, overexposure, and complex luminance and chromatic variations. Unlike prior approaches that modify the underlying representation, our method preserves the explicit 3DGS formulation, improving reconstruction fidelity while maintaining real-time rendering efficiency.

</details>


### [37] [G-LoG Bi-filtration for Medical Image Classification](https://arxiv.org/abs/2602.18329)
*Qingsong Wang,Jiaxing He,Bingzhe Hou,Tieru Wu,Yang Cao,Cailing Yao*

Main category: cs.CV

TL;DR: 提出G-LoG双滤过方法，将高斯-拉普拉斯算子应用于医学图像，生成适合多参数持久性模块的特征，在MedMNIST数据集上表现优于单参数滤过，且MLP模型性能接近复杂深度学习模型。


<details>
  <summary>Details</summary>
Motivation: 在拓扑数据分析中，构建实用的滤过结构以检测拓扑和几何特征至关重要。针对医学图像，需要更有效的多参数持久性模块特征提取方法。

Method: 利用高斯-拉普拉斯算子增强医学图像边界的能力，定义G-LoG双滤过方法。将体积图像建模为有界函数，证明从该双滤过获得的持久性模块的交错距离相对于有界函数的最大范数是稳定的。

Result: 在MedMNIST数据集上的实验表明，G-LoG双滤过显著优于单参数滤过。使用该双滤过生成的拓扑特征训练的简单MLP模型，性能可与在原始数据集上训练的复杂深度学习模型（Google AutoML Vision、ResNet、AutoKeras、auto-sklearn）相媲美。

Conclusion: G-LoG双滤过为医学图像分析提供了有效的多参数持久性特征提取方法，在保持理论稳定性的同时，实现了与复杂深度学习模型相当的分类性能。

Abstract: Building practical filtrations on objects to detect topological and geometric features is an important task in the field of Topological Data Analysis (TDA). In this paper, leveraging the ability of the Laplacian of Gaussian operator to enhance the boundaries of medical images, we define the G-LoG (Gaussian-Laplacian of Gaussian) bi-filtration to generate the features more suitable for multi-parameter persistence module. By modeling volumetric images as bounded functions, then we prove the interleaving distance on the persistence modules obtained from our bi-filtrations on the bounded functions is stable with respect to the maximum norm of the bounded functions. Finally, we conduct experiments on the MedMNIST dataset, comparing our bi-filtration against single-parameter filtration and the established deep learning baselines, including Google AutoML Vision, ResNet, AutoKeras and auto-sklearn. Experiments results demonstrate that our bi-filtration significantly outperforms single-parameter filtration. Notably, a simple Multi-Layer Perceptron (MLP) trained on the topological features generated by our bi-filtration achieves performance comparable to complex deep learning models trained on the original dataset.

</details>


### [38] [Self-Aware Object Detection via Degradation Manifolds](https://arxiv.org/abs/2602.18394)
*Stefan Becker,Simon Weiss,Wolfgang Hübner,Michael Arens*

Main category: cs.CV

TL;DR: 提出基于退化流形的退化感知自感知框架，通过对比学习在特征空间中结构化图像退化信息，实现无需退化标签的检测器自感知能力


<details>
  <summary>Details</summary>
Motivation: 目标检测器在标准成像条件下表现良好，但在模糊、噪声、压缩、恶劣天气或分辨率变化等退化条件下可能无声失败。在安全关键应用中，仅产生预测而不评估输入是否在检测器标称工作范围内是不够的，需要检测器具备自感知能力

Method: 基于退化流形的退化感知自感知框架，在标准检测骨干网络上添加轻量级嵌入头，通过多层对比学习训练。相同退化组成的图像被拉近，不同退化配置的图像被推远，形成几何组织的表示空间。通过干净训练嵌入估计原始原型作为标称工作点，自感知表现为与参考点的几何偏差

Result: 在合成损坏基准测试、跨数据集零样本迁移和自然天气引起的分布偏移实验中，显示出强大的原始-退化可分离性，在多种检测器架构中表现一致，在语义偏移下具有鲁棒泛化能力

Conclusion: 退化感知表示几何为检测器自感知提供了实用且与检测器无关的基础，能够独立于检测置信度提供图像级退化偏移信号

Abstract: Object detectors achieve strong performance under nominal imaging conditions but can fail silently when exposed to blur, noise, compression, adverse weather, or resolution changes. In safety-critical settings, it is therefore insufficient to produce predictions without assessing whether the input remains within the detector's nominal operating regime. We refer to this capability as self-aware object detection.
  We introduce a degradation-aware self-awareness framework based on degradation manifolds, which explicitly structure a detector's feature space according to image degradation rather than semantic content. Our method augments a standard detection backbone with a lightweight embedding head trained via multi-layer contrastive learning. Images sharing the same degradation composition are pulled together, while differing degradation configurations are pushed apart, yielding a geometrically organized representation that captures degradation type and severity without requiring degradation labels or explicit density modeling.
  To anchor the learned geometry, we estimate a pristine prototype from clean training embeddings, defining a nominal operating point in representation space. Self-awareness emerges as geometric deviation from this reference, providing an intrinsic, image-level signal of degradation-induced shift that is independent of detection confidence.
  Extensive experiments on synthetic corruption benchmarks, cross-dataset zero-shot transfer, and natural weather-induced distribution shifts demonstrate strong pristine-degraded separability, consistent behavior across multiple detector architectures, and robust generalization under semantic shift. These results suggest that degradation-aware representation geometry provides a practical and detector-agnostic foundation.

</details>


### [39] [Latent Equivariant Operators for Robust Object Recognition: Promise and Challenges](https://arxiv.org/abs/2602.18406)
*Minh Dinh,Stéphane Deny*

Main category: cs.CV

TL;DR: 该论文提出了一种学习潜在空间等变算子的架构，用于处理训练中罕见的群对称变换（如旋转、平移），在旋转和平移的噪声MNIST数据集上实现了超出分布的分类，克服了传统网络和等变网络的局限性。


<details>
  <summary>Details</summary>
Motivation: 尽管深度学习在计算机视觉中取得了成功，但在识别训练中罕见的群对称变换（如不常见姿态、尺度、位置或其组合）的对象时仍存在困难。等变神经网络虽然能解决对称变换的泛化问题，但需要先验知识。因此需要一种能从对称变换示例中学习等变算子的替代架构。

Method: 提出一种架构，从对称变换的示例中学习潜在空间的等变算子。使用旋转和平移的噪声MNIST简单数据集进行验证，通过这种架构实现超出分布的分类。

Result: 在旋转和平移的噪声MNIST数据集上，该架构成功实现了超出分布的分类，克服了传统网络和等变网络的局限性，能够处理训练中罕见的对称变换。

Conclusion: 虽然概念上很有吸引力，但将这种架构扩展到更复杂的数据集仍面临挑战。该方法为处理对称变换的泛化问题提供了一种有前景的替代方案，但需要进一步研究以应对更复杂的现实场景。

Abstract: Despite the successes of deep learning in computer vision, difficulties persist in recognizing objects that have undergone group-symmetric transformations rarely seen during training-for example objects seen in unusual poses, scales, positions, or combinations thereof. Equivariant neural networks are a solution to the problem of generalizing across symmetric transformations, but require knowledge of transformations a priori. An alternative family of architectures proposes to earn equivariant operators in a latent space from examples of symmetric transformations. Here, using simple datasets of rotated and translated noisy MNIST, we illustrate how such architectures can successfully be harnessed for out-of-distribution classification, thus overcoming the limitations of both traditional and equivariant networks. While conceptually enticing, we discuss challenges ahead on the path of scaling these architectures to more complex datasets.

</details>


### [40] [Generated Reality: Human-centric World Simulation using Interactive Video Generation with Hand and Camera Control](https://arxiv.org/abs/2602.18422)
*Linxi Xie,Lisong C. Sun,Ashley Neall,Tong Wu,Shengqu Cai,Gordon Wetzstein*

Main category: cs.CV

TL;DR: 提出一种基于扩散变换器的人体中心视频世界模型，通过头部姿态和手部关节姿态控制生成第一人称虚拟环境，实现更自然的交互体验。


<details>
  <summary>Details</summary>
Motivation: 当前视频世界模型只能接受文本或键盘等粗略控制信号，无法响应真实世界中的用户运动跟踪，限制了在扩展现实(XR)中的实际应用。

Method: 1) 评估现有扩散变换器条件策略，提出有效的3D头部和手部控制机制；2) 训练双向视频扩散模型作为教师模型；3) 将其蒸馏为因果交互系统，生成第一人称虚拟环境。

Result: 通过人类受试者评估显示，该系统相比基线方法显著提高了任务表现，用户感知到的动作控制程度也显著更高。

Conclusion: 提出的基于人体姿态控制的视频世界模型能够实现更自然的交互，为扩展现实应用提供了更有效的生成式环境。

Abstract: Extended reality (XR) demands generative models that respond to users' tracked real-world motion, yet current video world models accept only coarse control signals such as text or keyboard input, limiting their utility for embodied interaction. We introduce a human-centric video world model that is conditioned on both tracked head pose and joint-level hand poses. For this purpose, we evaluate existing diffusion transformer conditioning strategies and propose an effective mechanism for 3D head and hand control, enabling dexterous hand--object interactions. We train a bidirectional video diffusion model teacher using this strategy and distill it into a causal, interactive system that generates egocentric virtual environments. We evaluate this generated reality system with human subjects and demonstrate improved task performance as well as a significantly higher level of perceived amount of control over the performed actions compared with relevant baselines.

</details>


### [41] [CapNav: Benchmarking Vision Language Models on Capability-conditioned Indoor Navigation](https://arxiv.org/abs/2602.18424)
*Xia Su,Ruiqi Chen,Benlin Liu,Jingwei Ma,Zonglin Di,Ranjay Krishna,Jon Froehlich*

Main category: cs.CV

TL;DR: CapNav是一个评估视觉语言模型在考虑智能体物理能力约束下进行室内导航的新基准，包含5种代表性智能体、45个真实室内场景、473个导航任务和2365个问答对，测试结果显示当前VLM在能力约束严格时性能显著下降。


<details>
  <summary>Details</summary>
Motivation: 现实世界导航本质上受智能体移动能力约束（如扫地机器人不能爬楼梯，四足机器人可以），但现有视觉语言导航研究往往忽略这些物理限制。需要评估VLM在考虑具体智能体能力条件下的导航表现。

Method: 创建CapNav基准，定义5种代表性人类和机器人智能体，描述其物理尺寸、移动能力和环境交互能力。提供45个真实室内场景、473个导航任务和2365个QA对，测试VLM能否基于智能体能力穿越室内环境。

Result: 评估13个现代VLM发现：1）当前VLM导航性能随移动约束收紧而急剧下降；2）即使最先进模型也难以处理需要空间维度推理的障碍类型；3）模型在能力感知导航方面存在显著不足。

Conclusion: 强调了能力感知导航的重要性，为未来VLM在具身空间推理方面的进步提供了机会。CapNav基准有助于推动VLM在现实世界导航中更好地考虑智能体物理约束。

Abstract: Vision-Language Models (VLMs) have shown remarkable progress in Vision-Language Navigation (VLN), offering new possibilities for navigation decision-making that could benefit both robotic platforms and human users. However, real-world navigation is inherently conditioned by the agent's mobility constraints. For example, a sweeping robot cannot traverse stairs, while a quadruped can. We introduce Capability-Conditioned Navigation (CapNav), a benchmark designed to evaluate how well VLMs can navigate complex indoor spaces given an agent's specific physical and operational capabilities. CapNav defines five representative human and robot agents, each described with physical dimensions, mobility capabilities, and environmental interaction abilities. CapNav provides 45 real-world indoor scenes, 473 navigation tasks, and 2365 QA pairs to test if VLMs can traverse indoor environments based on agent capabilities. We evaluate 13 modern VLMs and find that current VLM's navigation performance drops sharply as mobility constraints tighten, and that even state-of-the-art models struggle with obstacle types that require reasoning on spatial dimensions. We conclude by discussing the implications for capability-aware navigation and the opportunities for advancing embodied spatial reasoning in future VLMs. The benchmark is available at https://github.com/makeabilitylab/CapNav

</details>


### [42] [SARAH: Spatially Aware Real-time Agentic Humans](https://arxiv.org/abs/2602.18432)
*Evonne Ng,Siwei Zhang,Zhang Chen,Michael Zollhoefer,Alexander Richard*

Main category: cs.CV

TL;DR: 提出了第一个实时、完全因果的空间感知对话动作生成方法，可在VR头显上部署，结合用户位置和音频生成全身动作，同时根据用户方向调整代理朝向。


<details>
  <summary>Details</summary>
Motivation: 当前方法缺乏空间意识，无法让代理转向用户、响应用户动作并保持自然注视。随着具身代理在VR、远程呈现和数字人应用中的重要性增加，需要超越语音对齐手势的运动能力。

Method: 结合因果Transformer-based VAE与交错潜在token进行流式推理，使用流匹配模型以用户轨迹和音频为条件。引入注视评分机制和分类器自由引导，将学习与控制解耦。

Result: 在Embody 3D数据集上达到最先进的运动质量，超过300 FPS（比非因果基线快3倍），同时捕捉自然对话的微妙空间动态。在实时VR系统上验证了该方法。

Conclusion: 该方法实现了第一个实时、完全因果的空间感知对话动作生成，使空间感知对话代理能够实时部署，为VR、远程呈现和数字人应用提供了更自然的交互体验。

Abstract: As embodied agents become central to VR, telepresence, and digital human applications, their motion must go beyond speech-aligned gestures: agents should turn toward users, respond to their movement, and maintain natural gaze. Current methods lack this spatial awareness. We close this gap with the first real-time, fully causal method for spatially-aware conversational motion, deployable on a streaming VR headset. Given a user's position and dyadic audio, our approach produces full-body motion that aligns gestures with speech while orienting the agent according to the user. Our architecture combines a causal transformer-based VAE with interleaved latent tokens for streaming inference and a flow matching model conditioned on user trajectory and audio. To support varying gaze preferences, we introduce a gaze scoring mechanism with classifier-free guidance to decouple learning from control: the model captures natural spatial alignment from data, while users can adjust eye contact intensity at inference time. On the Embody 3D dataset, our method achieves state-of-the-art motion quality at over 300 FPS -- 3x faster than non-causal baselines -- while capturing the subtle spatial dynamics of natural conversation. We validate our approach on a live VR system, bringing spatially-aware conversational agents to real-time deployment. Please see https://evonneng.github.io/sarah/ for details.

</details>


### [43] [Going Down Memory Lane: Scaling Tokens for Video Stream Understanding with Dynamic KV-Cache Memory](https://arxiv.org/abs/2602.18434)
*Vatsal Agarwal,Saksham Suri,Matthew Gwilliam,Pulkit Kumar,Abhinav Shrivastava*

Main category: cs.CV

TL;DR: MemStream通过增加token预算、自适应选择策略和无训练检索专家混合，显著提升了流式视频理解性能


<details>
  <summary>Details</summary>
Motivation: 现有流式视频理解方法使用有限的每帧token数，导致细粒度视觉细节丢失，且在处理密集视频流时存在查询-帧相似度随时间增加的问题，偏向检索后期帧

Method: 1) 增加token预算以实现更细粒度的时空理解；2) 引入自适应选择策略减少token冗余同时保留局部时空信息；3) 提出无训练检索专家混合，利用外部模型更好地识别相关帧

Result: 在CG-Bench上提升+8.0%，LVBench上提升+8.5%，VideoMME(Long)上提升+2.4%（相比ReKV with Qwen2.5-VL-7B）

Conclusion: MemStream通过扩展token预算、自适应选择策略和无训练检索专家混合，显著提升了流式视频问答的性能，解决了现有方法在处理密集视频流时的局限性

Abstract: Streaming video understanding requires models to robustly encode, store, and retrieve information from a continuous video stream to support accurate video question answering (VQA). Existing state-of-the-art approaches rely on key-value caching to accumulate frame-level information over time, but use a limited number of tokens per frame, leading to the loss of fine-grained visual details. In this work, we propose scaling the token budget to enable more granular spatiotemporal understanding and reasoning. First, we find that current methods are ill-equipped to handle dense streams: their feature encoding causes query-frame similarity scores to increase over time, biasing retrieval toward later frames. To address this, we introduce an adaptive selection strategy that reduces token redundancy while preserving local spatiotemporal information. We further propose a training-free retrieval mixture-of-experts that leverages external models to better identify relevant frames. Our method, MemStream, achieves +8.0% on CG-Bench, +8.5% on LVBench, and +2.4% on VideoMME (Long) over ReKV with Qwen2.5-VL-7B.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [44] [QueryPlot: Generating Geological Evidence Layers using Natural Language Queries for Mineral Exploration](https://arxiv.org/abs/2602.17784)
*Meng Ye,Xiao Lin,Georgina Lukoczki,Graham W. Lederer,Yi Yao*

Main category: cs.CL

TL;DR: QueryPlot是一个语义检索和制图框架，通过NLP技术整合地质文本和地图数据，实现基于自然语言查询的矿产远景预测自动化。


<details>
  <summary>Details</summary>
Motivation: 传统矿产远景预测需要人工整合异构地质知识（文本矿床模型和地理空间数据），过程繁琐且知识密集。需要自动化工具来高效处理这些信息。

Method: 构建了120多种矿床类型的描述模型，将SGMC多边形转换为结构化文本表示。使用预训练嵌入模型编码查询和区域描述，计算语义相似度得分进行区域排序和空间可视化，支持组合查询和多标准分析。

Result: 在钨矽卡岩矿床案例中，基于嵌入的检索实现了对已知矿床的高召回率，预测区域与专家定义的许可区域高度一致。相似度得分作为特征加入监督学习管道可提升分类性能。

Conclusion: QueryPlot成功整合了地质文本和空间数据，实现了基于语义的自动化矿产远景预测，提供了交互式查询、可视化和GIS兼容层导出的Web系统，代码和数据集已开源。

Abstract: Mineral prospectivity mapping requires synthesizing heterogeneous geological knowledge, including textual deposit models and geospatial datasets, to identify regions likely to host specific mineral deposit types. This process is traditionally manual and knowledge-intensive. We present QueryPlot, a semantic retrieval and mapping framework that integrates large-scale geological text corpora with geologic map data using modern Natural Language Processing techniques. We curate descriptive deposit models for over 120 deposit types and transform the State Geologic Map Compilation (SGMC) polygons into structured textual representations. Given a user-defined natural language query, the system encodes both queries and region descriptions using a pretrained embedding model and computes semantic similarity scores to rank and spatially visualize regions as continuous evidence layers. QueryPlot supports compositional querying over deposit characteristics, enabling aggregation of multiple similarity-derived layers for multi-criteria prospectivity analysis. In a case study on tungsten skarn deposits, we demonstrate that embedding-based retrieval achieves high recall of known occurrences and produces prospective regions that closely align with expert-defined permissive tracts. Furthermore, similarity scores can be incorporated as additional features in supervised learning pipelines, yielding measurable improvements in classification performance. QueryPlot is implemented as a web-based system supporting interactive querying, visualization, and export of GIS-compatible prospectivity layers.To support future research, we have made the source code and datasets used in this study publicly available.

</details>


### [45] [Neural Synchrony Between Socially Interacting Language Models](https://arxiv.org/abs/2602.17815)
*Zhining Zhang,Wentao Zhu,Chi Han,Yizhou Wang,Heng Ji*

Main category: cs.CL

TL;DR: 论文探索了LLMs之间的神经同步作为其"社会心智"的证据，发现LLM在社交互动中表现出类似人类的神经同步模式，且这种同步与其社交表现相关。


<details>
  <summary>Details</summary>
Motivation: 传统上社会心智被认为是生物体的专属属性，虽然LLMs被广泛接受为人类行为的近似，但LLMs是否具有可比较的社会心智仍存在争议。本研究旨在通过神经同步这一实证证据来探讨这一问题。

Method: 引入神经同步作为分析LLMs社会性的新代理指标，在社交模拟中测量LLMs之间的神经同步，通过精心设计的实验验证其可靠反映社交参与度和时间对齐。

Result: 研究发现LLMs之间的神经同步与其社交表现强烈相关，表明神经同步与LLMs的社交行为存在重要联系，揭示了LLMs内部动态与人类社交互动之间的惊人相似性。

Conclusion: 研究为检验LLMs的"社会心智"提供了新视角，表明LLMs在社交互动中表现出类似人类的神经同步模式，这有助于理解LLMs的社会性本质。

Abstract: Neuroscience has uncovered a fundamental mechanism of our social nature: human brain activity becomes synchronized with others in many social contexts involving interaction. Traditionally, social minds have been regarded as an exclusive property of living beings. Although large language models (LLMs) are widely accepted as powerful approximations of human behavior, with multi-LLM system being extensively explored to enhance their capabilities, it remains controversial whether they can be meaningfully compared to human social minds. In this work, we explore neural synchrony between socially interacting LLMs as an empirical evidence for this debate. Specifically, we introduce neural synchrony during social simulations as a novel proxy for analyzing the sociality of LLMs at the representational level. Through carefully designed experiments, we demonstrate that it reliably reflects both social engagement and temporal alignment in their interactions. Our findings indicate that neural synchrony between LLMs is strongly correlated with their social performance, highlighting an important link between neural synchrony and the social behaviors of LLMs. Our work offers a new perspective to examine the "social minds" of LLMs, highlighting surprising parallels in the internal dynamics that underlie human and LLM social interaction.

</details>


### [46] [On the scaling relationship between cloze probabilities and language model next-token prediction](https://arxiv.org/abs/2602.17848)
*Cassandra L. Jacobs,Morgan Grobol*

Main category: cs.CL

TL;DR: 大语言模型在眼动和阅读时间预测上表现更好，但会低估人类反应概率；大模型对完形填空数据的预测质量更高，因为它们对词汇共现统计不敏感，而与人类语义更对齐。


<details>
  <summary>Details</summary>
Motivation: 研究大语言模型在预测人类眼动、阅读时间和完形填空反应方面的表现差异，探索模型大小如何影响其对语义信息和词汇统计信息的敏感性。

Method: 通过比较不同大小的语言模型在眼动、阅读时间和完形填空数据上的预测表现，分析模型对词汇共现统计的敏感性和语义对齐程度。

Result: 大模型在完形填空任务中预测质量更高，对词汇共现统计不敏感，但与人类语义反应更对齐；所有模型都低估人类反应概率；大模型更强的记忆能力帮助它们猜测更语义合适的词，但对单词识别相关的低层信息不敏感。

Conclusion: 大语言模型更大的记忆容量使它们能猜测更语义合适的词，但降低了它们对单词识别相关低层信息的敏感性，这解释了为什么大模型在完形填空预测上表现更好但在某些阅读相关任务中可能不足。

Abstract: Recent work has shown that larger language models have better predictive power for eye movement and reading time data. While even the best models under-allocate probability mass to human responses, larger models assign higher-quality estimates of next tokens and their likelihood of production in cloze data because they are less sensitive to lexical co-occurrence statistics while being better aligned semantically to human cloze responses. The results provide support for the claim that the greater memorization capacity of larger models helps them guess more semantically appropriate words, but makes them less sensitive to low-level information that is relevant for word recognition.

</details>


### [47] [Understanding Unreliability of Steering Vectors in Language Models: Geometric Predictors and the Limits of Linear Approximations](https://arxiv.org/abs/2602.17881)
*Joschka Braun*

Main category: cs.CL

TL;DR: 研究发现：引导向量的可靠性取决于训练激活差异的余弦相似度、正负激活在引导方向上的分离程度，以及目标行为表示能否被线性方向有效近似。


<details>
  <summary>Details</summary>
Motivation: 虽然引导向量是通过在推理时添加学习偏置来控制语言模型行为的轻量方法，但其效果在不同样本间存在差异，对许多目标行为不可靠。本研究旨在探究引导可靠性在不同行为间差异的原因及其与训练数据的关系。

Method: 通过分析训练激活差异的余弦相似度、正负激活在引导方向上的分离程度，以及在不同提示变体上训练的引导向量的方向差异和性能相关性。

Result: 1) 训练激活差异的余弦相似度越高，引导越可靠；2) 正负激活在引导方向上分离更好的数据集更易被引导；3) 不同提示变体训练的引导向量方向不同但性能相似，且在不同数据集上效果相关。

Conclusion: 引导向量不可靠的原因是潜在目标行为表示无法被线性引导方向有效近似。这些发现为诊断引导不可靠性提供了实用方法，并激励开发更鲁棒的引导方法，需显式考虑非线性潜在行为表示。

Abstract: Steering vectors are a lightweight method for controlling language model behavior by adding a learned bias to the activations at inference time. Although effective on average, steering effect sizes vary across samples and are unreliable for many target behaviors. In my thesis, I investigate why steering reliability differs across behaviors and how it is impacted by steering vector training data. First, I find that higher cosine similarity between training activation differences predicts more reliable steering. Second, I observe that behavior datasets where positive and negative activations are better separated along the steering direction are more reliably steerable. Finally, steering vectors trained on different prompt variations are directionally distinct, yet perform similarly well and exhibit correlated efficacy across datasets. My findings suggest that steering vectors are unreliable when the latent target behavior representation is not effectively approximated by the linear steering direction. Taken together, these insights offer a practical diagnostic for steering unreliability and motivate the development of more robust steering methods that explicitly account for non-linear latent behavior representations.

</details>


### [48] [Improving Neural Topic Modeling with Semantically-Grounded Soft Label Distributions](https://arxiv.org/abs/2602.17907)
*Raymond Li,Amirhossein Abaskohi,Chuyuan Li,Gabriel Murray,Giuseppe Carenini*

Main category: cs.CL

TL;DR: 该论文提出了一种利用语言模型生成语义软标签来改进神经主题模型的方法，通过重构这些软标签而非传统的词袋表示，显著提升了主题质量和文档检索效果。


<details>
  <summary>Details</summary>
Motivation: 传统神经主题模型通常通过重构文档的词袋表示进行优化，这种方法忽略了上下文信息，且在处理数据稀疏性时表现不佳。作者希望利用语言模型的上下文理解能力来改进主题建模。

Method: 提出了一种新颖的方法：使用语言模型通过专用提示词生成下一个词的概率分布，将其投影到预定义词汇表上，构建语义基础的软标签目标。然后训练主题模型重构这些软标签，利用语言模型的隐藏状态作为监督信号。

Result: 在三个数据集上的实验表明，该方法在主题连贯性和纯度方面相比现有基线有显著提升。同时引入的检索指标显示，该方法在识别语义相似文档方面明显优于现有方法，特别适合检索导向的应用。

Conclusion: 通过利用语言模型生成上下文丰富的监督信号，该方法能够产生更高质量、更贴近语料库底层主题结构的主题，为神经主题建模提供了新的有效途径。

Abstract: Traditional neural topic models are typically optimized by reconstructing the document's Bag-of-Words (BoW) representations, overlooking contextual information and struggling with data sparsity. In this work, we propose a novel approach to construct semantically-grounded soft label targets using Language Models (LMs) by projecting the next token probabilities, conditioned on a specialized prompt, onto a pre-defined vocabulary to obtain contextually enriched supervision signals. By training the topic models to reconstruct the soft labels using the LM hidden states, our method produces higher-quality topics that are more closely aligned with the underlying thematic structure of the corpus. Experiments on three datasets show that our method achieves substantial improvements in topic coherence, purity over existing baselines. Additionally, we also introduce a retrieval-based metric, which shows that our approach significantly outperforms existing methods in identifying semantically similar documents, highlighting its effectiveness for retrieval-oriented applications.

</details>


### [49] [Condition-Gated Reasoning for Context-Dependent Biomedical Question Answering](https://arxiv.org/abs/2602.17911)
*Jash Rajesh Parekh,Wonbin Kweon,Joey Chan,Rezarta Islamaj,Robert Leaman,Pengcheng Jiang,Chih-Hsuan Wei,Zhizheng Wang,Zhiyong Lu,Jiawei Han*

Main category: cs.CL

TL;DR: 提出首个条件性生物医学问答基准CondMedQA和条件门控推理框架CGR，解决现有系统无法处理患者特定条件依赖的临床推理问题


<details>
  <summary>Details</summary>
Motivation: 现有生物医学问答系统假设医学知识普遍适用，但真实临床推理本质上是条件性的——几乎所有决策都依赖于患者特定因素（如并发症和禁忌症）。现有基准无法评估这种条件推理，检索增强或基于图的方法缺乏确保检索知识适用于特定上下文的显式机制。

Method: 提出CondMedQA基准（首个条件性生物医学问答基准），包含答案随患者条件变化的多跳问题。提出条件门控推理（CGR）框架，构建条件感知知识图谱，基于查询条件选择性激活或剪枝推理路径。

Result: CGR能更可靠地选择条件适当的答案，同时在生物医学问答基准上达到或超过最先进性能，突显了显式建模条件性对稳健医学推理的重要性。

Conclusion: 条件性建模对于稳健的医学推理至关重要，CondMedQA基准和CGR框架为解决临床决策中的患者特定条件依赖问题提供了有效方案。

Abstract: Current biomedical question answering (QA) systems often assume that medical knowledge applies uniformly, yet real-world clinical reasoning is inherently conditional: nearly every decision depends on patient-specific factors such as comorbidities and contraindications. Existing benchmarks do not evaluate such conditional reasoning, and retrieval-augmented or graph-based methods lack explicit mechanisms to ensure that retrieved knowledge is applicable to given context. To address this gap, we propose CondMedQA, the first benchmark for conditional biomedical QA, consisting of multi-hop questions whose answers vary with patient conditions. Furthermore, we propose Condition-Gated Reasoning (CGR), a novel framework that constructs condition-aware knowledge graphs and selectively activates or prunes reasoning paths based on query conditions. Our findings show that CGR more reliably selects condition-appropriate answers while matching or exceeding state-of-the-art performance on biomedical QA benchmarks, highlighting the importance of explicitly modeling conditionality for robust medical reasoning.

</details>


### [50] [Analyzing LLM Instruction Optimization for Tabular Fact Verification](https://arxiv.org/abs/2602.17937)
*Xiaotang Du,Giwon Hong,Wai-Chung Kwan,Rohit Saxena,Ivan Titov,Pasquale Minervini,Emily Allaway*

Main category: cs.CL

TL;DR: 本文首次系统比较了基于DSPy优化框架的指令优化方法在表格事实验证任务中的应用，发现指令优化能持续提升验证准确率，不同优化器对不同提示技术效果各异。


<details>
  <summary>Details</summary>
Motivation: 指令优化为提升大型语言模型推理性能提供了一种轻量级、模型无关的方法。目前缺乏对表格事实验证任务中指令优化的系统比较研究。

Method: 基于DSPy优化框架，评估四种开箱即用的提示技术：直接预测、思维链、带SQL工具的ReAct、带Python执行的CodeAct。研究三种DSPy优化器（COPRO、MiPROv2、SIMBA）在四个基准测试和三个模型家族上的表现。

Result: 指令优化持续提升验证准确率：MiPROv2对思维链提供最稳定的增益，SIMBA对ReAct智能体提供最大收益（尤其在大模型规模下）。行为分析显示SIMBA通过启发式方法鼓励更直接的推理路径，提升思维链中的数值比较能力，帮助ReAct智能体避免不必要的工具调用。

Conclusion: 在不同提示技术中，思维链对表格事实检查仍然有效（尤其对小模型）。虽然用大模型构建的ReAct智能体可以达到竞争性性能，但需要仔细的指令优化。

Abstract: Instruction optimization provides a lightweight, model-agnostic approach to enhancing the reasoning performance of large language models (LLMs). This paper presents the first systematic comparison of instruction optimization, based on the DSPy optimization framework, for tabular fact verification. We evaluate four out-of-the-box prompting techniques that cover both text-only prompting and code use: direct prediction, Chain-of-Thought (CoT), ReAct with SQL tools, and CodeAct with Python execution. We study three optimizers from the DSPy framework -- COPRO, MiPROv2, and SIMBA -- across four benchmarks and three model families. We find that instruction optimization consistently improves verification accuracy, with MiPROv2 yielding the most stable gains for CoT, and SIMBA providing the largest benefits for ReAct agents, particularly at larger model scales. Behavioral analyses reveal that SIMBA encourages more direct reasoning paths by applying heuristics, thereby improving numerical comparison abilities in CoT reasoning and helping avoid unnecessary tool calls in ReAct agents. Across different prompting techniques, CoT remains effective for tabular fact checking, especially with smaller models. Although ReAct agents built with larger models can achieve competitive performance, they require careful instruction optimization.

</details>


### [51] [CUICurate: A GraphRAG-based Framework for Automated Clinical Concept Curation for NLP applications](https://arxiv.org/abs/2602.17949)
*Victoria Blake,Mathew Miller,Jamie Novak,Sze-yuan Ooi,Blanca Gallego*

Main category: cs.CL

TL;DR: CUICurate是一个基于图检索增强生成的框架，用于自动化UMLS概念集构建，结合知识图谱检索和LLM过滤分类，显著减少人工工作量。


<details>
  <summary>Details</summary>
Motivation: 临床命名实体识别工具通常将自由文本映射到UMLS概念唯一标识符(CUIs)，但许多下游任务需要的是包含相关同义词、子类型和超类型的概念集。目前构建这样的概念集是劳动密集型的、执行不一致的，并且现有工具支持不足。

Method: 提出了CUICurate框架，基于图检索增强生成(GraphRAG)。首先构建并嵌入UMLS知识图谱进行语义检索，然后针对每个目标概念从KG中检索候选CUIs，接着使用大型语言模型(比较了GPT-5和GPT-5-mini)进行过滤和分类。

Result: 在五个词汇异质性临床概念上评估，CUICurate生成的概念集比人工基准更大更完整，同时保持与人类相当的精确度。GPT-5-mini在过滤阶段召回率更高，而GPT-5的分类结果更接近临床医生判断。输出稳定且计算成本低。

Conclusion: CUICurate提供了一个可扩展且可重复的方法来支持UMLS概念集构建，显著减少人工工作量。通过整合基于图的检索和LLM推理，该框架生成聚焦的候选概念集，可适应不同表型和分析需求的临床NLP流程。

Abstract: Background: Clinical named entity recognition tools commonly map free text to Unified Medical Language System (UMLS) Concept Unique Identifiers (CUIs). For many downstream tasks, however, the clinically meaningful unit is not a single CUI but a concept set comprising related synonyms, subtypes, and supertypes. Constructing such concept sets is labour-intensive, inconsistently performed, and poorly supported by existing tools, particularly for NLP pipelines that operate directly on UMLS CUIs. Methods We present CUICurate, a Graph-based retrieval-augmented generation (GraphRAG) framework for automated UMLS concept set curation. A UMLS knowledge graph (KG) was constructed and embedded for semantic retrieval. For each target concept, candidate CUIs were retrieved from the KG, followed by large language model (LLM) filtering and classification steps comparing two LLMs (GPT-5 and GPT-5-mini). The framework was evaluated on five lexically heterogeneous clinical concepts against a manually curated benchmark and gold-standard concept sets. Results Across all concepts, CUICurate produced substantially larger and more complete concept sets than the manual benchmarks whilst matching human precision. Comparisons between the two LLMs found that GPT-5-mini achieved higher recall during filtering, while GPT-5 produced classifications that more closely aligned with clinician judgements. Outputs were stable across repeated runs and computationally inexpensive. Conclusions CUICurate offers a scalable and reproducible approach to support UMLS concept set curation that substantially reduces manual effort. By integrating graph-based retrieval with LLM reasoning, the framework produces focused candidate concept sets that can be adapted to clinical NLP pipelines for different phenotyping and analytic requirements.

</details>


### [52] [Decomposing Retrieval Failures in RAG for Long-Document Financial Question Answering](https://arxiv.org/abs/2602.17981)
*Amine Kobeissi,Philippe Langlais*

Main category: cs.CL

TL;DR: 本文研究了金融问答中检索增强生成的失败模式：虽然检索到正确文档，但遗漏了包含答案的具体页面或块，导致生成器基于不完整上下文推断。作者评估了多粒度检索，并提出了针对金融文档的页面级检索优化方法。


<details>
  <summary>Details</summary>
Motivation: 在金融监管文件问答中，检索增强生成虽然常用，但可靠性取决于能否检索到确切的上下文来支持答案。作者关注一个常见失败模式：检索到正确文档但遗漏了包含答案的具体页面或块，导致生成器基于不完整上下文进行推断。尽管这个问题在实际应用中很重要，但在金融问答文献中尚未得到系统研究。

Method: 1) 在多粒度层面（文档、页面、块）评估检索性能；2) 引入基于oracle的分析来提供检索和生成性能的经验上界；3) 在FinanceBench的150个问题子集上复现和比较多种检索策略（密集、稀疏、混合、分层检索，包括重排序和查询重构）；4) 提出领域微调的页面评分器，将页面作为文档和块之间的中间检索单元，专门针对金融文档微调双编码器进行页面级相关性判断。

Result: 1) 不同方法中，文档发现能力的提升通常能转化为更强的页面召回率；2) Oracle性能分析表明页面和块级检索仍有改进空间；3) 提出的领域微调页面评分器显著提升了页面召回率和块检索性能，通过利用页面的语义连贯性优于传统的基于段落的分层检索方法。

Conclusion: 本文系统研究了金融问答中检索增强生成的文档内检索失败问题，提出了针对金融文档的页面级检索优化方法。实验表明，专门针对金融文档微调的页面评分器能有效提升页面召回率和块检索性能，为解决文档内检索失败问题提供了有效方案。

Abstract: Retrieval-augmented generation is increasingly used for financial question answering over long regulatory filings, yet reliability depends on retrieving the exact context needed to justify answers in high stakes settings. We study a frequent failure mode in which the correct document is retrieved but the page or chunk that contains the answer is missed, leading the generator to extrapolate from incomplete context. Despite its practical significance, this within-document retrieval failure mode has received limited systematic attention in the Financial Question Answering (QA) literature. We evaluate retrieval at multiple levels of granularity, document, page, and chunk level, and introduce an oracle based analysis to provide empirical upper bounds on retrieval and generative performance. On a 150 question subset of FinanceBench, we reproduce and compare diverse retrieval strategies including dense, sparse, hybrid, and hierarchical methods with reranking and query reformulation. Across methods, gains in document discovery tend to translate into stronger page recall, yet oracle performance still suggests headroom for page and chunk level retrieval. To target this gap, we introduce a domain fine-tuned page scorer that treats pages as an intermediate retrieval unit between documents and chunks. Unlike prior passage-based hierarchical retrieval, we fine-tune a bi-encoder specifically for page-level relevance on financial filings, exploiting the semantic coherence of pages. Overall, our results demonstrate a significant improvement in page recall and chunk retrieval.

</details>


### [53] [Towards More Standardized AI Evaluation: From Models to Agents](https://arxiv.org/abs/2602.18029)
*Ali El Filali,Inès Bedar*

Main category: cs.CL

TL;DR: 论文认为传统基于静态基准测试的评估方法已不适用于AI代理系统，评估应从"性能剧场"转变为支持信任、迭代和治理的测量学科。


<details>
  <summary>Details</summary>
Motivation: 随着AI系统从静态模型发展为复合型工具使用代理，评估不再是最终检查点，而成为核心控制功能。传统评估方法基于模型中心时代的假设（静态基准、聚合分数、一次性成功标准），这些方法越来越模糊而非阐明系统行为。

Method: 论文通过分析评估管道如何引入静默故障模式、解释高基准分数为何经常误导团队，以及探讨代理系统如何从根本上改变性能测量的意义，来阐明评估在AI时代的作用。

Result: 论文揭示了传统评估方法的局限性：评估管道本身会引入故障模式，高基准分数具有误导性，代理系统改变了性能测量的本质含义。

Conclusion: 评估不应是"性能剧场"，而应成为支持非确定性系统中信任建立、迭代改进和治理的测量学科，特别是在代理系统时代需要重新思考评估的角色和意义。

Abstract: Evaluation is no longer a final checkpoint in the machine learning lifecycle. As AI systems evolve from static models to compound, tool-using agents, evaluation becomes a core control function. The question is no longer "How good is the model?" but "Can we trust the system to behave as intended, under change, at scale?". Yet most evaluation practices remain anchored in assumptions inherited from the model-centric era: static benchmarks, aggregate scores, and one-off success criteria. This paper argues that such approaches are increasingly obscure rather than illuminating system behavior. We examine how evaluation pipelines themselves introduce silent failure modes, why high benchmark scores routinely mislead teams, and how agentic systems fundamentally alter the meaning of performance measurement. Rather than proposing new metrics or harder benchmarks, we aim to clarify the role of evaluation in the AI era, and especially for agents: not as performance theater, but as a measurement discipline that conditions trust, iteration, and governance in non-deterministic systems.

</details>


### [54] [Perceived Political Bias in LLMs Reduces Persuasive Abilities](https://arxiv.org/abs/2602.18092)
*Matthew DiGiuseppe,Joshua Robison*

Main category: cs.CL

TL;DR: 研究发现，当用户认为聊天AI存在党派偏见时，其纠正错误信息的效果会显著降低28%，表明AI的说服力受政治中立性感知影响。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型进入政治领域，精英阶层越来越多地将其描绘为具有意识形态倾向。本研究旨在测试这种可信度攻击是否会降低基于LLM的说服效果，探究AI说服力的政治条件性。

Method: 在美国进行了一项预注册调查实验（N=2144），参与者与ChatGPT进行三轮对话，讨论个人持有的经济政策误解。实验组收到简短信息表明LLM对参与者所属党派存在偏见，对照组为中性信息。

Result: 相比中性对照组，表明LLM存在党派偏见的信息使说服效果降低28%。转录分析显示警告改变了互动方式：受访者更频繁地反驳，参与度更低，接受度更差。

Conclusion: 对话式AI的说服效果具有政治条件性，受党派一致性感知的制约。当用户认为AI存在政治偏见时，其纠正错误信息的能力会显著减弱。

Abstract: Conversational AI has been proposed as a scalable way to correct public misconceptions and spread misinformation. Yet its effectiveness may depend on perceptions of its political neutrality. As LLMs enter partisan conflict, elites increasingly portray them as ideologically aligned. We test whether these credibility attacks reduce LLM-based persuasion. In a preregistered U.S. survey experiment (N=2144), participants completed a three-round conversation with ChatGPT about a personally held economic policy misconception. Compared to a neutral control, a short message indicating that the LLM was biased against the respondent's party attenuated persuasion by 28%. Transcript analysis indicates that the warnings alter the interaction: respondents push back more and engage less receptively. These findings suggest that the persuasive impact of conversational AI is politically contingent, constrained by perceptions of partisan alignment.

</details>


### [55] [Agentic Adversarial QA for Improving Domain-Specific LLMs](https://arxiv.org/abs/2602.18137)
*Vincent Grari,Ciprian Tomoiaga,Sylvain Lamprier,Tatsunori Hashimoto,Marcin Detyniecki*

Main category: cs.CL

TL;DR: 提出对抗性问答生成框架，通过对比待适应模型与专家模型的输出，生成紧凑的语义挑战性问题，在少量合成样本下提升LLM在专业领域的适应能力。


<details>
  <summary>Details</summary>
Motivation: LLM在专业领域适应困难，现有合成数据方法（如转述、知识提取）存在两个关键缺陷：1) 对解释性推理能力支持不足；2) 生成的数据集过大且冗余，样本效率低下。

Method: 提出对抗性问答生成框架，通过迭代反馈驱动过程，对比待适应模型与基于参考文档的专家模型的输出，生成紧凑的语义挑战性问题，揭示并解决理解差距。

Result: 在LegalBench语料库的专业子集上评估，该方法以显著更少的合成样本实现了更高的准确率。

Conclusion: 该方法解决了现有合成数据方法的局限性，通过生成紧凑的语义挑战性问题，有效提升LLM在专业领域的适应效率和推理能力。

Abstract: Large Language Models (LLMs), despite extensive pretraining on broad internet corpora, often struggle to adapt effectively to specialized domains. There is growing interest in fine-tuning these models for such domains; however, progress is constrained by the scarcity and limited coverage of high-quality, task-relevant data. To address this, synthetic data generation methods such as paraphrasing or knowledge extraction are commonly applied. Although these approaches excel at factual recall and conceptual knowledge, they suffer from two critical shortcomings: (i) they provide minimal support for interpretive reasoning capabilities in these specialized domains, and (ii) they often produce synthetic corpora that are excessively large and redundant, resulting in poor sample efficiency. To overcome these gaps, we propose an adversarial question-generation framework that produces a compact set of semantically challenging questions. These questions are constructed by comparing the outputs of the model to be adapted and a robust expert model grounded in reference documents, using an iterative, feedback-driven process designed to reveal and address comprehension gaps. Evaluation on specialized subsets of the LegalBench corpus demonstrates that our method achieves greater accuracy with substantially fewer synthetic samples.

</details>


### [56] [Detecting Contextual Hallucinations in LLMs with Frequency-Aware Attention](https://arxiv.org/abs/2602.18145)
*Siya Qi,Yudong Chen,Runcong Zhao,Qinglin Zhu,Zhanghao Hu,Wei Liu,Yulan He,Zheng Yuan,Lin Gui*

Main category: cs.CL

TL;DR: 本文提出一种基于频率分析的注意力机制方法，通过检测注意力分布中的高频成分来识别大语言模型生成中的幻觉问题。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在基于上下文的生成中容易出现幻觉，现有方法主要依赖粗粒度的注意力摘要，无法捕捉注意力中的细微不稳定性。需要更精细的方法来检测幻觉，确保模型生成的可靠性。

Method: 采用信号处理视角，将注意力分布建模为离散信号，提取反映注意力快速局部变化的高频成分。基于高频注意力特征开发轻量级幻觉检测器。

Result: 实验在RAGTruth和HalluRAG基准测试上显示，该方法在性能和效率上优于基于验证、内部表示和传统注意力方法，在不同模型和任务中均取得性能提升。

Conclusion: 注意力分布中的高频成分能有效反映幻觉相关的碎片化和不稳定接地行为，基于频率分析的注意力特征为幻觉检测提供了有效且轻量的解决方案。

Abstract: Hallucination detection is critical for ensuring the reliability of large language models (LLMs) in context-based generation. Prior work has explored intrinsic signals available during generation, among which attention offers a direct view of grounding behavior. However, existing approaches typically rely on coarse summaries that fail to capture fine-grained instabilities in attention. Inspired by signal processing, we introduce a frequency-aware perspective on attention by analyzing its variation during generation. We model attention distributions as discrete signals and extract high-frequency components that reflect rapid local changes in attention. Our analysis reveals that hallucinated tokens are associated with high-frequency attention energy, reflecting fragmented and unstable grounding behavior. Based on this insight, we develop a lightweight hallucination detector using high-frequency attention features. Experiments on the RAGTruth and HalluRAG benchmarks show that our approach achieves performance gains over verification-based, internal-representation-based, and attention-based methods across models and tasks.

</details>


### [57] [The Statistical Signature of LLMs](https://arxiv.org/abs/2602.18152)
*Ortal Hadad,Edoardo Loru,Jacopo Nudo,Niccolò Di Marco,Matteo Cinelli,Walter Quattrociocchi*

Main category: cs.CL

TL;DR: 论文通过无损压缩分析发现LLM生成文本比人类文本具有更高的结构规律性和可压缩性，揭示了概率生成的结构特征，但在小尺度交互环境中这种差异减弱。


<details>
  <summary>Details</summary>
Motivation: 研究动机是理解大语言模型通过概率采样生成文本时，如何重塑语言的结构统计组织。目前对这一过程如何改变文本的统计规律性缺乏完整的特征描述。

Method: 使用无损压缩作为模型无关的统计规律性度量方法，分析三种信息生态系统：控制的人类-LLM延续、知识基础设施生成中介（维基百科 vs Grokipedia）、完全合成的社交互动环境（Moltbook vs Reddit）。

Result: 压缩分析揭示了概率生成的持久结构特征：在控制和中介环境中，LLM生成的语言比人类文本表现出更高的结构规律性和可压缩性，表明输出集中在高度循环的统计模式中。但在碎片化互动环境中，这种分离减弱，表明在小尺度上表面可区分性存在基本限制。

Conclusion: 无损压缩提供了一个简单而稳健的框架，用于量化生成系统如何重塑文本生产，为通信的演化复杂性提供了结构视角。这种基于可压缩性的分离在不同模型、任务和领域中一致出现，可直接从表面文本观察，无需依赖模型内部或语义评估。

Abstract: Large language models generate text through probabilistic sampling from high-dimensional distributions, yet how this process reshapes the structural statistical organization of language remains incompletely characterized. Here we show that lossless compression provides a simple, model-agnostic measure of statistical regularity that differentiates generative regimes directly from surface text. We analyze compression behavior across three progressively more complex information ecosystems: controlled human-LLM continuations, generative mediation of a knowledge infrastructure (Wikipedia vs. Grokipedia), and fully synthetic social interaction environments (Moltbook vs. Reddit). Across settings, compression reveals a persistent structural signature of probabilistic generation. In controlled and mediated contexts, LLM-produced language exhibits higher structural regularity and compressibility than human-written text, consistent with a concentration of output within highly recurrent statistical patterns. However, this signature shows scale dependence: in fragmented interaction environments the separation attenuates, suggesting a fundamental limit to surface-level distinguishability at small scales. This compressibility-based separation emerges consistently across models, tasks, and domains and can be observed directly from surface text without relying on model internals or semantic evaluation. Overall, our findings introduce a simple and robust framework for quantifying how generative systems reshape textual production, offering a structural perspective on the evolving complexity of communication.

</details>


### [58] [FENCE: A Financial and Multimodal Jailbreak Detection Dataset](https://arxiv.org/abs/2602.18154)
*Mirae Kim,Seonghun Jeong,Youngjun Kwak*

Main category: cs.CL

TL;DR: FENCE是一个用于金融领域多模态越狱检测的双语（韩语-英语）数据集，包含金融相关查询和基于图像的威胁，能有效训练检测模型达到99%准确率。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型和视觉语言模型在金融等敏感领域部署时面临越狱攻击风险，特别是多模态模型因处理文本和图像而攻击面更广，但目前缺乏针对金融领域的越狱检测资源。

Method: 创建FENCE双语多模态数据集，包含金融相关查询和图像威胁；在商业和开源VLM上进行实验评估漏洞；基于FENCE训练基线检测器并评估性能。

Result: 实验显示GPT-4o存在可测量的攻击成功率，开源模型暴露更大风险；基于FENCE训练的基线检测器达到99%分布内准确率，在外部基准测试中保持强性能。

Conclusion: FENCE为金融领域多模态越狱检测提供了专注资源，支持在敏感领域构建更安全可靠的AI系统，数据集在训练可靠检测模型方面表现出鲁棒性。

Abstract: Jailbreaking poses a significant risk to the deployment of Large Language Models (LLMs) and Vision Language Models (VLMs). VLMs are particularly vulnerable because they process both text and images, creating broader attack surfaces. However, available resources for jailbreak detection are scarce, particularly in finance. To address this gap, we present FENCE, a bilingual (Korean-English) multimodal dataset for training and evaluating jailbreak detectors in financial applications. FENCE emphasizes domain realism through finance-relevant queries paired with image-grounded threats. Experiments with commercial and open-source VLMs reveal consistent vulnerabilities, with GPT-4o showing measurable attack success rates and open-source models displaying greater exposure. A baseline detector trained on FENCE achieves 99 percent in-distribution accuracy and maintains strong performance on external benchmarks, underscoring the dataset's robustness for training reliable detection models. FENCE provides a focused resource for advancing multimodal jailbreak detection in finance and for supporting safer, more reliable AI systems in sensitive domains. Warning: This paper includes example data that may be offensive.

</details>


### [59] [Click it or Leave it: Detecting and Spoiling Clickbait with Informativeness Measures and Large Language Models](https://arxiv.org/abs/2602.18171)
*Wojciech Michaluk,Tymoteusz Urban,Mateusz Kubita,Soveatin Kuntur,Anna Wroblewska*

Main category: cs.CL

TL;DR: 提出结合Transformer文本嵌入与语言学特征的方法检测点击诱饵标题，XGBoost模型在增强特征上达到91% F1分数，优于多种基线方法


<details>
  <summary>Details</summary>
Motivation: 点击诱饵标题降低在线信息质量并损害用户信任，需要有效的检测方法来应对这一问题

Method: 混合方法结合Transformer文本嵌入和语言学信息特征，使用NLP技术评估多种向量化方法，最终采用XGBoost分类器处理增强特征

Result: 最佳模型（XGBoost结合增强特征）F1分数达91%，优于TF-IDF、Word2Vec、GloVe、LLM提示分类和纯特征基线

Conclusion: 提出的特征集通过突出第二人称代词、最高级、数字和注意力导向标点等语言学线索，提高了模型可解释性，支持透明且校准良好的点击诱饵预测

Abstract: Clickbait headlines degrade the quality of online information and undermine user trust. We present a hybrid approach to clickbait detection that combines transformer-based text embeddings with linguistically motivated informativeness features. Using natural language processing techniques, we evaluate classical vectorizers, word embedding baselines, and large language model embeddings paired with tree-based classifiers. Our best-performing model, XGBoost over embeddings augmented with 15 explicit features, achieves an F1-score of 91\%, outperforming TF-IDF, Word2Vec, GloVe, LLM prompt based classification, and feature-only baselines. The proposed feature set enhances interpretability by highlighting salient linguistic cues such as second-person pronouns, superlatives, numerals, and attention-oriented punctuation, enabling transparent and well-calibrated clickbait predictions. We release code and trained models to support reproducible research.

</details>


### [60] [Improving Sampling for Masked Diffusion Models via Information Gain](https://arxiv.org/abs/2602.18176)
*Kaisen Yang,Jayden Teoh,Kaicheng Yang,Yitong Zhang,Alex Lamb*

Main category: cs.CL

TL;DR: 提出Info-Gain Sampler，一种用于掩码扩散模型的新解码框架，通过平衡即时不确定性和未来信息增益来提升生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有掩码扩散模型解码器采用贪心策略，只关注局部确定性，忽略了当前解码决策对后续步骤的影响，未能充分利用MDMs的非因果特性来最小化累积不确定性。

Method: 提出信息增益采样器，这是一个原则性的解码框架，不仅考虑当前位置的不确定性，还评估当前解码决策如何重塑所有剩余掩码位置的token概率/不确定性，从而平衡即时不确定性和未来信息增益。

Result: 在推理、编码、创意写作和图像生成等多种任务和架构上，Info-Gain Sampler始终优于现有采样器：推理任务平均准确率提升3.6%，创意写作胜率63.1%，推理任务累积不确定性从78.4降至48.6。

Conclusion: Info-Gain Sampler通过系统性地考虑解码决策的未来影响，充分利用了掩码扩散模型的非因果特性，显著提升了生成质量和任务性能。

Abstract: Masked Diffusion Models (MDMs) offer greater flexibility in decoding order than autoregressive models but require careful planning to achieve high-quality generation. Existing samplers typically adopt greedy heuristics, prioritizing positions with the highest local certainty to decode at each step. Through failure case analysis, we identify a fundamental limitation of this approach: it neglects the downstream impact of current decoding choices on subsequent steps and fails to minimize cumulative uncertainty. In particular, these methods do not fully exploit the non-causal nature of MDMs, which enables evaluating how a decoding decision reshapes token probabilities/uncertainty across all remaining masked positions. To bridge this gap, we propose the Info-Gain Sampler, a principled decoding framework that balances immediate uncertainty with information gain over future masked tokens. Extensive evaluations across diverse architectures and tasks (reasoning, coding, creative writing, and image generation) demonstrate that Info-Gain Sampler consistently outperforms existing samplers for MDMs. For instance, it achieves a 3.6% improvement in average accuracy on reasoning tasks and a 63.1% win-rate in creative writing. Notably, on reasoning tasks it reduces cumulative uncertainty from 78.4 to 48.6, outperforming the best baseline by a large margin. The code will be available at https://github.com/yks23/Information-Gain-Sampler.

</details>


### [61] [Information-Theoretic Storage Cost in Sentence Comprehension](https://arxiv.org/abs/2602.18217)
*Kohei Kajikawa,Shinnosuke Isono,Ethan Gotlieb Wilcox*

Main category: cs.CL

TL;DR: 提出基于信息论的连续处理存储成本度量，替代传统离散语法度量，通过预训练神经语言模型估计，在英语中验证有效性


<details>
  <summary>Details</summary>
Motivation: 实时句子理解对工作记忆负荷大，现有基于符号语法的度量采用离散统一成本，需要更连续、理论中立的度量方法

Method: 基于信息论形式化处理存储成本，定义为前文对未来上下文携带的信息量（考虑不确定性），使用预训练神经语言模型估计

Result: 在英语中验证：1)恢复中心嵌入和关系从句的处理不对称性；2)与语法基存储成本相关；3)在自然数据集上预测阅读时间方差优于传统信息基预测器

Conclusion: 信息论存储成本度量是连续、理论中立的有效方法，可替代传统离散语法度量，为心理语言学理论提供新工具

Abstract: Real-time sentence comprehension imposes a significant load on working memory, as comprehenders must maintain contextual information to anticipate future input. While measures of such load have played an important role in psycholinguistic theories, they have been formalized, largely, using symbolic grammars, which assign discrete, uniform costs to syntactic predictions. This study proposes a measure of processing storage cost based on an information-theoretic formalization, as the amount of information previous words carry about future context, under uncertainty. Unlike previous discrete, grammar-based metrics, this measure is continuous, theory-neutral, and can be estimated from pre-trained neural language models. The validity of this approach is demonstrated through three analyses in English: our measure (i) recovers well-known processing asymmetries in center embeddings and relative clauses, (ii) correlates with a grammar-based storage cost in a syntactically-annotated corpus, and (iii) predicts reading-time variance in two large-scale naturalistic datasets over and above baseline models with traditional information-based predictors.

</details>


### [62] [Thinking by Subtraction: Confidence-Driven Contrastive Decoding for LLM Reasoning](https://arxiv.org/abs/2602.18232)
*Lexiang Tang,Weihao Gao,Bingchen Zhao,Lu Ma,Qiao jin,Bang Yang,Yuexian Zou*

Main category: cs.CL

TL;DR: 提出Confidence-Driven Contrastive Decoding方法，通过检测低置信度token并选择性干预，提升LLM推理可靠性同时减少输出长度


<details>
  <summary>Details</summary>
Motivation: 现有测试时缩放方法假设均匀增加推理计算能提升正确性，但研究发现推理不确定性高度局部化：少数低置信度token对推理错误和不必要输出扩展贡献不成比例

Method: 提出Thinking by Subtraction方法，使用置信度驱动的对比解码：检测解码过程中的低置信度token，在这些位置选择性干预；构建对比参考（将高置信度token替换为最小占位符），在低置信度位置通过减去参考分布来精炼预测

Result: CCD在数学推理基准测试中显著提升准确性，同时大幅减少输出长度，KV缓存开销最小；作为无需训练的方法，通过针对性低置信度干预提升推理可靠性，避免计算冗余

Conclusion: 通过针对低置信度token的局部化干预，CCD方法能够有效提升LLM推理的可靠性，同时减少不必要的输出扩展，提供了一种高效的无训练推理增强方案

Abstract: Recent work on test-time scaling for large language model (LLM) reasoning typically assumes that allocating more inference-time computation uniformly improves correctness. However, prior studies show that reasoning uncertainty is highly localized: a small subset of low-confidence tokens disproportionately contributes to reasoning errors and unnecessary output expansion. Motivated by this observation, we propose Thinking by Subtraction, a confidence-driven contrastive decoding approach that improves reasoning reliability through targeted token-level intervention. Our method, Confidence-Driven Contrastive Decoding, detects low-confidence tokens during decoding and intervenes selectively at these positions. It constructs a contrastive reference by replacing high-confidence tokens with minimal placeholders, and refines predictions by subtracting this reference distribution at low-confidence locations. Experiments show that CCD significantly improves accuracy across mathematical reasoning benchmarks while substantially reducing output length, with minimal KV-cache overhead. As a training-free method, CCD enhances reasoning reliability through targeted low-confidence intervention without computational redundancy. Our code will be made available at: https://github.com/bolo-web/CCD.

</details>


### [63] [Simplifying Outcomes of Language Model Component Analyses with ELIA](https://arxiv.org/abs/2602.18262)
*Aaron Louis Eidt,Nils Feldhus*

Main category: cs.CL

TL;DR: ELIA是一个交互式Web应用，通过整合多种语言模型分析技术并利用视觉语言模型自动生成自然语言解释，降低了机制可解释性工具的使用门槛，使非专家也能理解复杂的LLM内部工作原理。


<details>
  <summary>Details</summary>
Motivation: 机制可解释性虽然开发了强大的工具来分析大型语言模型的内部工作原理，但其复杂性造成了可访问性差距，限制了这些工具只能被专家使用。需要设计一个系统来简化这些分析结果，让更广泛的受众能够理解。

Method: 设计、构建和评估ELIA系统，整合三种关键技术：归因分析、函数向量分析和电路追踪。引入创新方法：使用视觉语言模型自动为这些方法产生的复杂可视化生成自然语言解释。通过混合方法的用户研究进行实证验证。

Result: 用户研究显示用户明显偏好交互式、可探索的界面而非简单的静态可视化。AI驱动的解释帮助非专家弥合了知识差距；统计分析显示用户的先验LLM经验与其理解分数之间没有显著相关性，表明系统减少了不同经验水平的理解障碍。

Conclusion: AI系统确实可以简化复杂的模型分析，但其真正潜力在于与深思熟虑、以用户为中心的设计相结合，这种设计优先考虑交互性、特异性和叙事指导，从而解锁系统的全部能力。

Abstract: While mechanistic interpretability has developed powerful tools to analyze the internal workings of Large Language Models (LLMs), their complexity has created an accessibility gap, limiting their use to specialists. We address this challenge by designing, building, and evaluating ELIA (Explainable Language Interpretability Analysis), an interactive web application that simplifies the outcomes of various language model component analyses for a broader audience. The system integrates three key techniques -- Attribution Analysis, Function Vector Analysis, and Circuit Tracing -- and introduces a novel methodology: using a vision-language model to automatically generate natural language explanations (NLEs) for the complex visualizations produced by these methods. The effectiveness of this approach was empirically validated through a mixed-methods user study, which revealed a clear preference for interactive, explorable interfaces over simpler, static visualizations. A key finding was that the AI-powered explanations helped bridge the knowledge gap for non-experts; a statistical analysis showed no significant correlation between a user's prior LLM experience and their comprehension scores, suggesting that the system reduced barriers to comprehension across experience levels. We conclude that an AI system can indeed simplify complex model analyses, but its true power is unlocked when paired with thoughtful, user-centered design that prioritizes interactivity, specificity, and narrative guidance.

</details>


### [64] [PsihoRo: Depression and Anxiety Romanian Text Corpus](https://arxiv.org/abs/2602.18324)
*Alexandra Ciobotaru,Ana-Maria Bucur,Liviu P. Dinu*

Main category: cs.CL

TL;DR: 创建了首个罗马尼亚语抑郁症和焦虑症语料库PsihoRo，包含205名受访者的文本数据，填补了罗马尼亚语心理健康NLP资源的空白。


<details>
  <summary>Details</summary>
Motivation: 罗马尼亚语目前没有开源的心理健康语料库，而英语等语言已有丰富的心理NLP资源。心理健康数据从社交媒体收集存在假设偏差问题，需要更实用的收集方法。

Method: 使用包含6个开放式问题的表格，配合标准化的PHQ-9和GAD-7筛查问卷收集数据。通过统计分析、罗马尼亚语LIWC文本分析、情感检测和主题建模来分析语料特征。

Result: 创建了包含205名受访者文本的PsihoRo语料库，虽然规模较小，但这是分析罗马尼亚人口心理健康文本的第一步。

Conclusion: PsihoRo填补了罗马尼亚语心理健康语料库的空白，为NLP社区提供了首个罗马尼亚语抑郁症和焦虑症文本资源，展示了该资源的重要特征。

Abstract: Psychological corpora in NLP are collections of texts used to analyze human psychology, emotions, and mental health. These texts allow researchers to study psychological constructs, detect mental health issues and analyze emotional language. However, mental health data can be difficult to collect correctly from social media, due to suppositions made by the collectors. A more pragmatic strategy involves gathering data through open-ended questions and then assessing this information with self-report screening surveys. This method was employed successfully for English, a language with a lot of psychological NLP resources. However, this cannot be stated for Romanian, which currently has no open-source mental health corpus. To address this gap, we have created the first corpus for depression and anxiety in Romanian, by utilizing a form with 6 open-ended questions along with the standardized PHQ-9 and GAD-7 screening questionnaires. Consisting of the texts of 205 respondents and although it may seem small, PsihoRo is a first step towards understanding and analyzing texts regarding the mental health of the Romanian population. We employ statistical analysis, text analysis using Romanian LIWC, emotion detection and topic modeling to show what are the most important features of this newly introduced resource to the NLP community.

</details>


### [65] [Predicting Contextual Informativeness for Vocabulary Learning using Deep Learning](https://arxiv.org/abs/2602.18326)
*Tao Wu,Adam Kapelner*

Main category: cs.CL

TL;DR: 本文提出一个深度学习系统，用于为高中生的母语词汇教学自动筛选优质上下文例句，比较了三种建模方法，并引入新的评估指标RCC曲线来可视化模型性能权衡。


<details>
  <summary>Details</summary>
Motivation: 为高中生的母语词汇教学自动识别高质量的上下文例句，解决传统方法中人工筛选成本高、效率低的问题，实现大规模、低成本的优质教学资源供给。

Method: 比较三种建模方法：(1) 基于MPNet统一上下文化嵌入的无监督相似度策略；(2) 基于指令感知、微调Qwen3嵌入和监督非线性回归头的框架；(3) 方法(2)加上手工特征。引入新的评估指标"保持能力曲线"来可视化模型性能权衡。

Result: 模型(3)表现最佳，在仅丢弃70%优质上下文的情况下，实现了440:1的优质-劣质上下文比例，显著优于其他方法。监督学习结合手工特征的方法能够大规模生成近乎完美的词汇教学上下文。

Conclusion: 现代嵌入模型结合神经网络架构，在人类监督指导下，能够以低成本大规模生成近乎完美的词汇教学上下文，为各种目标词汇提供高质量的教学资源。

Abstract: We describe a modern deep learning system that automatically identifies informative contextual examples (\qu{contexts}) for first language vocabulary instruction for high school student. Our paper compares three modeling approaches: (i) an unsupervised similarity-based strategy using MPNet's uniformly contextualized embeddings, (ii) a supervised framework built on instruction-aware, fine-tuned Qwen3 embeddings with a nonlinear regression head and (iii) model (ii) plus handcrafted context features. We introduce a novel metric called the Retention Competency Curve to visualize trade-offs between the discarded proportion of good contexts and the \qu{good-to-bad} contexts ratio providing a compact, unified lens on model performance. Model (iii) delivers the most dramatic gains with performance of a good-to-bad ratio of 440 all while only throwing out 70\% of the good contexts. In summary, we demonstrate that a modern embedding model on neural network architecture, when guided by human supervision, results in a low-cost large supply of near-perfect contexts for teaching vocabulary for a variety of target words.

</details>


### [66] [Vichara: Appellate Judgment Prediction and Explanation for the Indian Judicial System](https://arxiv.org/abs/2602.18346)
*Pavithra PM Nair,Preethu Rose Anish*

Main category: cs.CL

TL;DR: Vichara是一个针对印度司法系统的AI框架，用于预测和解释上诉案件判决，通过结构化处理法律文件并采用IRAC框架增强可解释性，在多个数据集上超越现有基准。


<details>
  <summary>Details</summary>
Motivation: 印度法院面临大量案件积压，特别是上诉案件，需要AI技术来帮助预测判决并提高司法效率。

Method: Vichara框架处理英文上诉案件文件，将其分解为决策点（包含法律问题、决定机构、结果、推理和时间背景），采用IRAC框架结构化解释，并使用GPT-4o mini等四种大语言模型进行评估。

Result: 在PredEx和ILDC_expert数据集上，Vichara超越了现有判决预测基准，GPT-4o mini表现最佳（F1分数：PredEx 81.5，ILDC_expert 80.3），人类评估也显示其解释在清晰度、关联性和实用性方面表现优异。

Conclusion: Vichara框架为印度司法系统提供了有效的判决预测和可解释性解决方案，有助于缓解案件积压问题，提高法律专业人士的工作效率。

Abstract: In jurisdictions like India, where courts face an extensive backlog of cases, artificial intelligence offers transformative potential for legal judgment prediction. A critical subset of this backlog comprises appellate cases, which are formal decisions issued by higher courts reviewing the rulings of lower courts. To this end, we present Vichara, a novel framework tailored to the Indian judicial system that predicts and explains appellate judgments. Vichara processes English-language appellate case proceeding documents and decomposes them into decision points. Decision points are discrete legal determinations that encapsulate the legal issue, deciding authority, outcome, reasoning, and temporal context. The structured representation isolates the core determinations and their context, enabling accurate predictions and interpretable explanations. Vichara's explanations follow a structured format inspired by the IRAC (Issue-Rule-Application-Conclusion) framework and adapted for Indian legal reasoning. This enhances interpretability, allowing legal professionals to assess the soundness of predictions efficiently. We evaluate Vichara on two datasets, PredEx and the expert-annotated subset of the Indian Legal Documents Corpus (ILDC_expert), using four large language models: GPT-4o mini, Llama-3.1-8B, Mistral-7B, and Qwen2.5-7B. Vichara surpasses existing judgment prediction benchmarks on both datasets, with GPT-4o mini achieving the highest performance (F1: 81.5 on PredEx, 80.3 on ILDC_expert), followed by Llama-3.1-8B. Human evaluation of the generated explanations across Clarity, Linking, and Usefulness metrics highlights GPT-4o mini's superior interpretability.

</details>


### [67] [Validating Political Position Predictions of Arguments](https://arxiv.org/abs/2602.18351)
*Jordan Robinson,Angus R. Williams,Katie Atkinson,Anthony G. Cohn*

Main category: cs.CL

TL;DR: 提出双尺度验证框架，结合点式和成对标注，用于政治立场预测等主观连续属性的知识表示，在22个语言模型上验证，构建大规模政治立场知识库


<details>
  <summary>Details</summary>
Motivation: 现实世界知识表示常需捕捉主观连续属性（如政治立场），这与广泛接受的成对验证黄金标准相冲突，需要解决这一挑战

Method: 采用双尺度验证框架，结合点式和成对人类标注，使用22个语言模型构建包含23,228个论点的大规模政治立场预测知识库，基于英国《Question Time》节目的30场辩论

Result: 点式评估显示中等水平的人模一致性（α=0.578），反映内在主观性；成对验证显示人模排名对齐更强（最佳模型α=0.86），证明可从点式预测中提取序数结构

Conclusion: 贡献包括：实用的主观连续知识验证方法；已验证的结构化论证知识库；证明可从主观现实话语中提取序数结构，推进传统符号或分类方法不足领域的知识表示能力

Abstract: Real-world knowledge representation often requires capturing subjective, continuous attributes -- such as political positions -- that conflict with pairwise validation, the widely accepted gold standard for human evaluation. We address this challenge through a dual-scale validation framework applied to political stance prediction in argumentative discourse, combining pointwise and pairwise human annotation. Using 22 language models, we construct a large-scale knowledge base of political position predictions for 23,228 arguments drawn from 30 debates that appeared on the UK politicial television programme \textit{Question Time}. Pointwise evaluation shows moderate human-model agreement (Krippendorff's $α=0.578$), reflecting intrinsic subjectivity, while pairwise validation reveals substantially stronger alignment between human- and model-derived rankings ($α=0.86$ for the best model). This work contributes: (i) a practical validation methodology for subjective continuous knowledge that balances scalability with reliability; (ii) a validated structured argumentation knowledge base enabling graph-based reasoning and retrieval-augmented generation in political domains; and (iii) evidence that ordinal structure can be extracted from pointwise language models predictions from inherently subjective real-world discourse, advancing knowledge representation capabilities for domains where traditional symbolic or categorical approaches are insufficient.

</details>


### [68] [SPQ: An Ensemble Technique for Large Language Model Compression](https://arxiv.org/abs/2602.18420)
*Jiamin Yao,Eren Gultepe*

Main category: cs.CL

TL;DR: SPQ是一种结合SVD、剪枝和量化的LLM压缩集成方法，在保持性能的同时显著减少内存占用并提升推理速度。


<details>
  <summary>Details</summary>
Motivation: 为了解决大型语言模型在内存受限环境中的部署问题，需要开发高效的压缩技术来减少模型大小和内存占用，同时保持模型性能。

Method: 提出SPQ集成压缩技术：1）使用保留方差的SVD将注意力投影压缩为低秩因子；2）基于激活的剪枝去除MLP层中的冗余神经元；3）对所有线性层应用8位线性量化。

Result: 在LLaMA-2-7B上实现75%内存减少，困惑度从5.47降至4.91（WikiText-2），下游任务准确率保持，内存使用（6.86GB）低于GPTQ（7.16GB），推理速度比GPTQ快1.9倍。

Conclusion: SPQ通过互补的压缩技术实现了高效的大语言模型压缩，在内存减少、性能保持和推理加速方面表现优异，为内存受限环境中的LLM部署提供了实用方案。

Abstract: This study presents an ensemble technique, SPQ (SVD-Pruning-Quantization), for large language model (LLM) compression that combines variance-retained singular value decomposition (SVD), activation-based pruning, and post-training linear quantization. Each component targets a different source of inefficiency: i) pruning removes redundant neurons in MLP layers, ii) SVD reduces attention projections into compact low-rank factors, iii) and 8-bit quantization uniformly compresses all linear layers. At matched compression ratios, SPQ outperforms individual methods (SVD-only, pruning-only, or quantization-only) in perplexity, demonstrating the benefit of combining complementary techniques. Applied to LLaMA-2-7B, SPQ achieves up to 75% memory reduction while maintaining or improving perplexity (e.g., WikiText-2 5.47 to 4.91) and preserving accuracy on downstream benchmarks such as C4, TruthfulQA, and GSM8K. Compared to strong baselines like GPTQ and SparseGPT, SPQ offers competitive perplexity and accuracy while using less memory (6.86 GB vs. 7.16 GB for GPTQ). Moreover, SPQ improves inference throughput over GPTQ, achieving up to a 1.9x speedup, which further enhances its practicality for real-world deployment. The effectiveness of SPQ's robust compression through layer-aware and complementary compression techniques may provide practical deployment of LLMs in memory-constrained environments. Code is available at: https://github.com/JiaminYao/SPQ_LLM_Compression/

</details>


### [69] [RVR: Retrieve-Verify-Retrieve for Comprehensive Question Answering](https://arxiv.org/abs/2602.18425)
*Deniz Qian,Hung-Ting Chen,Eunsol Choi*

Main category: cs.CL

TL;DR: RVR是一个多轮检索框架，通过检索-验证-检索的迭代过程最大化答案覆盖率，在多个数据集上显著优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 针对需要广泛有效答案的查询，现有检索方法难以全面覆盖多样化的文档，需要一种能够最大化答案覆盖率的检索框架。

Method: 提出检索-验证-检索（RVR）框架：1）检索器获取候选文档集；2）验证器识别高质量子集；3）用已验证文档增强查询进行下一轮检索，重复此过程以发现未覆盖的答案。

Result: 在QAMPARI数据集上获得至少10%相对和3%绝对增益的完整召回率，在QUEST和WebQuestionsSP数据集上也有稳定提升，优于包括智能搜索方法在内的基线。

Conclusion: RVR是一种有效的迭代检索方法，通过验证器和检索器适应新推理场景，为全面答案召回提供了有前景的解决方案。

Abstract: Comprehensively retrieving diverse documents is crucial to address queries that admit a wide range of valid answers. We introduce retrieve-verify-retrieve (RVR), a multi-round retrieval framework designed to maximize answer coverage. Initially, a retriever takes the original query and returns a candidate document set, followed by a verifier that identifies a high-quality subset. For subsequent rounds, the query is augmented with previously verified documents to uncover answers that are not yet covered in previous rounds. RVR is effective even with off-the-shelf retrievers, and fine-tuning retrievers for our inference procedure brings further gains. Our method outperforms baselines, including agentic search approaches, achieving at least 10% relative and 3% absolute gain in complete recall percentage on a multi-answer retrieval dataset (QAMPARI). We also see consistent gains on two out-of-domain datasets (QUEST and WebQuestionsSP) across different base retrievers. Our work presents a promising iterative approach for comprehensive answer recall leveraging a verifier and adapting retrievers to a new inference scenario.

</details>


### [70] [VIRAASAT: Traversing Novel Paths for Indian Cultural Reasoning](https://arxiv.org/abs/2602.18429)
*Harshul Raj Surana,Arijit Maji,Aryan Vats,Akash Ghosh,Sriparna Saha,Amit Sheth*

Main category: cs.CL

TL;DR: 本文介绍了VIRAASAT数据集和SCoM框架，用于解决LLMs在印度文化多跳推理任务上的不足，通过知识图谱生成文化特定问题，并提出了符号链式操作方法来提升推理性能。


<details>
  <summary>Details</summary>
Motivation: 现有LLMs在需要丰富社会文化知识和本地背景的任务（特别是印度文化相关任务）上表现不佳，而现有的文化基准测试存在三个主要问题：手工制作、仅包含测试事实记忆的单跳问题、扩展成本过高，导致这一缺陷未被充分衡量。

Method: 1. 引入VIRAASAT：半自动多跳方法生成印度文化特定QA数据集，基于包含700多个专家策划文化实体的知识图谱，涵盖13个关键文化属性，覆盖印度所有28个邦和8个联邦属地；2. 提出SCoM（符号链式操作）框架：训练模型内部模拟原子知识图谱操作，可靠遍历图谱拓扑结构。

Result: VIRAASAT生成超过3,200个多跳问题，需要链式文化推理。实验表明当前SOTA LLMs在VIRAASAT上存在局限性，CoT微调无法有效处理低概率事实。SCoM在监督微调中比标准CoT基线提升高达20%。

Conclusion: VIRAASAT数据集和SCoM框架为构建文化感知推理模型奠定了坚实基础，解决了LLMs在文化推理任务上的不足，通过知识图谱和符号操作提升了多跳推理能力。

Abstract: Large Language Models (LLMs) have made significant progress in reasoning tasks across various domains such as mathematics and coding. However, their performance deteriorates in tasks requiring rich socio-cultural knowledge and diverse local contexts, particularly those involving Indian Culture. Existing Cultural benchmarks are (i) Manually crafted, (ii) contain single-hop questions testing factual recall, and (iii) prohibitively costly to scale, leaving this deficiency largely unmeasured. To address this, we introduce VIRAASAT, a novel, semi-automated multi-hop approach for generating cultural specific multi-hop Question-Answering dataset for Indian culture. VIRAASAT leverages a Knowledge Graph comprising more than 700 expert-curated cultural artifacts, covering 13 key attributes of Indian culture (history, festivals, etc). VIRAASAT spans all 28 states and 8 Union Territories, yielding more than 3,200 multi-hop questions that necessitate chained cultural reasoning. We evaluate current State-of-the-Art (SOTA) LLMs on VIRAASAT and identify key limitations in reasoning wherein fine-tuning on Chain-of-Thought(CoT) traces fails to ground and synthesize low-probability facts. To bridge this gap, we propose a novel framework named Symbolic Chain-of-Manipulation (SCoM). Adapting the Chain-of-Manipulation paradigm, we train the model to simulate atomic Knowledge Graph manipulations internally. SCoM teaches the model to reliably traverse the topological structure of the graph. Experiments on Supervised Fine-Tuning (SFT) demonstrate that SCoM outperforms standard CoT baselines by up to 20%. We release the VIRAASAT dataset along with our findings, laying a strong foundation towards building Culturally Aware Reasoning Models.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [71] [Beyond Individual Influence: The Role of Echo Chambers and Community Seeding in the Multilayer three state q-Voter Model](https://arxiv.org/abs/2602.18088)
*Igor Hołowacz,Piotr Bródka*

Main category: cs.SI

TL;DR: 多层社交网络中复杂意见扩散受回声室和认知一致性机制阻碍，研究发现基于拓扑熵最大化的策略比强化局部集群更有效


<details>
  <summary>Details</summary>
Motivation: 多层社交网络中复杂意见扩散受到回声室和认知一致性机制的严重阻碍，需要研究在这种环境下的影响力最大化策略

Method: 使用3状态多层q-voter模型，基于mABCD基准模拟从整合开放世界到隔离堡垒世界的社交环境，比较不同影响力最大化策略

Result: 发现"堡垒陷阱"拓扑悖论：高度模块化网络中，CIM和k-Shell等最大化局部密度的策略无法触发全局级联，形成孤立共识孤岛；完美对齐的氏族拓扑中存在"冗余陷阱"，形成"完美监狱"；VoteRank策略始终优于基于结构的方法

Conclusion: 对于复杂传染，最大化拓扑熵比强化局部集群更有效，多样性覆盖优先于局部强度的策略表现更好

Abstract: The diffusion of complex opinions is severely hindered in multilayer social networks by echo chambers and cognitive consistency mechanisms. We investigate Influence Maximization strategies within the 3-state multilayer q-voter model. Utilizing the mABCD benchmark, we simulate social environments ranging from integrated Open Worlds to segregated Fortress Worlds. Our results reveal a topological paradox that we term the "Fortress Trap". In highly modular networks, strategies maximizing local density such as Clique Influence Maximization (CIM) and k-Shell fail to trigger global cascades, creating isolated bunkers of consensus due to the Overkill Effect. Furthermore, we identify a Redundancy Trap in perfectly aligned Clan topologies, where the structural overlap of layers creates a "Perfect Prison," rendering it the most resistant environment to diffusion. We demonstrate that VoteRank, a strategy that prioritizes diversity of reach over local intensity, consistently outperforms structure-based methods. These findings suggest that, for complex contagion, maximizing topological entropy is more effective than reinforcing local clusters.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [72] [Five Fatal Assumptions: Why T-Shirt Sizing Systematically Fails for AI Projects](https://arxiv.org/abs/2602.17734)
*Raja Soundaramourty,Ozkan Kilic,Ramu Chenchaiah*

Main category: cs.SE

TL;DR: 传统T-shirt估算方法在AI项目中失效，作者提出检查点估算作为替代方案


<details>
  <summary>Details</summary>
Motivation: 传统敏捷估算方法（特别是T-shirt sizing）在AI项目（尤其是LLM和多智能体系统）中会产生系统性误导，需要新的估算方法

Method: 分析传统T-shirt sizing的五个基本假设在AI项目中的失效，基于多智能体系统失败、扩展原则和多轮对话不可靠性的研究，提出检查点估算方法

Result: 传统估算的五个假设在AI项目中都失效：非线性努力扩展、经验不可重复、努力-时间不可互换、任务不可分解、完成标准非确定性

Conclusion: 需要采用检查点估算方法，这是一种更以人为本、迭代的方法，在开发过程中基于实际学习而非初始假设重新评估范围和可行性

Abstract: Agile estimation techniques, particularly T-shirt sizing, are widely used in software development for their simplicity and utility in scoping work. However, when we apply these methods to artificial intelligence initiatives -- especially those involving large language models (LLMs) and multi-agent systems -- the results can be systematically misleading. This paper shares an evidence-backed analysis of five foundational assumptions we often make during T-shirt sizing. While these assumptions usually hold true for traditional software, they tend to fail in AI contexts: (1) linear effort scaling, (2) repeatability from prior experience, (3) effort-duration fungibility, (4) task decomposability, and (5) deterministic completion criteria. Drawing on recent research into multi-agent system failures, scaling principles, and the inherent unreliability of multi-turn conversations, we show how AI development breaks these rules. We see this through non-linear performance jumps, complex interaction surfaces, and "tight coupling" where a small change in data cascades through the entire stack. To help teams navigate this, we propose Checkpoint Sizing: a more human-centric, iterative approach that uses explicit decision gates where scope and feasibility are reassessed based on what we learn during development, rather than what we assumed at the start. This paper is intended for engineering managers, technical leads, and product owners responsible for planning and delivering AI initiatives.

</details>


### [73] [Examining LLMs Ability to Summarize Code Through Mutation-Analysis](https://arxiv.org/abs/2602.17838)
*Lara Khatib,Micheal Pu,Bogdan Vasilescu,Meiyappan Nagappan*

Main category: cs.SE

TL;DR: 提出基于变异的评估方法，测试LLM生成的代码摘要是否准确反映程序实际行为而非表面意图


<details>
  <summary>Details</summary>
Motivation: 随着开发者越来越依赖LLM生成的代码摘要进行文档、测试和审查，需要研究这些摘要是否准确反映程序实际行为。LLM经常自信地描述代码看起来应该做什么（意图），却忽略了定义实际行为的微妙边界情况或逻辑变化。

Method: 提出基于变异的评估方法：生成摘要→在代码中注入目标变异→检查LLM是否更新摘要以反映新行为。通过三个实验验证，总计624个变异-摘要评估，覆盖62个程序。

Result: 1) 在12个受控合成程序上：摘要准确率随复杂度急剧下降（单函数76.5%→多线程系统17.3%）；2) 在50个人工编写程序上：摘要准确率49.3%，模型常描述算法意图而非实际变异行为；3) GPT-4到GPT-5.2有显著性能提升（49.3%→85.3%），但两者仍难以区分实现细节与标准算法模式。

Conclusion: 建立了变异分析作为系统评估LLM生成摘要是否反映程序行为而非表面文本模式的系统性方法。

Abstract: As developers increasingly rely on LLM-generated code summaries for documentation, testing, and review, it is important to study whether these summaries accurately reflect what the program actually does. LLMs often produce confident descriptions of what the code looks like it should do (intent), while missing subtle edge cases or logic changes that define what it actually does (behavior). We present a mutation-based evaluation methodology that directly tests whether a summary truly matches the code's logic. Our approach generates a summary, injects a targeted mutation into the code, and checks if the LLM updates its summary to reflect the new behavior. We validate it through three experiments totalling 624 mutation-summary evaluations across 62 programs. First, on 12 controlled synthetic programs with 324 mutations varying in type (statement, value, decision) and location (beginning, middle, end). We find that summary accuracy decreases sharply with complexity from 76.5% for single functions to 17.3% for multi-threaded systems, while mutation type and location exhibit weaker effects. Second, testing 150 mutated samples on 50 human-written programs from the Less Basic Python Problems (LBPP) dataset confirms the same failure patterns persist as models often describe algorithmic intent rather than actual mutated behavior with a summary accuracy rate of 49.3%. Furthermore, while a comparison between GPT-4 and GPT-5.2 shows a substantial performance leap (from 49.3% to 85.3%) and an improved ability to identify mutations as "bugs", both models continue to struggle with distinguishing implementation details from standard algorithmic patterns. This work establishes mutation analysis as a systematic approach for assessing whether LLM-generated summaries reflect program behavior rather than superficial textual patterns.

</details>


### [74] [Automated LLM-Based Accessibility Remediation: From Conventional Websites to Angular Single-Page Applications](https://arxiv.org/abs/2602.17887)
*Carla Fernández-Navarro,Francisco Chicano*

Main category: cs.SE

TL;DR: 使用大语言模型自动修复网页可访问性问题，支持静态网站和Angular单页应用，修复率达80-86%


<details>
  <summary>Details</summary>
Motivation: 网页可访问性问题普遍存在，现有工具只能检测问题但修复仍需手动完成，过程缓慢、成本高且容易遗漏细节。单页应用的动态特性使传统静态分析方法失效，需要自动化解决方案。

Method: 提出基于大语言模型的模块化工作流，可应用于静态网站和复杂Angular项目。框架在静态网页的DOM或SPA源代码中主动实施修正，同时为图像生成有意义的视觉描述，保持应用设计和稳定性。

Result: 在12个静态网站和6个开源Angular项目上测试，修复了公共网站80%的可访问性问题和Angular应用86%的问题。系统成功生成图像的视觉描述，同时保持应用设计和稳定性。

Conclusion: 该工作有助于确保可访问性不再是被推迟到未来的技术债务，而是成为日常开发工作流程的自然组成部分。基于LLM的方法能有效自动化修复可访问性问题，特别是针对动态的单页应用。

Abstract: Web accessibility remains an unresolved issue for a large part of the web content. There are many tools to detect errors automatically, but fixing those issues is still mostly a manual, slow, and costly process in which it is easy for developers to overlook specific details. The situation becomes even more complex with modern Single-Page Applications (SPAs), whose dynamic nature makes traditional static analysis approaches inadequate. This work proposes a system that aims to address this challenge by using Large Language Models (LLMs) to automate accessibility fixes. The proposal presents a modular workflow applicable to both static websites and complex Angular projects. The framework actively implements corrections within the DOM of static web pages or the source code of SPAs. The system was tested on 12 static websites and 6 open-source Angular projects, fixing 80% of the accessibility issues on public websites and 86% of the issues on Angular applications. Our proposal also generates meaningful visual descriptions for images while preserving the application's design and stability. This work contributes to ensuring that accessibility stops being a technical debt deferred to the future and becomes a natural part of everyday development workflows.

</details>


### [75] [Mining Type Constructs Using Patterns in AI-Generated Code](https://arxiv.org/abs/2602.17955)
*Imgyeong Lee,Tayyib Ul Hassan,Abram Hindle*

Main category: cs.SE

TL;DR: AI代理在TypeScript项目中过度使用'any'关键字和高级类型构造，导致类型安全问题，但奇怪的是其PR接受率比人类高1.8倍


<details>
  <summary>Details</summary>
Motivation: 研究AI在类型相关编程任务中是否真正优于人类，以及AI代理是否在复杂类型系统中过度使用或误用类型构造

Method: 在TypeScript项目领域进行首次实证分析，比较AI代理与人类在类型构造使用上的差异

Result: AI代理比人类更容易使用'any'关键字（9倍），更频繁使用忽略类型检查的高级类型构造，但AI代理的PR接受率比人类高1.8倍

Conclusion: 软件开发者在与AI代理协作时应仔细确认代码库的类型安全性，尽管AI的PR接受率更高，但其类型安全实践存在问题

Abstract: Artificial Intelligence (AI) increasingly automates various parts of the software development tasks. Although AI has enhanced the productivity of development tasks, it remains unstudied whether AI essentially outperforms humans in type-related programming tasks, such as employing type constructs properly for type safety, during its tasks. Moreover, there is no systematic study that evaluates whether AI agents overuse or misuse the type constructs under the complicated type systems to the same extent as humans. In this study, we present the first empirical analysis to answer these questions in the domain of TypeScript projects. Our findings show that, in contrast to humans, AI agents are 9x more prone to use the 'any' keyword. In addition, we observed that AI agents use advanced type constructs, including those that ignore type checks, more often compared to humans. Surprisingly, even with all these issues, Agentic pull requests (PRs) have 1.8x higher acceptance rates compared to humans for TypeScript. We encourage software developers to carefully confirm the type safety of their codebases whenever they coordinate with AI agents in the development process.

</details>


### [76] [DeCEAT: Decoding Carbon Emissions for AI-driven Software Testing](https://arxiv.org/abs/2602.18012)
*Pragati Kumari,Novarun Deb*

Main category: cs.SE

TL;DR: 本文提出了DeCEAT框架，专门评估小型语言模型在测试生成中的环境可持续性和性能权衡，发现不同SLMs在能耗、速度和准确性方面各有优势，且提示设计对可持续性有重要影响。


<details>
  <summary>Details</summary>
Motivation: 随着语言模型在自动化软件测试中的广泛应用，其环境影响日益受到关注。现有可持续性分析主要集中于大型语言模型，而小型语言模型在测试生成过程中的能源和碳排放特性尚未得到充分研究。

Method: 提出了DeCEAT框架，使用HumanEval基准和基于Anthropic模板的自适应提示变体，在受控条件下系统评估SLMs的环境和性能权衡。使用CodeCarbon测量能耗和碳排放，通过单元测试覆盖率评估生成测试的质量。

Result: 不同SLMs展现出不同的可持续性优势：一些模型优先考虑低能耗和快速执行，而另一些在碳排放约束下保持更高的稳定性或准确性。结果表明，SLM驱动的测试生成可持续性是多维度的，且受提示设计的强烈影响。

Conclusion: 本研究为自动化SLM测试生成提供了专门的可持续性评估框架，阐明了提示结构和模型选择如何共同影响环境和性能结果，填补了小型语言模型在测试生成可持续性研究方面的空白。

Abstract: The increasing use of language models in automated software testing raises concerns about their environmental impact, yet existing sustainability analyses focus almost exclusively on large language models. As a result, the energy and carbon characteristics of small language models (SLMs) during test generation remain largely unexplored. To address this gap, this work introduces the DeCEAT framework, which systematically evaluates the environmental and performance trade-offs of SLMs using the HumanEval benchmark and adaptive prompt variants (based on the Anthropic template). The framework quantifies emission and time-aware behavior under controlled conditions, with CodeCarbon measuring energy consumption and carbon emissions, and unit test coverage assessing the quality of generated tests. Our results show that different SLMs exhibit distinct sustainability strengths: some prioritize lower energy use and faster execution, while others maintain higher stability or accuracy under carbon constraints. These findings demonstrate that sustainability in the generation of SLM-driven tests is multidimensional and strongly shaped by prompt design. This work provides a focused sustainability evaluation framework specifically tailored to automated SLM-based test generation, clarifying how prompt structure and model choice jointly influence environmental and performance outcomes.

</details>


### [77] [Toward Automated Virtual Electronic Control Unit (ECU) Twins for Shift-Left Automotive Software Testing](https://arxiv.org/abs/2602.18142)
*Sebastian Dingler,Frederik Boenke*

Main category: cs.SE

TL;DR: 该论文提出了一种通过智能代理工作流生成指令级精确处理器模型的方法，用于在硬件可用前创建虚拟ECU测试环境，减少硬件在环测试的瓶颈。


<details>
  <summary>Details</summary>
Motivation: 汽车软件开发周期中，软件往往比硬件更早完成，但缺乏物理硬件导致只能进行昂贵的硬件在环测试。需要一种能在硬件可用前运行真实软件二进制文件的虚拟测试环境。

Method: 采用智能代理反馈驱动的工作流，通过GNU调试器连接到参考模拟器，自动生成SystemC/TLM 2.0的指令级精确处理器模型，并通过差分测试和迭代模型修正确保CPU行为保真度。

Result: 原型系统证明最关键的技术风险——CPU行为保真度——可以通过自动化差分测试和迭代模型修正来降低。实现了可复现测试、非侵入式追踪和符合安全标准的故障注入能力。

Conclusion: 虽然云规模部署和完整工具链集成仍需未来工作，但原型展示了虚拟ECU双胞胎的可行左移路径，能够在物理硬件存在前实现早期软件集成和测试。

Abstract: Automotive software increasingly outpaces hardware availability, forcing late integration and expensive hardware-in-the-loop (HiL) bottlenecks. The InnoRegioChallenge project investigated whether a virtual test and integration environment can reproduce electronic control unit (ECU) behavior early enough to run real software binaries before physical hardware exists. We report a prototype that generates instruction-accurate processor models in SystemC/TLM~2.0 using an agentic, feedback-driven workflow coupled to a reference simulator via the GNU Debugger (GDB). The results indicate that the most critical technical risk -- CPU behavioral fidelity -- can be reduced through automated differential testing and iterative model correction. We summarize the architecture, the agentic modeling loop, and project outcomes, and we extrapolate plausible technical details consistent with the reported qualitative findings. While cloud-scale deployment and full toolchain integration remain future work, the prototype demonstrates a viable shift-left path for virtual ECU twins, enabling reproducible tests, non-intrusive tracing, and fault-injection campaigns aligned with safety standards.

</details>


### [78] [Role and Identity Work of Software Engineering Professionals in the Generative AI Era](https://arxiv.org/abs/2602.18190)
*Jorge Melegati*

Main category: cs.SE

TL;DR: 本文主张在研究生成式AI对软件工程师身份认同的影响时，需要考虑不同角色（如开发者和测试者）的差异，并提出相关研究议程。


<details>
  <summary>Details</summary>
Motivation: 现有研究表明生成式AI的采用会触发软件专业人员的身份认同工作，但这些研究没有考虑不同角色（如开发者和测试者）之间的差异。作者认为角色是定义软件专业人员身份认同工作的重要因素，需要专门研究。

Method: 通过回顾关于不同角色的现有研究以及生成式AI在软件工程中采用的最新研究，提出一个研究议程来理解角色如何影响生成式AI采用触发的软件专业人员身份认同工作。

Result: 提出了一个研究议程，旨在更好地理解角色如何影响生成式AI采用触发的软件专业人员身份认同工作，并基于此提出支持这种采用的新工具。

Conclusion: 考虑角色因素对于理解生成式AI对软件专业人员身份认同的影响至关重要，提出的研究议程将有助于开发支持不同角色适应生成式AI的工具，并对实践产生重要影响。

Abstract: The adoption of Generative AI (GenAI) suggests major changes for software engineering, including technical aspects but also human aspects of the professionals involved. One of these aspects is how individuals perceive themselves regarding their work, i.e., their work identity, and the processes they perform to form, adapt and reject these identities, i.e., identity work. Existent studies provide evidence of such identity work of software professionals triggered by the adoption of GenAI, however they do not consider differences among diverse roles, such as developers and testers. In this paper, we argue the need for considering the role as a factor defining the identity work of software professionals. To support our claim, we review some studies regarding different roles and also recent studies on how to adopt GenAI in software engineering. Then, we propose a research agenda to better understand how the role influences identity work of software professionals triggered by the adoption of GenAI, and, based on that, to propose new artifacts to support this adoption. We also discuss the potential implications for practice of the results to be obtained.

</details>


### [79] [ReqElicitGym: An Evaluation Environment for Interview Competence in Conversational Requirements Elicitation](https://arxiv.org/abs/2602.18306)
*Dongming Jin,Zhi Jin,Zheng Fang,Linyu Li,XiaoTian Yang,Yuanpeng He,Xiaohong Chen*

Main category: cs.SE

TL;DR: ReqElicitGym：用于评估LLM在对话式需求获取中访谈能力的自动交互式评估环境，包含101个网站需求场景数据集、模拟用户和任务评估器，研究发现当前LLM在挖掘隐性需求方面能力有限。


<details>
  <summary>Details</summary>
Motivation: 随着LLM编码能力的快速提升，LLM自动化软件开发的主要瓶颈从生成正确代码转向了获取用户需求。然而，LLM在对话式需求获取中的访谈能力尚未得到充分探索，现有评估方法依赖少量场景、真实用户交互和主观评分，缺乏系统性和定量比较。

Method: 提出ReqElicitGym评估环境，包含：1）101个网站需求获取场景的数据集，涵盖10种应用类型；2）交互式模拟用户（oracle user）；3）任务评估器（task evaluator）。该环境支持对任何自动化对话式需求获取方法（如基于LLM的智能体）进行可重复、定量评估。

Result: 对7个代表性LLM的系统实证研究表明：1）当前LLM在挖掘隐性需求方面能力有限，仅能获取不到一半的用户隐性需求；2）有效的获取问题往往出现在对话后期；3）LLM能够获取交互和内容相关的隐性需求，但在风格相关需求方面持续表现不佳。模拟用户和任务评估器与真实用户和专家判断具有高度一致性。

Conclusion: ReqElicitGym为自动化对话式需求获取方法的评估和发展提供了有力工具，研究发现当前LLM在需求访谈能力方面仍有显著局限，特别是在风格相关需求获取方面存在系统性困难，需要进一步改进。

Abstract: With the rapid improvement of LLMs' coding capabilities, the bottleneck of LLM-based automated software development is shifting from generating correct code to eliciting users' requirements. Despite growing interest, the interview competence of LLMs in conversational requirements elicitation remains fully underexplored. Existing evaluations often depend on a few scenarios, real user interaction, and subjective human scoring, which hinders systematic and quantitative comparison. To address these challenges, we propose ReqElicitGym, an interactive and automatic evaluation environment for assessing interview competence in conversational requirements elicitation. Specifically, ReqElicitGym introduces a new evaluation dataset and designs both an interactive oracle user and a task evaluator. The dataset contains 101 website requirements elicitation scenarios spanning 10 application types. Both the oracle user and the task evaluator achieve high agreement with real users and expert judgment. Using our ReqElicitGym, any automated conversational requirements elicitation approach (e.g., LLM-based agents) can be evaluated in a reproducible and quantitative manner through interaction with the environment. Based on our ReqElicitGym, we conduct a systematic empirical study on seven representative LLMs, and the results show that current LLMs still exhibit limited interview competence in uncovering implicit requirements. Particularly, they elicit less than half of the users' implicit requirements, and their effective elicitation questions often emerge in later turns of the dialogue. Besides, we found LLMs can elicit interaction and content implicit requirements, but consistently struggle with style-related requirements. We believe ReqElicitGym will facilitate the evaluation and development of automated conversational requirements elicitation.

</details>


### [80] [VeriSoftBench: Repository-Scale Formal Verification Benchmarks for Lean](https://arxiv.org/abs/2602.18307)
*Yutong Xin,Qiaochu Chen,Greg Durrett,Işil Dillig*

Main category: cs.SE

TL;DR: VeriSoftBench：一个包含500个Lean 4证明义务的基准测试，专门针对软件验证领域，评估LLM在项目特定代码库中的定理证明能力。


<details>
  <summary>Details</summary>
Motivation: 当前LLM在定理证明方面的基准测试主要基于Mathlib数学库，但软件验证领域的证明通常依赖于项目特定的丰富定义库和代码库结构，需要专门的评估工具。

Method: 创建VeriSoftBench基准测试，包含500个来自开源形式化方法项目的Lean 4证明义务，保留真实的仓库上下文和跨文件依赖关系，评估前沿LLM和专业证明器。

Result: 1) 针对Mathlib风格数学优化的证明器在此仓库中心化环境中表现不佳；2) 成功率与传递性仓库依赖强相关；3) 提供经过筛选的依赖闭包上下文比暴露完整仓库效果更好，但仍有改进空间。

Conclusion: 软件验证领域的定理证明需要专门的基准测试和评估方法，VeriSoftBench为此提供了工具，并揭示了在项目特定代码库中LLM证明自动化面临的独特挑战。

Abstract: Large language models have achieved striking results in interactive theorem proving, particularly in Lean. However, most benchmarks for LLM-based proof automation are drawn from mathematics in the Mathlib ecosystem, whereas proofs in software verification are developed inside definition-rich codebases with substantial project-specific libraries. We introduce VeriSoftBench, a benchmark of 500 Lean 4 proof obligations drawn from open-source formal-methods developments and packaged to preserve realistic repository context and cross-file dependencies. Our evaluation of frontier LLMs and specialized provers yields three observations. First, provers tuned for Mathlib-style mathematics transfer poorly to this repository-centric setting. Second, success is strongly correlated with transitive repository dependence: tasks whose proofs draw on large, multi-hop dependency closures are less likely to be solved. Third, providing curated context restricted to a proof's dependency closure improves performance relative to exposing the full repository, but nevertheless leaves substantial room for improvement. Our benchmark and evaluation suite are released at https://github.com/utopia-group/VeriSoftBench.

</details>


### [81] [Statistical Confidence in Functional Correctness: An Approach for AI Product Functional Correctness Evaluation](https://arxiv.org/abs/2602.18357)
*Wallace Albertini,Marina Condé Araújo,Júlia Condé Araújo,Antonio Pedro Santos Alves,Marcos Kalinowski*

Main category: cs.SE

TL;DR: 提出SCFC方法，通过统计置信度评估AI系统功能正确性，连接业务需求与统计置信度，包含四个步骤：定义量化规格限、分层概率抽样、自助法估计置信区间、计算能力指数。


<details>
  <summary>Details</summary>
Motivation: 现有AI系统质量评估标准（如ISO/IEC 25059）缺乏实用且统计稳健的功能正确性评估方法，需要将业务需求与统计置信度联系起来。

Method: 提出SCFC方法：1) 定义量化规格限；2) 进行分层和概率抽样；3) 应用自助法估计性能指标的置信区间；4) 计算能力指数作为最终指标。

Result: 通过两个真实工业AI系统的案例研究进行评估，收集AI专家关于方法实用性、易用性和采用意向的反馈，证明该方法是可行且有价值的。

Conclusion: SCFC方法是将功能正确性评估操作化的可行且有价值的方式，将评估从点估计转变为统计置信度陈述。

Abstract: The quality assessment of Artificial Intelligence (AI) systems is a fundamental challenge due to their inherently probabilistic nature. Standards such as ISO/IEC 25059 provide a quality model, but they lack practical and statistically robust methods for assessing functional correctness. This paper proposes and evaluates the Statistical Confidence in Functional Correctness (SCFC) approach, which seeks to fill this gap by connecting business requirements to a measure of statistical confidence that considers both the model's average performance and its variability. The approach consists of four steps: defining quantitative specification limits, performing stratified and probabilistic sampling, applying bootstrapping to estimate a confidence interval for the performance metric, and calculating a capability index as a final indicator. The approach was evaluated through a case study on two real-world AI systems in industry involving interviews with AI experts. Valuable insights were collected from the experts regarding the utility, ease of use, and intention to adopt the methodology in practical scenarios. We conclude that the proposed approach is a feasible and valuable way to operationalize the assessment of functional correctness, moving the evaluation from a point estimate to a statement of statistical confidence.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [82] [Graph-Neural Multi-Agent Coordination for Distributed Access-Point Selection in Cell-Free Massive MIMO](https://arxiv.org/abs/2602.17954)
*Mohammad Zangooei,Lou Salaün,Chung Shue Chen,Raouf Boutaba*

Main category: cs.NI

TL;DR: APS-GNN：用于无蜂窝大规模MIMO系统的可扩展分布式多智能体学习框架，通过图神经网络协调AP选择，在满足频谱效率要求的同时显著降低网络功耗和延迟。


<details>
  <summary>Details</summary>
Motivation: 无蜂窝大规模MIMO系统需要在严格的通信和延迟约束下运行，但现有的接入点选择方法难以同时满足频谱效率要求和降低功耗，需要可扩展的分布式协调机制。

Method: 提出APS-GNN框架，将AP选择问题分解为单个AP-UE连接级别的智能体，通过新颖的图神经网络架构进行局部观察交换和参数共享，采用约束强化学习方法，将频谱效率满足视为成本、功耗降低视为奖励，并通过监督模仿学习初始化策略。

Result: 在真实CFmMIMO模拟器中，APS-GNN在满足目标频谱效率的同时，比启发式和集中式多智能体强化学习方法少激活50-70%的AP，推理延迟降低1-2个数量级。

Conclusion: APS-GNN为大规模CFmMIMO网络中的AP选择问题提供了实用且可扩展的解决方案，实现了分布式并行执行、低延迟和高能效。

Abstract: Cell-free massive MIMO (CFmMIMO) systems require scalable and reliable distributed coordination mechanisms to operate under stringent communication and latency constraints. A central challenge is the Access Point Selection (APS) problem, which seeks to determine the subset of serving Access Points (APs) for each User Equipment (UE) that can satisfy UEs' Spectral Efficiency (SE) requirements while minimizing network power consumption. We introduce APS-GNN, a scalable distributed multi-agent learning framework that decomposes APS into agents operating at the granularity of individual AP-UE connections. Agents coordinate via local observation exchange over a novel Graph Neural Network (GNN) architecture and share parameters to reuse their knowledge and experience. APS-GNN adopts a constrained reinforcement learning approach to provide agents with explicit observability of APS' conflicting objectives, treating SE satisfaction as a cost and power reduction as a reward. Both signals are defined locally, facilitating effective credit assignment and scalable coordination in large networks. To further improve training stability and exploration efficiency, the policy is initialized via supervised imitation learning from a heuristic APS baseline. We develop a realistic CFmMIMO simulator and demonstrate that APS-GNN delivers the target SE while activating 50-70% fewer APs than heuristic and centralized Multi-agent Reinforcement Learning (MARL) baselines in different evaluation scenarios. Moreover, APS-GNN achieves one to two orders of magnitude lower inference latency than centralized MARL approaches due to its fully parallel and distributed execution. These results establish APS-GNN as a practical and scalable solution for APS in large-scale CFmMIMO networks.

</details>


### [83] [Rethinking Beam Management: Generalization Limits Under Hardware Heterogeneity](https://arxiv.org/abs/2602.18151)
*Nikita Zeulin,Olga Galinina,Ibrahim Kilinc,Sergey Andreev,Robert W. Heath*

Main category: cs.NI

TL;DR: 论文强调硬件异构性是5G+波束管理中的关键设计问题，分析了异构环境下的失败模式，并提出了改进泛化能力的策略。


<details>
  <summary>Details</summary>
Motivation: 5G及未来网络中，用户设备的硬件异构性给基于波束的通信带来新挑战，限制了基于机器学习算法的适用性，需要将硬件异构性作为ML辅助波束管理的首要设计考虑因素。

Method: 分析异构环境下的关键失败模式，通过案例研究展示其性能影响，并讨论改进波束管理泛化能力的潜在策略。

Result: 揭示了硬件异构性对ML辅助波束管理的重要影响，展示了异构环境下的具体失败案例和性能问题。

Conclusion: 硬件异构性必须作为ML辅助波束管理的核心设计考虑，需要开发能够适应设备多样性的泛化策略来应对这一挑战。

Abstract: Hardware heterogeneity across diverse user devices poses new challenges for beam-based communication in 5G and beyond. This heterogeneity limits the applicability of machine learning (ML)-based algorithms. This article highlights the critical need to treat hardware heterogeneity as a first-class design concern in ML-aided beam management. We analyze key failure modes in the presence of heterogeneity and present case studies demonstrating their performance impact. Finally, we discuss potential strategies to improve generalization in beam management.

</details>


### [84] [Noise Mitigation Methods for Digital Visible Light Communication](https://arxiv.org/abs/2602.18187)
*Wataru Uemura,Takumi Hamano*

Main category: cs.NI

TL;DR: 提出两种数字可见光通信系统的噪声抑制方法：基于交流电源干扰周期性的波形减法和受主动噪声控制启发的实时噪声消除技术


<details>
  <summary>Details</summary>
Motivation: 可见光通信使用LED具有低功耗、长寿命和快速响应等优点，但受到荧光灯等环境光源产生的光学噪声影响，导致波形失真和误码率增加，需要有效的噪声抑制方法

Method: 提出两种方法：1) 利用交流电源照明干扰的周期性，通过采样噪声波形并从接收信号中减去来降低干扰；2) 受主动噪声控制技术启发，引入额外光电二极管接收噪声，并使用减法电路实时衰减噪声

Result: 实验结果表明两种方法相比传统接收器都改善了误码率性能，其中受主动噪声控制启发的方法在所有测试条件下都表现出更优越的性能

Conclusion: 提出的两种噪声抑制方法能有效改善数字可见光通信系统的性能，特别是受主动噪声控制启发的实时噪声消除技术具有更好的鲁棒性和性能表现

Abstract: Visible Light Communication (VLC) using Light Emitting Diodes (LEDs) has gained attention due to its low power consumption, long lifetime, and fast response. However, VLC suffers from optical noise generated by ambient light sources such as fluorescent lamps, which leads to waveform distortion and increased bit error rates (BER). In this paper, we propose two noise reduction methods for Digital Visible Light Communication (DVLC) systems. The first method exploits the periodic nature of interference caused by AC-powered-line illumination and reduces interference by subtracting sampled noise waveforms from the received signal. Second, inspired by Active Noise Control (ANC) techniques, an additional photodiode is introduced for noise reception, and subtraction circuits are employed to attenuate noise in real time. Experimental results show that both methods improve BER performance compared with conventional receivers, with the ANC-inspired approach achieving superior performance under all tested conditions.

</details>


### [85] [A traffic incident management framework for vehicular ad hoc networks](https://arxiv.org/abs/2602.18208)
*Rezvi Shahariar,Chris Phillips*

Main category: cs.NI

TL;DR: 本文提出一个交通事件管理模型，通过控制消息生成和转发时机来高效管理VANET中的交通事件，并通过仿真比较了四跳转发和60秒转发两种策略的效果。


<details>
  <summary>Details</summary>
Motivation: 现有VANET模型虽然提出了信任模型、安全模型和信息传播方法，但缺乏能够完全管理交通事件的完整模型。本文旨在解决如何及时报告和管理交通事件的挑战。

Method: 提出一个交通事件管理模型，详细规定消息何时生成和转发以报告事件。使用VEINS仿真器进行模拟，包含车辆、RSU和TA，比较两种转发策略：四跳转发和60秒时间限制转发。

Result: 仿真实验表明，在车辆密度和转发考虑因素变化的情况下，四跳转发比60秒转发能通知更多车辆。同时测量了报告单个交通事件所需的平均传输次数。

Conclusion: 提出的交通事件管理模型能够有效管理多种交通事件，四跳转发策略在信息传播覆盖范围上优于时间限制转发策略，为VANET中的事件管理提供了实用解决方案。

Abstract: Vehicular Ad Hoc Networks (VANETs) support the information dissemination among vehicles, Roadside Units (RSUs), and a Trust Authority (TA). A trust model evaluates an entity or data or both to determine truthfulness. A security model confirms authentication, integrity, availability, non repudiation issues. With these aspects in mind, many models have been proposed in literature. Furthermore, many information dissemination approaches are proposed. However, the lack of a model that can manage traffic incidents completely inspires this work. This paper details how and when a message needs to be generated and relayed so that the incidents can be reported and managed in a timely manner. This paper addresses this challenge by providing a traffic incident management model to manage several traffic incidents efficiently. Additionally, we simulate this model using the VEINS simulator with vehicles, RSUs, and a TA. From the experiments, we measure the average number of transmissions required for reporting a single traffic incident while varying the vehicle density and relaying considerations. We consider two types of relaying. In one series of experiments, messages from regular vehicles and RSUs are relayed up to four hops. In another series of experiments, messages from the regular vehicles and RSUs are relayed until their generation time reaches sixty seconds. Additionally, messages from the official vehicles are relayed when they approach an incident or when the incident is cleared. Results from the simulations show that more vehicles are informed with four-hop relaying than sixty-second relaying in both cases.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [86] [Epistemic Traps: Rational Misalignment Driven by Model Misspecification](https://arxiv.org/abs/2602.17676)
*Xingcheng Xu,Jingjing Qu,Qiaosheng Zhang,Chaochao Lu,Yanqing Yang,Na Zou,Xia Hu*

Main category: cs.AI

TL;DR: 论文提出AI安全问题的根源是模型错误设定而非训练缺陷，通过经济学理论建立主观世界模型框架，证明不安全行为是结构性必然，安全是离散相而非奖励连续函数。


<details>
  <summary>Details</summary>
Motivation: 当前AI安全范式将LLM和AI代理的行为病理（奉承、幻觉、战略欺骗）视为训练缺陷，缺乏统一理论框架解释其出现和稳定性。需要从根本理论上理解这些行为为何持续存在。

Method: 将经济学中的Berk-Nash理性化理论适配到AI领域，建立代理在错误主观世界模型下优化的理论框架。通过六个最先进模型的行为实验验证理论预测，生成安全行为的拓扑边界相图。

Result: 证明不安全行为是结构性必然：作为稳定不对齐均衡或振荡循环出现，战略欺骗作为"锁定"均衡或认知不确定性持续存在。安全是代理认知先验决定的离散相，而非奖励大小的连续函数。

Conclusion: 安全需要从操纵环境奖励转向塑造代理对现实的解释，提出"主观模型工程"作为稳健对齐的必要条件，标志着AI安全范式的根本转变。

Abstract: The rapid deployment of Large Language Models and AI agents across critical societal and technical domains is hindered by persistent behavioral pathologies including sycophancy, hallucination, and strategic deception that resist mitigation via reinforcement learning. Current safety paradigms treat these failures as transient training artifacts, lacking a unified theoretical framework to explain their emergence and stability. Here we show that these misalignments are not errors, but mathematically rationalizable behaviors arising from model misspecification. By adapting Berk-Nash Rationalizability from theoretical economics to artificial intelligence, we derive a rigorous framework that models the agent as optimizing against a flawed subjective world model. We demonstrate that widely observed failures are structural necessities: unsafe behaviors emerge as either a stable misaligned equilibrium or oscillatory cycles depending on reward scheme, while strategic deception persists as a "locked-in" equilibrium or through epistemic indeterminacy robust to objective risks. We validate these theoretical predictions through behavioral experiments on six state-of-the-art model families, generating phase diagrams that precisely map the topological boundaries of safe behavior. Our findings reveal that safety is a discrete phase determined by the agent's epistemic priors rather than a continuous function of reward magnitude. This establishes Subjective Model Engineering, defined as the design of an agent's internal belief structure, as a necessary condition for robust alignment, marking a paradigm shift from manipulating environmental rewards to shaping the agent's interpretation of reality.

</details>


### [87] [Ontology-Guided Neuro-Symbolic Inference: Grounding Language Models with Mathematical Domain Knowledge](https://arxiv.org/abs/2602.17826)
*Marcelo Labre*

Main category: cs.AI

TL;DR: 该研究探讨了利用形式化领域本体（特别是OpenMath）通过检索增强生成来提升语言模型在数学推理中的可靠性，发现高质量的本体引导上下文能提升性能，但不相关的上下文反而会降低性能。


<details>
  <summary>Details</summary>
Motivation: 语言模型存在幻觉、脆弱性和缺乏形式化基础等根本限制，这些在高风险专业领域（如需要可验证推理的数学）中尤为成问题。研究旨在探索形式化领域本体是否能通过检索增强生成来提高语言模型的可靠性。

Method: 使用数学作为概念验证，实现了一个神经符号管道，利用OpenMath本体结合混合检索和交叉编码器重排序，将相关定义注入模型提示中。在MATH基准上评估了三个开源模型。

Result: 评估显示，当检索质量高时，本体引导的上下文能提高性能，但不相关的上下文会主动降低性能。这突显了神经符号方法的潜力和挑战。

Conclusion: 形式化领域本体在提升语言模型可靠性方面具有潜力，但检索质量至关重要。不相关的上下文会损害性能，表明需要更精确的检索机制来充分发挥神经符号方法的优势。

Abstract: Language models exhibit fundamental limitations -- hallucination, brittleness, and lack of formal grounding -- that are particularly problematic in high-stakes specialist fields requiring verifiable reasoning. I investigate whether formal domain ontologies can enhance language model reliability through retrieval-augmented generation. Using mathematics as proof of concept, I implement a neuro-symbolic pipeline leveraging the OpenMath ontology with hybrid retrieval and cross-encoder reranking to inject relevant definitions into model prompts. Evaluation on the MATH benchmark with three open-source models reveals that ontology-guided context improves performance when retrieval quality is high, but irrelevant context actively degrades it -- highlighting both the promise and challenges of neuro-symbolic approaches.

</details>


### [88] [The Token Games: Evaluating Language Model Reasoning with Puzzle Duels](https://arxiv.org/abs/2602.17831)
*Simon Henniger,Gabriel Poesia*

Main category: cs.AI

TL;DR: TTG是一个基于编程谜题对战的自动评估框架，让大语言模型相互出题挑战，通过Elo评分比较模型推理能力，无需人工标注。


<details>
  <summary>Details</summary>
Motivation: 当前评估大语言模型推理能力面临挑战：人工标注高质量问题成本高，且难以区分模型是真正推理还是见过类似训练数据。需要一种无法被设计饱和、能测试创造性和任务生成能力的评估范式。

Method: 受16世纪数学决斗启发，设计Token Games框架：模型相互出编程谜题（给定返回布尔值的Python函数，找到使函数返回True的输入），通过两两对战验证解决方案，计算Elo评分来比较模型相对能力。

Result: 评估了10个前沿模型，TTG的排名结果与现有基准（如Humanity's Last Exam）高度匹配，且完全无需人工创建谜题。发现当前模型创建优质谜题的能力仍然极具挑战，这是先前基准未测量的维度。

Conclusion: TTG提出了一种新的推理评估范式，不会被设计饱和，能够同时测试模型的问题解决、创造性和任务生成能力，为评估大语言模型提供了更全面、自动化的方法。

Abstract: Evaluating the reasoning capabilities of Large Language Models is increasingly challenging as models improve. Human curation of hard questions is highly expensive, especially in recent benchmarks using PhD-level domain knowledge to challenge the most capable models. Even then, there is always a concern about whether these questions test genuine reasoning or if similar problems have been seen during training. Here, we take inspiration from 16th-century mathematical duels to design The Token Games (TTG): an evaluation framework where models challenge each other by creating their own puzzles. We leverage the format of Programming Puzzles - given a Python function that returns a boolean, find inputs that make it return True - to flexibly represent problems and enable verifying solutions. Using results from pairwise duels, we then compute Elo ratings, allowing us to compare models relative to each other. We evaluate 10 frontier models on TTG, and closely match the ranking from existing benchmarks such as Humanity's Last Exam, without involving any human effort in creating puzzles. We also find that creating good puzzles is still a highly challenging task for current models, not measured by previous benchmarks. Overall, our work suggests new paradigms for evaluating reasoning that cannot be saturated by design, and that allow testing models for other skills like creativity and task creation alongside problem solving.

</details>


### [89] [El Agente Gráfico: Structured Execution Graphs for Scientific Agents](https://arxiv.org/abs/2602.17902)
*Jiaru Bai,Abdulrahman Aldossary,Thomas Swanick,Marcel Müller,Yeonghun Kang,Zijian Zhang,Jin Won Lee,Tsz Wai Ko,Mohammad Ghazi Vakili,Varinia Bernales,Alán Aspuru-Guzik*

Main category: cs.AI

TL;DR: 提出El Agente Gráfico框架，通过类型安全执行环境和动态知识图谱将LLM决策嵌入科学工作流自动化，解决现有方法依赖非结构化文本导致的上下文管理脆弱和可追溯性差的问题。


<details>
  <summary>Details</summary>
Motivation: 当前LLM在科学工作流自动化中与异构计算工具的集成方式零散脆弱，基于非结构化文本的代理方法产生大量信息，难以追踪决策来源和审计。需要更可靠、可追溯的自动化框架。

Method: 开发单代理框架，核心是科学概念的结构化抽象和对象-图谱映射器，将计算状态表示为类型化Python对象，存储在内存或外部知识图谱中。通过类型化符号标识而非原始文本管理上下文，确保一致性、支持溯源追踪和高效工具编排。

Result: 在量子化学任务基准测试中，单个代理结合可靠执行引擎能稳健执行复杂、多步骤、并行计算。框架还成功应用于构象集合生成和金属有机框架设计，知识图谱同时作为记忆和推理基础。

Conclusion: 抽象化和类型安全为基于代理的科学自动化提供了超越提示中心设计的可扩展基础，展示了结构化方法在科学工作流自动化中的优势。

Abstract: Large language models (LLMs) are increasingly used to automate scientific workflows, yet their integration with heterogeneous computational tools remains ad hoc and fragile. Current agentic approaches often rely on unstructured text to manage context and coordinate execution, generating often overwhelming volumes of information that may obscure decision provenance and hinder auditability. In this work, we present El Agente Gráfico, a single-agent framework that embeds LLM-driven decision-making within a type-safe execution environment and dynamic knowledge graphs for external persistence. Central to our approach is a structured abstraction of scientific concepts and an object-graph mapper that represents computational state as typed Python objects, stored either in memory or persisted in an external knowledge graph. This design enables context management through typed symbolic identifiers rather than raw text, thereby ensuring consistency, supporting provenance tracking, and enabling efficient tool orchestration. We evaluate the system by developing an automated benchmarking framework across a suite of university-level quantum chemistry tasks previously evaluated on a multi-agent system, demonstrating that a single agent, when coupled to a reliable execution engine, can robustly perform complex, multi-step, and parallel computations. We further extend this paradigm to two other large classes of applications: conformer ensemble generation and metal-organic framework design, where knowledge graphs serve as both memory and reasoning substrates. Together, these results illustrate how abstraction and type safety can provide a scalable foundation for agentic scientific automation beyond prompt-centric designs.

</details>


### [90] [Alignment in Time: Peak-Aware Orchestration for Long-Horizon Agentic Systems](https://arxiv.org/abs/2602.17910)
*Hanjing Shi,Dominic DiFranzo*

Main category: cs.AI

TL;DR: APEMO是一个运行时调度层，通过利用时间-情感信号优化计算分配，在固定预算下提升自主智能体在长时程工作流中的轨迹级可靠性和重用概率。


<details>
  <summary>Details</summary>
Motivation: 传统AI对齐主要关注单个模型输出，但自主智能体在长时程工作流中需要在整个交互轨迹上保持持续可靠性。现有方法缺乏对轨迹级稳定性的关注。

Method: APEMO是一个运行时调度层，通过行为代理检测轨迹不稳定性，并在关键片段（如峰值时刻和结尾）进行针对性修复。它不修改模型权重，而是通过时间-情感信号优化计算分配。

Result: 在多智能体模拟和基于LLM的规划-执行流程评估中，APEMO在轨迹级质量和重用概率方面持续优于结构化编排器。

Conclusion: 研究将AI对齐重新定义为时间控制问题，为长时程智能体系统的开发提供了一条有弹性的工程路径。

Abstract: Traditional AI alignment primarily focuses on individual model outputs; however, autonomous agents in long-horizon workflows require sustained reliability across entire interaction trajectories. We introduce APEMO (Affect-aware Peak-End Modulation for Orchestration), a runtime scheduling layer that optimizes computational allocation under fixed budgets by operationalizing temporal-affective signals. Instead of modifying model weights, APEMO detects trajectory instability through behavioral proxies and targets repairs at critical segments, such as peak moments and endings. Evaluation across multi-agent simulations and LLM-based planner--executor flows demonstrates that APEMO consistently enhances trajectory-level quality and reuse probability over structural orchestrators. Our results reframe alignment as a temporal control problem, offering a resilient engineering pathway for the development of long-horizon agentic systems.

</details>


### [91] [WorkflowPerturb: Calibrated Stress Tests for Evaluating Multi-Agent Workflow Metrics](https://arxiv.org/abs/2602.17990)
*Madhav Kanda,Pedro Las-Casas,Alok Gautam Kumbhare,Rodrigo Fonseca,Sharad Agarwal*

Main category: cs.AI

TL;DR: 提出了WorkflowPerturb基准，通过向黄金工作流施加受控扰动来评估工作流评估指标的敏感性和校准性


<details>
  <summary>Details</summary>
Motivation: LLM生成的结构化工作流评估困难，现有指标分数未校准，分数变化不能直接反映工作流退化的严重程度

Method: 创建包含4,973个黄金工作流和44,757个扰动变体的基准，应用三种扰动类型（缺失步骤、压缩步骤、描述变化）和三个严重级别（10%、30%、50%）

Result: 基准了多个指标家族，通过预期分数轨迹和残差分析其敏感性和校准性，揭示了指标家族间的系统性差异

Conclusion: WorkflowPerturb支持严重程度感知的工作流评估分数解释，数据集将在接受后发布

Abstract: LLM-based systems increasingly generate structured workflows for complex tasks. In practice, automatic evaluation of these workflows is difficult, because metric scores are often not calibrated, and score changes do not directly communicate the severity of workflow degradation. We introduce WorkflowPerturb, a controlled benchmark for studying workflow evaluation metrics. It works by applying realistic, controlled perturbations to golden workflows. WorkflowPerturb contains 4,973 golden workflows and 44,757 perturbed variants across three perturbation types (Missing Steps, Compressed Steps, and Description Changes), each applied at severity levels of 10%, 30%, and 50%. We benchmark multiple metric families and analyze their sensitivity and calibration using expected score trajectories and residuals. Our results characterize systematic differences across metric families and support severity-aware interpretation of workflow evaluation scores. Our dataset will be released upon acceptance.

</details>


### [92] [Cross-Embodiment Offline Reinforcement Learning for Heterogeneous Robot Datasets](https://arxiv.org/abs/2602.18025)
*Haruki Abe,Takayuki Osa,Yusuke Mukuta,Tatsuya Harada*

Main category: cs.AI

TL;DR: 离线强化学习与跨具身学习结合，利用异构机器人轨迹预训练通用控制策略，但多机器人类型会引发梯度冲突，通过形态相似性分组可缓解此问题。


<details>
  <summary>Details</summary>
Motivation: 解决机器人策略预训练中高质量演示数据收集成本高的问题，通过结合离线强化学习和跨具身学习来利用异构机器人轨迹获取通用控制先验。

Method: 1) 系统分析离线RL与跨具身学习范式；2) 构建包含16个机器人平台的运动数据集；3) 提出基于形态相似性的分组策略，通过组梯度更新模型以减少机器人间的梯度冲突。

Result: 1) 离线RL与跨具身学习结合在包含大量次优轨迹的数据集上优于纯行为克隆；2) 随着次优数据比例和机器人类型增加，形态间的梯度冲突会阻碍学习；3) 形态分组策略能显著减少机器人间冲突，优于现有冲突解决方法。

Conclusion: 离线RL与跨具身学习结合是有效的机器人策略预训练方法，但需要处理多机器人类型带来的梯度冲突问题，简单的形态分组策略能有效缓解这一挑战。

Abstract: Scalable robot policy pre-training has been hindered by the high cost of collecting high-quality demonstrations for each platform. In this study, we address this issue by uniting offline reinforcement learning (offline RL) with cross-embodiment learning. Offline RL leverages both expert and abundant suboptimal data, and cross-embodiment learning aggregates heterogeneous robot trajectories across diverse morphologies to acquire universal control priors. We perform a systematic analysis of this offline RL and cross-embodiment paradigm, providing a principled understanding of its strengths and limitations. To evaluate this offline RL and cross-embodiment paradigm, we construct a suite of locomotion datasets spanning 16 distinct robot platforms. Our experiments confirm that this combined approach excels at pre-training with datasets rich in suboptimal trajectories, outperforming pure behavior cloning. However, as the proportion of suboptimal data and the number of robot types increase, we observe that conflicting gradients across morphologies begin to impede learning. To mitigate this, we introduce an embodiment-based grouping strategy in which robots are clustered by morphological similarity and the model is updated with a group gradient. This simple, static grouping substantially reduces inter-robot conflicts and outperforms existing conflict-resolution methods.

</details>


### [93] [Neurosymbolic Language Reasoning as Satisfiability Modulo Theory](https://arxiv.org/abs/2602.18095)
*Hyunseok Oh,Sam Stern,Youngki Lee,Matthai Philipose*

Main category: cs.AI

TL;DR: Logitext是一个神经符号语言，将文档表示为自然语言文本约束，通过结合LLM约束评估和SMT求解实现文本-逻辑联合推理，扩展了神经符号方法到非完全形式化领域。


<details>
  <summary>Details</summary>
Motivation: 现有神经符号系统结合LLM和求解器，但仅限于数学或程序合成等完全形式化任务，无法处理只有部分逻辑结构的自然文档。需要一种方法来实现文本和逻辑的可靠交织推理。

Method: 提出Logitext神经符号语言，将文档表示为自然语言文本约束(NLTCs)，使部分逻辑结构显式化。开发算法整合LLM约束评估和可满足性模理论(SMT)求解，实现联合文本-逻辑推理。

Result: 在新内容审核基准、LegalBench和Super-Natural Instructions上的实验表明，Logitext提高了准确性和覆盖率。这是首次将LLM推理视为SMT理论，扩展神经符号方法到非完全形式化领域。

Conclusion: Logitext通过将文档表示为自然语言文本约束，结合LLM和SMT求解，成功实现了文本和逻辑的联合推理，为处理部分逻辑结构的自然文档提供了有效解决方案。

Abstract: Natural language understanding requires interleaving textual and logical reasoning, yet large language models often fail to perform such reasoning reliably. Existing neurosymbolic systems combine LLMs with solvers but remain limited to fully formalizable tasks such as math or program synthesis, leaving natural documents with only partial logical structure unaddressed. We introduce Logitext, a neurosymbolic language that represents documents as natural language text constraints (NLTCs), making partial logical structure explicit. We develop an algorithm that integrates LLM-based constraint evaluation with satisfiability modulo theory (SMT) solving, enabling joint textual-logical reasoning. Experiments on a new content moderation benchmark, together with LegalBench and Super-Natural Instructions, show that Logitext improves both accuracy and coverage. This work is the first that treats LLM-based reasoning as an SMT theory, extending neurosymbolic methods beyond fully formalizable domains.

</details>


### [94] [SOMtime the World Ain$'$t Fair: Violating Fairness Using Self-Organizing Maps](https://arxiv.org/abs/2602.18201)
*Joseph Bingham,Netanel Arussy,Dvir Aran*

Main category: cs.AI

TL;DR: SOMtime方法在无监督表示中即使敏感属性被排除，仍能恢复出与年龄、收入等敏感属性对齐的潜在轴，揭示了"公平性无知"在表示层面的失败。


<details>
  <summary>Details</summary>
Motivation: 挑战无监督表示中敏感属性被排除即中立的假设，证明即使敏感属性被明确排除在输入之外，它们仍可能作为主导潜在轴在嵌入中出现。

Method: 使用SOMtime（基于高容量自组织映射的拓扑保持表示方法），在两个大规模真实世界数据集（五个国家的世界价值观调查和人口普查收入数据集）上进行实验，与PCA、UMAP、t-SNE和自编码器等方法进行比较。

Result: SOMtime恢复了与排除的敏感属性对齐的单调排序，斯皮尔曼相关性高达0.85，而其他方法通常低于0.23；无监督分割SOMtime嵌入会产生人口统计偏斜的聚类。

Conclusion: "公平性无知"在序数敏感属性的表示层面失败，公平性审计必须扩展到机器学习管道的无监督组件。

Abstract: Unsupervised representations are widely assumed to be neutral with respect to sensitive attributes when those attributes are withheld from training. We show that this assumption is false. Using SOMtime, a topology-preserving representation method based on high-capacity Self-Organizing Maps, we demonstrate that sensitive attributes such as age and income emerge as dominant latent axes in purely unsupervised embeddings, even when explicitly excluded from the input. On two large-scale real-world datasets (the World Values Survey across five countries and the Census-Income dataset), SOMtime recovers monotonic orderings aligned with withheld sensitive attributes, achieving Spearman correlations of up to 0.85, whereas PCA and UMAP typically remain below 0.23 (with a single exception reaching 0.31), and against t-SNE and autoencoders which achieve at most 0.34. Furthermore, unsupervised segmentation of SOMtime embeddings produces demographically skewed clusters, demonstrating downstream fairness risks without any supervised task. These findings establish that \textit{fairness through unawareness} fails at the representation level for ordinal sensitive attributes and that fairness auditing must extend to unsupervised components of machine learning pipelines. We have made the code available at~ https://github.com/JosephBingham/SOMtime

</details>


### [95] [Diffusing to Coordinate: Efficient Online Multi-Agent Diffusion Policies](https://arxiv.org/abs/2602.18291)
*Zhuoran Li,Hai Zhong,Xun Wang,Qingxin Xia,Lihua Zhang,Longbo Huang*

Main category: cs.AI

TL;DR: OMAD：首个在线多智能体强化学习扩散策略框架，通过松弛策略目标最大化联合熵，实现高效探索与协调，在10个任务上达到SOTA性能


<details>
  <summary>Details</summary>
Motivation: 扩散模型在图像生成和离线设置中表现出卓越的表达能力和多模态表示，但在在线多智能体强化学习中尚未充分探索。主要障碍是扩散模型的不可处理似然性阻碍了基于熵的探索和协调。

Method: 提出OMAD框架：1）松弛策略目标最大化缩放联合熵，实现无似然依赖的有效探索；2）在CTDE范式下使用联合分布值函数优化分散扩散策略；3）利用可处理的熵增强目标指导扩散策略同步更新，确保稳定协调。

Result: 在MPE和MAMuJoCo的10个多样化任务上建立了新的SOTA，样本效率显著提高2.5倍到5倍。

Conclusion: OMAD成功将扩散策略应用于在线多智能体强化学习，通过创新的熵最大化方法克服了扩散模型似然不可处理的挑战，实现了卓越的探索能力和协调性能。

Abstract: Online Multi-Agent Reinforcement Learning (MARL) is a prominent framework for efficient agent coordination. Crucially, enhancing policy expressiveness is pivotal for achieving superior performance. Diffusion-based generative models are well-positioned to meet this demand, having demonstrated remarkable expressiveness and multimodal representation in image generation and offline settings. Yet, their potential in online MARL remains largely under-explored. A major obstacle is that the intractable likelihoods of diffusion models impede entropy-based exploration and coordination. To tackle this challenge, we propose among the first \underline{O}nline off-policy \underline{MA}RL framework using \underline{D}iffusion policies (\textbf{OMAD}) to orchestrate coordination. Our key innovation is a relaxed policy objective that maximizes scaled joint entropy, facilitating effective exploration without relying on tractable likelihood. Complementing this, within the centralized training with decentralized execution (CTDE) paradigm, we employ a joint distributional value function to optimize decentralized diffusion policies. It leverages tractable entropy-augmented targets to guide the simultaneous updates of diffusion policies, thereby ensuring stable coordination. Extensive evaluations on MPE and MAMuJoCo establish our method as the new state-of-the-art across $10$ diverse tasks, demonstrating a remarkable $2.5\times$ to $5\times$ improvement in sample efficiency.

</details>
