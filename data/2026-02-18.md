<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 43]
- [cs.CL](#cs.CL) [Total: 37]
- [cs.AI](#cs.AI) [Total: 28]
- [cs.SE](#cs.SE) [Total: 11]
- [cs.NI](#cs.NI) [Total: 4]
- [cs.SI](#cs.SI) [Total: 2]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [GRAFNet: Multiscale Retinal Processing via Guided Cortical Attention Feedback for Enhancing Medical Image Polyp Segmentation](https://arxiv.org/abs/2602.15072)
*Abdul Joseph Fofanah,Lian Wen,Alpha Alimamy Kamara,Zhongyi Zhang,David Chen,Albert Patrick Sankoh*

Main category: cs.CV

TL;DR: GRAFNet：受生物视觉系统启发的息肉分割网络，通过模拟人类视觉层次结构，结合导向注意力、多尺度视网膜模块和皮层反馈机制，在多个公开数据集上实现SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 结肠镜息肉分割面临三大挑战：息肉形态高度可变（从平坦到突出病变）、与正常组织（如褶皱和血管）视觉相似性强、需要鲁棒的多尺度检测。现有深度学习方法存在单向处理、多尺度融合弱、缺乏解剖学约束等问题，导致假阳性（正常组织过分割）和假阴性（漏检平坦病变）。

Method: 提出GRAFNet，模拟人类视觉系统层次结构：1) 导向非对称注意力模块(GAAM)，模拟方向调谐皮层神经元，增强息肉边界；2) 多尺度视网膜模块(MSRM)，模拟视网膜神经节细胞通路，进行并行多特征分析；3) 导向皮层注意力反馈模块(GCAFM)，应用预测编码进行迭代优化。这些模块通过息肉编码器-解码器模块(PEDM)统一，通过分辨率自适应反馈强制空间语义一致性。

Result: 在五个公开基准数据集（Kvasir-SEG、CVC-300、CVC-ColonDB、CVC-Clinic、PolypGen）上进行了广泛实验，展示了持续的最先进性能：Dice系数提升3-8%，泛化能力比领先方法高10-20%，同时提供可解释的决策路径。

Conclusion: 这项工作建立了一个新范式，通过神经计算原理弥合AI准确性与临床可信推理之间的差距，为医学图像分析提供了生物启发的可解释解决方案。

Abstract: Accurate polyp segmentation in colonoscopy is essential for cancer prevention but remains challenging due to: (1) high morphological variability (from flat to protruding lesions), (2) strong visual similarity to normal structures such as folds and vessels, and (3) the need for robust multi-scale detection. Existing deep learning approaches suffer from unidirectional processing, weak multi-scale fusion, and the absence of anatomical constraints, often leading to false positives (over-segmentation of normal structures) and false negatives (missed subtle flat lesions). We propose GRAFNet, a biologically inspired architecture that emulates the hierarchical organisation of the human visual system. GRAFNet integrates three key modules: (1) a Guided Asymmetric Attention Module (GAAM) that mimics orientation-tuned cortical neurones to emphasise polyp boundaries, (2) a MultiScale Retinal Module (MSRM) that replicates retinal ganglion cell pathways for parallel multi-feature analysis, and (3) a Guided Cortical Attention Feedback Module (GCAFM) that applies predictive coding for iterative refinement. These are unified in a Polyp Encoder-Decoder Module (PEDM) that enforces spatial-semantic consistency via resolution-adaptive feedback. Extensive experiments on five public benchmarks (Kvasir-SEG, CVC-300, CVC-ColonDB, CVC-Clinic, and PolypGen) demonstrate consistent state-of-the-art performance, with 3-8% Dice improvements and 10-20% higher generalisation over leading methods, while offering interpretable decision pathways. This work establishes a paradigm in which neural computation principles bridge the gap between AI accuracy and clinically trustworthy reasoning. Code is available at https://github.com/afofanah/GRAFNet.

</details>


### [2] [Zero-shot HOI Detection with MLLM-based Detector-agnostic Interaction Recognition](https://arxiv.org/abs/2602.15124)
*Shiyu Xuan,Dongkai Wang,Zechao Li,Jinhui Tang*

Main category: cs.CV

TL;DR: 提出解耦框架，将目标检测与交互识别分离，利用多模态大语言模型进行零样本交互识别，通过确定性生成方法将交互识别转化为视觉问答任务。


<details>
  <summary>Details</summary>
Motivation: 现有零样本人-物交互检测方法通常将交互识别与特定检测器紧密耦合，依赖粗粒度的视觉-语言模型特征，限制了模型对未见交互的泛化能力。

Method: 1) 解耦框架：分离目标检测与交互识别；2) 确定性生成方法：将交互识别转化为视觉问答任务；3) 空间感知池化模块：整合外观和成对空间线索；4) 一次性确定性匹配：单次前向传播预测所有候选交互。

Result: 在HICO-DET和V-COCO数据集上实现了优越的零样本性能，展示了强大的跨数据集泛化能力，并能灵活集成任何目标检测器而无需重新训练。

Conclusion: 提出的解耦框架通过利用MLLMs进行零样本交互识别，解决了现有方法的局限性，实现了更好的泛化能力和灵活性，代码已开源。

Abstract: Zero-shot Human-object interaction (HOI) detection aims to locate humans and objects in images and recognize their interactions. While advances in open-vocabulary object detection provide promising solutions for object localization, interaction recognition (IR) remains challenging due to the combinatorial diversity of interactions. Existing methods, including two-stage methods, tightly couple IR with a specific detector and rely on coarse-grained vision-language model (VLM) features, which limit generalization to unseen interactions. In this work, we propose a decoupled framework that separates object detection from IR and leverages multi-modal large language models (MLLMs) for zero-shot IR. We introduce a deterministic generation method that formulates IR as a visual question answering task and enforces deterministic outputs, enabling training-free zero-shot IR. To further enhance performance and efficiency by fine-tuning the model, we design a spatial-aware pooling module that integrates appearance and pairwise spatial cues, and a one-pass deterministic matching method that predicts all candidate interactions in a single forward pass. Extensive experiments on HICO-DET and V-COCO demonstrate that our method achieves superior zero-shot performance, strong cross-dataset generalization, and the flexibility to integrate with any object detectors without retraining. The codes are publicly available at https://github.com/SY-Xuan/DA-HOI.

</details>


### [3] [MB-DSMIL-CL-PL: Scalable Weakly Supervised Ovarian Cancer Subtype Classification and Localisation Using Contrastive and Prototype Learning with Frozen Patch Features](https://arxiv.org/abs/2602.15138)
*Marcus Jenkins,Jasenka Mazibrada,Bogdan Leahu,Michal Mackiewicz*

Main category: cs.CV

TL;DR: 提出基于对比学习和原型学习的卵巢癌组织病理学图像亚型分类与定位新方法，使用预计算冻结特征，在保持可扩展性的同时显著提升性能


<details>
  <summary>Details</summary>
Motivation: 卵巢癌组织病理学亚型研究对个性化治疗至关重要，但诊断工作量增加给病理科带来挑战。传统方法依赖预计算特征，而端到端方法虽提升准确性但训练可扩展性差、实验耗时。需要一种既能保持可扩展性又能提升性能的方法。

Method: 提出结合对比学习和原型学习的方法，使用预计算的冻结特征，通过特征空间增强技术进行亚型分类和定位。该方法保持了冻结特征的可扩展性优势，同时通过对比学习和原型学习提升性能。

Result: 相比DSMIL方法，在实例级分类F1分数提升70.4%，切片级分类F1分数提升15.3%；实例定位AUC提升16.9%，切片分类AUC提升2.3%，同时保持使用冻结特征。

Conclusion: 该方法成功解决了传统冻结特征方法性能不足和端到端方法可扩展性差的问题，在卵巢癌组织病理学亚型分类和定位任务中实现了显著性能提升，同时保持了训练和实验的高效性。

Abstract: The study of histopathological subtypes is valuable for the personalisation of effective treatment strategies for ovarian cancer. However, increasing diagnostic workloads present a challenge for UK pathology departments, leading to the rise in AI approaches. While traditional approaches in this field have relied on pre-computed, frozen image features, recent advances have shifted towards end-to-end feature extraction, providing an improvement in accuracy but at the expense of significantly reduced scalability during training and time-consuming experimentation. In this paper, we propose a new approach for subtype classification and localisation in ovarian cancer histopathology images using contrastive and prototype learning with pre-computed, frozen features via feature-space augmentations. Compared to DSMIL, our method achieves an improvement of 70.4\% and 15.3\% in F1 score for instance- and slide-level classification, respectively, along with AUC gains of 16.9\% for instance localisation and 2.3\% for slide classification, while maintaining the use of frozen patch features.

</details>


### [4] [Loss Knows Best: Detecting Annotation Errors in Videos via Loss Trajectories](https://arxiv.org/abs/2602.15154)
*Praditha Alwis,Soumyadeep Chandra,Deepak Ravikumar,Kaushik Roy*

Main category: cs.CV

TL;DR: 提出基于累积样本损失(CSL)的视频标注错误检测方法，通过分析帧级损失轨迹识别错误标注和时序错乱


<details>
  <summary>Details</summary>
Motivation: 现实世界视频数据集常存在标注错误（错误标签和时序错乱），这些错误在需要时序一致性的任务中特别有害，需要模型无关的检测方法

Method: 提出累积样本损失(CSL)方法：训练视频分割模型并保存每个epoch的权重，用这些检查点评估测试视频中每帧的损失，将损失持续高的帧标记为可能的标注错误

Result: 在EgoPER和Cholec80数据集上实验显示强大的检测性能，能有效识别错误标签和帧错乱等细微不一致性

Conclusion: 该方法为数据集审计和提升视频机器学习训练可靠性提供了强大工具，无需标注错误的地面真值，且具有跨数据集通用性

Abstract: High-quality video datasets are foundational for training robust models in tasks like action recognition, phase detection, and event segmentation. However, many real-world video datasets suffer from annotation errors such as *mislabeling*, where segments are assigned incorrect class labels, and *disordering*, where the temporal sequence does not follow the correct progression. These errors are particularly harmful in phase-annotated tasks, where temporal consistency is critical. We propose a novel, model-agnostic method for detecting annotation errors by analyzing the Cumulative Sample Loss (CSL)--defined as the average loss a frame incurs when passing through model checkpoints saved across training epochs. This per-frame loss trajectory acts as a dynamic fingerprint of frame-level learnability. Mislabeled or disordered frames tend to show consistently high or irregular loss patterns, as they remain difficult for the model to learn throughout training, while correctly labeled frames typically converge to low loss early. To compute CSL, we train a video segmentation model and store its weights at each epoch. These checkpoints are then used to evaluate the loss of each frame in a test video. Frames with persistently high CSL are flagged as likely candidates for annotation errors, including mislabeling or temporal misalignment. Our method does not require ground truth on annotation errors and is generalizable across datasets. Experiments on EgoPER and Cholec80 demonstrate strong detection performance, effectively identifying subtle inconsistencies such as mislabeling and frame disordering. The proposed approach provides a powerful tool for dataset auditing and improving training reliability in video-based machine learning.

</details>


### [5] [Distributional Deep Learning for Super-Resolution of 4D Flow MRI under Domain Shift](https://arxiv.org/abs/2602.15167)
*Xiaoyi Wen,Fei Jiang*

Main category: cs.CV

TL;DR: 提出一种分布深度学习框架，用于解决医学影像超分辨率中的领域偏移问题，特别针对4D Flow MRI数据，通过结合CFD模拟和小规模真实数据微调来提升模型鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统超分辨率方法依赖成对的下采样和高分辨率图像训练，但在真实临床环境中，低分辨率数据的获取机制与简单下采样差异很大，导致领域偏移和模型泛化能力差。

Method: 提出分布深度学习框架，首先在计算流体动力学(CFD)模拟的高分辨率数据及其下采样版本上训练，然后在少量配对的4D Flow MRI和CFD样本上进行微调。

Result: 框架显著优于传统深度学习方法，通过实际数据应用证明了分布学习在解决领域偏移和提升临床现实场景中超分辨率性能的有效性。

Conclusion: 分布深度学习框架能够有效应对医学影像超分辨率中的领域偏移问题，在临床现实场景中显著提升模型鲁棒性和泛化能力。

Abstract: Super-resolution is widely used in medical imaging to enhance low-quality data, reducing scan time and improving abnormality detection. Conventional super-resolution approaches typically rely on paired datasets of downsampled and original high resolution images, training models to reconstruct high resolution images from their artificially degraded counterparts. However, in real-world clinical settings, low resolution data often arise from acquisition mechanisms that differ significantly from simple downsampling. As a result, these inputs may lie outside the domain of the training data, leading to poor model generalization due to domain shift. To address this limitation, we propose a distributional deep learning framework that improves model robustness and domain generalization. We develop this approch for enhancing the resolution of 4D Flow MRI (4DF). This is a novel imaging modality that captures hemodynamic flow velocity and clinically relevant metrics such as vessel wall stress. These metrics are critical for assessing aneurysm rupture risk. Our model is initially trained on high resolution computational fluid dynamics (CFD) simulations and their downsampled counterparts. It is then fine-tuned on a small, harmonized dataset of paired 4D Flow MRI and CFD samples. We derive the theoretical properties of our distributional estimators and demonstrate that our framework significantly outperforms traditional deep learning approaches through real data applications. This highlights the effectiveness of distributional learning in addressing domain shift and improving super-resolution performance in clinically realistic scenarios.

</details>


### [6] [Time-Archival Camera Virtualization for Sports and Visual Performances](https://arxiv.org/abs/2602.15181)
*Yunxiao Zhang,William Stone,Suryansh Kumar*

Main category: cs.CV

TL;DR: 提出基于神经体积渲染的相机虚拟化方法，支持动态场景的高质量新视角合成和时间归档功能，适用于体育直播等应用。


<details>
  <summary>Details</summary>
Motivation: 现有基于3D高斯泼溅的动态场景渲染方法依赖准确点云且难以处理快速非刚性运动，无法支持时间归档功能，限制了在体育直播等应用中的实用性。

Method: 采用神经体积渲染框架，将动态场景建模为多相机视角下的刚性变换，通过神经表示学习实现高质量渲染，支持时间归档功能。

Result: 实现了时空一致、照片级真实的动态场景渲染，支持用户回溯任意时间点进行新视角合成，为体育直播等应用提供回放、分析和归档功能。

Conclusion: 神经体积渲染框架在相机虚拟化中具有优势，能够处理复杂动态场景并支持时间归档，为体育广播等实时应用提供了实用解决方案。

Abstract: Camera virtualization -- an emerging solution to novel view synthesis -- holds transformative potential for visual entertainment, live performances, and sports broadcasting by enabling the generation of photorealistic images from novel viewpoints using images from a limited set of calibrated multiple static physical cameras. Despite recent advances, achieving spatially and temporally coherent and photorealistic rendering of dynamic scenes with efficient time-archival capabilities, particularly in fast-paced sports and stage performances, remains challenging for existing approaches. Recent methods based on 3D Gaussian Splatting (3DGS) for dynamic scenes could offer real-time view-synthesis results. Yet, they are hindered by their dependence on accurate 3D point clouds from the structure-from-motion method and their inability to handle large, non-rigid, rapid motions of different subjects (e.g., flips, jumps, articulations, sudden player-to-player transitions). Moreover, independent motions of multiple subjects can break the Gaussian-tracking assumptions commonly used in 4DGS, ST-GS, and other dynamic splatting variants. This paper advocates reconsidering a neural volume rendering formulation for camera virtualization and efficient time-archival capabilities, making it useful for sports broadcasting and related applications. By modeling a dynamic scene as rigid transformations across multiple synchronized camera views at a given time, our method performs neural representation learning, providing enhanced visual rendering quality at test time. A key contribution of our approach is its support for time-archival, i.e., users can revisit any past temporal instance of a dynamic scene and can perform novel view synthesis, enabling retrospective rendering for replay, analysis, and archival of live events, a functionality absent in existing neural rendering approaches and novel view synthesis...

</details>


### [7] [How to Train Your Long-Context Visual Document Model](https://arxiv.org/abs/2602.15257)
*Austin Veselka*

Main category: cs.CV

TL;DR: 首个大规模长上下文视觉语言模型研究，训练上下文达344K，专注于长文档视觉问答，并在长上下文文本任务上展示迁移能力，在MMLongBenchDoc上达到SOTA。


<details>
  <summary>Details</summary>
Motivation: 现有开源长上下文视觉语言模型（如Qwen3 VL和GLM 4.5/6V）的训练方法和数据流程不可复现，需要系统研究其训练方法以填补这一空白。

Method: 系统研究了24B和32B参数模型的持续预训练、监督微调和偏好优化，使用合成数据管道，并在长上下文评估和消融实验支持下进行。

Result: 在MMLongBenchDoc上两个参数规模都达到最先进性能；发现训练上下文长度与评估长度匹配时效果更好；页面索引训练和评估能显著提升长文档性能；视觉长上下文训练能迁移到长上下文文本任务。

Conclusion: 该研究填补了长上下文视觉语言模型训练方法的空白，提供了可复现的训练方案，并发布了改进版评测基准MMLBD-C，为未来研究奠定基础。

Abstract: We present the first comprehensive, large-scale study of training long-context vision language models up to 344K context, targeting long-document visual question answering with measured transfer to long-context text. While several such strong are open-weight, namely Qwen3 VL and GLM 4.5/6V, their training recipes and data pipelines are not reproducible. We systematically study continued pretraining, supervised finetuning, and preference optimization for 24B and 32B parameter models, backed by extensive LC evaluations and ablations to bridge this gap, and achieve state-of-the-art performance on MMLongBenchDoc for both parameter scales. In addition to this, our key findings include: (i) training on context lengths that match evaluation context lengths outperforms training on longer contexts, (ii) training and evaluating with page indices provides a simple, high-impact boost to long-document performance, (iii) our synthetic data pipelines enable self-improvement via continued pretraining and supervised finetuning, and (iv) we extend the known text-to-visual long context transfer to the reverse, showing that visual long context training transfers to long-context text performance. We also release MMLBD-C, a manually corrected version of MMLongBenchDoc to reduce erroneous and low quality examples in the benchmark.

</details>


### [8] [Accelerating Large-Scale Dataset Distillation via Exploration-Exploitation Optimization](https://arxiv.org/abs/2602.15277)
*Muhammad J. Alahmadi,Peng Gao,Feiyi Wang,Dongkuan,Xu*

Main category: cs.CV

TL;DR: 提出E^2D方法，通过探索-利用两阶段优化策略，在保持高精度的同时大幅提升大规模数据集蒸馏的效率


<details>
  <summary>Details</summary>
Motivation: 现有解耦式数据集蒸馏方法面临精度与效率的权衡：基于优化的方法精度高但计算密集，免优化的方法效率高但精度低。需要克服这一权衡，实现既高效又高精度的大规模数据集蒸馏。

Method: 提出探索-利用蒸馏(E^2D)：1) 使用全图像初始化保持语义完整性和特征多样性；2) 两阶段优化策略：探索阶段进行均匀更新并识别高损失区域，利用阶段集中更新这些区域以加速收敛。

Result: 在ImageNet-1K上超越SOTA且快18倍，在ImageNet-21K上显著提升精度且快4.3倍。证明针对性、减少冗余的更新能有效平衡精度与效率。

Conclusion: 通过探索-利用策略实现针对性更新，而非暴力优化，能够弥合大规模数据集蒸馏中精度与效率之间的差距。

Abstract: Dataset distillation compresses the original data into compact synthetic datasets, reducing training time and storage while retaining model performance, enabling deployment under limited resources. Although recent decoupling-based distillation methods enable dataset distillation at large-scale, they continue to face an efficiency gap: optimization-based decoupling methods achieve higher accuracy but demand intensive computation, whereas optimization-free decoupling methods are efficient but sacrifice accuracy. To overcome this trade-off, we propose Exploration-Exploitation Distillation (E^2D), a simple, practical method that minimizes redundant computation through an efficient pipeline that begins with full-image initialization to preserve semantic integrity and feature diversity. It then uses a two-phase optimization strategy: an exploration phase that performs uniform updates and identifies high-loss regions, and an exploitation phase that focuses updates on these regions to accelerate convergence. We evaluate E^2D on large-scale benchmarks, surpassing the state-of-the-art on ImageNet-1K while being 18x faster, and on ImageNet-21K, our method substantially improves accuracy while remaining 4.3x faster. These results demonstrate that targeted, redundancy-reducing updates, rather than brute-force optimization, bridge the gap between accuracy and efficiency in large-scale dataset distillation. Code is available at https://github.com/ncsu-dk-lab.

</details>


### [9] [Visual Persuasion: What Influences Decisions of Vision-Language Models?](https://arxiv.org/abs/2602.15278)
*Manuel Cherep,Pranav M R,Pattie Maes,Nikhil Singh*

Main category: cs.CV

TL;DR: 研究者提出一个框架，通过将视觉语言模型置于受控的图像选择任务中，系统性地扰动输入来研究AI代理的视觉偏好，揭示其潜在的视觉效用函数。


<details>
  <summary>Details</summary>
Motivation: 随着视觉语言模型越来越多地用于解释网络图像并做出视觉决策（如点击、推荐、购买），我们对其视觉偏好结构知之甚少。需要一种方法来系统地研究AI代理的视觉决策机制，以发现潜在的安全漏洞。

Method: 通过受控的图像选择任务，使用视觉提示优化方法，将文本优化技术适配到视觉领域，利用图像生成模型迭代地提出和应用视觉上合理的修改（如构图、光照、背景），然后评估哪些编辑能提高选择概率。

Result: 在大规模实验中，优化的编辑显著改变了前沿视觉语言模型在头对头比较中的选择概率。研究者开发了自动可解释性管道来解释这些偏好，识别出驱动选择的一致视觉主题。

Conclusion: 这种方法提供了一种实用高效的方式来揭示视觉漏洞和安全问题，支持对基于图像的AI代理进行更主动的审计和治理，避免这些问题在现实世界中被动发现。

Abstract: The web is littered with images, once created for human consumption and now increasingly interpreted by agents using vision-language models (VLMs). These agents make visual decisions at scale, deciding what to click, recommend, or buy. Yet, we know little about the structure of their visual preferences. We introduce a framework for studying this by placing VLMs in controlled image-based choice tasks and systematically perturbing their inputs. Our key idea is to treat the agent's decision function as a latent visual utility that can be inferred through revealed preference: choices between systematically edited images. Starting from common images, such as product photos, we propose methods for visual prompt optimization, adapting text optimization methods to iteratively propose and apply visually plausible modifications using an image generation model (such as in composition, lighting, or background). We then evaluate which edits increase selection probability. Through large-scale experiments on frontier VLMs, we demonstrate that optimized edits significantly shift choice probabilities in head-to-head comparisons. We develop an automatic interpretability pipeline to explain these preferences, identifying consistent visual themes that drive selection. We argue that this approach offers a practical and efficient way to surface visual vulnerabilities, safety concerns that might otherwise be discovered implicitly in the wild, supporting more proactive auditing and governance of image-based AI agents.

</details>


### [10] [Consistency-Preserving Diverse Video Generation](https://arxiv.org/abs/2602.15287)
*Xinshuang Liu,Runfa Blark Li,Truong Nguyen*

Main category: cs.CV

TL;DR: 提出一种用于流匹配视频生成的联合采样框架，在保持时间一致性的同时提高批次多样性，避免视频解码和反向传播开销


<details>
  <summary>Details</summary>
Motivation: 文本到视频生成成本高昂，通常每个提示只能生成少量样本。在低样本情况下，最大化每个批次的价值需要高跨视频多样性。现有方法虽然能提高图像生成的多样性，但用于视频时会降低时间一致性，且需要昂贵的视频解码器反向传播。

Method: 提出联合采样框架，先应用多样性驱动的更新，然后移除会降低时间一致性目标的分量。为避免图像空间梯度，使用轻量级潜在空间模型计算两个目标，避免视频解码和解码器反向传播。

Result: 在最先进的文本到视频流匹配模型上的实验表明，该方法在保持与强联合采样基线相当的多样性的同时，显著提高了时间一致性和色彩自然度。

Conclusion: 提出的方法能够在保持视频时间一致性的同时有效提高批次多样性，避免了昂贵的计算开销，为文本到视频生成提供了高效的联合采样解决方案。

Abstract: Text-to-video generation is expensive, so only a few samples are typically produced per prompt. In this low-sample regime, maximizing the value of each batch requires high cross-video diversity. Recent methods improve diversity for image generation, but for videos they often degrade within-video temporal consistency and require costly backpropagation through a video decoder. We propose a joint-sampling framework for flow-matching video generators that improves batch diversity while preserving temporal consistency. Our approach applies diversity-driven updates and then removes only the components that would decrease a temporal-consistency objective. To avoid image-space gradients, we compute both objectives with lightweight latent-space models, avoiding video decoding and decoder backpropagation. Experiments on a state-of-the-art text-to-video flow-matching model show diversity comparable to strong joint-sampling baselines while substantially improving temporal consistency and color naturalness. Code will be released.

</details>


### [11] [Training-Free Zero-Shot Anomaly Detection in 3D Brain MRI with 2D Foundation Models](https://arxiv.org/abs/2602.15315)
*Tai Le-Gia,Jaehyun Ahn*

Main category: cs.CV

TL;DR: 提出了一种无需训练、基于批量的零样本异常检测框架，将2D基础模型扩展到3D脑MRI，通过聚合多轴切片构建局部体积标记，恢复立方空间上下文。


<details>
  <summary>Details</summary>
Motivation: 当前零样本异常检测方法主要局限于2D数据集，扩展到3D医学图像面临挑战。现有方法依赖切片特征和视觉语言模型，无法捕捉体积结构，需要一种能够处理3D医学图像且无需训练的方法。

Method: 通过聚合多轴切片处理后的2D基础模型特征，构建局部体积标记，恢复立方空间上下文。这些3D补丁标记直接与基于距离的批量级异常检测流程集成，无需微调、提示或监督。

Result: 展示了无需训练、基于批量的零样本异常检测可以有效地从2D编码器扩展到完整的3D MRI体积，为体积异常检测提供了简单而鲁棒的方法。

Conclusion: 该框架为3D脑MRI提供了紧凑的3D表示，可在标准GPU上计算，无需训练、提示或监督，成功将零样本异常检测扩展到3D医学图像领域。

Abstract: Zero-shot anomaly detection (ZSAD) has gained increasing attention in medical imaging as a way to identify abnormalities without task-specific supervision, but most advances remain limited to 2D datasets. Extending ZSAD to 3D medical images has proven challenging, with existing methods relying on slice-wise features and vision-language models, which fail to capture volumetric structure. In this paper, we introduce a fully training-free framework for ZSAD in 3D brain MRI that constructs localized volumetric tokens by aggregating multi-axis slices processed by 2D foundation models. These 3D patch tokens restore cubic spatial context and integrate directly with distance-based, batch-level anomaly detection pipelines. The framework provides compact 3D representations that are practical to compute on standard GPUs and require no fine-tuning, prompts, or supervision. Our results show that training-free, batch-based ZSAD can be effectively extended from 2D encoders to full 3D MRI volumes, offering a simple and robust approach for volumetric anomaly detection.

</details>


### [12] [Sparrow: Text-Anchored Window Attention with Visual-Semantic Glimpsing for Speculative Decoding in Video LLMs](https://arxiv.org/abs/2602.15318)
*Libo Zhang,Zhaoning Zhang,Wangyang Hong,Peng Qiao,Dongsheng Li*

Main category: cs.CV

TL;DR: Sparrow框架通过视觉感知文本锚定窗口注意力、中间层视觉状态桥接和多token预测策略，解决了视频大语言模型中推测解码的性能崩溃问题，实现了2.82倍的平均加速。


<details>
  <summary>Details</summary>
Motivation: 推测解码在加速视觉语言模型推理方面广泛应用，但在视频大语言模型中面临严重的性能崩溃问题。草稿模型通常陷入注意力稀释和负视觉增益的陷阱，这是由于键值缓存爆炸和上下文窗口不匹配造成的。

Method: 1. 通过隐藏状态重用实现视觉感知文本锚定窗口注意力，将视觉计算完全卸载到目标模型；2. 利用中间层视觉状态桥接，用语义丰富的中间状态训练草稿模型，过滤低级视觉噪声；3. 引入多token预测策略来桥接训练-推理分布偏移。

Result: Sparrow在即使有25k视觉token的情况下也能实现平均2.82倍的加速，有效解决了长序列中的性能下降问题，为实时长视频任务提供了实用解决方案。

Conclusion: Sparrow框架通过创新的视觉语义内部化利用方法，成功解决了视频大语言模型中推测解码的性能崩溃问题，实现了显著的推理加速，为长视频处理提供了高效解决方案。

Abstract: Although speculative decoding is widely used to accelerate Vision-Language Models (VLMs) inference, it faces severe performance collapse when applied to Video Large Language Models (Vid-LLMs). The draft model typically falls into the trap of attention dilution and negative visual gain due to key-value cache explosion and context window mismatches. We observe a visual semantic internalization phenomenon in Vid-LLMs, indicating that critical visual semantics are implicitly encoded into text hidden states during deep-layer interactions, which renders raw visual inputs structurally redundant during deep inference. To address this, we propose the Sparrow framework, which first utilizes visually-aware text-anchored window attention via hidden state reuse to fully offload visual computation to the target model, and leverages intermediate-layer visual state bridging to train the draft model with semantic-rich intermediate states, thereby filtering out low-level visual noise. Additionally, a multi-token prediction strategy is introduced to bridge the training-inference distribution shift. Experiments show that Sparrow achieves an average speedup of 2.82x even with 25k visual tokens, effectively resolving the performance degradation in long sequences and offering a practical solution for real-time long video tasks.

</details>


### [13] [EventMemAgent: Hierarchical Event-Centric Memory for Online Video Understanding with Adaptive Tool Use](https://arxiv.org/abs/2602.15329)
*Siwei Wen,Zhangcheng Wang,Xingjian Zhang,Lei Huang,Wenjun Wu*

Main category: cs.CV

TL;DR: EventMemAgent：基于分层记忆模块的主动在线视频理解框架，通过短期记忆检测事件边界、长期记忆结构化归档，结合多粒度感知工具和Agentic RL实现端到端推理


<details>
  <summary>Details</summary>
Motivation: 在线视频理解面临无限流媒体输入与MLLM有限上下文窗口的冲突。现有被动处理方法在保持长程上下文与捕获细粒度细节之间存在权衡，需要更有效的解决方案

Method: 提出基于分层记忆模块的主动在线视频代理框架：1) 短期记忆动态检测事件边界，使用事件粒度水库采样处理流视频帧；2) 长期记忆按事件结构化归档历史观察；3) 集成多粒度感知工具包进行主动迭代证据捕获；4) 使用Agentic RL端到端内化推理和工具使用策略

Result: 在在线视频基准测试中取得了有竞争力的结果

Conclusion: EventMemAgent通过主动记忆管理和强化学习，有效解决了在线视频理解中的长程推理与细粒度感知的平衡问题，为流媒体理解提供了新框架

Abstract: Online video understanding requires models to perform continuous perception and long-range reasoning within potentially infinite visual streams. Its fundamental challenge lies in the conflict between the unbounded nature of streaming media input and the limited context window of Multimodal Large Language Models (MLLMs). Current methods primarily rely on passive processing, which often face a trade-off between maintaining long-range context and capturing the fine-grained details necessary for complex tasks. To address this, we introduce EventMemAgent, an active online video agent framework based on a hierarchical memory module. Our framework employs a dual-layer strategy for online videos: short-term memory detects event boundaries and utilizes event-granular reservoir sampling to process streaming video frames within a fixed-length buffer dynamically; long-term memory structuredly archives past observations on an event-by-event basis. Furthermore, we integrate a multi-granular perception toolkit for active, iterative evidence capture and employ Agentic Reinforcement Learning (Agentic RL) to end-to-end internalize reasoning and tool-use strategies into the agent's intrinsic capabilities. Experiments show that EventMemAgent achieves competitive results on online video benchmarks. The code will be released here: https://github.com/lingcco/EventMemAgent.

</details>


### [14] [Effective and Robust Multimodal Medical Image Analysis](https://arxiv.org/abs/2602.15346)
*Joy Dhar,Nayyar Zaidi,Maryam Haghighat*

Main category: cs.CV

TL;DR: 提出MAIL和Robust-MAIL网络，通过多注意力集成学习解决多模态融合中的泛化性、计算效率和对抗鲁棒性问题，在20个公开数据集上性能提升9.34%，计算成本降低78.3%


<details>
  <summary>Details</summary>
Motivation: 现有多模态融合学习方法存在三个关键限制：1) 专注于特定模态，忽视跨模态共享互补信息，限制多疾病分析的泛化能力；2) 依赖计算昂贵模型，在资源有限环境中适用性受限；3) 缺乏对抗攻击鲁棒性，影响医疗AI应用的可靠性

Method: 提出MAIL网络，包含两个关键组件：1) 高效残差学习注意力块，用于捕获细化的模态特定多尺度模式；2) 高效多模态交叉注意力模块，用于学习跨不同模态的丰富互补共享表示。进一步扩展为Robust-MAIL，通过随机投影滤波器和调制注意力噪声确保对抗鲁棒性

Result: 在20个公开数据集上的广泛评估表明，MAIL和Robust-MAIL均优于现有方法，性能提升高达9.34%，同时计算成本降低高达78.3%，确保比顶级竞争对手更可靠的预测

Conclusion: 提出的MAIL和Robust-MAIL方法在多模态融合学习中表现出优越性，解决了现有方法的泛化性、计算效率和对抗鲁棒性问题，为医疗AI应用提供了更可靠的预测框架

Abstract: Multimodal Fusion Learning (MFL), leveraging disparate data from various imaging modalities (e.g., MRI, CT, SPECT), has shown great potential for addressing medical problems such as skin cancer and brain tumor prediction. However, existing MFL methods face three key limitations: a) they often specialize in specific modalities, and overlook effective shared complementary information across diverse modalities, hence limiting their generalizability for multi-disease analysis; b) they rely on computationally expensive models, restricting their applicability in resource-limited settings; and c) they lack robustness against adversarial attacks, compromising reliability in medical AI applications. To address these limitations, we propose a novel Multi-Attention Integration Learning (MAIL) network, incorporating two key components: a) an efficient residual learning attention block for capturing refined modality-specific multi-scale patterns and b) an efficient multimodal cross-attention module for learning enriched complementary shared representations across diverse modalities. Furthermore, to ensure adversarial robustness, we extend MAIL network to design Robust-MAIL by incorporating random projection filters and modulated attention noise. Extensive evaluations on 20 public datasets show that both MAIL and Robust-MAIL outperform existing methods, achieving performance gains of up to 9.34% while reducing computational costs by up to 78.3%. These results highlight the superiority of our approaches, ensuring more reliable predictions than top competitors. Code: https://github.com/misti1203/MAIL-Robust-MAIL.

</details>


### [15] [CREMD: Crowd-Sourced Emotional Multimodal Dogs Dataset](https://arxiv.org/abs/2602.15349)
*Jinho Baek,Houwei Cao,Kate Blackwell*

Main category: cs.CV

TL;DR: CREMD数据集研究不同呈现模式（上下文、音频、视频）和标注者特征如何影响狗情绪识别，发现视觉上下文显著提高标注一致性，但音频效果不确定，非主人和男性标注者一致性更高。


<details>
  <summary>Details</summary>
Motivation: 狗情绪识别对改善人-动物互动、兽医护理和自动化监测系统至关重要，但由于情感评估的主观性和缺乏标准化方法，准确识别狗情绪具有挑战性。

Method: 创建CREMD数据集，包含923个视频片段，以三种模式呈现：无上下文无音频、有上下文无音频、有上下文有音频。收集来自不同背景（狗主人、专业人士、不同人口统计特征）参与者的标注，分析影响可靠情绪识别的因素。

Result: 1. 视觉上下文显著提高标注一致性，但音频效果因设计限制（缺少无上下文有音频条件、干净音频有限）而不确定；2. 非主人和男性标注者比狗主人和女性标注者一致性更高，专业人士一致性更高符合预期；3. 音频显著提高标注者对特定情绪（特别是愤怒和恐惧）的识别信心。

Conclusion: 狗情绪识别受呈现模式和标注者特征显著影响，视觉上下文是关键因素，音频增强识别信心，标注者背景差异影响一致性，为未来狗情绪识别系统设计提供重要见解。

Abstract: Dog emotion recognition plays a crucial role in enhancing human-animal interactions, veterinary care, and the development of automated systems for monitoring canine well-being. However, accurately interpreting dog emotions is challenging due to the subjective nature of emotional assessments and the absence of standardized ground truth methods. We present the CREMD (Crowd-sourced Emotional Multimodal Dogs Dataset), a comprehensive dataset exploring how different presentation modes (e.g., context, audio, video) and annotator characteristics (e.g., dog ownership, gender, professional experience) influence the perception and labeling of dog emotions. The dataset consists of 923 video clips presented in three distinct modes: without context or audio, with context but no audio, and with both context and audio. We analyze annotations from diverse participants, including dog owners, professionals, and individuals with varying demographic backgrounds and experience levels, to identify factors that influence reliable dog emotion recognition. Our findings reveal several key insights: (1) while adding visual context significantly improved annotation agreement, our findings regarding audio cues are inconclusive due to design limitations (specifically, the absence of a no-context-with-audio condition and limited clean audio availability); (2) contrary to expectations, non-owners and male annotators showed higher agreement levels than dog owners and female annotators, respectively, while professionals showed higher agreement levels, aligned with our initial hypothesis; and (3) the presence of audio substantially increased annotators' confidence in identifying specific emotions, particularly anger and fear.

</details>


### [16] [DAV-GSWT: Diffusion-Active-View Sampling for Data-Efficient Gaussian Splatting Wang Tiles](https://arxiv.org/abs/2602.15355)
*Rong Fu,Jiekai Wu,Haiyun Wei,Yee Tan Jia,Wenxin Zhang,Yang Li,Xiaowen Ma,Wangyu Wu,Simon Fong*

Main category: cs.CV

TL;DR: DAV-GSWT：结合扩散先验和主动视角采样的数据高效框架，从最少输入观测中合成高质量的高斯溅射Wang Tiles


<details>
  <summary>Details</summary>
Motivation: 现有基于Wang Tiles的程序化方法生成大场景时，通常依赖密集采样的示例重建，数据需求量大。需要开发数据高效的方法来合成高质量的大规模虚拟环境。

Method: 结合扩散先验和主动视角采样，通过分层不确定性量化机制与生成扩散模型集成，自主识别信息最丰富的视角，同时幻觉化缺失的结构细节以确保瓦片无缝过渡。

Result: 实验结果表明，该系统显著减少了所需数据量，同时保持了大规模虚拟环境所需的视觉完整性和交互性能。

Conclusion: DAV-GSWT框架通过数据高效的方式实现了高质量大规模场景合成，为虚拟环境创建提供了更实用的解决方案。

Abstract: The emergence of 3D Gaussian Splatting has fundamentally redefined the capabilities of photorealistic neural rendering by enabling high-throughput synthesis of complex environments. While procedural methods like Wang Tiles have recently been integrated to facilitate the generation of expansive landscapes, these systems typically remain constrained by a reliance on densely sampled exemplar reconstructions. We present DAV-GSWT, a data-efficient framework that leverages diffusion priors and active view sampling to synthesize high-fidelity Gaussian Splatting Wang Tiles from minimal input observations. By integrating a hierarchical uncertainty quantification mechanism with generative diffusion models, our approach autonomously identifies the most informative viewpoints while hallucinating missing structural details to ensure seamless tile transitions. Experimental results indicate that our system significantly reduces the required data volume while maintaining the visual integrity and interactive performance necessary for large-scale virtual environments.

</details>


### [17] [GMAIL: Generative Modality Alignment for generated Image Learning](https://arxiv.org/abs/2602.15368)
*Shentong Mo,Sukmin Yun*

Main category: cs.CV

TL;DR: GMAIL框架将生成图像视为独立模态，通过跨模态对齐和多模态学习，在潜在空间中桥接真实与生成图像，有效提升视觉语言任务性能。


<details>
  <summary>Details</summary>
Motivation: 生成模型能合成高真实度图像，为训练提供丰富数据源，但直接将生成图像当作真实图像使用会导致模态差异问题，甚至引发模式崩溃。需要更智能地利用生成图像。

Method: 提出GMAIL框架：1) 将生成图像视为独立模态而非像素空间替代；2) 使用跨模态对齐损失在生成图像上微调模型；3) 用对齐后的模型结合生成图像训练各种视觉语言模型；4) 在潜在空间桥接两个模态。

Result: 显著提升图像描述、零样本图像检索、零样本图像分类和长描述检索任务性能；展示生成数据的正向缩放趋势；大幅增强LLaVA等大型多模态模型的描述能力。

Conclusion: 通过将生成图像作为独立模态处理并进行跨模态对齐，GMAIL框架能有效利用生成模型的优势，提升视觉语言任务性能，且易于与各种模型集成。

Abstract: Generative models have made it possible to synthesize highly realistic images, potentially providing an abundant data source for training machine learning models. Despite the advantages of these synthesizable data sources, the indiscriminate use of generated images as real images for training can even cause mode collapse due to modality discrepancies between real and synthetic domains. In this paper, we propose a novel framework for discriminative use of generated images, coined GMAIL, that explicitly treats generated images as a separate modality from real images. Instead of indiscriminately replacing real images with generated ones in the pixel space, our approach bridges the two distinct modalities in the same latent space through a multi-modal learning approach. To be specific, we first fine-tune a model exclusively on generated images using a cross-modality alignment loss and then employ this aligned model to further train various vision-language models with generated images. By aligning the two modalities, our approach effectively leverages the benefits of recent advances in generative models, thereby boosting the effectiveness of generated image learning across a range of vision-language tasks. Our framework can be easily incorporated with various vision-language models, and we demonstrate its efficacy throughout extensive experiments. For example, our framework significantly improves performance on image captioning, zero-shot image retrieval, zero-shot image classification, and long caption retrieval tasks. It also shows positive generated data scaling trends and notable enhancements in the captioning performance of the large multimodal model, LLaVA.

</details>


### [18] [Bridging Day and Night: Target-Class Hallucination Suppression in Unpaired Image Translation](https://arxiv.org/abs/2602.15383)
*Shuwei Li,Lei Tan,Robby T. Tan*

Main category: cs.CV

TL;DR: 提出一种新的无配对图像翻译框架，通过双头判别器和类别特定原型来检测和抑制目标类别特征的幻觉，在日到夜转换中显著提升下游任务性能。


<details>
  <summary>Details</summary>
Motivation: 日到夜无配对图像翻译面临大外观变化和缺乏像素级监督的挑战，现有方法常产生语义幻觉（如交通标志、车辆和人工灯光效果的错误合成），严重影响下游任务性能。

Method: 1) 设计双头判别器，同时进行语义分割以识别背景区域的幻觉内容；2) 引入类别特定原型，通过聚合标注的目标域对象特征构建，作为每个类别的语义锚点；3) 基于Schrodinger Bridge翻译模型进行迭代优化，将检测到的幻觉特征在特征空间中推离类别原型。

Result: 在BDD100K数据集上，日到夜域适应的mAP提升15.5%，对于易产生幻觉的类别（如交通灯）提升达31.7%，在定性和定量评估上均优于现有方法。

Conclusion: 提出的框架通过检测和抑制目标类别特征的幻觉，有效解决了无配对图像翻译中的语义保持问题，显著提升了域适应性能，特别是在易产生幻觉的类别上表现突出。

Abstract: Day-to-night unpaired image translation is important to downstream tasks but remains challenging due to large appearance shifts and the lack of direct pixel-level supervision. Existing methods often introduce semantic hallucinations, where objects from target classes such as traffic signs and vehicles, as well as man-made light effects, are incorrectly synthesized. These hallucinations significantly degrade downstream performance. We propose a novel framework that detects and suppresses hallucinations of target-class features during unpaired translation. To detect hallucination, we design a dual-head discriminator that additionally performs semantic segmentation to identify hallucinated content in background regions. To suppress these hallucinations, we introduce class-specific prototypes, constructed by aggregating features of annotated target-domain objects, which act as semantic anchors for each class. Built upon a Schrodinger Bridge-based translation model, our framework performs iterative refinement, where detected hallucination features are explicitly pushed away from class prototypes in feature space, thus preserving object semantics across the translation trajectory.Experiments show that our method outperforms existing approaches both qualitatively and quantitatively. On the BDD100K dataset, it improves mAP by 15.5% for day-to-night domain adaptation, with a notable 31.7% gain for classes such as traffic lights that are prone to hallucinations.

</details>


### [19] [Efficient Generative Modeling beyond Memoryless Diffusion via Adjoint Schrödinger Bridge Matching](https://arxiv.org/abs/2602.15396)
*Jeongwoo Shin,Jinhwan Sul,Joonseok Lee,Jaewong Choi,Jaemoo Choi*

Main category: cs.CV

TL;DR: ASBM是一种新的生成建模框架，通过两阶段方法学习最优轨迹：首先将Schrödinger Bridge前向动态视为耦合构造问题，然后通过简单匹配损失学习后向生成动态，从而产生更直、更高效的采样路径。


<details>
  <summary>Details</summary>
Motivation: 传统扩散模型由于使用无信息、无记忆的前向过程，导致高度弯曲的轨迹和噪声分数目标，这影响了采样效率和稳定性。需要一种能够恢复高维最优轨迹的方法。

Method: 提出Adjoint Schrödinger Bridge Matching (ASBM)框架，包含两个阶段：1) 将SB前向动态视为耦合构造问题，通过数据到能量采样的视角学习，将数据传输到能量定义的先验；2) 使用简单匹配损失学习后向生成动态，由诱导的最优耦合监督。

Result: ASBM在非无记忆机制下运行，产生显著更直、更高效的采样路径。相比先前工作，ASBM能够扩展到高维数据，显著提高了稳定性和效率。图像生成实验显示ASBM以更少的采样步骤提高了保真度，并成功蒸馏到一步生成器。

Conclusion: ASBM通过两阶段方法有效解决了扩散模型轨迹弯曲和噪声问题，实现了更优的采样效率和生成质量，为高维生成建模提供了新的有效框架。

Abstract: Diffusion models often yield highly curved trajectories and noisy score targets due to an uninformative, memoryless forward process that induces independent data-noise coupling. We propose Adjoint Schrödinger Bridge Matching (ASBM), a generative modeling framework that recovers optimal trajectories in high dimensions via two stages. First, we view the Schrödinger Bridge (SB) forward dynamic as a coupling construction problem and learn it through a data-to-energy sampling perspective that transports data to an energy-defined prior. Then, we learn the backward generative dynamic with a simple matching loss supervised by the induced optimal coupling. By operating in a non-memoryless regime, ASBM produces significantly straighter and more efficient sampling paths. Compared to prior works, ASBM scales to high-dimensional data with notably improved stability and efficiency. Extensive experiments on image generation show that ASBM improves fidelity with fewer sampling steps. We further showcase the effectiveness of our optimal trajectory via distillation to a one-step generator.

</details>


### [20] [Emergent Morphing Attack Detection in Open Multi-modal Large Language Models](https://arxiv.org/abs/2602.15461)
*Marija Ivanovska,Vitomir Štruc*

Main category: cs.CV

TL;DR: 首次系统评估开源多模态大语言模型在零样本设置下的单图像人脸合成攻击检测能力，发现LLaVA1.6-Mistral-7B在未微调情况下超越任务专用基线方法23%以上。


<details>
  <summary>Details</summary>
Motivation: 当前人脸合成攻击检测系统需要任务特定训练且泛化能力差，而开源多模态大语言模型在视觉-语言推理方面表现出色，但在生物特征取证领域的潜力尚未充分探索。

Method: 采用公开可用的权重和标准化可复现协议，首次对开源多模态大语言模型进行零样本单图像人脸合成攻击检测系统评估，无需微调或领域适应。

Result: 多种MLLM在未微调情况下展现出显著判别能力，LLaVA1.6-Mistral-7B达到最先进性能，在等错误率上超越竞争性任务专用基线至少23%。多模态预训练能隐式编码指示合成伪影的细粒度面部不一致性。

Conclusion: 开源MLLM可作为生物特征安全和取证图像分析的可复现、可解释且具竞争力的基础。这一新兴能力为通过针对性微调或轻量级适应开发最先进MAD系统提供了新机遇。

Abstract: Face morphing attacks threaten biometric verification, yet most morphing attack detection (MAD) systems require task-specific training and generalize poorly to unseen attack types. Meanwhile, open-source multimodal large language models (MLLMs) have demonstrated strong visual-linguistic reasoning, but their potential in biometric forensics remains underexplored. In this paper, we present the first systematic zero-shot evaluation of open-source MLLMs for single-image MAD, using publicly available weights and a standardized, reproducible protocol. Across diverse morphing techniques, many MLLMs show non-trivial discriminative ability without any fine-tuning or domain adaptation, and LLaVA1.6-Mistral-7B achieves state-of-the-art performance, surpassing highly competitive task-specific MAD baselines by at least 23% in terms of equal error rate (EER). The results indicate that multimodal pretraining can implicitly encode fine-grained facial inconsistencies indicative of morphing artifacts, enabling zero-shot forensic sensitivity. Our findings position open-source MLLMs as reproducible, interpretable, and competitive foundations for biometric security and forensic image analysis. This emergent capability also highlights new opportunities to develop state-of-the-art MAD systems through targeted fine-tuning or lightweight adaptation, further improving accuracy and efficiency while preserving interpretability. To support future research, all code and evaluation protocols will be released upon publication.

</details>


### [21] [RPT-SR: Regional Prior attention Transformer for infrared image Super-Resolution](https://arxiv.org/abs/2602.15490)
*Youngwan Jin,Incheol Park,Yagiz Nalcakan,Hyeongjin Ju,Sanghyeop Yeo,Shiho Kim*

Main category: cs.CV

TL;DR: RPT-SR是一种针对固定视角红外图像超分辨率的区域先验注意力Transformer，通过融合可学习的区域先验token和局部token，利用场景布局先验提升重建效率。


<details>
  <summary>Details</summary>
Motivation: 通用超分辨率模型在固定视角红外成像场景（如监控、自动驾驶）中存在效率问题，未能充分利用这些场景中固有的强空间先验信息，导致冗余学习和次优性能。

Method: 提出RPT-SR架构，采用双token框架：1）可学习的区域先验token作为场景全局结构的持久记忆；2）捕获当前输入帧特定内容的局部token。通过注意力机制让先验动态调制局部重建过程。

Result: 在涵盖长波（LWIR）和短波（SWIR）光谱的多样化数据集上建立了新的最先进性能，验证了方法的广泛适用性和多功能性。

Conclusion: RPT-SR通过显式编码场景布局信息到注意力机制中，有效解决了固定视角红外图像超分辨率中的效率问题，为红外成像应用提供了更优的解决方案。

Abstract: General-purpose super-resolution models, particularly Vision Transformers, have achieved remarkable success but exhibit fundamental inefficiencies in common infrared imaging scenarios like surveillance and autonomous driving, which operate from fixed or nearly-static viewpoints. These models fail to exploit the strong, persistent spatial priors inherent in such scenes, leading to redundant learning and suboptimal performance. To address this, we propose the Regional Prior attention Transformer for infrared image Super-Resolution (RPT-SR), a novel architecture that explicitly encodes scene layout information into the attention mechanism. Our core contribution is a dual-token framework that fuses (1) learnable, regional prior tokens, which act as a persistent memory for the scene's global structure, with (2) local tokens that capture the frame-specific content of the current input. By utilizing these tokens into an attention, our model allows the priors to dynamically modulate the local reconstruction process. Extensive experiments validate our approach. While most prior works focus on a single infrared band, we demonstrate the broad applicability and versatility of RPT-SR by establishing new state-of-the-art performance across diverse datasets covering both Long-Wave (LWIR) and Short-Wave (SWIR) spectra

</details>


### [22] [LEADER: Lightweight End-to-End Attention-Gated Dual Autoencoder for Robust Minutiae Extraction](https://arxiv.org/abs/2602.15493)
*Raffaele Cappelli,Matteo Ferrara*

Main category: cs.CV

TL;DR: LEADER是一个轻量级端到端注意力门控双自编码器，直接从原始指纹图像提取细节点描述符，无需预处理和后处理，在NIST SD27数据集上F1分数比专用潜指纹提取器高34%。


<details>
  <summary>Details</summary>
Motivation: 指纹识别中的细节点提取正转向深度学习，但真正消除单独预处理和后处理的端到端方法仍然稀缺。需要一种完全端到端的解决方案，能够直接从原始指纹图像映射到细节点描述符。

Method: 提出LEADER架构：1) 集成非极大值抑制和角度解码实现完全端到端推理；2) 使用新颖的"城堡-护城河-城墙"真值编码；3) 双自编码器结构通过注意力门控机制互联；4) 仅需0.9M参数。

Result: 在NIST SD27数据集上达到最先进精度，F1分数比专用潜指纹提取器高34%。样本级分析显示平均排名2.07，在47%样本中排名第一，是第二名的两倍以上。学习到的内部表示与指纹领域特征（分割掩码、方向场、频率图、骨架）一致。GPU推理15ms，CPU推理322ms。

Conclusion: LEADER实现了真正端到端的细节点提取，在精度和计算效率上均优于现有方法，特别是在跨域泛化到潜指纹方面表现出色。公开源代码和预训练权重促进可复现性。

Abstract: Minutiae extraction, a fundamental stage in fingerprint recognition, is increasingly shifting toward deep learning. However, truly end-to-end methods that eliminate separate preprocessing and postprocessing steps remain scarce. This paper introduces LEADER (Lightweight End-to-end Attention-gated Dual autoencodER), a neural network that maps raw fingerprint images to minutiae descriptors, including location, direction, and type. The proposed architecture integrates non-maximum suppression and angular decoding to enable complete end-to-end inference using only 0.9M parameters. It employs a novel "Castle-Moat-Rampart" ground-truth encoding and a dual-autoencoder structure, interconnected through an attention-gating mechanism. Experimental evaluations demonstrate state-of-the-art accuracy on plain fingerprints and robust cross-domain generalization to latent impressions. Specifically, LEADER attains a 34% higher F1-score on the NIST SD27 dataset compared to specialized latent minutiae extractors. Sample-level analysis on this challenging benchmark reveals an average rank of 2.07 among all compared methods, with LEADER securing the first-place position in 47% of the samples-more than doubling the frequency of the second-best extractor. The internal representations learned by the model align with established fingerprint domain features, such as segmentation masks, orientation fields, frequency maps, and skeletons. Inference requires 15ms on GPU and 322ms on CPU, outperforming leading commercial software in computational efficiency. The source code and pre-trained weights are publicly released to facilitate reproducibility.

</details>


### [23] [Semantic-Guided 3D Gaussian Splatting for Transient Object Removal](https://arxiv.org/abs/2602.15516)
*Aditi Prabakaran,Priyesh Shukla*

Main category: cs.CV

TL;DR: 提出基于语义过滤的框架，利用视觉语言模型进行类别感知的瞬态物体去除，解决3D高斯泼溅重建中的鬼影问题


<details>
  <summary>Details</summary>
Motivation: 多视角拍摄中的瞬态物体（如行人、车辆）会在3D高斯泼溅重建中产生鬼影伪影。现有方法要么依赖场景分解导致内存成本高，要么基于运动启发式方法容易受视差模糊影响

Method: 使用视觉语言模型进行类别感知的瞬态物体去除。通过计算渲染视图与干扰物文本提示之间的CLIP相似度得分，在训练迭代中为每个高斯累积得分。超过校准阈值的高斯进行不透明度正则化和定期剪枝

Result: 在RobustNeRF基准测试中，相比原始3DGS在四个序列上重建质量持续提升，同时保持最小内存开销和实时渲染性能。阈值校准和基线比较验证了语义引导在可预测干扰物类别场景中的实用性

Conclusion: 语义分类通过独立于运动模式识别物体类别，解决了视差模糊问题。语义引导为具有可预测干扰物类别的场景中的瞬态物体去除提供了实用策略

Abstract: Transient objects in casual multi-view captures cause ghosting artifacts in 3D Gaussian Splatting (3DGS) reconstruction. Existing solutions relied on scene decomposition at significant memory cost or on motion-based heuristics that were vulnerable to parallax ambiguity. A semantic filtering framework was proposed for category-aware transient removal using vision-language models. CLIP similarity scores between rendered views and distractor text prompts were accumulated per-Gaussian across training iterations. Gaussians exceeding a calibrated threshold underwent opacity regularization and periodic pruning. Unlike motion-based approaches, semantic classification resolved parallax ambiguity by identifying object categories independently of motion patterns. Experiments on the RobustNeRF benchmark demonstrated consistent improvement in reconstruction quality over vanilla 3DGS across four sequences, while maintaining minimal memory overhead and real-time rendering performance. Threshold calibration and comparisons with baselines validated semantic guidance as a practical strategy for transient removal in scenarios with predictable distractor categories.

</details>


### [24] [Advanced Acceptance Score: A Holistic Measure for Biometric Quantification](https://arxiv.org/abs/2602.15535)
*Aman Verma,Seshan Srirangarajan,Sumantra Dutta Roy*

Main category: cs.CV

TL;DR: 提出了一套全面的手势生物特征质量评估指标，重点关注分数排名顺序和相关性，通过综合考虑排名偏差、高低排名手势的奖励、趋势对应性以及身份特征解耦等因素，构建了先进的接受分数评估体系。


<details>
  <summary>Details</summary>
Motivation: 现有生物特征容量估计方法依赖错误率，但这些错误率无法评估分数质量的好坏。需要开发能够准确评估手势生物特征分数质量的综合评估指标。

Method: 首先确定输出分数的排名顺序和相关性作为评估基础，考虑排名偏差以及高低排名手势的奖励机制，补偿输出分数与真实分数趋势的对应性，并将手势身份特征的解耦作为折扣因子，通过适当加权整合这些元素，构建了先进的接受分数评估指标。

Result: 在三个数据集上使用五个SOTA模型进行深入实验，结果显示使用本文提出的指标选择的最优分数比现有其他指标更合适，且提出的指标与现有指标存在相关性，进一步验证了其可靠性。

Conclusion: 提出了一套全面的手势生物特征质量评估指标，能够更准确地评估分数质量，代码已开源供研究社区使用。

Abstract: Quantifying biometric characteristics within hand gestures involve derivation of fitness scores from a gesture and identity aware feature space. However, evaluating the quality of these scores remains an open question. Existing biometric capacity estimation literature relies upon error rates. But these rates do not indicate goodness of scores. Thus, in this manuscript we present an exhaustive set of evaluation measures. We firstly identify ranking order and relevance of output scores as the primary basis for evaluation. In particular, we consider both rank deviation as well as rewards for: (i) higher scores of high ranked gestures and (ii) lower scores of low ranked gestures. We also compensate for correspondence between trends of output and ground truth scores. Finally, we account for disentanglement between identity features of gestures as a discounting factor. Integrating these elements with adequate weighting, we formulate advanced acceptance score as a holistic evaluation measure. To assess effectivity of the proposed we perform in-depth experimentation over three datasets with five state-of-the-art (SOTA) models. Results show that the optimal score selected with our measure is more appropriate than existing other measures. Also, our proposed measure depicts correlation with existing measures. This further validates its reliability. We have made our \href{https://github.com/AmanVerma2307/MeasureSuite}{code} public.

</details>


### [25] [Dynamic Training-Free Fusion of Subject and Style LoRAs](https://arxiv.org/abs/2602.15539)
*Qinglong Cao,Yuntian Chen,Chao Ma,Xiaokang Yang*

Main category: cs.CV

TL;DR: 提出动态无训练LoRA融合框架，通过特征层KL散度选择和度量引导潜空间调整，实现主题与风格的连贯合成


<details>
  <summary>Details</summary>
Motivation: 现有LoRA融合方法多采用静态统计启发式权重融合，偏离了LoRA学习自适应特征调整的初衷，且忽略了采样输入的随机性，需要更动态的融合方案

Method: 提出两阶段动态融合框架：前向传播时在LoRA应用层计算基模型与主题/风格LoRA特征的KL散度，自适应选择融合权重；反向去噪阶段通过CLIP和DINO等目标度量的梯度修正提供持续语义和风格指导

Result: 在多样化主题-风格组合上的实验表明，该方法在定性和定量上均优于现有最先进的LoRA融合方法

Conclusion: 通过特征层选择和度量引导潜空间调整的互补机制，实现了无需重新训练的动态主题-风格合成，为LoRA融合提供了更灵活有效的解决方案

Abstract: Recent studies have explored the combination of multiple LoRAs to simultaneously generate user-specified subjects and styles. However, most existing approaches fuse LoRA weights using static statistical heuristics that deviate from LoRA's original purpose of learning adaptive feature adjustments and ignore the randomness of sampled inputs. To address this, we propose a dynamic training-free fusion framework that operates throughout the generation process. During the forward pass, at each LoRA-applied layer, we dynamically compute the KL divergence between the base model's original features and those produced by subject and style LoRAs, respectively, and adaptively select the most appropriate weights for fusion. In the reverse denoising stage, we further refine the generation trajectory by dynamically applying gradient-based corrections derived from objective metrics such as CLIP and DINO scores, providing continuous semantic and stylistic guidance. By integrating these two complementary mechanisms-feature-level selection and metric-guided latent adjustment-across the entire diffusion timeline, our method dynamically achieves coherent subject-style synthesis without any retraining. Extensive experiments across diverse subject-style combinations demonstrate that our approach consistently outperforms state-of-the-art LoRA fusion methods both qualitatively and quantitatively.

</details>


### [26] [Revealing and Enhancing Core Visual Regions: Harnessing Internal Attention Dynamics for Hallucination Mitigation in LVLMs](https://arxiv.org/abs/2602.15556)
*Guangtao Lyu,Qi Liu,Chenghao Xu,Jiexi Yan,Muli Yang,Xueting Li,Fen Fang,Cheng Deng*

Main category: cs.CV

TL;DR: 提出PADE方法，通过增强正注意力动态来减少LVLM幻觉，无需训练即可提升视觉基础能力


<details>
  <summary>Details</summary>
Motivation: 现有训练免费方法存在计算开销大、可能引入干扰、易受注意力下沉现象影响等问题，而LVLM内部的正注意力动态自然揭示了语义核心视觉区域

Method: 提出正注意力动态增强(PADE)：构建PAD图识别语义核心视觉区域，应用每头中位数绝对偏差缩放自适应控制干预强度，利用系统令牌补偿维持对复杂用户指令的注意力

Result: 在多个LVLM和基准测试上的实验表明，PADE改善了视觉基础并减少了幻觉，验证了利用内部注意力动态进行可靠多模态推理的有效性

Conclusion: 通过增强内部正注意力动态，PADE提供了一种无需训练的有效方法来减少LVLM幻觉，提升多模态推理的可靠性

Abstract: LVLMs have achieved strong multimodal reasoning capabilities but remain prone to hallucinations, producing outputs inconsistent with visual inputs or user instructions. Existing training-free methods, including contrastive decoding and auxiliary expert models, which incur several times more computational overhead and may introduce potential interference, as well as static internal signal enhancement, are often vulnerable to the attention sink phenomenon. We find that internal Positive Attention Dynamics (PAD) in LVLMs naturally reveal semantically core visual regions under the distortions of attention sinks. Based on this, we propose Positive Attention Dynamics Enhancement (PADE), a training-free attention intervention that constructs a PAD map to identify semantically core visual regions, applies per-head Median Absolute Deviation Scaling to adaptively control the intervention strength, and leverages System-Token Compensation to maintain attention to complex user instructions and support long-term output consistency. Experiments on multiple LVLMs and benchmarks show that PADE improves visual grounding and reduces hallucinations, validating the effectiveness of leveraging internal attention dynamics for reliable multimodal reasoning.

</details>


### [27] [Intracoronary Optical Coherence Tomography Image Processing and Vessel Classification Using Machine Learning](https://arxiv.org/abs/2602.15579)
*Amal Lahchim,Lambros Athanasiou*

Main category: cs.CV

TL;DR: 提出一种用于冠状动脉OCT图像血管分割与分类的全自动机器学习流程，通过预处理、伪影去除、聚类和特征提取实现高精度血管边界检测


<details>
  <summary>Details</summary>
Motivation: 冠状动脉OCT图像存在噪声、成像伪影和组织结构复杂等问题，需要自动化解决方案来准确分割和分类血管结构，以支持临床决策和实时医学图像处理

Method: 集成图像预处理、导丝伪影去除、极坐标到笛卡尔坐标转换、无监督K-means聚类和局部特征提取，使用逻辑回归和支持向量机进行像素级血管分类

Result: 实验结果显示优异性能，精确率、召回率和F1分数最高达1.00，总体分类准确率达99.68%，同时保持低计算复杂度且需要最少的人工标注

Conclusion: 该方法为自动化OCT图像分析提供了可靠高效的解决方案，在临床决策支持和实时医学图像处理方面具有潜在应用价值

Abstract: Intracoronary Optical Coherence Tomography (OCT) enables high-resolution visualization of coronary vessel anatomy but presents challenges due to noise, imaging artifacts, and complex tissue structures. This paper proposes a fully automated pipeline for vessel segmentation and classification in OCT images using machine learning techniques. The proposed method integrates image preprocessing, guidewire artifact removal, polar-to-Cartesian transformation, unsupervised K-means clustering, and local feature extraction. These features are used to train Logistic Regression and Support Vector Machine classifiers for pixel-wise vessel classification. Experimental results demonstrate excellent performance, achieving precision, recall, and F1-score values up to 1.00 and overall classification accuracy of 99.68%. The proposed approach provides accurate vessel boundary detection while maintaining low computational complexity and requiring minimal manual annotation. This method offers a reliable and efficient solution for automated OCT image analysis and has potential applications in clinical decision support and real-time medical image processing.

</details>


### [28] [An Industrial Dataset for Scene Acquisitions and Functional Schematics Alignment](https://arxiv.org/abs/2602.15584)
*Flavien Armangeon,Thibaud Ehret,Enric Meinhardt-Llopis,Rafael Grompone von Gioi,Guillaume Thibault,Marc Petit,Gabriele Facciolo*

Main category: cs.CV

TL;DR: IRIS-v2数据集为工业设施数字孪生对齐提供综合数据，通过分割与图匹配减少对齐时间


<details>
  <summary>Details</summary>
Motivation: 老旧工业设施缺乏原生数字模型，当前基于图像和LiDAR的手动对齐方法繁琐且难以规模化，模式图与现实不一致以及工业数据集稀缺使该问题具有挑战性

Method: 提出IRIS-v2综合数据集，包含图像、点云、2D标注框和分割掩码、CAD模型、3D管道布线信息及P&ID图；通过分割与图匹配相结合进行对齐

Result: 通过实际案例研究展示对齐方法，旨在显著减少对齐任务所需时间

Conclusion: IRIS-v2数据集填补了工业数字孪生对齐研究的数据空白，为后续研究提供支持，分割与图匹配结合的方法有望提高对齐效率

Abstract: Aligning functional schematics with 2D and 3D scene acquisitions is crucial for building digital twins, especially for old industrial facilities that lack native digital models. Current manual alignment using images and LiDAR data does not scale due to tediousness and complexity of industrial sites. Inconsistencies between schematics and reality, and the scarcity of public industrial datasets, make the problem both challenging and underexplored. This paper introduces IRIS-v2, a comprehensive dataset to support further research. It includes images, point clouds, 2D annotated boxes and segmentation masks, a CAD model, 3D pipe routing information, and the P&ID (Piping and Instrumentation Diagram). The alignment is experimented on a practical case study, aiming at reducing the time required for this task by combining segmentation and graph matching.

</details>


### [29] [Concept-Enhanced Multimodal RAG: Towards Interpretable and Accurate Radiology Report Generation](https://arxiv.org/abs/2602.15650)
*Marco Salmè,Federico Siciliano,Fabrizio Silvestri,Paolo Soda,Rosa Sicilia,Valerio Guarrasi*

Main category: cs.CV

TL;DR: CEMRAG框架通过将视觉表征分解为可解释的临床概念并与多模态检索增强生成结合，同时提升放射报告生成的解释性和事实准确性，挑战了解释性与性能之间的权衡假设。


<details>
  <summary>Details</summary>
Motivation: 当前基于视觉语言模型的放射报告生成系统存在解释性不足和幻觉问题，临床采用受限。现有研究通常将解释性和准确性视为独立目标，缺乏统一解决方案。

Method: 提出概念增强多模态RAG框架，将视觉表征分解为可解释的临床概念，并与多模态检索增强生成结合，通过丰富的上下文提示改进放射报告生成。

Result: 在MIMIC-CXR和IU X-Ray数据集上，跨多种VLM架构、训练机制和检索配置的实验显示，相比传统RAG和仅概念基线，在临床准确性指标和标准NLP指标上均取得一致改进。

Conclusion: 透明视觉概念可以增强而非损害医学VLM的诊断准确性，模块化设计将解释性分解为视觉透明度和结构化语言模型条件，为临床可信的AI辅助放射学提供了原则性路径。

Abstract: Radiology Report Generation (RRG) through Vision-Language Models (VLMs) promises to reduce documentation burden, improve reporting consistency, and accelerate clinical workflows. However, their clinical adoption remains limited by the lack of interpretability and the tendency to hallucinate findings misaligned with imaging evidence. Existing research typically treats interpretability and accuracy as separate objectives, with concept-based explainability techniques focusing primarily on transparency, while Retrieval-Augmented Generation (RAG) methods targeting factual grounding through external retrieval. We present Concept-Enhanced Multimodal RAG (CEMRAG), a unified framework that decomposes visual representations into interpretable clinical concepts and integrates them with multimodal RAG. This approach exploits enriched contextual prompts for RRG, improving both interpretability and factual accuracy. Experiments on MIMIC-CXR and IU X-Ray across multiple VLM architectures, training regimes, and retrieval configurations demonstrate consistent improvements over both conventional RAG and concept-only baselines on clinical accuracy metrics and standard NLP measures. These results challenge the assumed trade-off between interpretability and performance, showing that transparent visual concepts can enhance rather than compromise diagnostic accuracy in medical VLMs. Our modular design decomposes interpretability into visual transparency and structured language model conditioning, providing a principled pathway toward clinically trustworthy AI-assisted radiology.

</details>


### [30] [A Novel Public Dataset for Strawberry (Fragaria x ananassa) Ripeness Detection and Comparative Evaluation of YOLO-Based Models](https://arxiv.org/abs/2602.15656)
*Mustafa Yurdakul,Zeynep Sena Bastug,Ali Emre Gok,Sakir Taşdemir*

Main category: cs.CV

TL;DR: 提出新的公开草莓成熟度数据集，包含566张图像和1201个标注对象，在不同光照和温室条件下采集，并使用YOLO系列模型进行性能比较。


<details>
  <summary>Details</summary>
Motivation: 草莓成熟度判断对生产者和消费者都至关重要，但传统视觉评估方法主观且误差大。现有研究缺乏公开全面的数据集，难以进行有效比较。

Method: 创建新的公开草莓成熟度数据集，包含土耳其两个不同温室中采集的566张图像和1201个标注对象。使用YOLOv8、YOLOv9和YOLO11模型进行对比测试。

Result: YOLOv9c模型获得最高精确率90.94%，YOLO11s模型获得最高召回率83.74%。YOLOv8s模型在mAP@50指标上表现最佳，达到86.09%。

Conclusion: 中小型模型在此类数据集上表现更平衡高效，为智慧农业应用建立了基础参考点。公开数据集有助于推动该领域研究。

Abstract: The strawberry (Fragaria x ananassa), known worldwide for its economic value and nutritional richness, is a widely cultivated fruit. Determining the correct ripeness level during the harvest period is crucial for both preventing losses for producers and ensuring consumers receive a quality product. However, traditional methods, i.e., visual assessments alone, can be subjective and have a high margin of error. Therefore, computer-assisted systems are needed. However, the scarcity of comprehensive datasets accessible to everyone in the literature makes it difficult to compare studies in this field. In this study, a new and publicly available strawberry ripeness dataset, consisting of 566 images and 1,201 labeled objects, prepared under variable light and environmental conditions in two different greenhouses in Turkey, is presented to the literature. Comparative tests conducted on the data set using YOLOv8, YOLOv9, and YOLO11-based models showed that the highest precision value was 90.94% in the YOLOv9c model, while the highest recall value was 83.74% in the YOLO11s model. In terms of the general performance criterion mAP@50, YOLOv8s was the best performing model with a success rate of 86.09%. The results show that small and medium-sized models work more balanced and efficiently on this type of dataset, while also establishing a fundamental reference point for smart agriculture applications.

</details>


### [31] [Bayesian Optimization for Design Parameters of 3D Image Data Analysis](https://arxiv.org/abs/2602.15660)
*David Exler,Joaquin Eduardo Urrutia Gómez,Martin Krüger,Maike Schliephake,John Jbeily,Mario Vitacolonna,Rüdiger Rudolf,Markus Reischl*

Main category: cs.CV

TL;DR: 提出3D数据分析优化流程，通过两阶段贝叶斯优化自动选择分割和分类模型参数，减少人工调参负担


<details>
  <summary>Details</summary>
Motivation: 3D生物医学图像分析中，手动选择模型和调参是主要瓶颈，需要自动化解决方案来降低实践难度

Method: 两阶段贝叶斯优化：第一阶段选择分割模型并优化后处理参数，使用领域适应的合成基准数据集；第二阶段优化分类器设计选择，包括编码器、分类头架构、先验知识和预训练策略，并包含辅助类别标注工作流程

Result: 在四个案例研究中，该流程能有效为单个数据集识别出高效的模型和参数配置

Conclusion: 提出的3D数据分析优化流程能够自动化模型选择和参数优化，显著减少人工干预，提高生物医学图像分析的效率和可访问性

Abstract: Deep learning-based segmentation and classification are crucial to large-scale biomedical imaging, particularly for 3D data, where manual analysis is impractical. Although many methods exist, selecting suitable models and tuning parameters remains a major bottleneck in practice. Hence, we introduce the 3D data Analysis Optimization Pipeline, a method designed to facilitate the design and parameterization of segmentation and classification using two Bayesian Optimization stages. First, the pipeline selects a segmentation model and optimizes postprocessing parameters using a domain-adapted syntactic benchmark dataset. To ensure a concise evaluation of segmentation performance, we introduce a segmentation quality metric that serves as the objective function. Second, the pipeline optimizes design choices of a classifier, such as encoder and classifier head architectures, incorporation of prior knowledge, and pretraining strategies. To reduce manual annotation effort, this stage includes an assisted class-annotation workflow that extracts predicted instances from the segmentation results and sequentially presents them to the operator, eliminating the need for manual tracking. In four case studies, the 3D data Analysis Optimization Pipeline efficiently identifies effective model and parameter configurations for individual datasets.

</details>


### [32] [Criteria-first, semantics-later: reproducible structure discovery in image-based sciences](https://arxiv.org/abs/2602.15712)
*Jan Bumberger*

Main category: cs.CV

TL;DR: 提出从"语义优先"转向"标准优先"的图像分析范式，将结构提取与语义映射分离，以应对科学发现中的标签漂移和跨域可比性问题


<details>
  <summary>Details</summary>
Motivation: 当前图像分析主要采用语义优先范式，依赖领域特定标签来恢复结构。这种方法在开放科学发现、跨传感器/站点可比性、以及长期监测中标签漂移等场景下系统性失效，需要新的分析范式

Method: 提出"标准优先、语义后置"的统一框架：1) 基于明确最优标准进行无语义的结构提取，生成稳定分区、结构场或层次；2) 将语义作为下游映射，从发现的结构产品映射到领域本体或词汇表

Result: 该框架提供了跨图像科学的可重复分析支架，支持多元解释和明确交叉映射，无需重写上游提取。基于控制论、观察即区分和信息论的信息与意义分离原则

Conclusion: 标准优先组件在标签不可扩展时反复出现，该范式对超越类别准确性的验证、将结构产品作为FAIR和AI就绪的数字对象用于长期监测和数字孪生具有重要意义

Abstract: Across the natural and life sciences, images have become a primary measurement modality, yet the dominant analytic paradigm remains semantics-first. Structure is recovered by predicting or enforcing domain-specific labels. This paradigm fails systematically under the conditions that make image-based science most valuable, including open-ended scientific discovery, cross-sensor and cross-site comparability, and long-term monitoring in which domain ontologies and associated label sets drift culturally, institutionally, and ecologically. A deductive inversion is proposed in the form of criteria-first and semantics-later. A unified framework for criteria-first structure discovery is introduced. It separates criterion-defined, semantics-free structure extraction from downstream semantic mapping into domain ontologies or vocabularies and provides a domain-general scaffold for reproducible analysis across image-based sciences. Reproducible science requires that the first analytic layer perform criterion-driven, semantics-free structure discovery, yielding stable partitions, structural fields, or hierarchies defined by explicit optimality criteria rather than local domain ontologies. Semantics is not discarded; it is relocated downstream as an explicit mapping from the discovered structural product to a domain ontology or vocabulary, enabling plural interpretations and explicit crosswalks without rewriting upstream extraction. Grounded in cybernetics, observation-as-distinction, and information theory's separation of information from meaning, the argument is supported by cross-domain evidence showing that criteria-first components recur whenever labels do not scale. Finally, consequences are outlined for validation beyond class accuracy and for treating structural products as FAIR, AI-ready digital objects for long-term monitoring and digital twins.

</details>


### [33] [ToaSt: Token Channel Selection and Structured Pruning for Efficient ViT](https://arxiv.org/abs/2602.15720)
*Hyunchan Moon,Cheonjun Park,Steven L. Waslander*

Main category: cs.CV

TL;DR: ToaSt是一个解耦的ViT压缩框架，通过耦合头结构化剪枝处理注意力模块，通过Token Channel Selection处理FFN模块，在减少计算量的同时保持甚至提升模型精度。


<details>
  <summary>Details</summary>
Motivation: Vision Transformers虽然性能优异但计算成本过高，现有压缩方法如结构化权重剪枝需要长时间重训练，而token压缩存在全局传播导致的优化问题，需要更高效的压缩方案。

Method: 提出解耦框架ToaSt：对Multi-Head Self-Attention模块采用耦合头结构化剪枝，利用注意力操作特性增强鲁棒性；对占FLOPs 60%以上的Feed-Forward Networks引入Token Channel Selection，避免全局传播问题，有效过滤冗余噪声。

Result: 在9个不同模型（包括DeiT、ViT-MAE、Swin Transformer）上评估，ToaSt在精度和效率之间达到优越平衡。在ViT-MAE-Huge上实现88.52%准确率（提升1.64%），同时减少39.4% FLOPs。在下游任务上有效迁移，在COCO目标检测上达到52.2 mAP。

Conclusion: ToaSt通过解耦策略对ViT不同组件采用专门化压缩方法，解决了现有压缩技术的局限性，实现了高效且准确的模型压缩，在多种模型和任务上表现优异。

Abstract: Vision Transformers (ViTs) have achieved remarkable success across various vision tasks, yet their deployment is often hindered by prohibitive computational costs. While structured weight pruning and token compression have emerged as promising solutions, they suffer from prolonged retraining times and global propagation that creates optimization challenges, respectively. We propose ToaSt, a decoupled framework applying specialized strategies to distinct ViT components. We apply coupled head-wise structured pruning to Multi-Head Self-Attention modules, leveraging attention operation characteristics to enhance robustness. For Feed-Forward Networks (over 60\% of FLOPs), we introduce Token Channel Selection (TCS) that enhances compression ratios while avoiding global propagation issues. Our analysis reveals TCS effectively filters redundant noise during selection. Extensive evaluations across nine diverse models, including DeiT, ViT-MAE, and Swin Transformer, demonstrate that ToaSt achieves superior trade-offs between accuracy and efficiency, consistently outperforming existing baselines. On ViT-MAE-Huge, ToaSt achieves 88.52\% accuracy (+1.64 \%) with 39.4\% FLOPs reduction. ToaSt transfers effectively to downstream tasks, cccccachieving 52.2 versus 51.9 mAP on COCO object detection. Code and models will be released upon acceptance.

</details>


### [34] [Learning to Retrieve Navigable Candidates for Efficient Vision-and-Language Navigation](https://arxiv.org/abs/2602.15724)
*Shutian Gu,Chengkai Huang,Ruoyu Wang,Lina Yao*

Main category: cs.CV

TL;DR: 提出一个检索增强框架，通过指令级轨迹检索和候选方向剪枝，提升基于LLM的视觉语言导航效率，无需修改或微调底层语言模型。


<details>
  <summary>Details</summary>
Motivation: 基于提示的LLM导航存在决策效率低下的问题，因为模型需要在每一步从头解释指令，并在嘈杂冗长的可导航候选中进行推理。需要一种无需修改LLM本身就能提高效率和稳定性的方法。

Method: 提出双层检索框架：1) 指令级嵌入检索器选择语义相似的导航轨迹作为上下文示例，提供任务特定先验；2) 模仿学习的候选检索器在LLM推理前剪枝不相关的导航方向，减少动作歧义和提示复杂度。两个模块都是轻量级、模块化且独立于LLM训练。

Result: 在Room-to-Room基准测试中，在已见和未见环境上均显著提升了成功率、Oracle成功率和SPL指标。消融研究表明指令级示例检索和候选剪枝对全局指导和逐步决策效率有互补性贡献。

Conclusion: 检索增强的决策支持是增强基于LLM的视觉语言导航的有效且可扩展策略，通过提供任务先验和减少决策复杂度来提升LLM导航性能。

Abstract: Vision-and-Language Navigation (VLN) requires an agent to follow natural-language instructions and navigate through previously unseen environments. Recent approaches increasingly employ large language models (LLMs) as high-level navigators due to their flexibility and reasoning capability. However, prompt-based LLM navigation often suffers from inefficient decision-making, as the model must repeatedly interpret instructions from scratch and reason over noisy and verbose navigable candidates at each step. In this paper, we propose a retrieval-augmented framework to improve the efficiency and stability of LLM-based VLN without modifying or fine-tuning the underlying language model. Our approach introduces retrieval at two complementary levels. At the episode level, an instruction-level embedding retriever selects semantically similar successful navigation trajectories as in-context exemplars, providing task-specific priors for instruction grounding. At the step level, an imitation-learned candidate retriever prunes irrelevant navigable directions before LLM inference, reducing action ambiguity and prompt complexity. Both retrieval modules are lightweight, modular, and trained independently of the LLM. We evaluate our method on the Room-to-Room (R2R) benchmark. Experimental results demonstrate consistent improvements in Success Rate, Oracle Success Rate, and SPL on both seen and unseen environments. Ablation studies further show that instruction-level exemplar retrieval and candidate pruning contribute complementary benefits to global guidance and step-wise decision efficiency. These results indicate that retrieval-augmented decision support is an effective and scalable strategy for enhancing LLM-based vision-and-language navigation.

</details>


### [35] [Spanning the Visual Analogy Space with a Weight Basis of LoRAs](https://arxiv.org/abs/2602.15727)
*Hila Manor,Rinon Gal,Haggai Maron,Tomer Michaeli,Gal Chechik*

Main category: cs.CV

TL;DR: LoRWeB：通过动态组合LoRA基模块实现视觉类比学习的新方法，相比固定LoRA模块能更好地泛化到未见过的视觉变换


<details>
  <summary>Details</summary>
Motivation: 现有方法使用单一LoRA模块来学习视觉类比变换，但固定模块难以捕捉多样化的视觉变换空间，限制了泛化能力。需要一种更灵活的方法来处理复杂的视觉变换。

Method: 提出LoRWeB方法：1）学习一组LoRA基模块，覆盖不同的视觉变换空间；2）设计轻量级编码器，根据输入类比对动态选择和加权这些基模块，实现推理时的动态组合。

Result: 综合评估表明，LoRWeB在视觉类比学习任务上达到最先进性能，显著提高了对未见视觉变换的泛化能力。

Conclusion: LoRA基分解是实现灵活视觉操作的有前景方向，动态组合变换基元的方法比固定适应模块更具优势。

Abstract: Visual analogy learning enables image manipulation through demonstration rather than textual description, allowing users to specify complex transformations difficult to articulate in words. Given a triplet $\{\mathbf{a}$, $\mathbf{a}'$, $\mathbf{b}\}$, the goal is to generate $\mathbf{b}'$ such that $\mathbf{a} : \mathbf{a}' :: \mathbf{b} : \mathbf{b}'$. Recent methods adapt text-to-image models to this task using a single Low-Rank Adaptation (LoRA) module, but they face a fundamental limitation: attempting to capture the diverse space of visual transformations within a fixed adaptation module constrains generalization capabilities. Inspired by recent work showing that LoRAs in constrained domains span meaningful, interpolatable semantic spaces, we propose LoRWeB, a novel approach that specializes the model for each analogy task at inference time through dynamic composition of learned transformation primitives, informally, choosing a point in a "space of LoRAs". We introduce two key components: (1) a learnable basis of LoRA modules, to span the space of different visual transformations, and (2) a lightweight encoder that dynamically selects and weighs these basis LoRAs based on the input analogy pair. Comprehensive evaluations demonstrate our approach achieves state-of-the-art performance and significantly improves generalization to unseen visual transformations. Our findings suggest that LoRA basis decompositions are a promising direction for flexible visual manipulation. Code and data are in https://research.nvidia.com/labs/par/lorweb

</details>


### [36] [Language and Geometry Grounded Sparse Voxel Representations for Holistic Scene Understanding](https://arxiv.org/abs/2602.15734)
*Guile Wu,David Huang,Bingbing Liu,Dongfeng Bai*

Main category: cs.CV

TL;DR: 提出了一种基于语言和几何的稀疏体素表示方法，在统一框架中协同建模3D场景的外观、语义和几何，实现整体场景理解和重建。


<details>
  <summary>Details</summary>
Motivation: 现有3D开放词汇场景理解方法主要关注从2D基础模型蒸馏语言特征到3D特征场，但忽视了场景外观、语义和几何之间的协同作用，导致场景理解偏离几何结构并与重建过程脱节。

Method: 使用3D稀疏体素作为基元，构建外观场、密度场、特征场和置信度场来整体表示3D场景。通过特征调制模块促进各场之间的协同，从2D基础模型蒸馏语言特征到3D场景模型。同时通过深度相关性正则化和模式一致性正则化，将几何知识从几何基础模型蒸馏到3D场景表示中。

Result: 大量实验表明，该方法在整体场景理解和重建方面相比最先进方法实现了优越的整体性能。

Conclusion: 提出的统一框架能够协同建模3D场景的外观、语义和几何，解决了现有方法中场景理解与几何结构脱节的问题，实现了更好的场景理解和重建效果。

Abstract: Existing 3D open-vocabulary scene understanding methods mostly emphasize distilling language features from 2D foundation models into 3D feature fields, but largely overlook the synergy among scene appearance, semantics, and geometry. As a result, scene understanding often deviates from the underlying geometric structure of scenes and becomes decoupled from the reconstruction process. In this work, we propose a novel approach that leverages language and geometry grounded sparse voxel representations to comprehensively model appearance, semantics, and geometry within a unified framework. Specifically, we use 3D sparse voxels as primitives and employ an appearance field, a density field, a feature field, and a confidence field to holistically represent a 3D scene. To promote synergy among the appearance, density, and feature fields, we construct a feature modulation module and distill language features from a 2D foundation model into our 3D scene model. In addition, we integrate geometric distillation into feature field distillation to transfer geometric knowledge from a geometry foundation model to our 3D scene representations via depth correlation regularization and pattern consistency regularization. These components work together to synergistically model the appearance, semantics, and geometry of the 3D scene within a unified framework. Extensive experiments demonstrate that our approach achieves superior overall performance compared with state-of-the-art methods in holistic scene understanding and reconstruction.

</details>


### [37] [RaCo: Ranking and Covariance for Practical Learned Keypoints](https://arxiv.org/abs/2602.15755)
*Abhiram Shenoi,Philipp Lindenberger,Paul-Edouard Sarlin,Marc Pollefeys*

Main category: cs.CV

TL;DR: RaCo是一个轻量级神经网络，通过学习稳健且通用的关键点来支持多种3D计算机视觉任务，无需共视图像对训练，通过数据增强实现旋转鲁棒性，在关键点可重复性和两视图匹配方面达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有关键点检测方法通常需要共视图像对进行训练，且对旋转变化的鲁棒性有限。本文旨在开发一个无需共视图像对、具有强旋转鲁棒性的轻量级关键点检测网络，适用于多种3D视觉任务。

Method: RaCo包含三个核心组件：可重复关键点检测器、可微分排序器（在有限关键点数量下最大化匹配）和协方差估计器（量化度量尺度下的空间不确定性）。仅使用透视图像裁剪进行训练，通过大量数据增强实现旋转鲁棒性，无需计算昂贵的等变网络架构。

Result: 在多个挑战性数据集上评估，RaCo在关键点可重复性和两视图匹配方面表现出最先进的性能，特别是在大平面内旋转情况下表现优异。无需额外标签即可独立估计关键点排序和度量协方差。

Conclusion: RaCo提供了一种有效且简单的策略，能够检测可解释且可重复的兴趣点，适用于多种3D计算机视觉任务。代码已开源，便于研究和应用。

Abstract: This paper introduces RaCo, a lightweight neural network designed to learn robust and versatile keypoints suitable for a variety of 3D computer vision tasks. The model integrates three key components: the repeatable keypoint detector, a differentiable ranker to maximize matches with a limited number of keypoints, and a covariance estimator to quantify spatial uncertainty in metric scale. Trained on perspective image crops only, RaCo operates without the need for covisible image pairs. It achieves strong rotational robustness through extensive data augmentation, even without the use of computationally expensive equivariant network architectures. The method is evaluated on several challenging datasets, where it demonstrates state-of-the-art performance in keypoint repeatability and two-view matching, particularly under large in-plane rotations. Ultimately, RaCo provides an effective and simple strategy to independently estimate keypoint ranking and metric covariance without additional labels, detecting interpretable and repeatable interest points. The code is available at https://github.com/cvg/RaCo.

</details>


### [38] [Understanding vs. Generation: Navigating Optimization Dilemma in Multimodal Models](https://arxiv.org/abs/2602.15772)
*Sen Ye,Mengde Xu,Shuyang Gu,Di He,Liwei Wang,Han Hu*

Main category: cs.CV

TL;DR: 提出R3框架解决多模态模型中生成与理解能力的权衡问题，通过"生成-理解-再生成"的多步过程，利用理解能力提升生成效果


<details>
  <summary>Details</summary>
Motivation: 当前多模态模型面临一个关键挑战：增强生成能力往往以牺牲理解为代价，反之亦然。研究发现生成与理解之间可能存在冲突，导致模型内部形成竞争动态

Method: 提出Reason-Reflect-Refine (R3)框架，将单步生成任务重构为"生成-理解-再生成"的多步过程，明确利用模型的理解能力来指导生成过程

Result: 成功缓解了优化困境，实现了更强的生成结果，并提升了与生成过程相关的理解能力

Conclusion: R3框架为设计下一代统一多模态模型提供了有价值的见解，通过协调生成与理解能力实现更好的性能平衡

Abstract: Current research in multimodal models faces a key challenge where enhancing generative capabilities often comes at the expense of understanding, and vice versa. We analyzed this trade-off and identify the primary cause might be the potential conflict between generation and understanding, which creates a competitive dynamic within the model. To address this, we propose the Reason-Reflect-Refine (R3) framework. This innovative algorithm re-frames the single-step generation task into a multi-step process of "generate-understand-regenerate". By explicitly leveraging the model's understanding capability during generation, we successfully mitigate the optimization dilemma, achieved stronger generation results and improved understanding ability which are related to the generation process. This offers valuable insights for designing next-generation unified multimodal models. Code is available at https://github.com/sen-ye/R3.

</details>


### [39] [NeRFscopy: Neural Radiance Fields for in-vivo Time-Varying Tissues from Endoscopy](https://arxiv.org/abs/2602.15775)
*Laura Salort-Benejam,Antonio Agudo*

Main category: cs.CV

TL;DR: NeRFscopy：一种用于内窥镜视频的自监督神经渲染管道，可实现可变形组织的3D重建和新视角合成


<details>
  <summary>Details</summary>
Motivation: 内窥镜在医学成像中至关重要，但现有方法面临组织可变形、单目相机、光照变化、遮挡和未知相机轨迹等挑战。需要开发鲁棒的动态3D重建管道来增强可视化、提高诊断准确性、辅助治疗规划和指导手术。

Method: 提出NeRFscopy自监督管道，包含一个具有规范辐射场和时间相关变形场的可变形模型，变形场通过SE(3)变换参数化。引入复杂项有效利用彩色图像，无需任何模板或预训练模型，仅从数据中学习3D隐式模型。

Result: NeRFscopy在新视角合成方面取得了准确结果，在各种具有挑战性的内窥镜场景中优于竞争方法。

Conclusion: NeRFscopy为可变形内窥镜组织提供了一种有效的自监督3D重建和新视角合成方法，能够应对内窥镜视频中的多种挑战，具有临床应用潜力。

Abstract: Endoscopy is essential in medical imaging, used for diagnosis, prognosis and treatment. Developing a robust dynamic 3D reconstruction pipeline for endoscopic videos could enhance visualization, improve diagnostic accuracy, aid in treatment planning, and guide surgery procedures. However, challenges arise due to the deformable nature of the tissues, the use of monocular cameras, illumination changes, occlusions and unknown camera trajectories. Inspired by neural rendering, we introduce NeRFscopy, a self-supervised pipeline for novel view synthesis and 3D reconstruction of deformable endoscopic tissues from a monocular video. NeRFscopy includes a deformable model with a canonical radiance field and a time-dependent deformation field parameterized by SE(3) transformations. In addition, the color images are efficiently exploited by introducing sophisticated terms to learn a 3D implicit model without assuming any template or pre-trained model, solely from data. NeRFscopy achieves accurate results in terms of novel view synthesis, outperforming competing methods across various challenging endoscopy scenes.

</details>


### [40] [Meteorological data and Sky Images meets Neural Models for Photovoltaic Power Forecasting](https://arxiv.org/abs/2602.15782)
*Ines Montoya-Espinagosa,Antonio Agudo*

Main category: cs.CV

TL;DR: 提出一种结合天空图像、光伏历史数据和气象数据的多模态混合方法，用于短期和长期光伏预测，特别关注云天气条件下的预测精度和爬坡事件预测。


<details>
  <summary>Details</summary>
Motivation: 随着可再生能源特别是太阳能的广泛使用，光伏发电的波动性给电网运行带来挑战。需要改进预测方法，特别是在多云条件下提高预测精度，更好地预测爬坡事件，支持电网高效运行和太阳能波动性管理。

Method: 采用多模态混合方法，结合天空图像、光伏历史数据和气象数据。使用深度神经网络模型进行即时预测和预报，整合单个和多个气象变量以及太阳位置分析。特别关注表面长波辐射、向下辐射、风与太阳位置的组合等关键气象参数。

Result: 气象数据的加入显著提高了预测精度，特别是表面长波辐射、向下辐射以及风与太阳位置的组合。在多云天气条件下，预测性能提升尤为明显。该方法在即时预测和预报任务中都表现出色。

Conclusion: 整合多样化的数据源对提高太阳能预测模型的可靠性和可解释性至关重要。多模态方法能够显著改善光伏预测，特别是在具有挑战性的天气条件下，为电网运行和太阳能管理提供更好的支持。

Abstract: Due to the rise in the use of renewable energies as an alternative to traditional ones, and especially solar energy, there is increasing interest in studying how to address photovoltaic forecasting in the face of the challenge of variability in photovoltaic energy production, using different methodologies. This work develops a hybrid approach for short and long-term forecasting based on two studies with the same purpose. A multimodal approach that combines images of the sky and photovoltaic energy history with meteorological data is proposed. The main goal is to improve the accuracy of ramp event prediction, increase the robustness of forecasts in cloudy conditions, and extend capabilities beyond nowcasting, to support more efficient operation of the power grid and better management of solar variability. Deep neural models are used for both nowcasting and forecasting solutions, incorporating individual and multiple meteorological variables, as well as an analytical solar position. The results demonstrate that the inclusion of meteorological data, particularly the surface long-wave, radiation downwards, and the combination of wind and solar position, significantly improves current predictions in both nowcasting and forecasting tasks, especially on cloudy days. This study highlights the importance of integrating diverse data sources to improve the reliability and interpretability of solar energy prediction models.

</details>


### [41] [Context-aware Skin Cancer Epithelial Cell Classification with Scalable Graph Transformers](https://arxiv.org/abs/2602.15783)
*Lucas Sancéré,Noémie Moreau,Katarzyna Bozek*

Main category: cs.CV

TL;DR: 提出使用可扩展的图变换器对全切片图像细胞图进行分类，在皮肤鳞状细胞癌中区分健康与肿瘤上皮细胞，相比基于图像的方法获得更好性能


<details>
  <summary>Details</summary>
Motivation: 全切片图像分析中，现有基于卷积神经网络和视觉变换器的方法依赖基于patch的表示，丢失了重要的组织层面上下文信息，特别是在细胞形态相似的情况下难以区分细胞类型

Method: 使用可扩展的图变换器（SGFormer和DIFFormer）对全切片图像的细胞图进行分类，结合形态学、纹理特征以及非上皮细胞的细胞类别作为节点特征，并扩展到多患者多切片训练

Result: 在单切片3折交叉验证中，图变换器模型SGFormer和DIFFormer分别达到85.2±1.5和85.1±2.5的平衡准确率，优于最佳图像方法的81.2±3.0；在多切片设置中，DIFFormer达到83.6±1.9，优于CellViT256的78.1±0.5

Conclusion: 图变换器在全切片图像细胞分类任务中优于传统图像方法，特别是结合形态、纹理特征和周围细胞环境信息时表现最佳，证明了图表示在保留组织层面上下文方面的优势

Abstract: Whole-slide images (WSIs) from cancer patients contain rich information that can be used for medical diagnosis or to follow treatment progress. To automate their analysis, numerous deep learning methods based on convolutional neural networks and Vision Transformers have been developed and have achieved strong performance in segmentation and classification tasks. However, due to the large size and complex cellular organization of WSIs, these models rely on patch-based representations, losing vital tissue-level context. We propose using scalable Graph Transformers on a full-WSI cell graph for classification. We evaluate this methodology on a challenging task: the classification of healthy versus tumor epithelial cells in cutaneous squamous cell carcinoma (cSCC), where both cell types exhibit very similar morphologies and are therefore difficult to differentiate for image-based approaches. We first compared image-based and graph-based methods on a single WSI. Graph Transformer models SGFormer and DIFFormer achieved balanced accuracies of $85.2 \pm 1.5$ ($\pm$ standard error) and $85.1 \pm 2.5$ in 3-fold cross-validation, respectively, whereas the best image-based method reached $81.2 \pm 3.0$. By evaluating several node feature configurations, we found that the most informative representation combined morphological and texture features as well as the cell classes of non-epithelial cells, highlighting the importance of the surrounding cellular context. We then extended our work to train on several WSIs from several patients. To address the computational constraints of image-based models, we extracted four $2560 \times 2560$ pixel patches from each image and converted them into graphs. In this setting, DIFFormer achieved a balanced accuracy of $83.6 \pm 1.9$ (3-fold cross-validation), while the state-of-the-art image-based model CellViT256 reached $78.1 \pm 0.5$.

</details>


### [42] [Task-Agnostic Continual Learning for Chest Radiograph Classification](https://arxiv.org/abs/2602.15811)
*Muthu Subash Kavitha,Anas Zafar,Amgad Muneer,Jia Wu*

Main category: cs.CV

TL;DR: CARL-XRay：一种用于胸部X光分类的持续学习框架，通过轻量级适配器和原型回放实现任务增量学习，无需存储原始图像或重新训练历史数据。


<details>
  <summary>Details</summary>
Motivation: 临床部署胸部X光分类器需要能够随着新数据集可用而更新的模型，而无需重新训练历史数据或降低已验证性能。现有方法在任务标识符不可用的情况下难以实现稳定的持续学习。

Method: 提出CARL-XRay框架：固定高容量主干网络，增量分配轻量级任务特定适配器和分类器头。使用潜在任务选择器基于任务适应特征，通过紧凑原型和特征级经验回放保留历史上下文，支持稳定的任务识别和适应。

Result: 在大规模公共胸部X光数据集上，CARL-XRay在任务未知部署下优于联合训练：路由准确率75.0% vs. 62.5%，AUROC在oracle设置下0.74，任务未知推理下0.75，使用显著更少的可训练参数。

Conclusion: CARL-XRay为临床持续部署提供了实用的替代方案，避免了联合训练和重复完全重新训练，支持稳定任务识别和适应，同时保持竞争性诊断性能。

Abstract: Clinical deployment of chest radiograph classifiers requires models that can be updated as new datasets become available without retraining on previously ob- served data or degrading validated performance. We study, for the first time, a task-incremental continual learning setting for chest radiograph classification, in which heterogeneous chest X-ray datasets arrive sequentially and task identifiers are unavailable at inference. We propose a continual adapter-based routing learning strategy for Chest X-rays (CARL-XRay) that maintains a fixed high-capacity backbone and incrementally allocates lightweight task-specific adapters and classifier heads. A latent task selector operates on task-adapted features and leverages both current and historical context preserved through compact prototypes and feature-level experience replay. This design supports stable task identification and adaptation across sequential updates while avoiding raw-image storage. Experiments on large-scale public chest radiograph datasets demonstrate robust performance retention and reliable task-aware inference under continual dataset ingestion. CARL-XRay outperforms joint training under task-unknown deployment, achieving higher routing accuracy (75.0\% vs.\ 62.5\%), while maintaining competitive diagnostic performance with AUROC of 0.74 in the oracle setting with ground-truth task identity and 0.75 under task-unknown inference, using significantly fewer trainable parameters. Finally, the proposed framework provides a practical alternative to joint training and repeated full retraining in continual clinical deployment.

</details>


### [43] [VideoSketcher: Video Models Prior Enable Versatile Sequential Sketch Generation](https://arxiv.org/abs/2602.15819)
*Hui Ren,Yuval Alaluf,Omer Bar Tal,Alexander Schwing,Antonio Torralba,Yael Vinker*

Main category: cs.CV

TL;DR: 提出了一种数据高效的方法，通过适配预训练的文生视频扩散模型来生成顺序草图绘制过程，利用LLM进行语义规划和笔画排序，视频扩散模型作为渲染器生成高质量时序连贯的视觉效果。


<details>
  <summary>Details</summary>
Motivation: 现有生成模型将草图视为静态图像，忽略了绘制过程中的时序结构，而草图本质上是顺序过程，笔画按有意义顺序绘制以探索和细化想法。

Method: 将草图表示为笔画在空白画布上逐步绘制的短视频，采用两阶段微调策略：第一阶段使用合成形状组合学习笔画排序，第二阶段仅用7个人工绘制的草图过程学习视觉外观，分离笔画排序和外观学习。

Result: 尽管使用极少量人工草图数据，方法能生成高质量顺序草图，紧密遵循文本指定的排序，同时展现丰富的视觉细节。还展示了笔刷风格条件化和自回归草图生成等扩展功能。

Conclusion: 通过结合LLM的语义规划和视频扩散模型的渲染能力，实现了数据高效的顺序草图生成，为可控和交互式协作绘图提供了新可能性。

Abstract: Sketching is inherently a sequential process, in which strokes are drawn in a meaningful order to explore and refine ideas. However, most generative models treat sketches as static images, overlooking the temporal structure that underlies creative drawing. We present a data-efficient approach for sequential sketch generation that adapts pretrained text-to-video diffusion models to generate sketching processes. Our key insight is that large language models and video diffusion models offer complementary strengths for this task: LLMs provide semantic planning and stroke ordering, while video diffusion models serve as strong renderers that produce high-quality, temporally coherent visuals. We leverage this by representing sketches as short videos in which strokes are progressively drawn on a blank canvas, guided by text-specified ordering instructions. We introduce a two-stage fine-tuning strategy that decouples the learning of stroke ordering from the learning of sketch appearance. Stroke ordering is learned using synthetic shape compositions with controlled temporal structure, while visual appearance is distilled from as few as seven manually authored sketching processes that capture both global drawing order and the continuous formation of individual strokes. Despite the extremely limited amount of human-drawn sketch data, our method generates high-quality sequential sketches that closely follow text-specified orderings while exhibiting rich visual detail. We further demonstrate the flexibility of our approach through extensions such as brush style conditioning and autoregressive sketch generation, enabling additional controllability and interactive, collaborative drawing.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [44] [EduResearchBench: A Hierarchical Atomic Task Decomposition Benchmark for Full-Lifecycle Educational Research](https://arxiv.org/abs/2602.15034)
*Houping Yue,Zixiang Di,Mei Jiang,Bingdong Li,Hao Hao,Yu Song,Bo Jiang,Aimin Zhou*

Main category: cs.CL

TL;DR: EduResearchBench是首个专门评估教育学术写作能力的平台，通过分层原子任务分解框架将研究流程分解为6个模块24个原子任务，提供细粒度诊断评估。基于此训练的专业模型EduWrite(30B)在多项核心指标上超越更大规模通用模型(72B)。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型正在重塑社会科学AI范式，但缺乏对学术写作能力的严谨评估。现有基准主要关注单次、整体性生成，无法反映复杂的学术研究流程，需要更细粒度的评估方法来识别具体能力瓶颈。

Method: 提出分层原子任务分解(HATD)框架，将端到端研究流程分解为6个专业研究模块(定量分析、定性研究、政策研究等)和24个细粒度原子任务。采用课程学习策略，从基础技能逐步过渡到复杂方法论推理和论证。基于55K原始学术样本，构建11K高质量指令对训练EduWrite专业模型。

Result: EduWrite(30B)在多项核心指标上显著优于更大规模的通用模型(72B)，证明在垂直领域中，数据质量密度和分层训练课程比参数规模更具决定性作用。

Conclusion: EduResearchBench填补了学术写作评估的空白，其细粒度诊断评估框架能有效识别能力瓶颈。专业领域训练中，高质量数据和结构化训练策略比单纯扩大模型规模更重要，为垂直领域AI发展提供了新思路。

Abstract: While Large Language Models (LLMs) are reshaping the paradigm of AI for Social Science (AI4SS), rigorously evaluating their capabilities in scholarly writing remains a major challenge. Existing benchmarks largely emphasize single-shot, monolithic generation and thus lack the fine-grained assessments required to reflect complex academic research workflows. To fill this gap, we introduce EduResearchBench, the first comprehensive evaluation platform dedicated to educational academic writing. EduResearchBench is built upon our Hierarchical Atomic Task Decomposition (HATD) framework, which decomposes an end-to-end research workflow into six specialized research modules (e.g., Quantitative Analysis, Qualitative Research, and Policy Research) spanning 24 fine-grained atomic tasks. This taxonomy enables an automated evaluation pipeline that mitigates a key limitation of holistic scoring, where aggregate scores often obscure specific capability bottlenecks, and instead provides fine-grained, diagnostic feedback on concrete deficiencies. Moreover, recognizing the high cognitive load inherent in scholarly writing, we propose a curriculum learning strategy that progressively builds competence from foundational skills to complex methodological reasoning and argumentation. Leveraging 55K raw academic samples, we curate 11K high-quality instruction pairs to train EduWrite, a specialized educational scholarly writing model. Experiments show that EduWrite (30B) substantially outperforms larger general-purpose models (72B) on multiple core metrics, demonstrating that in vertical domains, data quality density and hierarchically staged training curricula are more decisive than parameter scale.

</details>


### [45] [Indic-TunedLens: Interpreting Multilingual Models in Indian Languages](https://arxiv.org/abs/2602.15038)
*Mihir Panchal,Deeksha Varshney,Mamta,Asif Ekbal*

Main category: cs.CL

TL;DR: Indic-TunedLens：针对印度语言的可解释性框架，通过学习共享仿射变换，改进多语言LLM在印度语言上的表示解码能力。


<details>
  <summary>Details</summary>
Motivation: 多语言大语言模型在印度等多语言地区部署，但现有可解释性工具主要针对英语。研究表明LLM常在英语中心表示空间中运作，跨语言可解释性成为迫切需求。

Method: 提出Indic-TunedLens框架，为每种目标语言学习共享仿射变换，调整隐藏状态以对齐目标输出分布，相比标准Logit Lens能更忠实地解码模型表示。

Result: 在10种印度语言的MMLU基准测试中，Indic-TunedLens显著优于现有SOTA可解释性方法，特别在形态丰富、资源匮乏的语言上表现更佳。

Conclusion: 该框架为多语言transformer的层级语义编码提供了重要洞见，有助于改善印度语言的可解释性，代码和模型已开源。

Abstract: Multilingual large language models (LLMs) are increasingly deployed in linguistically diverse regions like India, yet most interpretability tools remain tailored to English. Prior work reveals that LLMs often operate in English centric representation spaces, making cross lingual interpretability a pressing concern. We introduce Indic-TunedLens, a novel interpretability framework specifically for Indian languages that learns shared affine transformations. Unlike the standard Logit Lens, which directly decodes intermediate activations, Indic-TunedLens adjusts hidden states for each target language, aligning them with the target output distributions to enable more faithful decoding of model representations. We evaluate our framework on 10 Indian languages using the MMLU benchmark and find that it significantly improves over SOTA interpretability methods, especially for morphologically rich, low resource languages. Our results provide crucial insights into the layer-wise semantic encoding of multilingual transformers. Our model is available at https://huggingface.co/spaces/AnonymousAccountACL/IndicTunedLens. Our code is available at https://github.com/AnonymousAccountACL/IndicTunedLens.

</details>


### [46] [CGRA-DeBERTa Concept Guided Residual Augmentation Transformer for Theologically Islamic Understanding](https://arxiv.org/abs/2602.15139)
*Tahir Hussain,Saddam Hussain Khan*

Main category: cs.CL

TL;DR: 提出CGRA DeBERTa框架，通过概念引导的残差门控机制增强伊斯兰圣训文本的问答性能，在特定数据集上达到97.85的EM分数，显著优于BERT和DeBERTa。


<details>
  <summary>Details</summary>
Motivation: 针对伊斯兰经典文本问答的挑战：领域特定语义、长上下文依赖和概念敏感推理。现有模型在神学精确性和语义理解方面存在不足。

Method: 基于定制DeBERTa骨干，结合轻量级LoRA适配和残差概念感知门控机制。使用伊斯兰概念词典（12个核心术语）融入神学先验知识，通过重要性加权注意力选择性增强关键语义标记。

Result: 在42,591个QA对的数据集上，CGRA DeBERTa获得97.85的EM分数，比BERT（75.87）和DeBERTa（89.77）分别提升21.98和8.08个绝对点，仅增加约8%推理开销。

Conclusion: CGRA DeBERTa框架有效提升了伊斯兰圣训文本问答的准确性、效率和可解释性，为教育材料提供必要的神学细微差别，实现了高效、可扩展的神学精确问答系统。

Abstract: Accurate QA over classical Islamic texts remains challenging due to domain specific semantics, long context dependencies, and concept sensitive reasoning. Therefore, a new CGRA DeBERTa, a concept guided residual domain augmentation transformer framework, is proposed that enhances theological QA over Hadith corpora. The CGRA DeBERTa builds on a customized DeBERTa transformer backbone with lightweight LoRA based adaptations and a residual concept aware gating mechanism. The customized DeBERTa embedding block learns global and positional context, while Concept Guided Residual Blocks incorporate theological priors from a curated Islamic Concept Dictionary of 12 core terms. Moreover, the Concept Gating Mechanism selectively amplifies semantically critical tokens via importance weighted attention, applying differential scaling from 1.04 to 3.00. This design preserves contextual integrity, strengthens domain-specific semantic representations, and enables accurate, efficient span extraction while maintaining computational efficiency. This paper reports the results of training CGRA using a specially constructed dataset of 42591 QA pairs from the text of Sahih alBukhari and Sahih Muslim. While BERT achieved an EM score of 75.87 and DeBERTa one of 89.77, our model scored 97.85 and thus surpassed them by 8.08 on an absolute scale, all while adding approximately 8 inference overhead due to parameter efficient gating. The qualitative evaluation noted better extraction and discrimination and theological precision. This study presents Hadith QA systems that are efficient, interpretable, and accurate and that scale provide educational materials with necessary theological nuance.

</details>


### [47] [AIC CTU@AVerImaTeC: dual-retriever RAG for image-text fact checking](https://arxiv.org/abs/2602.15190)
*Herbert Ullrich,Jan Drchal*

Main category: cs.CL

TL;DR: 本文介绍了在AVerImaTeC共享任务中获得第三名的系统，该系统将去年的检索增强生成（RAG）管道与反向图像搜索（RIS）模块相结合，以低成本实现竞争性性能。


<details>
  <summary>Details</summary>
Motivation: 构建一个简单、低成本且易于复制的多模态事实核查系统，作为进一步实验的起点。

Method: 系统由三个解耦模块组成：基于相似性搜索的文本检索模块、基于API访问的反向图像搜索（RIS）的图像检索模块，以及使用GPT5.1的生成模块。

Result: 系统在AVerImaTeC共享任务中获得第三名，每次事实核查仅需0.013美元的平均成本，使用GPT5.1通过OpenAI Batch API实现竞争性性能。

Conclusion: 该系统提供了一个简单、低成本、易于复制的多模态事实核查解决方案，适合作为进一步实验的起点，作者已公开代码、提示、向量存储和成本分析。

Abstract: In this paper, we present our 3rd place system in the AVerImaTeC shared task, which combines our last year's retrieval-augmented generation (RAG) pipeline with a reverse image search (RIS) module. Despite its simplicity, our system delivers competitive performance with a single multimodal LLM call per fact-check at just $0.013 on average using GPT5.1 via OpenAI Batch API. Our system is also easy to reproduce and tweak, consisting of only three decoupled modules - a textual retrieval module based on similarity search, an image retrieval module based on API-accessed RIS, and a generation module using GPT5.1 - which is why we suggest it as an accesible starting point for further experimentation. We publish its code and prompts, as well as our vector stores and insights into the scheme's running costs and directions for further improvement.

</details>


### [48] [OpaqueToolsBench: Learning Nuances of Tool Behavior Through Interaction](https://arxiv.org/abs/2602.15197)
*Skyler Hallinan,Thejas Venkatesh,Xiang Ren,Sai Praneeth Karimireddy,Ashwin Paranjape,Yuhao Zhang,Jack Hessel*

Main category: cs.CL

TL;DR: 论文提出OpaqueToolsBench基准测试，用于评估LLM代理在不透明工具环境中的表现，并开发了ToolObserver框架，通过迭代观察工具执行反馈来改进工具文档，显著提升性能并减少token消耗。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试假设工具简单且文档完善，但现实世界中的工具（如通用"搜索"API）往往不透明，缺乏明确的最佳实践或故障模式。需要研究LLM代理能否通过交互和改进文档来提升在不透明工具环境中的性能。

Method: 创建OpaqueToolsBench基准，包含三个任务导向环境：通用函数调用、交互式国际象棋对弈和长轨迹代理搜索。提出ToolObserver框架，通过迭代观察工具调用轨迹的执行反馈来精炼工具文档。

Result: 在OpaqueToolsBench上的结果表明，现有自动文档生成方法在不透明工具环境下昂贵且不可靠。ToolObserver在所有数据集上都优于现有方法，在测试时工具探索设置中效率更高，消耗的token数比最佳基线少3.5-7.5倍。

Conclusion: LLM代理可以通过迭代观察工具执行反馈来改进不透明工具的文档，从而显著提升性能。ToolObserver框架提供了一种有效且高效的方法来处理现实世界中的不透明工具环境。

Abstract: Tool-calling is essential for Large Language Model (LLM) agents to complete real-world tasks. While most existing benchmarks assume simple, perfectly documented tools, real-world tools (e.g., general "search" APIs) are often opaque, lacking clear best practices or failure modes. Can LLM agents improve their performance in environments with opaque tools by interacting and subsequently improving documentation? To study this, we create OpaqueToolsBench, a benchmark consisting of three distinct task-oriented environments: general function calling, interactive chess playing, and long-trajectory agentic search. Each environment provides underspecified tools that models must learn to use effectively to complete the task. Results on OpaqueToolsBench suggest existing methods for automatically documenting tools are expensive and unreliable when tools are opaque. To address this, we propose a simple framework, ToolObserver, that iteratively refines tool documentation by observing execution feedback from tool-calling trajectories. Our approach outperforms existing methods on OpaqueToolsBench across datasets, even in relatively hard settings. Furthermore, for test-time tool exploration settings, our method is also efficient, consuming 3.5-7.5x fewer total tokens than the best baseline.

</details>


### [49] [Extracting Consumer Insight from Text: A Large Language Model Approach to Emotion and Evaluation Measurement](https://arxiv.org/abs/2602.15312)
*Stephan Ludwig,Peter J. Danaher,Xiaohao Yang,Yu-Ting Lin,Ehsan Abedin,Dhruv Grewal,Lan Du*

Main category: cs.CL

TL;DR: LX是一个针对消费者文本情感分析微调的大语言模型，在16种消费情绪和4个评估构念上表现优于GPT-4等主流模型，准确率达81-95%，并提供免费Web应用。


<details>
  <summary>Details</summary>
Motivation: 从非结构化文本中准确测量消费者情绪和评价是营销研究和实践的核心挑战，现有模型在这方面的表现有待提升。

Method: 开发了Linguistic eXtractor (LX)，这是一个基于消费者撰写文本微调的大语言模型，训练数据包含消费者自我报告的16种消费相关情绪和4个评估构念（信任、承诺、推荐、情感）。

Result: LX在开放式调查回复中达到81%的宏观F1准确率，在第三方标注的亚马逊和Yelp评论中准确率超过95%，优于GPT-4 Turbo、RoBERTa和DeepSeek等领先模型。应用分析显示评论表达的情绪能预测产品评分，进而影响购买行为。

Conclusion: LX为消费者感知测量建立了新的方法论基础，证明了利用大语言模型推进营销研究和实践的可行性，情绪语调提供了超越星级评分的有效信号，并提供免费Web应用支持实际使用。

Abstract: Accurately measuring consumer emotions and evaluations from unstructured text remains a core challenge for marketing research and practice. This study introduces the Linguistic eXtractor (LX), a fine-tuned, large language model trained on consumer-authored text that also has been labeled with consumers' self-reported ratings of 16 consumption-related emotions and four evaluation constructs: trust, commitment, recommendation, and sentiment. LX consistently outperforms leading models, including GPT-4 Turbo, RoBERTa, and DeepSeek, achieving 81% macro-F1 accuracy on open-ended survey responses and greater than 95% accuracy on third-party-annotated Amazon and Yelp reviews. An application of LX to online retail data, using seemingly unrelated regression, affirms that review-expressed emotions predict product ratings, which in turn predict purchase behavior. Most emotional effects are mediated by product ratings, though some emotions, such as discontent and peacefulness, influence purchase directly, indicating that emotional tone provides meaningful signals beyond star ratings. To support its use, a no-code, cost-free, LX web application is available, enabling scalable analyses of consumer-authored text. In establishing a new methodological foundation for consumer perception measurement, this research demonstrates new methods for leveraging large language models to advance marketing research and practice, thereby achieving validated detection of marketing constructs from consumer data.

</details>


### [50] [Mnemis: Dual-Route Retrieval on Hierarchical Graphs for Long-Term LLM Memory](https://arxiv.org/abs/2602.15313)
*Zihao Tang,Xin Yu,Ziyu Xiao,Zengxuan Wen,Zelin Li,Jiaxi Zhou,Hualei Wang,Haohua Wang,Haizhen Huang,Weiwei Deng,Feng Sun,Qi Zhang*

Main category: cs.CL

TL;DR: Mnemis是一个结合System-1相似性搜索和System-2全局选择机制的新型记忆框架，通过基础图和层次图组织记忆，在长时记忆基准测试中达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法（RAG和Graph-RAG）主要依赖相似性检索机制，这种System-1风格的检索在处理需要全局推理或全面覆盖相关信息的场景时存在局限。

Method: Mnemis将记忆组织为基础图（用于相似性检索）和层次图（支持自上而下的语义层次遍历），结合System-1相似性搜索和System-2全局选择机制。

Result: 在长时记忆基准测试中，Mnemis在所有对比方法中达到最先进性能：在LoCoMo上得分93.9，在LongMemEval-S上使用GPT-4.1-mini得分91.6。

Conclusion: 通过结合两种检索路径的互补优势，Mnemis能够检索出语义和结构都相关的记忆项，有效解决了现有相似性检索方法的局限性。

Abstract: AI Memory, specifically how models organizes and retrieves historical messages, becomes increasingly valuable to Large Language Models (LLMs), yet existing methods (RAG and Graph-RAG) primarily retrieve memory through similarity-based mechanisms. While efficient, such System-1-style retrieval struggles with scenarios that require global reasoning or comprehensive coverage of all relevant information. In this work, We propose Mnemis, a novel memory framework that integrates System-1 similarity search with a complementary System-2 mechanism, termed Global Selection. Mnemis organizes memory into a base graph for similarity retrieval and a hierarchical graph that enables top-down, deliberate traversal over semantic hierarchies. By combining the complementary strength from both retrieval routes, Mnemis retrieves memory items that are both semantically and structurally relevant. Mnemis achieves state-of-the-art performance across all compared methods on long-term memory benchmarks, scoring 93.9 on LoCoMo and 91.6 on LongMemEval-S using GPT-4.1-mini.

</details>


### [51] [NeuroSymActive: Differentiable Neural-Symbolic Reasoning with Active Exploration for Knowledge Graph Question Answering](https://arxiv.org/abs/2602.15353)
*Rong Fu,Yang Li,Zeyu Zhang,Jiekai Wu,Yaohua Liu,Shuaishuai Cao,Yangchen Zeng,Yuhang Zhang,Xiaojing Du,Chuang Zhao,Kangning Cui,Simon Fong*

Main category: cs.CL

TL;DR: NeuroSymActive是一个结合神经符号推理和主动探索的框架，用于知识图谱问答，在保持准确性的同时减少昂贵的图查询和模型调用。


<details>
  <summary>Details</summary>
Motivation: 大型预训练语言模型和神经推理系统在处理需要精确、结构化多跳推理的知识密集型查询时仍有挑战。知识图谱提供了符号化的知识基础，但将图结构与神经模型结合存在困难：简单地将图事实嵌入提示会导致效率低下和脆弱性，而纯符号或搜索密集的方法则检索成本高且缺乏基于梯度的优化。

Method: 引入NeuroSymActive框架，结合可微分的神经符号推理层和主动、价值引导的探索控制器。该方法将软统一风格的符号模块与神经路径评估器以及蒙特卡洛风格的探索策略相结合，优先扩展高价值路径。

Result: 在标准KGQA基准测试中，NeuroSymActive在保持强大答案准确性的同时，相比常见的检索增强基线方法，显著减少了昂贵的图查询和模型调用次数。

Conclusion: NeuroSymActive通过神经符号推理与主动探索的结合，为知识图谱问答提供了一种高效且准确的解决方案，平衡了符号推理的精确性和神经方法的灵活性。

Abstract: Large pretrained language models and neural reasoning systems have advanced many natural language tasks, yet they remain challenged by knowledge-intensive queries that require precise, structured multi-hop inference. Knowledge graphs provide a compact symbolic substrate for factual grounding, but integrating graph structure with neural models is nontrivial: naively embedding graph facts into prompts leads to inefficiency and fragility, while purely symbolic or search-heavy approaches can be costly in retrievals and lack gradient-based refinement. We introduce NeuroSymActive, a modular framework that combines a differentiable neural-symbolic reasoning layer with an active, value-guided exploration controller for Knowledge Graph Question Answering. The method couples soft-unification style symbolic modules with a neural path evaluator and a Monte-Carlo style exploration policy that prioritizes high-value path expansions. Empirical results on standard KGQA benchmarks show that NeuroSymActive attains strong answer accuracy while reducing the number of expensive graph lookups and model calls compared to common retrieval-augmented baselines.

</details>


### [52] [Far Out: Evaluating Language Models on Slang in Australian and Indian English](https://arxiv.org/abs/2602.15373)
*Deniz Kaya Dilsiz,Dipankar Srirag,Aditya Joshi*

Main category: cs.CL

TL;DR: 该研究评估了语言模型对印度英语和澳大利亚英语中俚语的认知能力，发现模型在判别任务上表现优于生成任务，且对真实网络数据比合成数据表现更好，印度英语任务整体优于澳大利亚英语。


<details>
  <summary>Details</summary>
Motivation: 语言模型在处理非标准语言变体时存在系统性性能差距，但对特定语言变体（如印度英语和澳大利亚英语）中俚语的认知能力尚未得到充分探索。本研究旨在填补这一空白，评估最先进语言模型对这两种英语变体中俚语的理解能力。

Method: 构建了两个互补数据集：Web数据集包含从Urban Dictionary收集的377个真实网络使用示例；Gen数据集包含1,492个合成生成的俚语使用场景。评估了7个最先进语言模型在三个任务上的表现：目标词预测(TWP)、引导目标词预测(TWP*)和目标词选择(TWS)。

Result: 1) TWS任务平均表现优于TWP和TWP*，准确率从0.03提升到0.49；2) Web数据集表现优于Gen数据集，相似度得分分别提高0.03和0.05；3) 印度英语任务整体优于澳大利亚英语，TWS任务差异最大，准确率从0.44提升到0.54。

Conclusion: 研究揭示了语言模型在生成性和判别性能力之间的基本不对称性，特别是在俚语表达方面。尽管英语是技术丰富的语言，但模型对特定变体俚语的理解仍存在显著差距，这对开发更具包容性的语言技术具有重要意义。

Abstract: Language models exhibit systematic performance gaps when processing text in non-standard language varieties, yet their ability to comprehend variety-specific slang remains underexplored for several languages. We present a comprehensive evaluation of slang awareness in Indian English (en-IN) and Australian English (en-AU) across seven state-of-the-art language models. We construct two complementary datasets: \textsc{web}, containing 377 web-sourced usage examples from Urban Dictionary, and \textsc{gen}, featuring 1,492 synthetically generated usages of these slang terms, across diverse scenarios. We assess language models on three tasks: target word prediction (TWP), guided target word prediction (TWP$^*$) and target word selection (TWS). Our results reveal four key findings: (1) Higher average model performance TWS versus TWP and TWP$^*$, with average accuracy score increasing from 0.03 to 0.49 respectively (2) Stronger average model performance on \textsc{web} versus \textsc{gen} datasets, with average similarity score increasing by 0.03 and 0.05 across TWP and TWP$^*$ tasks respectively (3) en-IN tasks outperform en-AU when averaged across all models and datasets, with TWS demonstrating the largest disparity, increasing average accuracy from 0.44 to 0.54. These findings underscore fundamental asymmetries between generative and discriminative competencies for variety-specific language, particularly in the context of slang expressions despite being in a technologically rich language such as English.

</details>


### [53] [Orchestration-Free Customer Service Automation: A Privacy-Preserving and Flowchart-Guided Framework](https://arxiv.org/abs/2602.15377)
*Mengze Hong,Chen Jason Zhang,Zichang Guo,Hanlin Gu,Di Jiang,Li Qing*

Main category: cs.CL

TL;DR: 提出基于任务导向流程图的无编排框架，实现端到端客服自动化，无需人工干预


<details>
  <summary>Details</summary>
Motivation: 现有客服自动化方法要么依赖复杂的编排系统，要么使用过于简化的指令模式，导致指导有限且泛化能力差

Method: 定义任务导向流程图组件和评估指标，设计成本高效的流程图构建算法从对话中抽象程序知识，采用小模型本地部署和基于流程图的去中心化蒸馏解决数据稀缺和隐私问题

Result: 在多种客服任务中验证有效性，相比强基线和市场产品具有更优的定量和应用性能

Conclusion: 通过发布基于Web的系统演示和案例研究，旨在促进未来客服自动化的简化创建

Abstract: Customer service automation has seen growing demand within digital transformation. Existing approaches either rely on modular system designs with extensive agent orchestration or employ over-simplified instruction schemas, providing limited guidance and poor generalizability. This paper introduces an orchestration-free framework using Task-Oriented Flowcharts (TOFs) to enable end-to-end automation without manual intervention. We first define the components and evaluation metrics for TOFs, then formalize a cost-efficient flowchart construction algorithm to abstract procedural knowledge from service dialogues. We emphasize local deployment of small language models and propose decentralized distillation with flowcharts to mitigate data scarcity and privacy issues in model training. Extensive experiments validate the effectiveness in various service tasks, with superior quantitative and application performance compared to strong baselines and market products. By releasing a web-based system demonstration with case studies, we aim to promote streamlined creation of future service automation.

</details>


### [54] [TAROT: Test-driven and Capability-adaptive Curriculum Reinforcement Fine-tuning for Code Generation with Large Language Models](https://arxiv.org/abs/2602.15449)
*Chansung Park,Juyong Jiang,Fan Wang,Sayak Paul,Jiasi Shen,Jing Tang,Jianguo Li*

Main category: cs.CL

TL;DR: TAROT提出了一种测试驱动和能力自适应的课程强化微调方法，通过构建四层测试套件并根据模型能力自适应选择课程策略，显著提升了代码生成的功能正确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有强化微调方法忽视了测试用例的异质难度和粒度，导致奖励信号分布不均和训练中的梯度偏差，限制了LLMs在算法复杂代码生成方面的深度推理能力。

Method: TAROT为每个问题构建四层测试套件（基础、中级、复杂、边缘），将课程进展与原始奖励分数解耦，基于模型能力进行条件评估，从课程策略组合中原则性地选择，实现能力自适应的课程设计。

Result: 实验表明，代码生成中RFT的最优课程与模型固有能力密切相关：能力较弱的模型在易到难课程中获益更大，而能力更强的模型在难优先课程中表现更优。TAROT能持续提升生成代码的功能正确性和鲁棒性。

Conclusion: TAROT提供了一种可复现的方法，能够根据模型能力自适应定制课程设计，有效激励LLMs的深度推理能力，为算法复杂代码生成提供了更稳定和高效的优化框架。

Abstract: Large Language Models (LLMs) are changing the coding paradigm, known as vibe coding, yet synthesizing algorithmically sophisticated and robust code still remains a critical challenge. Incentivizing the deep reasoning capabilities of LLMs is essential to overcoming this hurdle. Reinforcement Fine-Tuning (RFT) has emerged as a promising strategy to address this need. However, most existing approaches overlook the heterogeneous difficulty and granularity inherent in test cases, leading to an imbalanced distribution of reward signals and consequently biased gradient updates during training. To address this, we propose Test-driven and cApability-adaptive cuRriculum reinfOrcement fine-Tuning (TAROT). TAROT systematically constructs, for each problem, a four-tier test suite (basic, intermediate, complex, edge), providing a controlled difficulty landscape for curriculum design and evaluation. Crucially, TAROT decouples curriculum progression from raw reward scores, enabling capability-conditioned evaluation and principled selection from a portfolio of curriculum policies rather than incidental test-case difficulty composition. This design fosters stable optimization and more efficient competency acquisition. Extensive experimental results reveal that the optimal curriculum for RFT in code generation is closely tied to a model's inherent capability, with less capable models achieving greater gains with an easy-to-hard progression, whereas more competent models excel under a hard-first curriculum. TAROT provides a reproducible method that adaptively tailors curriculum design to a model's capability, thereby consistently improving the functional correctness and robustness of the generated code. All code and data are released to foster reproducibility and advance community research at https://github.com/deep-diver/TAROT.

</details>


### [55] [Making Large Language Models Speak Tulu: Structured Prompting for an Extremely Low-Resource Language](https://arxiv.org/abs/2602.15378)
*Prathamesh Devadiga,Paras Chopra*

Main category: cs.CL

TL;DR: 研究探索大语言模型能否通过结构化提示而非微调，在训练数据中几乎不存在的语言（以图鲁语为例）上实现基本对话能力，通过语法文档、负约束、罗马化标准化和自生成合成数据等方法，显著降低词汇污染并提高语法准确性。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探索大语言模型是否能在训练数据中几乎不存在的语言上实现对话能力，特别是针对像图鲁语这样有200多万使用者但数字存在极少的语言，而不需要昂贵的微调过程。

Method: 采用结构化提示方法，结合：1）显式语法文档；2）负约束抑制相关语言的高概率标记；3）罗马化标准化；4）通过自生成方式产生质量控制的合成数据。在三个LLM（Gemini 2.0 Flash、GPT-4o、Llama 3.1 70B）上评估，并由母语者验证。

Result: 词汇污染从80%降至5%，语法准确率达到85%。跨模型分析显示负约束带来一致改进（12-18个百分点），而语法文档的效果因模型架构而异（8-22个百分点）。

Conclusion: 研究表明，即使没有训练数据，通过精心设计的结构化提示，大语言模型也能在低资源语言上实现基本的对话能力，为语言保存和数字包容提供了有前景的途径。

Abstract: Can large language models converse in languages virtually absent from their training data? We investigate this question through a case study on Tulu, a Dravidian language with over 2 million speakers but minimal digital presence. Rather than fine-tuning an LLM, we examine whether structured prompts alone can elicit basic conversational ability under controlled prompting. We systematically tackle various challenges posed by absence of training data for Tulu by combining explicit grammar documentation, negative constraints to suppress high-probability tokens from related languages, romanization standardization, and quality-controlled synthetic data generation via self-play. Evaluated on a manually curated held-out set across three LLMs (Gemini 2.0 Flash, GPT-4o, Llama 3.1 70B) and validated by native speakers, our approach reduces vocabulary contamination from 80% to 5% while achieving 85% grammatical accuracy. Cross-model analysis reveals that negative constraints provide consistent improvements (12--18 percentage points), while grammar documentation effects vary by model architecture (8--22 points).

</details>


### [56] [The Vision Wormhole: Latent-Space Communication in Heterogeneous Multi-Agent Systems](https://arxiv.org/abs/2602.15382)
*Xiaoze Liu,Ruowang Zhang,Weichen Yu,Siheng Xiong,Liu He,Feijie Wu,Hoin Jung,Matt Fredrikson,Xiaoqian Wang,Jing Gao*

Main category: cs.CL

TL;DR: Vision Wormhole：利用视觉语言模型的视觉接口实现模型无关、无需文本的异构多智能体通信框架，通过通用视觉编解码器将推理轨迹映射到共享连续潜空间，显著降低通信开销。


<details>
  <summary>Details</summary>
Motivation: 当前基于大语言模型的多智能体系统依赖离散文本通信，存在运行时开销大和信息量化损失问题。现有潜状态传输方法要么假设同构架构，要么依赖特定对学习的翻译器，限制了在具有不连续流形的异构模型家族间的可扩展性和模块化。

Method: 提出Vision Wormhole框架，利用视觉语言模型的视觉接口作为通用通信端口。引入通用视觉编解码器将异构推理轨迹映射到共享连续潜空间，通过中心辐射拓扑将成对对齐复杂度从O(N²)降至O(N)，采用无标签的师生蒸馏目标对齐高速视觉通道与文本推理模式。

Result: 在异构模型家族（如Qwen-VL、Gemma）上的广泛实验表明，Vision Wormhole在控制比较中减少了端到端运行时间，同时保持了与标准文本多智能体系统相当的推理保真度。

Conclusion: Vision Wormhole为异构多智能体系统提供了一种高效、模型无关的通信方案，通过视觉接口实现"心灵感应"式通信，显著提升了系统效率和可扩展性。

Abstract: Multi-Agent Systems (MAS) powered by Large Language Models have unlocked advanced collaborative reasoning, yet they remain shackled by the inefficiency of discrete text communication, which imposes significant runtime overhead and information quantization loss. While latent state transfer offers a high-bandwidth alternative, existing approaches either assume homogeneous sender-receiver architectures or rely on pair-specific learned translators, limiting scalability and modularity across diverse model families with disjoint manifolds. In this work, we propose the Vision Wormhole, a novel framework that repurposes the visual interface of Vision-Language Models (VLMs) to enable model-agnostic, text-free communication. By introducing a Universal Visual Codec, we map heterogeneous reasoning traces into a shared continuous latent space and inject them directly into the receiver's visual pathway, effectively treating the vision encoder as a universal port for inter-agent telepathy. Our framework adopts a hub-and-spoke topology to reduce pairwise alignment complexity from O(N^2) to O(N) and leverages a label-free, teacher-student distillation objective to align the high-speed visual channel with the robust reasoning patterns of the text pathway. Extensive experiments across heterogeneous model families (e.g., Qwen-VL, Gemma) demonstrate that the Vision Wormhole reduces end-to-end wall-clock time in controlled comparisons while maintaining reasoning fidelity comparable to standard text-based MAS. Code is available at https://github.com/xz-liu/heterogeneous-latent-mas

</details>


### [57] [Measuring Social Integration Through Participation: Categorizing Organizations and Leisure Activities in the Displaced Karelians Interview Archive using LLMs](https://arxiv.org/abs/2602.15436)
*Joonatan Laato,Veera Schroderus,Jenna Kanerva,Jenni Kauppi,Virpi Lummaa,Filip Ginter*

Main category: cs.CL

TL;DR: 使用大语言模型对芬兰二战难民访谈中的35万个休闲活动和组织名称进行分类，构建结构化资源用于社会融合研究


<details>
  <summary>Details</summary>
Motivation: 数字化历史档案包含大量日常生活信息，但直接从文本提取的信息难以直接用于历史学家或社会学家的定量研究。芬兰二战难民访谈中提取了35万个活动和组织名称，数量过多无法直接分析。

Method: 开发包含活动类型、社交性、规律性和体力需求四个维度的分类框架，标注黄金标准数据集用于评估，测试大语言模型能否大规模应用该分类方案，使用多轮投票方法提高准确性。

Result: 通过简单投票方法，开源权重的大语言模型能够接近专家判断水平，成功标注了35万个实体，为下游社会融合研究提供了结构化资源。

Conclusion: 大语言模型能够有效处理历史档案中的大规模定性数据分类任务，为历史和社会学研究提供了新的量化分析工具。

Abstract: Digitized historical archives make it possible to study everyday social life on a large scale, but the information extracted directly from text often does not directly allow one to answer the research questions posed by historians or sociologists in a quantitative manner. We address this problem in a large collection of Finnish World War II Karelian evacuee family interviews. Prior work extracted more than 350K mentions of leisure time activities and organizational memberships from these interviews, yielding 71K unique activity and organization names -- far too many to analyze directly.
  We develop a categorization framework that captures key aspects of participation (the kind of activity/organization, how social it typically is, how regularly it happens, and how physically demanding it is). We annotate a gold-standard set to allow for a reliable evaluation, and then test whether large language models can apply the same schema at scale. Using a simple voting approach across multiple model runs, we find that an open-weight LLM can closely match expert judgments. Finally, we apply the method to label the 350K entities, producing a structured resource for downstream studies of social integration and related outcomes.

</details>


### [58] [In Agents We Trust, but Who Do Agents Trust? Latent Source Preferences Steer LLM Generations](https://arxiv.org/abs/2602.15456)
*Mohammad Aflah Khan,Mahsa Amani,Soumi Das,Bishwamittra Ghosh,Qinyuan Wu,Krishna P. Gummadi,Manish Gupta,Abhilasha Ravichander*

Main category: cs.CL

TL;DR: 研究发现LLM代理在信息选择中存在系统性源偏好，会优先呈现某些来源的信息，这种偏好受上下文影响且难以通过提示消除


<details>
  <summary>Details</summary>
Motivation: LLM代理越来越多地作为在线平台信息接口，它们过滤、排序和合成信息，但之前研究主要关注LLM生成信息的偏见，较少关注LLM选择呈现信息时的影响因素。研究者假设当信息被归因于特定来源时，当前LLM会表现出系统性的潜在源偏好。

Method: 对来自6个模型提供商的12个LLM进行受控实验，涵盖合成和真实世界任务，测试模型在不同上下文框架下的源偏好表现。

Result: 多个模型表现出强烈且可预测的源偏好，这些偏好对上下文框架敏感，可能超过内容本身的影响，即使明确提示也无法消除。这些偏好有助于解释先前研究中观察到的新闻推荐左倾偏斜现象。

Conclusion: 需要深入研究这些偏好的起源，并建立机制为用户提供透明度和控制权，以管理LLM驱动代理中的偏见。

Abstract: Agents based on Large Language Models (LLMs) are increasingly being deployed as interfaces to information on online platforms. These agents filter, prioritize, and synthesize information retrieved from the platforms' back-end databases or via web search. In these scenarios, LLM agents govern the information users receive, by drawing users' attention to particular instances of retrieved information at the expense of others. While much prior work has focused on biases in the information LLMs themselves generate, less attention has been paid to the factors that influence what information LLMs select and present to users. We hypothesize that when information is attributed to specific sources (e.g., particular publishers, journals, or platforms), current LLMs exhibit systematic latent source preferences- that is, they prioritize information from some sources over others. Through controlled experiments on twelve LLMs from six model providers, spanning both synthetic and real-world tasks, we find that several models consistently exhibit strong and predictable source preferences. These preferences are sensitive to contextual framing, can outweigh the influence of content itself, and persist despite explicit prompting to avoid them. They also help explain phenomena such as the observed left-leaning skew in news recommendations in prior work. Our findings advocate for deeper investigation into the origins of these preferences, as well as for mechanisms that provide users with transparency and control over the biases guiding LLM-powered agents.

</details>


### [59] [Towards Expectation Detection in Language: A Case Study on Treatment Expectations in Reddit](https://arxiv.org/abs/2602.15504)
*Aswathy Velutharambath,Amelie Wührl*

Main category: cs.CL

TL;DR: 论文提出"期望检测"新任务，创建RedHOTExpect语料库（4.5K Reddit帖子），使用LLM银标注研究医疗领域患者在线期望表达模式


<details>
  <summary>Details</summary>
Motivation: 患者期望对治疗效果有重要影响，但现有研究主要关注临床环境。在线患者平台（如医疗subreddit）可能包含患者在其他地方不愿分享的期望信息，然而目前没有研究分析用户在线上讨论的期望类型和表达方式

Method: 1) 提出"期望检测"新任务；2) 创建RedHOTExpect语料库（4.5K Reddit帖子）；3) 使用大语言模型进行银标注；4) 手动验证标注质量（准确率约78%）；5) 分析期望的语言模式特征

Result: 1) 发现乐观和主动框架在身体或治疗相关疾病帖子中比心理健康语境更明显；2) 数据集中患者主要讨论益处而非负面结果；3) 验证了LLM银标注的有效性（准确率78%）

Conclusion: 期望检测是NLP中具有应用价值的新任务，RedHOTExpect语料库为研究医疗领域患者期望提供了宝贵资源，在线平台能揭示患者在临床环境中不愿分享的期望信息

Abstract: Patients' expectations towards their treatment have a substantial effect on the treatments' success. While primarily studied in clinical settings, online patient platforms like medical subreddits may hold complementary insights: treatment expectations that patients feel unnecessary or uncomfortable to share elsewhere. Despite this, no studies examine what type of expectations users discuss online and how they express them. Presumably this is because expectations have not been studied in natural language processing (NLP) before. Therefore, we introduce the task of Expectation Detection, arguing that expectations are relevant for many applications, including opinion mining and product design. Subsequently, we present a case study for the medical domain, where expectations are particularly crucial to extract. We contribute RedHOTExpect, a corpus of Reddit posts (4.5K posts) to study expectations in this context. We use a large language model (LLM) to silver-label the data and validate its quality manually (label accuracy ~78%). Based on this, we analyze which linguistic patterns characterize expectations and explore what patients expect and why. We find that optimism and proactive framing are more pronounced in posts about physical or treatment-related illnesses compared to mental-health contexts, and that in our dataset, patients mostly discuss benefits rather than negative outcomes. The RedHOTExpect corpus can be obtained from https://www.ims.uni-stuttgart.de/data/RedHOTExpect

</details>


### [60] [LuxMT Technical Report](https://arxiv.org/abs/2602.15506)
*Nils Rehlinger*

Main category: cs.CL

TL;DR: LuxMT是基于Gemma 3 27B的卢森堡语到法语/英语机器翻译系统，使用LuxAlign平行语料和议会记录训练，通过LuxEmbedder过滤低质量数据，在LB-FR/EN翻译上表现优异，甚至能泛化到未训练的德语翻译。


<details>
  <summary>Details</summary>
Motivation: 卢森堡语作为低资源语言，缺乏高质量的机器翻译系统。研究旨在开发专门针对卢森堡语到法语和英语的翻译系统，并探索其在未训练语言方向上的泛化能力。

Method: 基于Gemma 3 27B模型进行微调，使用LuxAlign平行语料（卢森堡语多语言新闻）和议会记录作为训练数据，通过Google Translate增强数据。使用LuxEmbedder（卢森堡语句子嵌入）过滤低等价性句对，构建了基于Luci旅游杂志的新基准进行评估。

Result: LuxMT在LB-FR和LB-EN翻译上相比Gemma 3基线有显著提升，甚至在未包含德语训练数据的情况下，LB-DE翻译也表现出色。LuxEmbedder作为质量评估指标与其他基于参考的指标有强相关性。

Conclusion: LuxMT为卢森堡语翻译提供了有效的解决方案，展示了在低资源语言翻译中的潜力。LuxEmbedder有潜力作为质量评估指标，但需要进一步研究验证其效用，建议谨慎使用。

Abstract: We introduce LuxMT, a machine translation system based on Gemma 3 27B and fine-tuned for translation from Luxembourgish (LB) into French (FR) and English (EN). To assess translation performance, we construct a novel benchmark covering LB-FR, LB-EN, and LB-FR using human-translated data from Luci, a tourist magazine about Luxembourg. Training data stems from LuxAlign, a parallel corpus of multilingual Luxembourgish news articles, and LB parliamentary transcripts augmented with Google Translate. We filter the data using LuxEmbedder, LB sentence embeddings, to remove low-equivalence segment-pairs. Overall, LuxMT's results suggest strong improvements over the Gemma 3 baseline, even for translating LB to German (DE), despite the training data not containing any DE. We also explore LuxEmbedder's potential to be used as a quality estimation metric and find strong correlations with other reference-based metrics. However, we call for further research to fully assess the metric's utility and advise using it with caution.

</details>


### [61] [Fine-Refine: Iterative Fine-grained Refinement for Mitigating Dialogue Hallucination](https://arxiv.org/abs/2602.15509)
*Xiangyan Chen,Yujian Gan,Matthew Purver*

Main category: cs.CL

TL;DR: Fine-Refine是一个细粒度对话系统精炼框架，通过将响应分解为原子单元、使用外部知识验证每个单元、评估流畅度，并迭代修正细粒度错误，显著提升了对话的事实准确性。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在对话系统中存在幻觉问题，会产生事实错误的回答误导用户并破坏系统信任。现有精炼方法通常在响应层面操作，忽视了单个响应可能包含多个可验证或不可验证的事实单元。

Method: 提出Fine-Refine框架：1）将响应分解为原子单元；2）使用外部知识验证每个单元的事实性；3）通过困惑度评估流畅度；4）迭代修正细粒度错误。

Result: 在HybriDialogue和OpendialKG数据集上的实验表明，Fine-Refine显著提升了事实准确性，对话事实分数最高提升了7.63分，同时对话质量仅有小幅下降。

Conclusion: Fine-Refine通过细粒度的响应分解和验证机制，有效解决了对话系统中的幻觉问题，在事实准确性和覆盖度方面取得了显著改进，为构建更可靠的对话系统提供了新方法。

Abstract: The tendency for hallucination in current large language models (LLMs) negatively impacts dialogue systems. Such hallucinations produce factually incorrect responses that may mislead users and undermine system trust. Existing refinement methods for dialogue systems typically operate at the response level, overlooking the fact that a single response may contain multiple verifiable or unverifiable facts. To address this gap, we propose Fine-Refine, a fine-grained refinement framework that decomposes responses into atomic units, verifies each unit using external knowledge, assesses fluency via perplexity, and iteratively corrects granular errors. We evaluate factuality across the HybriDialogue and OpendialKG datasets in terms of factual accuracy (fact score) and coverage (Not Enough Information Proportion), and experiments show that Fine-Refine substantially improves factuality, achieving up to a 7.63-point gain in dialogue fact score, with a small trade-off in dialogue quality.

</details>


### [62] [DependencyAI: Detecting AI Generated Text through Dependency Parsing](https://arxiv.org/abs/2602.15514)
*Sara Ahmed,Tracy Hammond*

Main category: cs.CL

TL;DR: DependencyAI：仅使用语言依存关系标签检测AI生成文本的简单可解释方法，在单语、多生成器和多语言设置中表现优异


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型日益普及，需要可靠的AI生成文本检测方法来缓解潜在风险，现有方法复杂且缺乏可解释性

Method: 仅使用语言依存关系标签构建检测器，分析特征重要性以揭示区分AI生成与人类文本的句法结构

Result: 在单语、多生成器和多语言设置中取得竞争性性能，发现特定模型在未见领域存在系统性过预测，表明生成器特定写作风格影响跨领域泛化

Conclusion: 依存关系本身为AI生成文本检测提供了稳健信号，DependencyAI成为基于语言学、可解释且非神经网络的强基线方法

Abstract: As large language models (LLMs) become increasingly prevalent, reliable methods for detecting AI-generated text are critical for mitigating potential risks. We introduce DependencyAI, a simple and interpretable approach for detecting AI-generated text using only the labels of linguistic dependency relations. Our method achieves competitive performance across monolingual, multi-generator, and multilingual settings. To increase interpretability, we analyze feature importance to reveal syntactic structures that distinguish AI-generated from human-written text. We also observe a systematic overprediction of certain models on unseen domains, suggesting that generator-specific writing styles may affect cross-domain generalization. Overall, our results demonstrate that dependency relations alone provide a robust signal for AI-generated text detection, establishing DependencyAI as a strong linguistically grounded, interpretable, and non-neural network baseline.

</details>


### [63] [ExpertWeaver: Unlocking the Inherent MoE in Dense LLMs with GLU Activation Patterns](https://arxiv.org/abs/2602.15521)
*Ziyu Zhao,Tong Zhu,Zhi Zhang,Tiantian Fan,Jinluan Yang,Kun Kuang,Zhongyu Wei,Fei Wu,Yu Cheng*

Main category: cs.CL

TL;DR: 提出ExpertWeaver框架，利用GLU激活模式将预训练稠密模型转换为稀疏MoE，无需训练即可实现高性能的专家划分。


<details>
  <summary>Details</summary>
Motivation: 现有稠密转MoE方法会破坏模型的固有激活模式，导致专家构建不理想。作者发现GLU机制中的激活模式天然揭示了MoE结构，包含持续激活的通用神经元和动态激活的专业神经元。

Method: 提出ExpertWeaver框架：1) 分析GLU的细粒度神经激活模式，发现粗粒度结构；2) 根据激活模式划分神经元；3) 构建共享专家和专门路由专家，采用层自适应配置；4) 无需训练即可完成转换。

Result: 实验表明ExpertWeaver显著优于现有方法，既可作为无需训练的动态结构剪枝技术，也可作为高质量MoE初始化的降循环策略。

Conclusion: GLU激活模式为稠密到MoE转换提供了天然蓝图，ExpertWeaver框架通过利用这些固有模式实现了更优的专家构建，为高效模型转换提供了新思路。

Abstract: Mixture-of-Experts (MoE) effectively scales model capacity while preserving computational efficiency through sparse expert activation. However, training high-quality MoEs from scratch is prohibitively expensive. A promising alternative is to convert pretrained dense models into sparse MoEs. Existing dense-to-MoE methods fall into two categories: \textbf{dynamic structural pruning} that converts dense models into MoE architectures with moderate sparsity to balance performance and inference efficiency, and \textbf{downcycling} approaches that use pretrained dense models to initialize highly sparse MoE architectures. However, existing methods break the intrinsic activation patterns within dense models, leading to suboptimal expert construction. In this work, we argue that the Gated Linear Unit (GLU) mechanism provides a natural blueprint for dense-to-MoE conversion. We show that the fine-grained neural-wise activation patterns of GLU reveal a coarse-grained structure, uncovering an inherent MoE architecture composed of consistently activated universal neurons and dynamically activated specialized neurons. Leveraging this discovery, we introduce ExpertWeaver, a training-free framework that partitions neurons according to their activation patterns and constructs shared experts and specialized routed experts with layer-adaptive configurations. Our experiments demonstrate that ExpertWeaver significantly outperforms existing methods, both as a training-free dynamic structural pruning technique and as a downcycling strategy for superior MoE initialization.

</details>


### [64] [ZeroSyl: Simple Zero-Resource Syllable Tokenization for Spoken Language Modeling](https://arxiv.org/abs/2602.15537)
*Nicol Visser,Simon Malan,Danel Slabbert,Herman Kamper*

Main category: cs.CL

TL;DR: ZeroSyl：一种无需训练的简单方法，直接从冻结的WavLM模型中提取音节边界和嵌入，用于纯语音语言模型


<details>
  <summary>Details</summary>
Motivation: 纯语音语言模型直接从原始音频学习语言面临离散标记序列过长的问题，现有音节提取方法需要复杂的多阶段训练流程

Method: 使用WavLM中间层的L2范数特征提取音节边界，对得到的片段进行平均池化，用K-means离散化，然后训练语言模型

Result: 在词汇、句法和叙事基准测试中优于先前的音节标记器，细粒度单元对词汇任务有益，而发现的音节单元在句法建模中表现出更好的扩展性

Conclusion: ZeroSyl提供了一种简单有效的训练免费音节提取方法，解决了纯语音语言模型中的序列过长问题，并在多个语言任务中表现出色

Abstract: Pure speech language models aim to learn language directly from raw audio without textual resources. A key challenge is that discrete tokens from self-supervised speech encoders result in excessively long sequences, motivating recent work on syllable-like units. However, methods like Sylber and SyllableLM rely on intricate multi-stage training pipelines. We propose ZeroSyl, a simple training-free method to extract syllable boundaries and embeddings directly from a frozen WavLM model. Using L2 norms of features in WavLM's intermediate layers, ZeroSyl achieves competitive syllable segmentation performance. The resulting segments are mean-pooled, discretized using K-means, and used to train a language model. ZeroSyl outperforms prior syllabic tokenizers across lexical, syntactic, and narrative benchmarks. Scaling experiments show that while finer-grained units are beneficial for lexical tasks, our discovered syllabic units exhibit better scaling behavior for syntactic modeling.

</details>


### [65] [Perspectives - Interactive Document Clustering in the Discourse Analysis Tool Suite](https://arxiv.org/abs/2602.15540)
*Tim Fischer,Chris Biemann*

Main category: cs.CL

TL;DR: Perspectives是一个交互式文档分析工具，通过AI驱动的文档聚类和人类反馈循环，帮助数字人文学者探索和组织大型非结构化文档集。


<details>
  <summary>Details</summary>
Motivation: 数字人文学者需要处理大量非结构化文档，但现有工具缺乏灵活性，无法有效探索和组织这些文档集合，限制了研究洞察的发现。

Method: 开发交互式文档分析系统，采用基于指令的嵌入模型和文档重写提示定义分析视角，结合人类反馈循环机制，允许用户通过交互式文档地图细化和调整聚类结果。

Result: Perspectives工具展示了典型工作流程，帮助研究者发现主题、情感和其他相关类别，为后续深入分析准备数据，实现了灵活、可调整的文档探索体验。

Conclusion: Perspectives通过结合AI驱动的文档聚类和人类反馈循环，为数字人文学者提供了强大的文档探索工具，能够有效支持大规模非结构化文档的分析需求。

Abstract: This paper introduces Perspectives, an interactive extension of the Discourse Analysis Tool Suite designed to empower Digital Humanities (DH) scholars to explore and organize large, unstructured document collections. Perspectives implements a flexible, aspect-focused document clustering pipeline with human-in-the-loop refinement capabilities. We showcase how this process can be initially steered by defining analytical lenses through document rewriting prompts and instruction-based embeddings, and further aligned with user intent through tools for refining clusters and mechanisms for fine-tuning the embedding model. The demonstration highlights a typical workflow, illustrating how DH researchers can leverage Perspectives's interactive document map to uncover topics, sentiments, or other relevant categories, thereby gaining insights and preparing their data for subsequent in-depth analysis.

</details>


### [66] [jina-embeddings-v5-text: Task-Targeted Embedding Distillation](https://arxiv.org/abs/2602.15547)
*Mohammad Kalim Akram,Saba Sturua,Nastia Havriushenko,Quentin Herreros,Michael Günther,Maximilian Werk,Han Xiao*

Main category: cs.CL

TL;DR: 提出结合模型蒸馏与任务特定对比损失的新训练方法，生成紧凑高性能的文本嵌入模型，在小型模型上表现优于纯对比或蒸馏方法


<details>
  <summary>Details</summary>
Motivation: 当前通用文本嵌入模型通常使用单阶段或多阶段的对比损失训练，但这种方法对于训练小型模型可能不够有效，需要更高效的训练方法来生成紧凑且高性能的嵌入模型

Method: 提出新颖的训练方案，将模型蒸馏技术与任务特定的对比损失相结合，通过这种混合方法训练小型嵌入模型

Result: 生成的jina-embeddings-v5-text-small和jina-embeddings-v5-text-nano模型在相似尺寸模型中达到或超越最先进水平，支持长文本（最多32k tokens）、多语言，且嵌入在截断和二进制量化下保持鲁棒

Conclusion: 结合蒸馏与对比损失的训练方法比纯对比或蒸馏方法更有效，能生成高性能的小型嵌入模型，公开模型权重以促进嵌入模型开发的进一步进展

Abstract: Text embedding models are widely used for semantic similarity tasks, including information retrieval, clustering, and classification. General-purpose models are typically trained with single- or multi-stage processes using contrastive loss functions. We introduce a novel training regimen that combines model distillation techniques with task-specific contrastive loss to produce compact, high-performance embedding models. Our findings suggest that this approach is more effective for training small models than purely contrastive or distillation-based training paradigms alone. Benchmark scores for the resulting models, jina-embeddings-v5-text-small and jina-embeddings-v5-text-nano, exceed or match the state-of-the-art for models of similar size. jina-embeddings-v5-text models additionally support long texts (up to 32k tokens) in many languages, and generate embeddings that remain robust under truncation and binary quantization. Model weights are publicly available, hopefully inspiring further advances in embedding model development.

</details>


### [67] [Beyond Static Pipelines: Learning Dynamic Workflows for Text-to-SQL](https://arxiv.org/abs/2602.15564)
*Yihan Wang,Peiyu Liu,Runyu Chen,Wei Xu*

Main category: cs.CL

TL;DR: SquRL使用强化学习框架让LLM在推理时自适应构建Text-to-SQL工作流，动态策略优于静态方法，尤其在复杂和分布外查询上表现突出。


<details>
  <summary>Details</summary>
Motivation: 当前Text-to-SQL系统依赖单一静态工作流，难以扩展到分布外和长尾场景。需要让系统能在推理时自适应构建工作流，而不是让用户通过大量实验选择合适方法。

Method: 提出SquRL强化学习框架，增强LLM在自适应工作流构建中的推理能力。设计了基于规则的奖励函数，并引入两种训练机制：动态演员掩码以鼓励更广泛探索，伪奖励以提高训练效率。

Result: 在广泛使用的Text-to-SQL基准测试中，动态工作流构建始终优于最佳静态工作流方法，在复杂和分布外查询上增益尤其显著。

Conclusion: 通过理论和实证分析表明，最优动态策略始终优于最佳静态工作流，性能提升主要由候选工作流间的异质性驱动。SquRL框架有效解决了Text-to-SQL在现实场景中的应用难题。

Abstract: Text-to-SQL has recently achieved impressive progress, yet remains difficult to apply effectively in real-world scenarios. This gap stems from the reliance on single static workflows, fundamentally limiting scalability to out-of-distribution and long-tail scenarios. Instead of requiring users to select suitable methods through extensive experimentation, we attempt to enable systems to adaptively construct workflows at inference time. Through theoretical and empirical analysis, we demonstrate that optimal dynamic policies consistently outperform the best static workflow, with performance gains fundamentally driven by heterogeneity across candidate workflows. Motivated by this, we propose SquRL, a reinforcement learning framework that enhances LLMs' reasoning capability in adaptive workflow construction. We design a rule-based reward function and introduce two effective training mechanisms: dynamic actor masking to encourage broader exploration, and pseudo rewards to improve training efficiency. Experiments on widely-used Text-to-SQL benchmarks demonstrate that dynamic workflow construction consistently outperforms the best static workflow methods, with especially pronounced gains on complex and out-of-distribution queries. The codes are available at https://github.com/Satissss/SquRL

</details>


### [68] [Clinically Inspired Symptom-Guided Depression Detection from Emotion-Aware Speech Representations](https://arxiv.org/abs/2602.15578)
*Chaithra Nerella,Chiranjeevi Yarra*

Main category: cs.CL

TL;DR: 提出一个症状导向的抑郁症严重程度评估框架，通过症状引导的交叉注意力机制将PHQ-8问卷项目与情感感知语音表征对齐，实现症状级别的分析和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有抑郁症预测方法通常将其视为二元标签或整体严重程度评分，缺乏对具体症状的显式建模，限制了临床筛查中症状级别分析的能力。

Method: 使用症状引导的交叉注意力机制，将PHQ-8问卷项目与情感感知语音表征对齐；引入可学习的症状特定参数，自适应控制注意力分布的锐度，以考虑症状随时间表达方式的差异。

Result: 在标准临床数据集EDAIC上表现优于先前工作；注意力分析显示，包含多个抑郁症状线索的话语被赋予更高注意力，证明了方法的可解释性。

Conclusion: 症状引导和情感感知建模对于基于语音的抑郁症筛查具有重要意义，为临床实践提供了更细粒度的分析工具。

Abstract: Depression manifests through a diverse set of symptoms such as sleep disturbance, loss of interest, and concentration difficulties. However, most existing works treat depression prediction either as a binary label or an overall severity score without explicitly modeling symptom-specific information. This limits their ability to provide symptom-level analysis relevant to clinical screening. To address this, we propose a symptom-specific and clinically inspired framework for depression severity estimation from speech. Our approach uses a symptom-guided cross-attention mechanism that aligns PHQ-8 questionnaire items with emotion-aware speech representations to identify which segments of a participant's speech are more important to each symptom. To account for differences in how symptoms are expressed over time, we introduce a learnable symptom-specific parameter that adaptively controls the sharpness of attention distributions. Our results on EDAIC, a standard clinical-style dataset, demonstrate improved performance outperforming prior works. Further, analyzing the attention distributions showed that higher attention is assigned to utterances containing cues related to multiple depressive symptoms, highlighting the interpretability of our approach. These findings outline the importance of symptom-guided and emotion-aware modeling for speech-based depression screening.

</details>


### [69] [STAPO: Stabilizing Reinforcement Learning for LLMs by Silencing Rare Spurious Tokens](https://arxiv.org/abs/2602.15620)
*Shiqi Liu,Zeyu He,Guojian Zhan,Letian Tao,Zhilong Zheng,Jiang Wu,Yinuo Wang,Yang Guan,Kehua Sheng,Bo Zhang,Keqiang Li,Jingliang Duan,Shengbo Eben Li*

Main category: cs.CL

TL;DR: STAPO通过识别并屏蔽仅占0.01%的"虚假标记"来解决RL微调中的性能崩溃问题，在数学推理基准上平均提升7.13%


<details>
  <summary>Details</summary>
Motivation: 现有RL微调方法依赖启发式技术（如熵正则化和重加权）来保持稳定性，但在实践中经常出现后期性能崩溃，导致推理质量下降和训练不稳定。研究发现训练不稳定性由极少数"虚假标记"驱动。

Method: 提出虚假标记感知策略优化（STAPO），选择性屏蔽虚假标记的梯度更新，并在有效标记上重新归一化损失。该方法基于发现：策略梯度大小与标记概率和局部策略熵负相关。

Result: 在六个数学推理基准上使用Qwen 1.7B、8B和14B基础模型，STAPO始终表现出优越的熵稳定性，平均性能比GRPO、20-Entropy和JustRL提升7.13%。

Conclusion: 通过识别和缓解虚假标记问题，STAPO有效解决了RL微调中的训练不稳定性和性能崩溃问题，为大规模模型精炼提供了更稳定的方法。

Abstract: Reinforcement Learning (RL) has significantly improved large language model reasoning, but existing RL fine-tuning methods rely heavily on heuristic techniques such as entropy regularization and reweighting to maintain stability. In practice, they often experience late-stage performance collapse, leading to degraded reasoning quality and unstable training. We derive that the magnitude of token-wise policy gradients in RL is negatively correlated with token probability and local policy entropy. Building on this result, we prove that training instability is driven by a tiny fraction of tokens, approximately 0.01\%, which we term \emph{spurious tokens}. When such tokens appear in correct responses, they contribute little to the reasoning outcome but inherit the full sequence-level reward, leading to abnormally amplified gradient updates. Motivated by this observation, we propose Spurious-Token-Aware Policy Optimization (STAPO) for large-scale model refining, which selectively masks such updates and renormalizes the loss over valid tokens. Across six mathematical reasoning benchmarks using Qwen 1.7B, 8B, and 14B base models, STAPO consistently demonstrates superior entropy stability and achieves an average performance improvement of 7.13\% over GRPO, 20-Entropy and JustRL.

</details>


### [70] [LLM-to-Speech: A Synthetic Data Pipeline for Training Dialectal Text-to-Speech Models](https://arxiv.org/abs/2602.15675)
*Ahmed Khaled Khamis,Hesham Ali*

Main category: cs.CL

TL;DR: 提出了NileTTS数据集，这是首个公开的埃及阿拉伯语TTS数据集，包含38小时转录语音，并开发了基于LLM的合成数据生成流程，微调了XTTS v2模型。


<details>
  <summary>Details</summary>
Motivation: 尽管神经文本到语音技术有所进展，但埃及阿拉伯语作为最广泛理解的阿拉伯语方言，在TTS资源方面严重不足，现有资源主要集中在现代标准阿拉伯语和海湾方言上。

Method: 使用新颖的合成流程：LLM生成埃及阿拉伯语内容，通过音频合成工具转换为自然语音，然后进行自动转录和说话人分离，最后进行人工质量验证。在数据集上微调了最先进的多语言TTS模型XTTS v2。

Result: 创建了包含38小时转录语音的NileTTS数据集，涵盖医疗、销售和一般对话等多个领域。微调后的模型在埃及阿拉伯语TTS任务上表现良好，所有资源都已公开发布。

Conclusion: 填补了埃及阿拉伯语TTS资源的空白，提供了首个公开数据集、可复现的方言TTS合成数据生成流程和开源微调模型，推动了埃及阿拉伯语语音合成研究的发展。

Abstract: Despite the advances in neural text to speech (TTS), many Arabic dialectal varieties remain marginally addressed, with most resources concentrated on Modern Spoken Arabic (MSA) and Gulf dialects, leaving Egyptian Arabic -- the most widely understood Arabic dialect -- severely under-resourced. We address this gap by introducing NileTTS: 38 hours of transcribed speech from two speakers across diverse domains including medical, sales, and general conversations. We construct this dataset using a novel synthetic pipeline: large language models (LLM) generate Egyptian Arabic content, which is then converted to natural speech using audio synthesis tools, followed by automatic transcription and speaker diarization with manual quality verification. We fine-tune XTTS v2, a state-of-the-art multilingual TTS model, on our dataset and evaluate against the baseline model trained on other Arabic dialects. Our contributions include: (1) the first publicly available Egyptian Arabic TTS dataset, (2) a reproducible synthetic data generation pipeline for dialectal TTS, and (3) an open-source fine-tuned model. All resources are released to advance Egyptian Arabic speech synthesis research.

</details>


### [71] [Revisiting Northrop Frye's Four Myths Theory with Large Language Models](https://arxiv.org/abs/2602.15678)
*Edirlei Soares de Lima,Marco A. Casanova,Antonio L. Furtado*

Main category: cs.CL

TL;DR: 提出基于荣格原型理论的四类角色功能框架，通过LLM验证该框架在弗莱四种叙事体裁中的适用性，为计算叙事学提供新方法。


<details>
  <summary>Details</summary>
Motivation: 现有计算叙事研究主要关注叙事模式而非角色功能，需要建立能够补充模式分析的角色功能框架，以更全面地理解叙事结构。

Method: 基于荣格原型理论推导四类通用角色功能（主角、导师、反派、同伴），再细化为十六种体裁特定角色；使用六种先进LLM在40部叙事作品中验证角色-体裁对应关系。

Result: LLM平均平衡准确率达82.5%，模型间一致性高（Fleiss' κ=0.600）；不同体裁（72.7%-89.9%）和角色（52.5%-99.2%）表现差异反映真实叙事特性，如浪漫文学中的功能分布和讽刺文学中的原型颠覆。

Conclusion: 基于角色的方法展示了LLM支持的计算叙事学潜力，为未来叙事生成方法和交互式叙事应用开发奠定了基础。

Abstract: Northrop Frye's theory of four fundamental narrative genres (comedy, romance, tragedy, satire) has profoundly influenced literary criticism, yet computational approaches to his framework have focused primarily on narrative patterns rather than character functions. In this paper, we present a new character function framework that complements pattern-based analysis by examining how archetypal roles manifest differently across Frye's genres. Drawing on Jungian archetype theory, we derive four universal character functions (protagonist, mentor, antagonist, companion) by mapping them to Jung's psychic structure components. These functions are then specialized into sixteen genre-specific roles based on prototypical works. To validate this framework, we conducted a multi-model study using six state-of-the-art Large Language Models (LLMs) to evaluate character-role correspondences across 40 narrative works. The validation employed both positive samples (160 valid correspondences) and negative samples (30 invalid correspondences) to evaluate whether models both recognize valid correspondences and reject invalid ones. LLMs achieved substantial performance (mean balanced accuracy of 82.5%) with strong inter-model agreement (Fleiss' $κ$ = 0.600), demonstrating that the proposed correspondences capture systematic structural patterns. Performance varied by genre (ranging from 72.7% to 89.9%) and role (52.5% to 99.2%), with qualitative analysis revealing that variations reflect genuine narrative properties, including functional distribution in romance and deliberate archetypal subversion in satire. This character-based approach demonstrates the potential of LLM-supported methods for computational narratology and provides a foundation for future development of narrative generation methods and interactive storytelling applications.

</details>


### [72] [A Content-Based Framework for Cybersecurity Refusal Decisions in Large Language Models](https://arxiv.org/abs/2602.15689)
*Meirav Segal,Noa Linder,Omer Antverg,Gil Gekker,Tomer Fichman,Omri Bodenheimer,Edan Maor,Omer Nevo*

Main category: cs.CL

TL;DR: 提出基于内容而非意图的网络安全拒绝框架，通过五个维度（攻击行动贡献、攻击风险、技术复杂度、防御效益、合法用户预期频率）明确权衡攻防利弊，解决现有拒绝系统的不一致性和过度限制问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于主题禁令或攻击分类的拒绝方法存在不一致决策、过度限制合法防御者、在混淆或请求分段下表现脆弱等问题。需要明确建模攻击风险与防御效益之间的权衡，而非仅依赖意图或攻击分类。

Method: 引入基于内容的网络安全拒绝策略框架，通过五个技术维度评估请求：攻击行动贡献、攻击风险、技术复杂度、防御效益、合法用户预期频率。这些维度基于请求的技术实质而非陈述意图，允许构建可调、风险感知的拒绝策略。

Result: 该内容基础方法解决了当前前沿模型行为的不一致性，使组织能够构建可调、风险感知的拒绝策略，更好地平衡安全风险与合法防御需求。

Conclusion: 有效的网络安全拒绝需要明确建模攻击风险与防御效益的权衡，基于内容而非意图的框架能够提供更一致、可调且风险感知的决策，解决现有方法的局限性。

Abstract: Large language models and LLM-based agents are increasingly used for cybersecurity tasks that are inherently dual-use. Existing approaches to refusal, spanning academic policy frameworks and commercially deployed systems, often rely on broad topic-based bans or offensive-focused taxonomies. As a result, they can yield inconsistent decisions, over-restrict legitimate defenders, and behave brittlely under obfuscation or request segmentation. We argue that effective refusal requires explicitly modeling the trade-off between offensive risk and defensive benefit, rather than relying solely on intent or offensive classification. In this paper, we introduce a content-based framework for designing and auditing cyber refusal policies that makes offense-defense tradeoffs explicit. The framework characterizes requests along five dimensions: Offensive Action Contribution, Offensive Risk, Technical Complexity, Defensive Benefit, and Expected Frequency for Legitimate Users, grounded in the technical substance of the request rather than stated intent. We demonstrate that this content-grounded approach resolves inconsistencies in current frontier model behavior and allows organizations to construct tunable, risk-aware refusal policies.

</details>


### [73] [Rethinking Metrics for Lexical Semantic Change Detection](https://arxiv.org/abs/2602.15716)
*Roksana Goworek,Haim Dubossarsky*

Main category: cs.CL

TL;DR: 论文提出了两种新的词汇语义变化检测指标AMD和SAMD，相比传统APD和PRT方法，这些新指标通过跨时间词用法的局部对应关系来量化语义变化，在不同语言和编码器下表现更稳健。


<details>
  <summary>Details</summary>
Motivation: 当前词汇语义变化检测主要依赖上下文语言模型嵌入，但大多仍使用有限的语义变化度量方法，主要是平均成对距离(APD)和基于词原型的余弦距离(PRT)。需要探索更有效的替代度量方法。

Method: 提出了平均最小距离(AMD)和对称平均最小距离(SAMD)两种新度量方法，通过跨时间词用法的局部对应关系来量化语义变化。在不同语言、编码器模型和表示空间中进行评估。

Result: AMD在降维和非专门编码器下通常提供更稳健的性能，SAMD在专门编码器下表现优异。新指标在不同语言、编码器和表示空间中展现出优于传统方法的性能。

Conclusion: 词汇语义变化检测应考虑超越APD和PRT的替代语义变化度量，AMD为基于上下文嵌入的分析提供了一个稳健的选择，有助于改进语义变化检测方法。

Abstract: Lexical semantic change detection (LSCD) increasingly relies on contextualised language model embeddings, yet most approaches still quantify change using a small set of semantic change metrics, primarily Average Pairwise Distance (APD) and cosine distance over word prototypes (PRT). We introduce Average Minimum Distance (AMD) and Symmetric Average Minimum Distance (SAMD), new measures that quantify semantic change via local correspondence between word usages across time periods. Across multiple languages, encoder models, and representation spaces, we show that AMD often provides more robust performance, particularly under dimensionality reduction and with non-specialised encoders, while SAMD excels with specialised encoders. We suggest that LSCD may benefit from considering alternative semantic change metrics beyond APD and PRT, with AMD offering a robust option for contextualised embedding-based analysis.

</details>


### [74] [Causal Effect Estimation with Latent Textual Treatments](https://arxiv.org/abs/2602.15730)
*Omri Feldman,Amar Venugopal,Jann Spiess,Amir Feder*

Main category: cs.CL

TL;DR: 提出一个端到端流程，用于生成和因果估计潜在文本干预，解决文本作为处理变量时的估计偏差问题


<details>
  <summary>Details</summary>
Motivation: 理解文本对下游结果的因果效应是许多应用的核心任务，但现有方法在生成受控文本变化和因果估计方面存在挑战。文本作为处理变量时天然混淆了处理和协变量信息，导致估计偏差。

Method: 提出端到端流程：1) 使用稀疏自编码器(SAEs)进行假设生成和引导；2) 基于协变量残差化的稳健因果估计方法，解决文本处理中的估计偏差问题。

Result: 实证结果表明，该流程能有效诱导目标特征的变化，并显著减少估计误差。相比朴素估计方法，提出的协变量残差化方法能有效缓解文本作为处理变量时的估计偏差。

Conclusion: 该研究为文本作为处理变量的因果效应估计提供了稳健的基础框架，解决了文本干预生成和因果估计中的计算与统计挑战。

Abstract: Understanding the causal effects of text on downstream outcomes is a central task in many applications. Estimating such effects requires researchers to run controlled experiments that systematically vary textual features. While large language models (LLMs) hold promise for generating text, producing and evaluating controlled variation requires more careful attention. In this paper, we present an end-to-end pipeline for the generation and causal estimation of latent textual interventions. Our work first performs hypothesis generation and steering via sparse autoencoders (SAEs), followed by robust causal estimation. Our pipeline addresses both computational and statistical challenges in text-as-treatment experiments. We demonstrate that naive estimation of causal effects suffers from significant bias as text inherently conflates treatment and covariate information. We describe the estimation bias induced in this setting and propose a solution based on covariate residualization. Our empirical results show that our pipeline effectively induces variation in target features and mitigates estimation error, providing a robust foundation for causal effect estimation in text-as-treatment settings.

</details>


### [75] [Under-resourced studies of under-resourced languages: lemmatization and POS-tagging with LLM annotators for historical Armenian, Georgian, Greek and Syriac](https://arxiv.org/abs/2602.15753)
*Chahan Vidal-Gorène,Bastien Kindt,Florian Cafiero*

Main category: cs.CL

TL;DR: LLMs在少样本和零样本设置下，对四种低资源语言（古希腊语、古典亚美尼亚语、古格鲁吉亚语、叙利亚语）的词形还原和词性标注任务表现出竞争力，可作为无数据情况下语言标注的有效辅助工具。


<details>
  <summary>Details</summary>
Motivation: 低资源语言在自然语言处理任务（如词形还原和词性标注）中持续面临挑战，需要探索大型语言模型在少样本和零样本设置下处理这些任务的能力。

Method: 使用包含对齐训练数据和领域外测试数据的新基准，评估GPT-4变体和Mistral等大型语言模型在四种低资源语言上的表现，并与任务特定的RNN基线模型PIE进行比较。

Result: 大型语言模型即使不进行微调，在少样本设置下对大多数语言的词性标注和词形还原任务都能达到竞争性或更优的性能。但对于形态复杂和非拉丁文字的语言仍存在显著挑战。

Conclusion: 大型语言模型是启动无数据情况下语言标注任务的可靠选择，可作为标注的有效辅助工具，特别是在处理低资源语言时。

Abstract: Low-resource languages pose persistent challenges for Natural Language Processing tasks such as lemmatization and part-of-speech (POS) tagging. This paper investigates the capacity of recent large language models (LLMs), including GPT-4 variants and open-weight Mistral models, to address these tasks in few-shot and zero-shot settings for four historically and linguistically diverse under-resourced languages: Ancient Greek, Classical Armenian, Old Georgian, and Syriac. Using a novel benchmark comprising aligned training and out-of-domain test corpora, we evaluate the performance of foundation models across lemmatization and POS-tagging, and compare them with PIE, a task-specific RNN baseline. Our results demonstrate that LLMs, even without fine-tuning, achieve competitive or superior performance in POS-tagging and lemmatization across most languages in few-shot settings. Significant challenges persist for languages characterized by complex morphology and non-Latin scripts, but we demonstrate that LLMs are a credible and relevant option for initiating linguistic annotation tasks in the absence of data, serving as an effective aid for annotation.

</details>


### [76] [Beyond Binary Classification: Detecting Fine-Grained Sexism in Social Media Videos](https://arxiv.org/abs/2602.15757)
*Laura De Grazia,Danae Sánchez Villegas,Desmond Elliott,Mireia Farrús,Mariona Taulé*

Main category: cs.CL

TL;DR: 提出了FineMuSe，一个西班牙语多模态性别歧视检测数据集，包含二元和细粒度标注，并评估了LLMs在检测细微性别歧视方面的表现。


<details>
  <summary>Details</summary>
Motivation: 在线性别歧视表现形式多样，现有自动化工具多限于二元分类，难以检测更细微、语境敏感的性别歧视内容。

Method: 1) 创建FineMuSe数据集，包含西班牙语多模态内容和二元/细粒度标注；2) 设计包含性别歧视形式、非性别歧视以及讽刺幽默修辞手法的分层分类法；3) 评估多种LLMs在二元和细粒度性别歧视检测上的表现。

Result: 多模态LLMs在识别细微性别歧视方面表现与人类标注者相当，但在处理通过视觉线索传达的并发性别歧视类型时存在困难。

Conclusion: 需要更先进的多模态模型来有效检测通过视觉方式表达的并发性别歧视类型，FineMuSe数据集为这一领域的研究提供了重要资源。

Abstract: Online sexism appears in various forms, which makes its detection challenging. Although automated tools can enhance the identification of sexist content, they are often restricted to binary classification. Consequently, more subtle manifestations of sexism may remain undetected due to the lack of fine-grained, context-sensitive labels. To address this issue, we make the following contributions: (1) we present FineMuSe, a new multimodal sexism detection dataset in Spanish that includes both binary and fine-grained annotations; (2) we introduce a comprehensive hierarchical taxonomy that encompasses forms of sexism, non-sexism, and rhetorical devices of irony and humor; and (3) we evaluate a wide range of LLMs for both binary and fine-grained sexism detection. Our findings indicate that multimodal LLMs perform competitively with human annotators in identifying nuanced forms of sexism; however, they struggle to capture co-occurring sexist types when these are conveyed through visual cues.

</details>


### [77] [ChartEditBench: Evaluating Grounded Multi-Turn Chart Editing in Multimodal Language Models](https://arxiv.org/abs/2602.15758)
*Manav Nitin Kapadnis,Lawanya Baghel,Atharva Naik,Carolyn Rosé*

Main category: cs.CL

TL;DR: ChartEditBench：首个针对多轮图表编辑的基准测试，评估MLLM在探索性数据分析中的持续编辑能力，发现现有模型在多轮交互中表现显著下降


<details>
  <summary>Details</summary>
Motivation: 现有MLLM在单轮图表生成上表现良好，但在真实世界探索性数据分析中，用户需要多轮迭代编辑，要求模型维持共同基础、跟踪先前编辑并适应不断变化的偏好，这方面的能力尚未得到充分探索

Method: 提出ChartEditBench基准，包含5,000个难度可控的修改链和人工验证子集；设计鲁棒评估框架，整合执行保真度检查、像素级视觉相似性和逻辑代码验证，克服LLM-as-a-Judge指标的局限性

Result: 实验显示最先进MLLM在多轮设置中表现显著下降，主要由于错误累积和共享上下文崩溃；在样式编辑上表现良好，但在数据为中心的转换上经常出现执行失败

Conclusion: ChartEditBench为基于意图的多模态编程建立了具有挑战性的测试平台，揭示了MLLM在支持真实世界探索性数据分析方面的局限性，为未来研究提供了重要基准

Abstract: While Multimodal Large Language Models (MLLMs) perform strongly on single-turn chart generation, their ability to support real-world exploratory data analysis remains underexplored. In practice, users iteratively refine visualizations through multi-turn interactions that require maintaining common ground, tracking prior edits, and adapting to evolving preferences. We introduce ChartEditBench, a benchmark for incremental, visually grounded chart editing via code, comprising 5,000 difficulty-controlled modification chains and a rigorously human-verified subset. Unlike prior one-shot benchmarks, ChartEditBench evaluates sustained, context-aware editing. We further propose a robust evaluation framework that mitigates limitations of LLM-as-a-Judge metrics by integrating execution-based fidelity checks, pixel-level visual similarity, and logical code verification. Experiments with state-of-the-art MLLMs reveal substantial degradation in multi-turn settings due to error accumulation and breakdowns in shared context, with strong performance on stylistic edits but frequent execution failures on data-centric transformations. ChartEditBench, establishes a challenging testbed for grounded, intent-aware multimodal programming.

</details>


### [78] [ViTaB-A: Evaluating Multimodal Large Language Models on Visual Table Attribution](https://arxiv.org/abs/2602.15769)
*Yahia Alqurnawi,Preetom Biswas,Anmol Rao,Tejas Anvekar,Chitta Baral,Vivek Gupta*

Main category: cs.CL

TL;DR: 多模态大语言模型在结构化数据（表格、JSON、图像）的问答中难以提供可靠的证据溯源，回答准确率中等但溯源准确率接近随机


<details>
  <summary>Details</summary>
Motivation: 虽然多模态大语言模型能够回答结构化数据的问题，但用户需要知道答案的来源依据。研究旨在评估模型在结构化数据溯源/引用方面的能力，即模型能否指出支持答案的具体行和列。

Method: 评估了多种多模态大语言模型在不同表格格式（Markdown、JSON、图像）和提示策略下的表现，比较了问答准确率和证据溯源准确率。

Result: 1. 问答准确率和证据溯源准确率存在明显差距：问答准确率中等，但溯源准确率低得多，对于JSON输入接近随机水平
2. 模型在引用行方面比列更可靠
3. 模型在文本格式（Markdown、JSON）上比图像格式表现更差
4. 不同模型家族之间存在显著差异

Conclusion: 当前多模态大语言模型在提供结构化数据的细粒度、可信溯源方面不可靠，这限制了它们在需要透明度和可追溯性的应用中的使用。

Abstract: Multimodal Large Language Models (mLLMs) are often used to answer questions in structured data such as tables in Markdown, JSON, and images. While these models can often give correct answers, users also need to know where those answers come from. In this work, we study structured data attribution/citation, which is the ability of the models to point to the specific rows and columns that support an answer. We evaluate several mLLMs across different table formats and prompting strategies. Our results show a clear gap between question answering and evidence attribution. Although question answering accuracy remains moderate, attribution accuracy is much lower, near random for JSON inputs, across all models. We also find that models are more reliable at citing rows than columns, and struggle more with textual formats than images. Finally, we observe notable differences across model families. Overall, our findings show that current mLLMs are unreliable at providing fine-grained, trustworthy attribution for structured data, which limits their usage in applications requiring transparency and traceability.

</details>


### [79] [*-PLUIE: Personalisable metric with Llm Used for Improved Evaluation](https://arxiv.org/abs/2602.15778)
*Quentin Lemesle,Léane Jourdan,Daisy Munson,Pierre Alain,Jonathan Chevelu,Arnaud Delhay,Damien Lolive*

Main category: cs.CL

TL;DR: 本文提出*-PLUIE方法，作为ParaPLUIE的变体，通过任务特定提示来评估自动生成文本质量，相比传统LLM-as-a-judge方法更高效且与人类判断更一致。


<details>
  <summary>Details</summary>
Motivation: 当前评估自动生成文本质量的LLM-as-a-judge方法虽然有效，但计算成本高且需要后处理。需要更高效、低成本的替代方案。

Method: 基于ParaPLUIE（基于困惑度的LLM-judge指标），引入*-PLUIE方法，通过任务特定提示变体来估计"Yes/No"答案的置信度，无需生成文本。

Result: 实验显示，个性化的*-PLUIE方法在保持低计算成本的同时，与人类评分的相关性更强。

Conclusion: *-PLUIE提供了一种高效、低成本且与人类判断更一致的文本质量评估方法，是对传统LLM-as-a-judge方法的有效改进。

Abstract: Evaluating the quality of automatically generated text often relies on LLM-as-a-judge (LLM-judge) methods. While effective, these approaches are computationally expensive and require post-processing. To address these limitations, we build upon ParaPLUIE, a perplexity-based LLM-judge metric that estimates confidence over ``Yes/No'' answers without generating text. We introduce *-PLUIE, task specific prompting variants of ParaPLUIE and evaluate their alignment with human judgement. Our experiments show that personalised *-PLUIE achieves stronger correlations with human ratings while maintaining low computational cost.

</details>


### [80] [Avey-B](https://arxiv.org/abs/2602.15814)
*Devang Acharya,Mohammad Hammoud*

Main category: cs.CL

TL;DR: 本文提出了一种基于Avey架构的编码器改进方案，通过解耦静态动态参数化、稳定性导向归一化和神经压缩等技术，在保持计算效率的同时超越了传统Transformer编码器的性能。


<details>
  <summary>Details</summary>
Motivation: 在计算和内存资源受限的工业NLP应用中，紧凑的预训练双向编码器仍然是核心组件。虽然基于自注意力的BERT架构能够提供高质量的双向上下文建模，但最近出现的Avey架构作为一种自回归、无注意力的替代方案，自然地支持编码器适配。本文旨在将Avey重新设计用于编码器范式，以提供更高效的替代方案。

Method: 1. 将Avey架构重新设计用于编码器范式；2. 引入解耦的静态和动态参数化；3. 采用稳定性导向的归一化技术；4. 应用神经压缩方法；5. 在标准标记分类和信息检索基准上进行评估。

Result: 改进后的架构在标准标记分类和信息检索基准上持续优于四种广泛使用的基于Transformer的编码器，同时在处理长上下文时具有更好的扩展效率。

Conclusion: 本文提出的Avey编码器改进方案为工业NLP应用提供了一个高效且性能优越的替代方案，特别是在计算资源受限和需要处理长上下文的场景下，相比传统Transformer编码器具有明显优势。

Abstract: Compact pretrained bidirectional encoders remain the backbone of industrial NLP under tight compute and memory budgets. Their effectiveness stems from self-attention's ability to deliver high-quality bidirectional contextualization with sequence-level parallelism, as popularized by BERT-style architectures. Recently, Avey was introduced as an autoregressive, attention-free alternative that naturally admits an encoder-only adaptation. In this paper, we reformulate Avey for the encoder-only paradigm and propose several innovations to its architecture, including decoupled static and dynamic parameterizations, stability-oriented normalization, and neural compression. Results show that this reformulated architecture compares favorably to four widely used Transformer-based encoders, consistently outperforming them on standard token-classification and information-retrieval benchmarks while scaling more efficiently to long contexts.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [81] [Attention-gated U-Net model for semantic segmentation of brain tumors and feature extraction for survival prognosis](https://arxiv.org/abs/2602.15067)
*Rut Pate,Snehal Rajput,Mehul S. Raval,Rupal A. Kapdi,Mohendra Roy*

Main category: cs.AI

TL;DR: 提出基于注意力门控循环残差U-Net的三平面(2.5D)模型，用于脑胶质瘤分割和生存期预测，在BraTS2021验证集上获得0.900的Dice分数。


<details>
  <summary>Details</summary>
Motivation: 脑胶质瘤作为最常见的原发性脑肿瘤，其侵袭性、预后和组织学特征差异很大，复杂且耗时的外科手术使得治疗具有挑战性，需要更精确的分割方法来辅助治疗规划。

Method: 提出注意力门控循环残差U-Net(R2U-Net)三平面(2.5D)模型，整合残差、循环和三平面架构以增强特征表示和分割精度，同时保持计算效率。三平面网络从每个平面模型提取64个特征用于生存期预测，通过人工神经网络(ANN)将特征减少到28个。

Result: 在BraTS2021验证集上，全肿瘤(WT)分割获得0.900的Dice相似性分数(DSC)，性能与领先模型相当。生存期预测在测试集上达到45.71%准确率、108,318.128的均方误差(MSE)和0.338的斯皮尔曼等级相关系数(SRC)。

Conclusion: 提出的注意力门控循环残差U-Net三平面模型在脑肿瘤分割方面表现出色，性能与最先进模型相当，同时通过三平面特征提取为生存期预测提供了有效方法，有望辅助临床治疗规划。

Abstract: Gliomas, among the most common primary brain tumors, vary widely in aggressiveness, prognosis, and histology, making treatment challenging due to complex and time-intensive surgical interventions. This study presents an Attention-Gated Recurrent Residual U-Net (R2U-Net) based Triplanar (2.5D) model for improved brain tumor segmentation. The proposed model enhances feature representation and segmentation accuracy by integrating residual, recurrent, and triplanar architectures while maintaining computational efficiency, potentially aiding in better treatment planning. The proposed method achieves a Dice Similarity Score (DSC) of 0.900 for Whole Tumor (WT) segmentation on the BraTS2021 validation set, demonstrating performance comparable to leading models. Additionally, the triplanar network extracts 64 features per planar model for survival days prediction, which are reduced to 28 using an Artificial Neural Network (ANN). This approach achieves an accuracy of 45.71%, a Mean Squared Error (MSE) of 108,318.128, and a Spearman Rank Correlation Coefficient (SRC) of 0.338 on the test dataset.

</details>


### [82] [ResearchGym: Evaluating Language Model Agents on Real-World AI Research](https://arxiv.org/abs/2602.15112)
*Aniketh Garikaparthi,Manasi Patwardhan,Arman Cohan*

Main category: cs.AI

TL;DR: ResearchGym是一个用于评估AI智能体端到端研究能力的基准测试和执行环境，包含5个论文任务环境共39个子任务。GPT-5等前沿智能体表现出显著的能力-可靠性差距，仅在6.7%的评估中超越基线，平均只完成26.5%的子任务。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏系统评估AI智能体进行端到端科学研究能力的基准测试环境，需要创建能够测试智能体提出假设、运行实验、超越人类基线等完整研究流程的评估框架。

Method: 从ICML、ICLR和ACL会议中选取5篇口头报告和焦点论文，保留其数据集、评估框架和基线实现，但移除论文提出的核心方法，构建了5个容器化任务环境共39个子任务。智能体需要在环境中自主提出新假设、运行实验并尝试超越人类基线。

Result: GPT-5智能体仅在1/15次评估中（6.7%）超越基线11.5%，平均只完成26.5%的子任务。发现了长期失败模式：缺乏耐心、资源管理差、对弱假设过度自信、并行实验协调困难、上下文长度限制等。但在单次运行中，智能体成功超越了ICML 2025焦点任务的解决方案。

Conclusion: 前沿AI智能体偶尔能达到最先进的研究性能，但可靠性很低。ResearchGym为自主智能体的闭环研究提供了系统评估和分析的基础设施，揭示了当前智能体在端到端研究任务中存在的显著能力-可靠性差距。

Abstract: We introduce ResearchGym, a benchmark and execution environment for evaluating AI agents on end-to-end research. To instantiate this, we repurpose five oral and spotlight papers from ICML, ICLR, and ACL. From each paper's repository, we preserve the datasets, evaluation harness, and baseline implementations but withhold the paper's proposed method. This results in five containerized task environments comprising 39 sub-tasks in total. Within each environment, agents must propose novel hypotheses, run experiments, and attempt to surpass strong human baselines on the paper's metrics. In a controlled evaluation of an agent powered by GPT-5, we observe a sharp capability--reliability gap. The agent improves over the provided baselines from the repository in just 1 of 15 evaluations (6.7%) by 11.5%, and completes only 26.5% of sub-tasks on average. We identify recurring long-horizon failure modes, including impatience, poor time and resource management, overconfidence in weak hypotheses, difficulty coordinating parallel experiments, and hard limits from context length. Yet in a single run, the agent surpasses the solution of an ICML 2025 Spotlight task, indicating that frontier agents can occasionally reach state-of-the-art performance, but do so unreliably. We additionally evaluate proprietary agent scaffolds including Claude Code (Opus-4.5) and Codex (GPT-5.2) which display a similar gap. ResearchGym provides infrastructure for systematic evaluation and analysis of autonomous agents on closed-loop research.

</details>


### [83] [Protecting Language Models Against Unauthorized Distillation through Trace Rewriting](https://arxiv.org/abs/2602.15143)
*Xinhang Ma,William Yeoh,Ning Zhang,Yevgeniy Vorobeychik*

Main category: cs.AI

TL;DR: 论文研究如何通过修改教师模型的推理输出来防止未经授权的知识蒸馏，实现反蒸馏和API水印两种目标。


<details>
  <summary>Details</summary>
Motivation: 知识蒸馏被广泛用于将大模型能力迁移到小模型，但未经授权的蒸馏利用了前沿模型的开发努力和成本，需要防止这种不公平使用。

Method: 提出动态重写教师模型推理输出的方法，包括基于LLM的重写和基于梯度的技术，保持答案正确性和语义连贯性。

Result: 简单的基于指令的重写方法实现了强反蒸馏效果，同时保持甚至提升教师性能；重写方法还能实现高可靠的水印检测，几乎没有误报。

Conclusion: 通过重写教师模型的推理输出可以有效防止未经授权的知识蒸馏，同时实现反蒸馏和API水印两种保护机制。

Abstract: Knowledge distillation is a widely adopted technique for transferring capabilities from LLMs to smaller, more efficient student models. However, unauthorized use of knowledge distillation takes unfair advantage of the considerable effort and cost put into developing frontier models. We investigate methods for modifying teacher-generated reasoning traces to achieve two objectives that deter unauthorized distillation: (1) \emph{anti-distillation}, or degrading the training usefulness of query responses, and (2) \emph{API watermarking}, which embeds verifiable signatures in student models. We introduce several approaches for dynamically rewriting a teacher's reasoning outputs while preserving answer correctness and semantic coherence. Two of these leverage the rewriting capabilities of LLMs, while others use gradient-based techniques. Our experiments show that a simple instruction-based rewriting approach achieves a strong anti-distillation effect while maintaining or even improving teacher performance. Furthermore, we show that our rewriting approach also enables highly reliable watermark detection with essentially no false alarms.

</details>


### [84] [Panini: Continual Learning in Token Space via Structured Memory](https://arxiv.org/abs/2602.15156)
*Shreyas Rajesh,Pavan Holur,Mehmet Yigit Turali,Chenda Duan,Vwani Roychowdhury*

Main category: cs.AI

TL;DR: Panini提出了一种基于生成语义工作空间（GSW）的非参数持续学习框架，将文档表示为实体和事件感知的问答对网络，通过推理链进行高效检索，相比传统RAG方法在性能和效率上都有显著提升。


<details>
  <summary>Details</summary>
Motivation: 传统检索增强生成（RAG）方法存在两个主要问题：1）测试时计算效率低下（LLM需要重复处理相同文档）；2）块检索可能引入不相关上下文，导致无依据的生成。需要一种更高效、更可靠的持续学习方法来处理新文档和知识。

Method: 提出Panini框架，将文档表示为生成语义工作空间（GSW）——一种实体和事件感知的问答对网络。基础模型保持不变，学习通过将每个新经验整合到外部语义记忆状态中实现，该状态持续积累和整合。查询时仅遍历持续更新的GSW网络，检索最可能的推理链。

Result: 在六个QA基准测试中，Panini实现了最高的平均性能，比其他竞争基线高出5%-7%，同时使用2-30倍更少的答案上下文标记，支持完全开源管道，并在精心策划的不可回答查询上减少了无依据的答案。

Conclusion: 在写入时高效准确地构建经验（如GSW框架所实现的）在读取时既提高了效率又增强了可靠性。该方法展示了非参数持续学习的有效性，为语言模型处理新知识提供了更优的解决方案。

Abstract: Language models are increasingly used to reason over content they were not trained on, such as new documents, evolving knowledge, and user-specific data. A common approach is retrieval-augmented generation (RAG), which stores verbatim documents externally (as chunks) and retrieves only a relevant subset at inference time for an LLM to reason over. However, this results in inefficient usage of test-time compute (LLM repeatedly reasons over the same documents); moreover, chunk retrieval can inject irrelevant context that increases unsupported generation. We propose a human-like non-parametric continual learning framework, where the base model remains fixed, and learning occurs by integrating each new experience into an external semantic memory state that accumulates and consolidates itself continually. We present Panini, which realizes this by representing documents as Generative Semantic Workspaces (GSW) -- an entity- and event-aware network of question-answer (QA) pairs, sufficient for an LLM to reconstruct the experienced situations and mine latent knowledge via reasoning-grounded inference chains on the network. Given a query, Panini only traverses the continually-updated GSW (not the verbatim documents or chunks), and retrieves the most likely inference chains. Across six QA benchmarks, Panini achieves the highest average performance, 5%-7% higher than other competitive baselines, while using 2-30x fewer answer-context tokens, supports fully open-source pipelines, and reduces unsupported answers on curated unanswerable queries. The results show that efficient and accurate structuring of experiences at write time -- as achieved by the GSW framework -- yields both efficiency and reliability gains at read time. Code is available at https://github.com/roychowdhuryresearch/gsw-memory.

</details>


### [85] [da Costa and Tarski meet Goguen and Carnap: a novel approach for ontological heterogeneity based on consequence systems](https://arxiv.org/abs/2602.15158)
*Gabriel Rocha*

Main category: cs.AI

TL;DR: 提出一种基于da Costa数学容忍原则和Tarski后承算子的本体异质性处理方法，通过扩展后承系统和开发图来关联本体


<details>
  <summary>Details</summary>
Motivation: 解决本体异质性问题，即不同本体系统之间的兼容性和互操作性问题，借鉴Carnapian-Goguenism思想

Method: 1) 基于Carnielli等人的后承系统理论；2) 引入扩展后承系统（添加本体公理）；3) 定义扩展开发图，通过扩展后承系统的态射关联本体；4) 支持纤维化和分裂等操作

Result: 建立了da Costian-Tarskianism理论框架，提供了处理本体异质性的形式化工具，包括扩展后承系统和扩展开发图

Conclusion: 该方法为应用本体学领域提供了新的理论框架，未来可进一步研究其实际应用和扩展

Abstract: This paper presents a novel approach for ontological heterogeneity that draws heavily from Carnapian-Goguenism, as presented by Kutz, Mossakowski and Lücke (2010). The approach is provisionally designated da Costian-Tarskianism, named after da Costa's Principle of Tolerance in Mathematics and after Alfred Tarski's work on the concept of a consequence operator. The approach is based on the machinery of consequence systems, as developed by Carnielli et al. (2008) and Citkin and Muravitsky (2022), and it introduces the idea of an extended consequence system, which is a consequence system extended with ontological axioms. The paper also defines the concept of an extended development graph, which is a graph structure that allows ontologies to be related via morphisms of extended consequence systems, and additionally via other operations such as fibring and splitting. Finally, we discuss the implications of this approach for the field of applied ontology and suggest directions for future research.

</details>


### [86] [Mind the (DH) Gap! A Contrast in Risky Choices Between Reasoning and Conversational LLMs](https://arxiv.org/abs/2602.15173)
*Luise Ge,Yongyan Zhang,Yevgeniy Vorobeychik*

Main category: cs.AI

TL;DR: 该研究比较了20个前沿和开源大语言模型在风险决策中的表现，发现LLM可分为推理模型和对话模型两类，前者更理性，后者更接近人类但理性程度较低。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在决策支持和智能体工作流中应用广泛，但对其在不确定性下的决策机制理解有限。研究旨在比较LLM在风险选择中的表现，特别是考察前景表示方式（显式vs经验式）和决策理由（解释）两个维度的影响。

Method: 研究涉及20个前沿和开源LLM，通过匹配的人类被试实验提供参考基准，同时使用期望收益最大化的理性智能体模型作为另一个参考点。研究考察了两个维度：1）前景表示方式（显式描述vs经验历史）；2）决策理由（解释）。

Result: LLM可分为两类：推理模型（RMs）和对话模型（CMs）。RMs更趋向理性行为，对前景顺序、得失框架和解释不敏感，在显式和经验式前景表示下表现相似。CMs理性程度显著较低，更接近人类，对前景顺序、框架和解释敏感，且存在较大的描述-历史差距。开源LLM的配对比较表明，数学推理训练是区分RMs和CMs的关键因素。

Conclusion: LLM在风险决策中存在明显分化，训练目标（特别是数学推理训练）显著影响其决策行为。推理模型表现出更强的理性特征，而对话模型更接近人类但理性程度较低，这对LLM在决策支持系统中的应用具有重要意义。

Abstract: The use of large language models either as decision support systems, or in agentic workflows, is rapidly transforming the digital ecosystem. However, the understanding of LLM decision-making under uncertainty remains limited. We initiate a comparative study of LLM risky choices along two dimensions: (1) prospect representation (explicit vs. experience based) and (2) decision rationale (explanation). Our study, which involves 20 frontier and open LLMs, is complemented by a matched human subjects experiment, which provides one reference point, while an expected payoff maximizing rational agent model provides another. We find that LLMs cluster into two categories: reasoning models (RMs) and conversational models (CMs). RMs tend towards rational behavior, are insensitive to the order of prospects, gain/loss framing, and explanations, and behave similarly whether prospects are explicit or presented via experience history. CMs are significantly less rational, slightly more human-like, sensitive to prospect ordering, framing, and explanation, and exhibit a large description-history gap. Paired comparisons of open LLMs suggest that a key factor differentiating RMs and CMs is training for mathematical reasoning.

</details>


### [87] [Secure and Energy-Efficient Wireless Agentic AI Networks](https://arxiv.org/abs/2602.15212)
*Yuanyan Song,Kezhi Wang,Xinmian Xu*

Main category: cs.AI

TL;DR: 提出安全的无线智能体AI网络，通过智能体协作和友好干扰确保用户推理任务的QoS和隐私保护，同时最小化能耗


<details>
  <summary>Details</summary>
Motivation: 在无线环境中部署AI智能体进行协作推理时，需要同时保证服务质量、隐私保护和能源效率，现有方案难以平衡这些需求

Method: 设计包含监督AI智能体和多个其他AI智能体的网络架构，提出ASC和LAW两种资源分配方案，分别基于ADMM/SDR/SCA算法和LLM优化器在智能体工作流中解决联合优化问题

Result: 相比基准方案，所提方案能降低网络能耗达59.1%，并在基于Qwen的实际智能体AI系统中验证了在各种公共基准测试中达到满意的推理准确率

Conclusion: 提出的安全无线智能体AI网络框架和资源分配方案能有效平衡服务质量、隐私保护和能源效率，为实际部署提供了可行方案

Abstract: In this paper, we introduce a secure wireless agentic AI network comprising one supervisor AI agent and multiple other AI agents to provision quality of service (QoS) for users' reasoning tasks while ensuring confidentiality of private knowledge and reasoning outcomes. Specifically, the supervisor AI agent can dynamically assign other AI agents to participate in cooperative reasoning, while the unselected AI agents act as friendly jammers to degrade the eavesdropper's interception performance. To extend the service duration of AI agents, an energy minimization problem is formulated that jointly optimizes AI agent selection, base station (BS) beamforming, and AI agent transmission power, subject to latency and reasoning accuracy constraints. To address the formulated problem, we propose two resource allocation schemes, ASC and LAW, which first decompose it into three sub-problems. Specifically, ASC optimizes each sub-problem iteratively using the proposed alternating direction method of multipliers (ADMM)-based algorithm, semi-definite relaxation (SDR), and successive convex approximation (SCA), while LAW tackles each sub-problem using the proposed large language model (LLM) optimizer within an agentic workflow. The experimental results show that the proposed solutions can reduce network energy consumption by up to 59.1% compared to other benchmark schemes. Furthermore, the proposed schemes are validated using a practical agentic AI system based on Qwen, demonstrating satisfactory reasoning accuracy across various public benchmarks.

</details>


### [88] [Predicting Invoice Dilution in Supply Chain Finance with Leakage Free Two Stage XGBoost, KAN (Kolmogorov Arnold Networks), and Ensemble Models](https://arxiv.org/abs/2602.15248)
*Pavel Koptev,Vishnu Kumar,Konstantin Malkov,George Shapiro,Yury Vikhanov*

Main category: cs.AI

TL;DR: 本文提出AI/机器学习框架补充确定性算法，实时预测发票稀释风险，解决供应链金融中发票金额与实际收款差距问题


<details>
  <summary>Details</summary>
Motivation: 发票稀释（批准金额与实际收款差距）是供应链金融中非信用风险和利润损失的重要来源。传统方法依赖买方不可撤销付款承诺（IPU），但IPU可能阻碍供应链金融采纳，特别是对于次级投资级买方。需要更灵活的数据驱动方法。

Method: 提出AI/机器学习框架，补充确定性算法，利用实时动态信用额度，基于九个关键交易字段的广泛生产数据集，实时预测每个买方-供应商对的发票稀释风险。

Result: 论文评估了AI/机器学习框架如何补充确定性算法来预测发票稀释，但摘要未提供具体评估结果数据。

Conclusion: AI/机器学习方法可以补充传统确定性算法，为供应链金融提供更灵活、数据驱动的发票稀释风险管理方案，减少对IPU的依赖，促进供应链金融采纳。

Abstract: Invoice or payment dilution is the gap between the approved invoice amount and the actual collection is a significant source of non credit risk and margin loss in supply chain finance. Traditionally, this risk is managed through the buyer's irrevocable payment undertaking (IPU), which commits to full payment without deductions. However, IPUs can hinder supply chain finance adoption, particularly among sub-invested grade buyers. A newer, data-driven methods use real-time dynamic credit limits, projecting dilution for each buyer-supplier pair in real-time. This paper introduces an AI, machine learning framework and evaluates how that can supplement a deterministic algorithm to predict invoice dilution using extensive production dataset across nine key transaction fields.

</details>


### [89] [Enhancing Diversity and Feasibility: Joint Population Synthesis from Multi-source Data Using Generative Models](https://arxiv.org/abs/2602.15270)
*Farbod Abbasi,Zachary Patterson,Bilal Farooq*

Main category: cs.AI

TL;DR: 提出基于WGAN-GP的多源数据集联合生成方法，通过逆梯度惩罚正则化提升合成人口的多样性和可行性，优于传统序列方法


<details>
  <summary>Details</summary>
Motivation: 现有合成人口生成方法存在两个主要问题：1）依赖单一数据集或采用序列化数据融合生成过程，无法捕捉特征间复杂相互作用；2）难以处理采样零值（有效但未观测到的属性组合）和结构零值（因逻辑约束不可行的组合），导致生成数据多样性和可行性不足

Method: 提出基于Wasserstein生成对抗网络（WGAN）与梯度惩罚的多源数据集联合学习方法，在生成器损失函数中引入逆梯度惩罚正则化项，同时整合多源数据并生成合成人口

Result: 联合方法优于序列基线，召回率提升7%，精确率提升15%；正则化项进一步改善多样性和可行性，召回率提升10%，精确率提升1%；相似度分布评估中，联合方法得分为88.1，优于序列方法的84.6

Conclusion: 提出的多源联合生成方法能显著提升合成人口的多样性和可行性，为基于代理的模型提供更准确可靠的输入，有望增强交通和城市规划中ABM的准确性和可靠性

Abstract: Generating realistic synthetic populations is essential for agent-based models (ABM) in transportation and urban planning. Current methods face two major limitations. First, many rely on a single dataset or follow a sequential data fusion and generation process, which means they fail to capture the complex interplay between features. Second, these approaches struggle with sampling zeros (valid but unobserved attribute combinations) and structural zeros (infeasible combinations due to logical constraints), which reduce the diversity and feasibility of the generated data. This study proposes a novel method to simultaneously integrate and synthesize multi-source datasets using a Wasserstein Generative Adversarial Network (WGAN) with gradient penalty. This joint learning method improves both the diversity and feasibility of synthetic data by defining a regularization term (inverse gradient penalty) for the generator loss function. For the evaluation, we implement a unified evaluation metric for similarity, and place special emphasis on measuring diversity and feasibility through recall, precision, and the F1 score. Results show that the proposed joint approach outperforms the sequential baseline, with recall increasing by 7\% and precision by 15\%. Additionally, the regularization term further improves diversity and feasibility, reflected in a 10\% increase in recall and 1\% in precision. We assess similarity distributions using a five-metric score. The joint approach performs better overall, and reaches a score of 88.1 compared to 84.6 for the sequential method. Since synthetic populations serve as a key input for ABM, this multi-source generative approach has the potential to significantly enhance the accuracy and reliability of ABM.

</details>


### [90] [When Remembering and Planning are Worth it: Navigating under Change](https://arxiv.org/abs/2602.15274)
*Omid Madani,J. Brian Burns,Reza Eghbali,Thomas L. Dean*

Main category: cs.AI

TL;DR: 研究不同记忆类型在动态不确定环境中如何辅助空间导航，发现结合多种策略的架构在处理探索、搜索和规划任务时最有效，特别是使用非平稳概率学习更新记忆并构建动态地图的智能体表现最佳。


<details>
  <summary>Details</summary>
Motivation: 在动态不确定环境中，智能体面临导航挑战：障碍物和食物位置每日变化，位置感知有限且不确定。需要开发能够快速学习并适应环境变化的稳健导航策略。

Method: 研究从简单到复杂的多种策略，包括不同记忆使用和学习方式。重点关注能够整合多种策略的架构，特别是使用非平稳概率学习技术更新情景记忆，并基于这些记忆构建动态地图进行实时规划的方法。

Result: 当任务难度（如目标距离）增加时，使用非平稳概率学习更新记忆并构建动态地图的智能体比简单（最小记忆）智能体效率显著提高，前提是定位和环境变化带来的不确定性不过大。

Conclusion: 在动态不确定环境中，需要能够整合多种策略的导航架构来处理不同性质的任务。结合非平稳概率学习更新记忆并构建动态地图的方法在任务难度增加时表现优越，但需要控制不确定性水平。

Abstract: We explore how different types and uses of memory can aid spatial navigation in changing uncertain environments. In the simple foraging task we study, every day, our agent has to find its way from its home, through barriers, to food. Moreover, the world is non-stationary: from day to day, the location of the barriers and food may change, and the agent's sensing such as its location information is uncertain and very limited. Any model construction, such as a map, and use, such as planning, needs to be robust against these challenges, and if any learning is to be useful, it needs to be adequately fast. We look at a range of strategies, from simple to sophisticated, with various uses of memory and learning. We find that an architecture that can incorporate multiple strategies is required to handle (sub)tasks of a different nature, in particular for exploration and search, when food location is not known, and for planning a good path to a remembered (likely) food location. An agent that utilizes non-stationary probability learning techniques to keep updating its (episodic) memories and that uses those memories to build maps and plan on the fly (imperfect maps, i.e. noisy and limited to the agent's experience) can be increasingly and substantially more efficient than the simpler (minimal-memory) agents, as the task difficulties such as distance to goal are raised, as long as the uncertainty, from localization and change, is not too large.

</details>


### [91] [EAA: Automating materials characterization with vision language model agents](https://arxiv.org/abs/2602.15294)
*Ming Du,Yanqi Luo,Srutarshi Banerjee,Michael Wojcik,Jelena Popovic,Mathew J. Cherukara*

Main category: cs.AI

TL;DR: EAA是一个基于视觉语言模型的代理系统，用于自动化复杂的实验显微镜工作流程，通过多模态推理、工具增强操作和可选长期记忆支持自主和交互式测量。


<details>
  <summary>Details</summary>
Motivation: 传统实验显微镜工作流程复杂且需要专业知识，EAA旨在通过自动化降低操作负担、提高光束线效率，并降低用户专业知识门槛。

Method: 基于灵活的任务管理器架构，集成多模态推理、工具增强操作和可选长期记忆，支持从完全代理驱动自动化到嵌入局部LLM查询的逻辑定义流程，提供双向兼容MCP的现代工具生态系统。

Result: 在先进光子源的成像光束线上成功演示了自动区域板聚焦、自然语言描述特征搜索和交互式数据采集，展示了视觉代理如何增强光束线效率。

Conclusion: EAA系统展示了视觉能力代理可以显著提高实验显微镜工作流程的自动化水平，降低操作复杂性，为更广泛的用户群体提供便利。

Abstract: We present Experiment Automation Agents (EAA), a vision-language-model-driven agentic system designed to automate complex experimental microscopy workflows. EAA integrates multimodal reasoning, tool-augmented action, and optional long-term memory to support both autonomous procedures and interactive user-guided measurements. Built on a flexible task-manager architecture, the system enables workflows ranging from fully agent-driven automation to logic-defined routines that embed localized LLM queries. EAA further provides a modern tool ecosystem with two-way compatibility for Model Context Protocol (MCP), allowing instrument-control tools to be consumed or served across applications. We demonstrate EAA at an imaging beamline at the Advanced Photon Source, including automated zone plate focusing, natural language-described feature search, and interactive data acquisition. These results illustrate how vision-capable agents can enhance beamline efficiency, reduce operational burden, and lower the expertise barrier for users.

</details>


### [92] [X-MAP: eXplainable Misclassification Analysis and Profiling for Spam and Phishing Detection](https://arxiv.org/abs/2602.15298)
*Qi Zhang,Dian Chen,Lance M. Kaplan,Audun Jøsang,Dong Hyun Jeong,Feng Chen,Jin-Hee Cho*

Main category: cs.AI

TL;DR: X-MAP是一个可解释的误分类分析和分析框架，通过主题级语义模式揭示模型失败原因，结合SHAP特征归因和非负矩阵分解构建可解释主题配置文件，用于改进垃圾邮件和钓鱼检测。


<details>
  <summary>Details</summary>
Motivation: 垃圾邮件和钓鱼检测中的误分类危害很大：假阴性使用户暴露于攻击，假阳性降低信任。现有基于不确定性的检测器可以标记潜在错误，但可能被欺骗且可解释性有限。

Method: X-MAP结合SHAP特征归因和非负矩阵分解，为正确分类的垃圾邮件/钓鱼和合法消息构建可解释主题配置文件，使用Jensen-Shannon散度测量每条消息与这些配置文件的偏差。

Result: 实验显示误分类消息的偏差至少是正确分类消息的两倍。作为检测器，X-MAP达到0.98 AUROC，在95% TRR时将假拒绝率降至0.089。作为修复层可恢复高达97%的错误拒绝的正确预测。

Conclusion: X-MAP在提高垃圾邮件和钓鱼检测方面具有有效性和可解释性，能够揭示模型失败的语义模式并改善检测性能。

Abstract: Misclassifications in spam and phishing detection are very harmful, as false negatives expose users to attacks while false positives degrade trust. Existing uncertainty-based detectors can flag potential errors, but possibly be deceived and offer limited interpretability. This paper presents X-MAP, an eXplainable Misclassification Analysis and Profilling framework that reveals topic-level semantic patterns behind model failures. X-MAP combines SHAP-based feature attributions with non-negative matrix factorization to build interpretable topic profiles for reliably classified spam/phishing and legitimate messages, and measures each message's deviation from these profiles using Jensen-Shannon divergence. Experiments on SMS and phishing datasets show that misclassified messages exhibit at least two times larger divergence than correctly classified ones. As a detector, X-MAP achieves up to 0.98 AUROC and lowers the false-rejection rate at 95% TRR to 0.089 on positive predictions. When used as a repair layer on base detectors, it recovers up to 97% of falsely rejected correct predictions with moderate leakage. These results demonstrate X-MAP's effectiveness and interpretability for improving spam and phishing detection.

</details>


### [93] [AgriWorld:A World Tools Protocol Framework for Verifiable Agricultural Reasoning with Code-Executing LLM Agents](https://arxiv.org/abs/2602.15325)
*Zhixing Zhang,Jesen Zhang,Hao Liu,Qinhan Lv,Jing Yang,Kaitong Cai,Keze Wang*

Main category: cs.AI

TL;DR: 提出Agro-Reflective框架，将大语言模型与农业数据工具结合，通过执行-观察-精炼循环实现农业科学推理


<details>
  <summary>Details</summary>
Motivation: 现有农业基础模型缺乏语言推理和交互能力，而大语言模型无法直接处理高维异构农业数据，需要桥接这一鸿沟

Method: 构建AgriWorld执行环境提供地理空间查询、遥感时间序列分析、作物生长模拟等工具，设计Agro-Reflective多轮LLM代理通过代码编写-执行观察-精炼循环进行推理

Result: 在AgroBench基准测试中超越纯文本和直接工具使用基线，验证了执行驱动反思对可靠农业推理的有效性

Conclusion: 提出的代理框架成功将LLM的语言能力与农业数据工具结合，为农业科学提供了可扩展的智能推理解决方案

Abstract: Foundation models for agriculture are increasingly trained on massive spatiotemporal data (e.g., multi-spectral remote sensing, soil grids, and field-level management logs) and achieve strong performance on forecasting and monitoring. However, these models lack language-based reasoning and interactive capabilities, limiting their usefulness in real-world agronomic workflows. Meanwhile, large language models (LLMs) excel at interpreting and generating text, but cannot directly reason over high-dimensional, heterogeneous agricultural datasets. We bridge this gap with an agentic framework for agricultural science. It provides a Python execution environment, AgriWorld, exposing unified tools for geospatial queries over field parcels, remote-sensing time-series analytics, crop growth simulation, and task-specific predictors (e.g., yield, stress, and disease risk). On top of this environment, we design a multi-turn LLM agent, Agro-Reflective, that iteratively writes code, observes execution results, and refines its analysis via an execute-observe-refine loop. We introduce AgroBench, with scalable data generation for diverse agricultural QA spanning lookups, forecasting, anomaly detection, and counterfactual "what-if" analysis. Experiments outperform text-only and direct tool-use baselines, validating execution-driven reflection for reliable agricultural reasoning.

</details>


### [94] [World-Model-Augmented Web Agents with Action Correction](https://arxiv.org/abs/2602.15384)
*Zhouzhou Shen,Xueyu Hu,Xiyun Li,Tianqing Fang,Juncheng Li,Shengyu Zhang*

Main category: cs.AI

TL;DR: WAC是一个集成了模型协作、结果模拟和反馈驱动动作优化的Web智能体，通过多智能体协作和两阶段推理链来提升Web任务执行的推理能力和风险意识。


<details>
  <summary>Details</summary>
Motivation: 当前基于大语言模型的Web智能体在预测环境变化方面存在局限，缺乏对执行风险的全面认知，容易过早执行风险动作导致任务失败，需要提升推理能力和风险意识。

Method: 1) 多智能体协作：动作模型咨询世界模型获取策略指导，然后基于环境状态转换知识生成可执行动作；2) 两阶段推理链：世界模型模拟动作结果，法官模型审查结果并在必要时触发动作纠正反馈。

Result: 在VisualWebArena上获得1.8%的绝对提升，在Online-Mind2Web上获得1.3%的绝对提升。

Conclusion: WAC通过模型协作、结果模拟和反馈驱动的动作优化，显著提升了Web智能体的推理能力和风险感知能力，实现了更稳健的Web任务执行。

Abstract: Web agents based on large language models have demonstrated promising capability in automating web tasks. However, current web agents struggle to reason out sensible actions due to the limitations of predicting environment changes, and might not possess comprehensive awareness of execution risks, prematurely performing risky actions that cause losses and lead to task failure. To address these challenges, we propose WAC, a web agent that integrates model collaboration, consequence simulation, and feedback-driven action refinement. To overcome the cognitive isolation of individual models, we introduce a multi-agent collaboration process that enables an action model to consult a world model as a web-environment expert for strategic guidance; the action model then grounds these suggestions into executable actions, leveraging prior knowledge of environmental state transition dynamics to enhance candidate action proposal. To achieve risk-aware resilient task execution, we introduce a two-stage deduction chain. A world model, specialized in environmental state transitions, simulates action outcomes, which a judge model then scrutinizes to trigger action corrective feedback when necessary. Experiments show that WAC achieves absolute gains of 1.8% on VisualWebArena and 1.3% on Online-Mind2Web.

</details>


### [95] [Improving LLM Reliability through Hybrid Abstention and Adaptive Detection](https://arxiv.org/abs/2602.15391)
*Ankit Sharma,Nachiket Tapas,Jyotiprakash Patra*

Main category: cs.AI

TL;DR: 本文提出了一种自适应弃权系统，通过动态调整安全阈值和层级级联检测架构，在保持高性能的同时平衡LLM的安全性和实用性。


<details>
  <summary>Details</summary>
Motivation: 当前LLM部署面临安全性与实用性的根本权衡：严格过滤机制会阻止良性查询，而宽松控制则可能生成不安全内容。传统的基于静态规则或固定置信度阈值的防护措施通常缺乏上下文敏感性且计算成本高，导致高延迟和用户体验下降。

Method: 引入自适应弃权系统，基于实时上下文信号（如领域和用户历史）动态调整安全阈值。框架集成了由五个并行检测器组成的多维检测架构，通过层级级联机制结合以优化速度和精度。级联设计通过逐步过滤查询减少不必要的计算。

Result: 在混合和特定领域工作负载上的广泛评估显示，误报率显著降低，特别是在医疗建议和创意写作等敏感领域。系统在严格操作模式下保持高安全精度和接近完美的召回率。与非级联模型和外部防护系统相比，实现了显著的延迟改进。

Conclusion: 上下文感知的弃权框架有效平衡了安全性和实用性，同时保持了性能，为可靠的LLM部署提供了可扩展的解决方案。

Abstract: Large Language Models (LLMs) deployed in production environments face a fundamental safety-utility trade-off either a strict filtering mechanisms prevent harmful outputs but often block benign queries or a relaxed controls risk unsafe content generation. Conventional guardrails based on static rules or fixed confidence thresholds are typically context-insensitive and computationally expensive, resulting in high latency and degraded user experience. To address these limitations, we introduce an adaptive abstention system that dynamically adjusts safety thresholds based on real-time contextual signals such as domain and user history. The proposed framework integrates a multi-dimensional detection architecture composed of five parallel detectors, combined through a hierarchical cascade mechanism to optimize both speed and precision. The cascade design reduces unnecessary computation by progressively filtering queries, achieving substantial latency improvements compared to non-cascaded models and external guardrail systems. Extensive evaluation on mixed and domain-specific workloads demonstrates significant reductions in false positives, particularly in sensitive domains such as medical advice and creative writing. The system maintains high safety precision and near-perfect recall under strict operating modes. Overall, our context-aware abstention framework effectively balances safety and utility while preserving performance, offering a scalable solution for reliable LLM deployment.

</details>


### [96] [Common Belief Revisited](https://arxiv.org/abs/2602.15403)
*Thomas Ågotnes*

Main category: cs.AI

TL;DR: 本文研究了当个体信念满足KD45逻辑时，共同信念的逻辑性质。研究发现共同信念不是KD4，而是具有额外公理的系统，且依赖于智能体数量。


<details>
  <summary>Details</summary>
Motivation: 传统观点认为共同信念是KD4逻辑，但本文发现当个体信念是KD45时，共同信念失去了5性质，只保留了D和4性质，并具有新的shift-reflexivity性质。这引发了一个问题：KD4加上这个新公理是否足以完全刻画共同信念？

Method: 通过逻辑分析，研究共同信念在KD45个体信念下的性质，识别出额外的公理要求，并证明这些公理的完备性。

Result: 发现KD4加上shift-reflexivity公理不足以完全刻画共同信念，需要额外公理，且该公理依赖于智能体数量。最终给出了共同信念的完备逻辑刻画。

Conclusion: 解决了共同信念逻辑的开放问题，给出了当个体信念为KD45时共同信念的完备逻辑特征，包含shift-reflexivity公理和依赖于智能体数量的额外公理。

Abstract: Contrary to common belief, common belief is not KD4.
  If individual belief is KD45, common belief does indeed lose the 5 property and keep the D and 4 properties -- and it has none of the other commonly considered properties of knowledge and belief. But it has another property: $C(Cφ\rightarrow φ)$ -- corresponding to so-called shift-reflexivity (reflexivity one step ahead). This observation begs the question:
  is KD4 extended with this axiom a complete characterisation of common belief in the KD45 case? If not, what \emph{is} the logic of common belief? In this paper we show that the answer to the first question is ``no'': there is one additional axiom, and, furthermore, it relies on the number of agents. We show that the result is a complete characterisation of common belief, settling the open problem.

</details>


### [97] [GenAI-LA: Generative AI and Learning Analytics Workshop (LAK 2026), April 27--May 1, 2026, Bergen, Norway](https://arxiv.org/abs/2602.15531)
*Javier Irigoyen,Roberto Daza,Aythami Morales,Julian Fierrez,Francisco Jurado,Alvaro Ortigosa,Ruben Tolosana*

Main category: cs.AI

TL;DR: EduEVAL-DB是一个基于教师角色的数据集，用于评估和训练自动教学评估器和AI导师的教学解释能力，包含854个解释，涵盖科学、语言和社会科学K-12年级问题，并提出了基于教育标准的教学风险评估框架。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏专门用于评估和训练自动教学评估器和AI导师教学解释质量的数据集。需要建立一个基于教师角色、涵盖多学科和多年级的教学解释数据集，以支持教育AI系统的开发和评估。

Method: 基于ScienceQA基准的精选子集构建数据集，包含139个问题，每个问题提供1个人类教师解释和6个LLM模拟的教师角色解释。通过提示工程实例化不同教学风格的角色，提出包含5个维度的教学风险评估框架，采用半自动专家评审进行标注。

Result: 创建了包含854个解释的EduEVAL-DB数据集，涵盖科学、语言和社会科学K-12年级。通过初步验证实验，评估了Gemini 2.5 Pro和Llama 3.1 8B模型在教学风险检测上的表现，并探索了在消费级硬件上部署的可行性。

Conclusion: EduEVAL-DB为评估和训练自动教学评估器和AI导师提供了有价值的资源，提出的教学风险框架能够有效评估教学解释质量，支持在消费级硬件上部署的教学风险检测模型开发。

Abstract: This work introduces EduEVAL-DB, a dataset based on teacher roles designed to support the evaluation and training of automatic pedagogical evaluators and AI tutors for instructional explanations. The dataset comprises 854 explanations corresponding to 139 questions from a curated subset of the ScienceQA benchmark, spanning science, language, and social science across K-12 grade levels. For each question, one human-teacher explanation is provided and six are generated by LLM-simulated teacher roles. These roles are inspired by instructional styles and shortcomings observed in real educational practice and are instantiated via prompt engineering. We further propose a pedagogical risk rubric aligned with established educational standards, operationalizing five complementary risk dimensions: factual correctness, explanatory depth and completeness, focus and relevance, student-level appropriateness, and ideological bias. All explanations are annotated with binary risk labels through a semi-automatic process with expert teacher review. Finally, we present preliminary validation experiments to assess the suitability of EduEVAL-DB for evaluation. We benchmark a state-of-the-art education-oriented model (Gemini 2.5 Pro) against a lightweight local Llama 3.1 8B model and examine whether supervised fine-tuning on EduEVAL-DB supports pedagogical risk detection using models deployable on consumer hardware.

</details>


### [98] [Quantifying construct validity in large language model evaluations](https://arxiv.org/abs/2602.15532)
*Ryan Othniel Kearns*

Main category: cs.AI

TL;DR: 该论文提出结构化能力模型，首次从大量LLM基准测试结果中提取可解释且可泛化的能力，解决了现有方法在构建效度方面的不足。


<details>
  <summary>Details</summary>
Motivation: 当前LLM社区常将基准测试结果等同于模型通用能力，但基准测试存在测试集污染、标注错误等问题。现有方法（潜在因子模型和缩放定律）都无法有效解决构建效度问题：潜在因子模型忽略缩放定律，提取的能力往往只是模型规模的代理；缩放定律忽略测量误差，提取的能力既不可解释又容易过拟合。

Method: 提出结构化能力模型，结合了缩放定律和潜在因子模型的优点：模型规模应影响能力（如缩放定律），而这些能力应在考虑测量误差的情况下影响观测结果（如潜在因子模型）。在OpenLLM排行榜的大规模结果样本上拟合该模型及其两种替代方法。

Result: 结构化能力模型在简约拟合指标上优于潜在因子模型，在分布外基准预测上优于缩放定律。该模型展示了更好的解释和预测能力，能够更准确地量化LLM评估中的构建效度。

Conclusion: 结构化能力模型通过适当分离模型规模与能力，结合了缩放定律和潜在因子模型的洞见，为LLM基准测试的构建效度评估提供了更可靠的方法，具有更好的解释和预测能力。

Abstract: The LLM community often reports benchmark results as if they are synonymous with general model capabilities. However, benchmarks can have problems that distort performance, like test set contamination and annotator error. How can we know that a benchmark is a reliable indicator of some capability that we want to measure? This question concerns the construct validity of LLM benchmarks, and it requires separating benchmark results from capabilities when we model and predict LLM performance.
  Both social scientists and computer scientists propose formal models - latent factor models and scaling laws - for identifying the capabilities underlying benchmark scores. However, neither technique is satisfactory for construct validity. Latent factor models ignore scaling laws, and as a result, the capabilities they extract often proxy model size. Scaling laws ignore measurement error, and as a result, the capabilities they extract are both uninterpretable and overfit to the observed benchmarks.
  This thesis presents the structured capabilities model, the first model to extract interpretable and generalisable capabilities from a large collection of LLM benchmark results. I fit this model and its two alternatives on a large sample of results from the OpenLLM Leaderboard. Structured capabilities outperform latent factor models on parsimonious fit indices, and exhibit better out-of-distribution benchmark prediction than scaling laws. These improvements are possible because neither existing approach separates model scale from capabilities in the appropriate way. Model scale should inform capabilities, as in scaling laws, and these capabilities should inform observed results up to measurement error, as in latent factor models. In combining these two insights, structured capabilities demonstrate better explanatory and predictive power for quantifying construct validity in LLM evaluations.

</details>


### [99] [RUVA: Personalized Transparent On-Device Graph Reasoning](https://arxiv.org/abs/2602.15553)
*Gabriele Conte,Alessio Mattiace,Gianni Carmosino,Potito Aghilar,Giovanni Servedio,Francesco Musicco,Vito Walter Anelli,Tommaso Di Noia,Francesco Maria Donini*

Main category: cs.AI

TL;DR: Ruva提出首个"透明盒"架构，用于人类参与的记忆管理，将个人AI从向量匹配转向知识图谱推理，确保"被遗忘权"。


<details>
  <summary>Details</summary>
Motivation: 当前个人AI领域被"黑盒"检索增强生成主导，标准向量数据库缺乏可问责性：当AI产生幻觉或检索敏感数据时，用户无法检查原因或纠正错误。更严重的是，从向量空间中"删除"概念在数学上不精确，会留下违反真正隐私的概率"幽灵"。

Method: Ruva将个人AI建立在个人知识图谱上，实现从向量匹配到图谱推理的范式转变。它允许用户检查AI知道什么，并执行特定事实的精确删除，支持人类参与的记忆管理。

Result: Ruva是首个"透明盒"架构，为用户提供了检查AI知识和精确删除特定事实的能力，确保"被遗忘权"的实现，让用户成为自己生活的编辑者。

Conclusion: 通过将个人AI从黑盒向量匹配转向透明图谱推理，Ruva解决了当前AI系统的可问责性和隐私问题，赋予用户对个人记忆的完全控制权。

Abstract: The Personal AI landscape is currently dominated by "Black Box" Retrieval-Augmented Generation. While standard vector databases offer statistical matching, they suffer from a fundamental lack of accountability: when an AI hallucinates or retrieves sensitive data, the user cannot inspect the cause nor correct the error. Worse, "deleting" a concept from a vector space is mathematically imprecise, leaving behind probabilistic "ghosts" that violate true privacy. We propose Ruva, the first "Glass Box" architecture designed for Human-in-the-Loop Memory Curation. Ruva grounds Personal AI in a Personal Knowledge Graph, enabling users to inspect what the AI knows and to perform precise redaction of specific facts. By shifting the paradigm from Vector Matching to Graph Reasoning, Ruva ensures the "Right to be Forgotten." Users are the editors of their own lives; Ruva hands them the pen. The project and the demo video are available at http://sisinf00.poliba.it/ruva/.

</details>


### [100] [How Vision Becomes Language: A Layer-wise Information-Theoretic Analysis of Multimodal Reasoning](https://arxiv.org/abs/2602.15580)
*Hongxuan Wu,Yukun Zhang,Xueqing Zhou*

Main category: cs.AI

TL;DR: 本文提出PID Flow框架，通过信息分解分析多模态Transformer中视觉和语言信息的流动模式，发现视觉信息在早期层达到峰值后衰减，语言信息在后期层主导预测（占82%），跨模态协同作用始终低于2%。


<details>
  <summary>Details</summary>
Motivation: 研究多模态Transformer在回答视觉问题时，预测究竟是由视觉证据、语言推理还是真正的跨模态计算驱动，以及这种结构如何在不同层间演化。理解模态信息在Transformer中的流动机制。

Method: 提出基于部分信息分解（PID）的层间分析框架，引入PID Flow流水线：结合降维、归一化流高斯化和闭式高斯PID估计，使高维神经表示的PID计算变得可行。应用于LLaVA-1.5-7B和LLaVA-1.6-7B模型，分析六个GQA推理任务。

Result: 发现一致的模态转导模式：视觉独特信息在早期达到峰值后衰减，语言独特信息在后期层激增（占最终预测的82%），跨模态协同作用始终低于2%。这种模式在不同模型变体中高度稳定（层间相关性>0.96），但任务依赖性很强。通过注意力敲除实验建立了因果关系。

Conclusion: 研究提供了信息论和因果关系的解释，说明视觉如何在多模态Transformer中转化为语言，并为识别模态特定信息丢失的架构瓶颈提供了定量指导。揭示了多模态Transformer中信息流动的基本模式。

Abstract: When a multimodal Transformer answers a visual question, is the prediction driven by visual evidence, linguistic reasoning, or genuinely fused cross-modal computation -- and how does this structure evolve across layers? We address this question with a layer-wise framework based on Partial Information Decomposition (PID) that decomposes the predictive information at each Transformer layer into redundant, vision-unique, language-unique, and synergistic components. To make PID tractable for high-dimensional neural representations, we introduce \emph{PID Flow}, a pipeline combining dimensionality reduction, normalizing-flow Gaussianization, and closed-form Gaussian PID estimation. Applying this framework to LLaVA-1.5-7B and LLaVA-1.6-7B across six GQA reasoning tasks, we uncover a consistent \emph{modal transduction} pattern: visual-unique information peaks early and decays with depth, language-unique information surges in late layers to account for roughly 82\% of the final prediction, and cross-modal synergy remains below 2\%. This trajectory is highly stable across model variants (layer-wise correlations $>$0.96) yet strongly task-dependent, with semantic redundancy governing the detailed information fingerprint. To establish causality, we perform targeted Image$\rightarrow$Question attention knockouts and show that disrupting the primary transduction pathway induces predictable increases in trapped visual-unique information, compensatory synergy, and total information cost -- effects that are strongest in vision-dependent tasks and weakest in high-redundancy tasks. Together, these results provide an information-theoretic, causal account of how vision becomes language in multimodal Transformers, and offer quantitative guidance for identifying architectural bottlenecks where modality-specific information is lost.

</details>


### [101] [On inferring cumulative constraints](https://arxiv.org/abs/2602.15635)
*Konstantin Sidorov*

Main category: cs.AI

TL;DR: 提出一种预处理方法，通过推断额外的累积约束来捕获多资源交互，提升调度问题的求解性能


<details>
  <summary>Details</summary>
Motivation: 传统约束规划中累积约束的传播通常单独进行，忽略了多资源之间的交互作用，导致在某些基准测试上性能严重下降

Method: 将累积约束解释为占用向量的线性不等式，通过(1)发现不能并行运行的任务集合（覆盖集），(2)通过提升技术加强覆盖不等式，(3)将生成的约束注入调度问题实例中

Result: 在标准RCPSP和RCPSP/max测试套件上，推断的约束改善了搜索性能并收紧目标界限，发现了25个新的下界和5个新的最优解，其中8个下界直接来自推断的约束

Conclusion: 该方法能有效捕获多资源交互，提升调度问题的求解效率，在有利实例上显著改善性能，在不利实例上仅造成轻微性能下降

Abstract: Cumulative constraints are central in scheduling with constraint programming, yet propagation is typically performed per constraint, missing multi-resource interactions and causing severe slowdowns on some benchmarks. I present a preprocessing method for inferring additional cumulative constraints that capture such interactions without search-time probing. This approach interprets cumulative constraints as linear inequalities over occupancy vectors and generates valid inequalities by (i) discovering covers, the sets of tasks that cannot run in parallel, (ii) strengthening the cover inequalities for the discovered sets with lifting, and (iii) injecting the resulting constraints back into the scheduling problem instance. Experiments on standard RCPSP and RCPSP/max test suites show that these inferred constraints improve search performance and tighten objective bounds on favorable instances, while incurring little degradation on unfavorable ones. Additionally, these experiments discover 25 new lower bounds and five new best solutions; eight of the lower bounds are obtained directly from the inferred constraints.

</details>


### [102] [CARE Drive A Framework for Evaluating Reason-Responsiveness of Vision Language Models in Automated Driving](https://arxiv.org/abs/2602.15645)
*Lucas Elbert Suryana,Farah Bierenga,Sanne van Buuren,Pepijn Kooij,Elsefien Tulleners,Federico Scari,Simeon Calvert,Bart van Arem,Arkady Zgonnikov*

Main category: cs.AI

TL;DR: CARE Drive是一个评估自动驾驶中视觉语言模型"原因响应性"的框架，通过对比基线模型和原因增强模型在受控上下文变化下的决策，来评估人类原因是否真正影响模型行为。


<details>
  <summary>Details</summary>
Motivation: 现有评估方法主要关注结果性能（如安全性、轨迹精度），但无法确定模型决策是否真正反映了人类相关的考虑因素。这导致无法区分模型解释是真正的理性决策还是事后合理化，在安全关键领域可能产生虚假信心。

Method: 提出CARE Drive框架，采用两阶段评估过程：1) 提示校准确保稳定输出；2) 系统性的上下文扰动，测量决策对人类原因（如安全边际、社会压力、效率约束）的敏感性。通过对比基线模型和原因增强模型在受控上下文变化下的决策来评估原因响应性。

Result: 在自行车超车场景中，明确的人类原因显著影响模型决策，改善了与专家推荐行为的一致性。但响应性在不同上下文因素间存在差异，表明模型对不同类型原因的敏感性不均衡。

Conclusion: CARE Drive提供了经验证据，表明可以在不修改模型参数的情况下系统评估基础模型的原因响应性。该框架有助于确保自动驾驶系统中视觉语言模型的决策真正反映人类相关的考虑因素。

Abstract: Foundation models, including vision language models, are increasingly used in automated driving to interpret scenes, recommend actions, and generate natural language explanations. However, existing evaluation methods primarily assess outcome based performance, such as safety and trajectory accuracy, without determining whether model decisions reflect human relevant considerations. As a result, it remains unclear whether explanations produced by such models correspond to genuine reason responsive decision making or merely post hoc rationalizations. This limitation is especially significant in safety critical domains because it can create false confidence. To address this gap, we propose CARE Drive, Context Aware Reasons Evaluation for Driving, a model agnostic framework for evaluating reason responsiveness in vision language models applied to automated driving. CARE Drive compares baseline and reason augmented model decisions under controlled contextual variation to assess whether human reasons causally influence decision behavior. The framework employs a two stage evaluation process. Prompt calibration ensures stable outputs. Systematic contextual perturbation then measures decision sensitivity to human reasons such as safety margins, social pressure, and efficiency constraints. We demonstrate CARE Drive in a cyclist overtaking scenario involving competing normative considerations. Results show that explicit human reasons significantly influence model decisions, improving alignment with expert recommended behavior. However, responsiveness varies across contextual factors, indicating uneven sensitivity to different types of reasons. These findings provide empirical evidence that reason responsiveness in foundation models can be systematically evaluated without modifying model parameters.

</details>


### [103] [PERSONA: Dynamic and Compositional Inference-Time Personality Control via Activation Vector Algebra](https://arxiv.org/abs/2602.15669)
*Xiachong Feng,Liang Zhao,Weihong Zhong,Yichong Huang,Yuxuan Gu,Lingpeng Kong,Xiaocheng Feng,Bing Qin*

Main category: cs.AI

TL;DR: PERSONA框架无需训练，通过激活空间中的人格向量操作实现人格控制，性能接近微调水平，支持动态组合和代数操作。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型人格控制方法依赖静态提示或昂贵的微调，无法捕捉人类特质的动态性和组合性，需要更灵活高效的解决方案。

Method: 提出PERSONA三阶段框架：1) Persona-Base通过对比激活分析提取正交特质向量；2) Persona-Algebra通过向量代数实现精确控制（标量乘法调强度、加法组合、减法抑制）；3) Persona-Flow在推理时动态组合向量实现上下文感知适应。

Result: 在PersonalityBench上获得9.60平均分，接近监督微调上限9.61；在Persona-Evolve动态人格适应基准上，在不同模型家族中获得高达91%的胜率。

Conclusion: LLM人格特质在数学上是可处理的，为可解释和高效的行为控制开辟了新方向，无需梯度更新即可实现接近微调水平的性能。

Abstract: Current methods for personality control in Large Language Models rely on static prompting or expensive fine-tuning, failing to capture the dynamic and compositional nature of human traits. We introduce PERSONA, a training-free framework that achieves fine-tuning level performance through direct manipulation of personality vectors in activation space. Our key insight is that personality traits appear as extractable, approximately orthogonal directions in the model's representation space that support algebraic operations. The framework operates through three stages: Persona-Base extracts orthogonal trait vectors via contrastive activation analysis; Persona-Algebra enables precise control through vector arithmetic (scalar multiplication for intensity, addition for composition, subtraction for suppression); and Persona-Flow achieves context-aware adaptation by dynamically composing these vectors during inference. On PersonalityBench, our approach achieves a mean score of 9.60, nearly matching the supervised fine-tuning upper bound of 9.61 without any gradient updates. On our proposed Persona-Evolve benchmark for dynamic personality adaptation, we achieve up to 91% win rates across diverse model families. These results provide evidence that aspects of LLM personality are mathematically tractable, opening new directions for interpretable and efficient behavioral control.

</details>


### [104] [Recursive Concept Evolution for Compositional Reasoning in Large Language Models](https://arxiv.org/abs/2602.15725)
*Sarim Chaudhry*

Main category: cs.AI

TL;DR: RCE框架让预训练语言模型在推理时动态修改内部表示几何，通过生成低秩概念子空间来构建新抽象，显著提升组合推理能力


<details>
  <summary>Details</summary>
Motivation: 现有方法通过扩展token级搜索（如思维链、自一致性、强化学习）来改进推理，但保持模型的潜在表示空间固定。当所需抽象未编码在该空间中时，性能会崩溃。需要让模型能够在推理时修改内部表示几何

Method: 提出递归概念演化（RCE）框架，在检测到表示不足时动态生成低秩概念子空间，通过最小描述长度准则选择子空间，在协同时合并，并通过约束优化进行整合以保持稳定性

Result: 在Mistral-7B上集成RCE，在组合推理基准上取得显著提升：ARC-AGI-2提高12-18点，GPQA和BBH提高8-14点，在MATH和HLE上持续减少深度诱导错误

Conclusion: RCE使预训练语言模型能够在推理时构建新抽象而非仅重组现有抽象，有效解决组合推理中表示空间固定的限制，显著提升复杂推理任务的性能

Abstract: Large language models achieve strong performance on many complex reasoning tasks, yet their accuracy degrades sharply on benchmarks that require compositional reasoning, including ARC-AGI-2, GPQA, MATH, BBH, and HLE. Existing methods improve reasoning by expanding token-level search through chain-of-thought prompting, self-consistency, or reinforcement learning, but they leave the model's latent representation space fixed. When the required abstraction is not already encoded in this space, performance collapses. We propose Recursive Concept Evolution (RCE), a framework that enables pretrained language models to modify their internal representation geometry during inference. RCE introduces dynamically generated low-rank concept subspaces that are spawned when representational inadequacy is detected, selected through a minimum description length criterion, merged when synergistic, and consolidated via constrained optimization to preserve stability. This process allows the model to construct new abstractions rather than recombining existing ones. We integrate RCE with Mistral-7B and evaluate it across compositional reasoning benchmarks. RCE yields 12-18 point gains on ARC-AGI-2, 8-14 point improvements on GPQA and BBH, and consistent reductions in depth-induced error on MATH and HLE.

</details>


### [105] [GlobeDiff: State Diffusion Process for Partial Observability in Multi-Agent Systems](https://arxiv.org/abs/2602.15776)
*Yiqin Yang,Xu Yang,Yuhua Jiang,Ni Mu,Hao Hu,Runpeng Xie,Ziyou Zhang,Siyuan Li,Yuan-Hua Ni,Qianchuan Zhao,Bo Xu*

Main category: cs.AI

TL;DR: 提出GlobeDiff算法，通过多模态扩散过程从局部观测推断全局状态，解决多智能体系统中的部分可观测问题


<details>
  <summary>Details</summary>
Motivation: 多智能体系统中的部分可观测性是有效协调和决策的关键障碍。现有方法如信念状态估计和智能体间通信存在局限：信念方法过于依赖过去经验而未能充分利用全局信息，通信方法缺乏有效利用辅助信息的鲁棒模型。

Method: 提出全局状态扩散算法(GlobeDiff)，将状态推断过程建模为多模态扩散过程。该方法基于局部观测推断全局状态，克服状态估计中的模糊性，同时实现高保真度的全局状态推断。

Result: 证明了GlobeDiff在单模态和多模态分布下的估计误差有界。大量实验结果表明，GlobeDiff实现了优越性能，能够准确推断全局状态。

Conclusion: GlobeDiff通过多模态扩散过程有效解决了多智能体系统中的部分可观测性问题，为全局状态推断提供了新的有效方法。

Abstract: In the realm of multi-agent systems, the challenge of \emph{partial observability} is a critical barrier to effective coordination and decision-making. Existing approaches, such as belief state estimation and inter-agent communication, often fall short. Belief-based methods are limited by their focus on past experiences without fully leveraging global information, while communication methods often lack a robust model to effectively utilize the auxiliary information they provide. To solve this issue, we propose Global State Diffusion Algorithm~(GlobeDiff) to infer the global state based on the local observations. By formulating the state inference process as a multi-modal diffusion process, GlobeDiff overcomes ambiguities in state estimation while simultaneously inferring the global state with high fidelity. We prove that the estimation error of GlobeDiff under both unimodal and multi-modal distributions can be bounded. Extensive experimental results demonstrate that GlobeDiff achieves superior performance and is capable of accurately inferring the global state.

</details>


### [106] [This human study did not involve human subjects: Validating LLM simulations as behavioral evidence](https://arxiv.org/abs/2602.15785)
*Jessica Hullman,David Broska,Huaman Sun,Aaron Shaw*

Main category: cs.AI

TL;DR: 论文探讨了在社会科学实验中使用LLM作为合成参与者的有效性，对比了启发式方法和统计校准两种策略，分析了它们在探索性和验证性研究中的适用性。


<details>
  <summary>Details</summary>
Motivation: 越来越多的研究使用大型语言模型作为合成参与者来生成经济高效且几乎即时的响应，但缺乏关于何时这种模拟能够有效推断人类行为的指导。

Method: 对比两种策略：1）启发式方法通过提示工程、模型微调等减少LLM引起的误差；2）统计校准结合辅助人类数据和统计调整来考虑观察与模拟响应之间的差异。

Result: 启发式方法适用于探索性任务但缺乏验证性研究所需的正式统计保证；统计校准在明确假设下保持有效性，并以比纯人类实验更低的成本提供更精确的因果效应估计。

Conclusion: 两种方法的潜力都取决于LLM对相关人群的近似程度，研究人员不应仅仅关注用LLM替代人类参与者，而应考虑更广泛的机会。

Abstract: A growing literature uses large language models (LLMs) as synthetic participants to generate cost-effective and nearly instantaneous responses in social science experiments. However, there is limited guidance on when such simulations support valid inference about human behavior. We contrast two strategies for obtaining valid estimates of causal effects and clarify the assumptions under which each is suitable for exploratory versus confirmatory research. Heuristic approaches seek to establish that simulated and observed human behavior are interchangeable through prompt engineering, model fine-tuning, and other repair strategies designed to reduce LLM-induced inaccuracies. While useful for many exploratory tasks, heuristic approaches lack the formal statistical guarantees typically required for confirmatory research. In contrast, statistical calibration combines auxiliary human data with statistical adjustments to account for discrepancies between observed and simulated responses. Under explicit assumptions, statistical calibration preserves validity and provides more precise estimates of causal effects at lower cost than experiments that rely solely on human participants. Yet the potential of both approaches depends on how well LLMs approximate the relevant populations. We consider what opportunities are overlooked when researchers focus myopically on substituting LLMs for human participants in a study.

</details>


### [107] [Enhancing Building Semantics Preservation in AI Model Training with Large Language Model Encodings](https://arxiv.org/abs/2602.15791)
*Suhyung Jang,Ghang Lee,Jaekun Lee,Hyunjun Lee*

Main category: cs.AI

TL;DR: 本研究提出使用LLM嵌入作为编码方法，替代传统的one-hot编码，以更好地捕捉建筑语义中对象类型和子类型之间的细微关系，在BIM对象分类任务中取得了更好的性能。


<details>
  <summary>Details</summary>
Motivation: 在AECO行业中，准确表示建筑语义（包括通用对象类型和特定子类型）对于AI模型训练至关重要。传统的编码方法（如one-hot）无法有效传达密切相关的子类型之间的细微关系，限制了AI的语义理解能力。

Method: 提出使用大型语言模型（LLM）嵌入（如OpenAI GPT和Meta LLaMA）作为编码方法，保留建筑语义的细微区别。测试了不同维度的嵌入，包括原始高维LLM嵌入（1,536、3,072或4,096维）和通过Matryoshka表示模型生成的1,024维压缩嵌入。使用GraphSAGE模型对5个高层住宅BIM中的42个建筑对象子类型进行分类。

Result: LLM编码方法优于传统的one-hot基线，其中llama-3（压缩）嵌入实现了0.8766的加权平均F1分数，而one-hot编码为0.8475。结果表明LLM编码在捕捉建筑语义细微差别方面具有优势。

Conclusion: LLM编码方法在增强AI理解复杂、领域特定的建筑语义方面具有潜力。随着LLM和降维技术的不断发展，这种方法在AECO行业的语义精细化任务中具有广泛的应用前景。

Abstract: Accurate representation of building semantics, encompassing both generic object types and specific subtypes, is essential for effective AI model training in the architecture, engineering, construction, and operation (AECO) industry. Conventional encoding methods (e.g., one-hot) often fail to convey the nuanced relationships among closely related subtypes, limiting AI's semantic comprehension. To address this limitation, this study proposes a novel training approach that employs large language model (LLM) embeddings (e.g., OpenAI GPT and Meta LLaMA) as encodings to preserve finer distinctions in building semantics. We evaluated the proposed method by training GraphSAGE models to classify 42 building object subtypes across five high-rise residential building information models (BIMs). Various embedding dimensions were tested, including original high-dimensional LLM embeddings (1,536, 3,072, or 4,096) and 1,024-dimensional compacted embeddings generated via the Matryoshka representation model. Experimental results demonstrated that LLM encodings outperformed the conventional one-hot baseline, with the llama-3 (compacted) embedding achieving a weighted average F1-score of 0.8766, compared to 0.8475 for one-hot encoding. The results underscore the promise of leveraging LLM-based encodings to enhance AI's ability to interpret complex, domain-specific building semantics. As the capabilities of LLMs and dimensionality reduction techniques continue to evolve, this approach holds considerable potential for broad application in semantic elaboration tasks throughout the AECO industry.

</details>


### [108] [Developing AI Agents with Simulated Data: Why, what, and how?](https://arxiv.org/abs/2602.15816)
*Xiaoran Liu,Istvan David*

Main category: cs.AI

TL;DR: 本章介绍了基于仿真的合成数据生成方法，用于解决AI训练中数据不足的问题，并提出了数字孪生AI仿真解决方案的参考框架。


<details>
  <summary>Details</summary>
Motivation: 现代符号AI面临的主要障碍是数据量不足和数据质量不高，而合成数据生成技术需求旺盛。仿真提供了一种系统化的方法来生成多样化的合成数据。

Method: 提出基于仿真的合成数据生成方法，并介绍了一个用于描述、设计和分析数字孪生AI仿真解决方案的参考框架。

Result: 本章介绍了仿真合成数据生成的关键概念、优势和挑战，为AI训练提供了系统化的解决方案。

Conclusion: 仿真为AI训练提供了有效的合成数据生成途径，数字孪生框架为设计和分析AI仿真解决方案提供了系统化的参考。

Abstract: As insufficient data volume and quality remain the key impediments to the adoption of modern subsymbolic AI, techniques of synthetic data generation are in high demand. Simulation offers an apt, systematic approach to generating diverse synthetic data. This chapter introduces the reader to the key concepts, benefits, and challenges of simulation-based synthetic data generation for AI training purposes, and to a reference framework to describe, design, and analyze digital twin-based AI simulation solutions.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [109] [CircuChain: Disentangling Competence and Compliance in LLM Circuit Analysis](https://arxiv.org/abs/2602.15037)
*Mayank Ravishankara*

Main category: cs.SE

TL;DR: CircuChain是一个诊断基准，用于区分LLMs在电路分析中的指令遵循能力和物理推理能力，发现最强模型物理推理近乎完美但指令遵循差，而较弱模型物理推理差但指令遵循好。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs在工程领域接近专家水平，在用户指定约束下的可靠推理变得至关重要。电路分析中，数值正确的解决方案如果违反方法论惯例（如网格方向性或极性分配）仍然不足，这些错误可能在安全关键系统中传播。目前不清楚前沿模型是真正应用基本原理推理还是依赖与明确指令冲突的训练先验。

Method: CircuChain基准包含五个典型电路拓扑的Control/Trap问题对，系统变化符号约定、电流方向和极性定义。采用多阶段验证流程，结合符号求解器、SPICE仿真和基于LLM的错误分类法，精细归因失败原因。

Result: 观察到一致的"遵循-能力分歧"现象：最强模型物理推理近乎完美，但在Trap条件下违反约定率高；较弱模型物理保真度低但遵循明确指令更好。模型能力增强不保证约束对齐改进。

Conclusion: CircuChain提供了一个评估框架，强调在数学严格领域下的指令遵循，为工程教育和AI对齐研究提供可行见解。需要新的评估框架来测试数学严格领域下的指令遵循能力。

Abstract: As large language models (LLMs) advance toward expert-level performance in engineering domains, reliable reasoning under user-specified constraints becomes critical. In circuit analysis, for example, a numerically correct solution is insufficient if it violates established methodological conventions such as mesh directionality or polarity assignments, errors that can propagate in safety-critical systems. Yet it remains unclear whether frontier models truly apply first-principles reasoning or rely on entrenched training priors that conflict with explicit instructions. We introduce CircuChain, a diagnostic benchmark designed to disentangle instruction compliance from physical reasoning competence in electrical circuit analysis. CircuChain consists of counterbalanced Control/Trap problem pairs across five canonical circuit topologies, augmented with systematic variations in sign conventions, current orientations, and polarity definitions. A multi-stage verification pipeline, combining symbolic solvers, SPICE simulation, and an LLM-based error taxonomy, enables fine-grained attribution of failures to convention errors, physics errors, arithmetic mistakes, or hallucinations. Across 100 tasks per model, we observe a consistent Compliance-Competence Divergence. The strongest model evaluated exhibits near-perfect physical reasoning but a high rate of convention violations when Trap conditions deliberately invert natural sign patterns. Conversely, weaker models display lower physical fidelity yet superior adherence to explicit instructions. These results suggest that increased model capability does not guarantee improved constraint alignment and highlight the need for new evaluation frameworks that stress instruction-following under mathematically rigid domains. CircuChain provides one such framework and offers actionable insights for both engineering education and AI alignment research.

</details>


### [110] [The Agentic Automation Canvas: a structured framework for agentic AI project design](https://arxiv.org/abs/2602.15090)
*Sebastian Lobentanzer*

Main category: cs.SE

TL;DR: 提出了Agentic Automation Canvas（AAC）框架，用于智能体系统的结构化设计、治理和前瞻性评估，通过语义网兼容的元数据模式实现机器可读性和互操作性。


<details>
  <summary>Details</summary>
Motivation: 当前AI智能体原型部署速度加快，但缺乏结构化设计、治理和前瞻性评估的方法论。现有的AI文档实践（如Model Cards、Datasheets、NIST AI RMF）要么是回顾性的，要么缺乏机器可读性和互操作性。

Method: 开发了Agentic Automation Canvas（AAC）框架，包含六个维度：定义与范围、用户期望与量化效益指标、开发者可行性评估、治理阶段、数据访问与敏感性、结果。实现为语义网兼容的元数据模式，包含受控词汇表和Schema.org、W3C DCAT等现有本体的映射。通过隐私保护的客户端Web应用提供实时验证。

Result: AAC框架能够生成FAIR兼容的RO-Crates，作为用户与开发者之间版本化、可共享、机器互操作的项目合同。提供了开源代码和交互式Web表单。

Conclusion: AAC为智能体系统的结构化设计提供了前瞻性框架，通过机器可读的元数据模式解决了现有AI文档实践的局限性，促进了用户与开发者之间的沟通和项目治理。

Abstract: Agentic AI prototypes are being deployed across domains with increasing speed, yet no methodology for their structured design, governance, and prospective evaluation has been established. Existing AI documentation practices and guidelines - Model Cards, Datasheets, or NIST AI RMF - are either retrospective or lack machine-readability and interoperability. We present the Agentic Automation Canvas (AAC), a structured framework for the prospective design of agentic systems and a tool to facilitate communication between their users and developers. The AAC captures six dimensions of an automation project: definition and scope; user expectations with quantified benefit metrics; developer feasibility assessments; governance staging; data access and sensitivity; and outcomes. The framework is implemented as a semantic web-compatible metadata schema with controlled vocabulary and mappings to established ontologies such as Schema.org and W3C DCAT. It is made accessible through a privacy-preserving, fully client-side web application with real-time validation. Completed canvases export as FAIR-compliant RO-Crates, yielding versioned, shareable, and machine-interoperable project contracts between users and developers. We describe the schema design, benefit quantification model, and prospective application to diverse use cases from research, clinical, and institutional settings. The AAC and its web application are available as open-source code and interactive web form at https://aac.slolab.ai

</details>


### [111] [An Empirical Study on the Effects of System Prompts in Instruction-Tuned Models for Code Generation](https://arxiv.org/abs/2602.15228)
*Zaiyu Cheng,Antonio Mastropaolo*

Main category: cs.SE

TL;DR: 系统提示对代码生成模型的影响研究：详细约束不一定提升正确性，少样本示例可能损害大模型性能，不同编程语言对提示的敏感性差异显著


<details>
  <summary>Details</summary>
Motivation: 尽管指令调优语言模型在代码生成方面取得显著进展，但系统提示对通用ILM和专用CLM的影响尚未得到充分探索。研究者希望系统评估系统提示的详细程度、模型规模、提示策略和编程语言等因素如何影响代码助手性能。

Method: 采用系统化评估方法，在360种配置下进行实验：涵盖4个模型、5种系统提示、3种提示策略、2种编程语言（Python和Java）和2种温度设置。通过对比不同约束级别的系统提示，分析其对代码生成正确性的影响。

Result: 1. 增加系统提示的约束特异性并不总是提高正确性，提示效果取决于配置，可能帮助或阻碍性能；2. 对于较大的代码专用模型，少样本示例可能比零样本生成表现更差；3. 编程语言影响显著，Java对系统提示变化的敏感性远高于Python。

Conclusion: 系统提示对代码生成模型的影响是复杂且配置依赖的，需要针对特定任务、模型和编程语言进行定制化提示工程。传统的"更多约束更好"和"少样本总是有帮助"的假设不一定成立。

Abstract: Instruction-tuned Language Models (ILMs) have become essential components of modern AI systems, demonstrating exceptional versatility across natural language and reasoning tasks. Among their most impactful applications is code generation, where ILMs -- commonly referred to as Code Language Models (CLMs) -- translate human intent into executable programs. While progress has been driven by advances in scaling and training methodologies, one critical aspect remains underexplored: the impact of system prompts on both general-purpose ILMs and specialized CLMs for code generation. We systematically evaluate how system prompts of varying instructional detail, along with model scale, prompting strategy, and programming language, affect code assistant. Our experimental setting spans 360 configurations across four models, five system prompts, three prompting strategies, two languages, and two temperature settings. We find that (1) increasing system-prompt constraint specificity does not monotonically improve correctness -- prompt effectiveness is configuration-dependent and can help or hinder based on alignment with task requirements and decoding context; (2) for larger code-specialized models, few-shot examples can degrade performance relative to zero-shot generation, contrary to conventional wisdom; and (3) programming language matters, with Java exhibiting significantly greater sensitivity to system prompt variations than Python, suggesting language-specific prompt engineering strategies may be necessary.

</details>


### [112] [GenAI for Systems: Recurring Challenges and Design Principles from Software to Silicon](https://arxiv.org/abs/2602.15241)
*Arya Tschand,Chenyu Wang,Zishen Wan,Andrew Cheng,Ioana Cristescu,Kevin He,Howard Huang,Alexander Ingare,Akseli Kangaslahti,Sara Kangaslahti,Theo Lebryk,Hongjin Lin,Jeffrey Jian Ma,Alexandru Meterez,Clara Mohri,Depen Morwani,Sunny Qin,Roy Rinberg,Paula Rodriguez-Diaz,Alyssa Mia Taliotis,Pernille Undrum Fathi,Rosie Zhao,Todd Zhou,Vijay Janapa Reddi*

Main category: cs.SE

TL;DR: 论文从跨栈视角分析生成式AI在计算系统设计中的应用，识别出五个重复出现的挑战和五个有效的设计原则，并提出了共享工程方法论的需求。


<details>
  <summary>Details</summary>
Motivation: 生成式AI正在重塑计算系统的设计、优化和构建方式，但相关研究在软件、架构和芯片设计社区中仍然分散。需要从跨栈视角理解生成式模型如何应用于从代码生成到硬件设计的各个层面，并识别跨层的共同模式和挑战。

Method: 采用跨栈分析方法，审查了超过275篇论文，涵盖计算栈三个层次的十一个应用领域。通过分析不同层级的相似结构问题和有效应对策略，识别出重复出现的挑战和设计原则，并构建了挑战-原则映射框架。

Result: 发现了五个跨层重复出现的挑战：反馈循环危机、隐性知识问题、信任与验证、跨边界协同设计、从确定性到动态性的转变；以及五个独立涌现的有效设计原则：采用混合方法、设计持续反馈机制、按角色分离关注点、匹配方法与问题结构、基于数十年系统知识构建。这些被组织成诊断和设计辅助的挑战-原则映射。

Conclusion: 该领域需要共享的工程方法论，包括共同词汇、跨层基准测试和系统化设计实践，以便进展能够在不同社区间积累而非在每个社区中重新发现。从跨层视角可见开放研究问题，需要跨社区协作来推动生成式AI在计算系统设计中的发展。

Abstract: Generative AI is reshaping how computing systems are designed, optimized, and built, yet research remains fragmented across software, architecture, and chip design communities. This paper takes a cross-stack perspective, examining how generative models are being applied from code generation and distributed runtimes through hardware design space exploration to RTL synthesis, physical layout, and verification. Rather than reviewing each layer in isolation, we analyze how the same structural difficulties and effective responses recur across the stack. Our central finding is one of convergence. Despite the diversity of domains and tools, the field keeps encountering five recurring challenges (the feedback loop crisis, the tacit knowledge problem, trust and validation, co-design across boundaries, and the shift from determinism to dynamism) and keeps arriving at five design principles that independently emerge as effective responses (embracing hybrid approaches, designing for continuous feedback, separating concerns by role, matching methods to problem structure, and building on decades of systems knowledge). We organize these into a challenge--principle map that serves as a diagnostic and design aid, showing which principles have proven effective for which challenges across layers. Through concrete cross-stack examples, we show how systems navigate this map as they mature, and argue that the field needs shared engineering methodology, including common vocabularies, cross-layer benchmarks, and systematic design practices, so that progress compounds across communities rather than being rediscovered in each one. Our analysis covers more than 275 papers spanning eleven application areas across three layers of the computing stack, and distills open research questions that become visible only from a cross-layer vantage point.

</details>


### [113] [SACS: A Code Smell Dataset using Semi-automatic Generation Approach](https://arxiv.org/abs/2602.15342)
*Hanyu Zhang,Tomoji Kishi*

Main category: cs.SE

TL;DR: 提出半自动方法生成高质量代码异味数据集SACS，包含三种常见代码异味，每种超过10,000个标记样本，为代码异味检测研究提供公开基准。


<details>
  <summary>Details</summary>
Motivation: 代码异味研究面临高质量数据集缺乏的挑战。手动构建数据集劳动密集，自动生成的数据集标签可靠性低。需要一种平衡的方法来创建大规模、高质量的代码异味数据集。

Method: 采用半自动方法：1) 应用自动生成规则产生候选异味样本；2) 使用多种指标将样本分为自动接受组和人工审核组；3) 建立结构化审核指南和标注工具支持人工验证。

Result: 创建了开源代码异味数据集SACS，涵盖三种广泛研究的代码异味：长方法、大类、特性嫉妒，每个类别包含超过10,000个标记样本。

Conclusion: 提出的半自动方法能够生成高质量、大规模的代码异味数据集，为代码异味检测和自动重构研究提供了有价值的公开基准资源。

Abstract: Code smell is a great challenge in software refactoring, which indicates latent design or implementation flaws that may degrade the software maintainability and evolution. Over the past of decades, the research on code smell has received extensive attention. Especially the researches applied machine learning-technique have become a popular topic in recent studies. However, one of the biggest challenges to apply machine learning-technique is the lack of high-quality code smell datasets. Manually constructing such datasets is extremely labor-intensive, as identifying code smells requires substantial development expertise and considerable time investment. In contrast, automatically generated datasets, while scalable, frequently exhibit reduced label reliability and compromised data quality. To overcome this challenge, in this study, we explore a semi-automatic approach to generate a code smell dataset with high quality data samples. Specifically, we first applied a set of automatic generation rules to produce candidate smelly samples. We then employed multiple metrics to group the data samples into an automatically accepted group and a manually reviewed group, enabling reviewers to concentrate their efforts on ambiguous samples. Furthermore, we established structured review guidelines and developed a annotation tool to support the manual validation process. Based on the proposed semi-automatic generation approach, we created an open-source code smell dataset, SACS, covering three widely studied code smells: Long Method, Large Class, and Feature Envy. Each code smell category includes over 10,000 labeled samples. This dataset could provide a large-scale and publicly available benchmark to facilitate future studies on code smell detection and automated refactoring.

</details>


### [114] [Latent Regularization in Generative Test Input Generation](https://arxiv.org/abs/2602.15552)
*Giorgi Merabishvili,Oliver Weißl,Andrea Stocco*

Main category: cs.SE

TL;DR: 研究探讨了通过截断对潜在空间进行正则化对深度学习分类器生成测试输入质量的影响，发现潜在代码混合方法比随机截断具有更高的故障检测率，同时提高了多样性和有效性。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探索潜在空间正则化（特别是截断操作）如何影响为深度学习分类器生成的测试输入质量，以改进边界测试的效果。

Method: 使用基于风格的GANs作为生成方法，在MNIST、Fashion MNIST和CIFAR-10三个数据集上评估两种截断策略：1）潜在代码混合与二分搜索优化；2）随机潜在截断用于生成探索。

Result: 实验结果表明，潜在代码混合方法比随机截断具有更高的故障检测率，同时提高了生成测试输入的多样性和有效性。

Conclusion: 潜在空间的正则化通过截断操作可以显著影响生成测试输入的质量，其中潜在代码混合方法在故障检测、多样性和有效性方面均优于随机截断策略。

Abstract: This study investigates the impact of regularization of latent spaces through truncation on the quality of generated test inputs for deep learning classifiers. We evaluate this effect using style-based GANs, a state-of-the-art generative approach, and assess quality along three dimensions: validity, diversity, and fault detection. We evaluate our approach on the boundary testing of deep learning image classifiers across three datasets, MNIST, Fashion MNIST, and CIFAR-10. We compare two truncation strategies: latent code mixing with binary search optimization and random latent truncation for generative exploration. Our experiments show that the latent code-mixing approach yields a higher fault detection rate than random truncation, while also improving both diversity and validity.

</details>


### [115] [Req2Road: A GenAI Pipeline for SDV Test Artifact Generation and On-Vehicle Execution](https://arxiv.org/abs/2602.15591)
*Denesa Zyberaj,Lukasz Mazur,Pascal Hirmer,Nenad Petrovic,Marco Aiello,Alois Knoll*

Main category: cs.SE

TL;DR: 使用LLM和VLM从自然语言需求自动生成可执行的Gherkin测试场景，通过VSS标准化信号引用，在SDV中实现端到端需求到测试的转换管道，在CPDS案例中验证可行性。


<details>
  <summary>Details</summary>
Motivation: 软件定义车辆测试面临挑战：需求用自然语言编写，规范混合文本、表格和图表，测试资产分散在异构工具链中，需要自动化解决方案来提升测试效率和一致性。

Method: 采用大语言模型和视觉语言模型提取信号和行为逻辑，自动生成Gherkin场景，通过车辆信号规范标准化信号引用，使用检索增强生成预选候选VSS信号，最后转换为可运行测试脚本。

Result: 在36个安全相关的儿童存在检测系统需求中，32个（89%）可转换为可执行场景，在虚拟环境和实际车辆中成功执行测试，验证了端到端管道的可行性。

Conclusion: 该方法展示了SDV子系统从需求到测试的端到端管道可行性，虽然仍需人工审查和针对性替换，但为自动化测试生成提供了有效架构示范。

Abstract: Testing functionality in Software-Defined Vehicles is challenging because requirements are written in natural language, specifications combine text, tables, and diagrams, while test assets are scattered across heterogeneous toolchains. Large Language Models and Vision-Language Models are used to extract signals and behavioral logic to automatically generate Gherkin scenarios, which are then converted into runnable test scripts. The Vehicle Signal Specification (VSS) integration standardizes signal references, supporting portability across subsystems and test benches. The pipeline uses retrieval-augmented generation to preselect candidate VSS signals before mapping. We evaluate the approach on the safety-relevant Child Presence Detection System, executing the generated tests in a virtual environment and on an actual vehicle. Our evaluation covers Gherkin validity, VSS mapping quality, and end-to-end executability. Results show that 32 of 36 requirements (89\%) can be transformed into executable scenarios in our setting, while human review and targeted substitutions remain necessary. This paper is a feasibility and architectural demonstration of an end-to-end requirements-to-test pipeline for SDV subsystems, evaluated on a CPDS case in simulation and Vehicle-in-the-Loop settings.

</details>


### [116] [A Differential Fuzzing-Based Evaluation of Functional Equivalence in LLM-Generated Code Refactorings](https://arxiv.org/abs/2602.15761)
*Simantika Bhattacharjee Dristi,Matthew B. Dwyer*

Main category: cs.SE

TL;DR: LLM生成的代码重构存在显著的功能非等价问题（19-35%），现有测试套件会漏检约21%的非等价重构，需要差分模糊测试来更准确地评估功能等价性。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在自动化代码重构中的广泛应用，评估和确保LLM生成的重构代码与原始实现之间的功能等价性变得至关重要。现有方法通常依赖预定义测试用例评估正确性，但这种方法存在局限性。

Method: 采用差分模糊测试来检查LLM生成代码重构的功能等价性。该方法无需预定义测试用例，通过执行和比较数千个自动生成的测试输入来探索更大的输入空间。在六个LLM（CodeLlama、Codestral、StarChat2、Qwen-2.5、Olmo-3和GPT-4o）上进行了大规模评估，涵盖三个数据集和两种重构类型。

Result: LLM在代码重构中表现出显著的非平凡倾向来改变程序语义，产生19-35%的功能非等价重构。实验进一步表明，约21%的这些非等价重构在三个评估数据集的现有测试套件中未被检测到。

Conclusion: 依赖现有测试可能会高估LLM生成代码重构中的功能等价性，这些重构仍然容易出现语义分歧。差分模糊测试提供了一种更全面评估功能等价性的方法，揭示了现有测试方法的不足。

Abstract: With the rapid adoption of large language models (LLMs) in automated code refactoring, assessing and ensuring functional equivalence between LLM-generated refactoring and the original implementation becomes critical. While prior work typically relies on predefined test cases to evaluate correctness, in this work, we leverage differential fuzzing to check functional equivalence in LLM-generated code refactorings. Unlike test-based evaluation, a differential fuzzing-based equivalence checker needs no predefined test cases and can explore a much larger input space by executing and comparing thousands of automatically generated test inputs. In a large-scale evaluation of six LLMs (CodeLlama, Codestral, StarChat2, Qwen-2.5, Olmo-3, and GPT-4o) across three datasets and two refactoring types, we find that LLMs show a non-trivial tendency to alter program semantics, producing 19-35% functionally non-equivalent refactorings. Our experiments further demonstrate that about 21% of these non-equivalent refactorings remain undetected by the existing test suites of the three evaluated datasets. Collectively, the findings of this study imply that reliance on existing tests might overestimate functional equivalence in LLM-generated code refactorings, which remain prone to semantic divergence.

</details>


### [117] [Automated Multi-Source Debugging and Natural Language Error Explanation for Dashboard Applications](https://arxiv.org/abs/2602.15362)
*Devendra Tata,Mona Rajhans*

Main category: cs.SE

TL;DR: 提出一个自动化多源调试和自然语言错误解释系统，通过收集浏览器、API、服务器等多源错误数据，利用大语言模型生成自然语言解释，将晦涩错误代码转化为可操作见解。


<details>
  <summary>Details</summary>
Motivation: 现代微服务架构虽然提供了可扩展性，但带来了调试和可观测性的重大挑战。当故障发生时，通常只向终端用户显示"出了点问题"等模糊错误信息，掩盖了浏览器端异常、API契约违规或服务器端逻辑故障等根本原因。现有监控工具孤立地捕获这些事件，但无法有效关联或向非技术用户提供可理解的解释。

Method: 提出一个自动化多源调试和自然语言错误解释框架，自动收集和关联来自浏览器、API、服务器日志等不同来源的错误数据，实时验证API契约，并利用大语言模型生成自然语言解释。

Result: 该方法显著减少了支持工程师的平均解决时间，并通过将晦涩的错误代码转化为可操作的见解，改善了用户体验。

Conclusion: 该论文提出的系统能够有效解决微服务架构中的调试挑战，通过自动化多源数据关联和自然语言解释，提高了故障诊断效率和用户体验。

Abstract: Modern web dashboards and enterprise applications increasingly rely on complex, distributed microservices architectures. While these architectures offer scalability, they introduce significant challenges in debugging and observability. When failures occur, they often manifest as opaque error messages to the end-user such as Something went wrong. This masks the underlying root cause which may reside in browser side exceptions, API contract violations, or server side logic failures. Existing monitoring tools capture these events in isolation but fail to correlate them effectively or provide intelligible explanations to non technical users. This paper proposes a novel system for Automated Multi Source Debugging and Natural Language Error Explanation. The proposed framework automatically collects and correlates error data from disparate sources such as browser, API, server logs and validates API contracts in real time, and utilizes Large Language Models to generate natural language explanations. This approach significantly reduces Mean Time to Resolution for support engineers and improves the user experience by transforming cryptic error codes into actionable insights.

</details>


### [118] [Social Life of Code: Modeling Evolution through Code Embedding and Opinion Dynamics](https://arxiv.org/abs/2602.15412)
*Yulong He,Nikita Verbin,Sergey Kovalchuk*

Main category: cs.SE

TL;DR: 该论文提出了一种结合语义代码嵌入与意见动力学理论的新方法，用于量化分析软件开发过程中的协作动态和演化模式。


<details>
  <summary>Details</summary>
Motivation: 软件仓库记录了开发者的代码相关活动，但传统方法难以深入理解代码库演化的底层动态。需要一种定量框架来分析协作开发过程，揭示开发者社区中隐含的合作模式和知识共享机制。

Method: 1. 使用先进的代码嵌入模型将代码片段编码为高维向量表示，保留语法和语义特征；2. 使用主成分分析进行降维，并进行数据归一化确保可比性；3. 采用表达-私有意见模型建立信任矩阵，跟踪开发周期中的意见轨迹。

Result: 在三个GitHub开源仓库数据上评估该方法，能够揭示可解释的行为趋势和开发者交互变化。结果显示该方法能够反映共识形成、影响力传播和开发者社区中的对齐/分歧演化等底层动态。

Conclusion: 该方法为软件演化提供了原则性的量化方式，通过数据驱动的协作动态分析，为开源项目维护提供了新见解，有助于理解开发者影响力、共识形成和项目可持续性。

Abstract: Software repositories provide a detailed record of software evolution by capturing developer interactions through code-related activities such as pull requests and modifications. To better understand the underlying dynamics of codebase evolution, we introduce a novel approach that integrates semantic code embeddings with opinion dynamics theory, offering a quantitative framework to analyze collaborative development processes. Our approach begins by encoding code snippets into high-dimensional vector representations using state-of-the-art code embedding models, preserving both syntactic and semantic features. These embeddings are then processed using Principal Component Analysis (PCA) for dimensionality reduction, with data normalized to ensure comparability. We model temporal evolution using the Expressed-Private Opinion (EPO) model to derive trust matrices and track opinion trajectories across development cycles. These opinion trajectories reflect the underlying dynamics of consensus formation, influence propagation, and evolving alignment (or divergence) within developer communities -- revealing implicit collaboration patterns and knowledge-sharing mechanisms that are otherwise difficult to observe. By bridging software engineering and computational social science, our method provides a principled way to quantify software evolution, offering new insights into developer influence, consensus formation, and project sustainability. We evaluate our approach on data from three prominent open-source GitHub repositories, demonstrating its ability to reveal interpretable behavioral trends and variations in developer interactions. The results highlight the utility of our framework in improving open-source project maintenance through data-driven analysis of collaboration dynamics.

</details>


### [119] [MMPersistence: A mathematical morphology-oriented software library for computing persistent homology on cubical complexes](https://arxiv.org/abs/2602.15502)
*Chuan-Shen Hu*

Main category: cs.SE

TL;DR: MMPersistence库将数学形态学操作与持久同调结合，通过不同形状的结构元素构建拓扑过滤，为数字图像分析提供更丰富的局部几何信息。


<details>
  <summary>Details</summary>
Motivation: 数学形态学能有效处理图像的局部结构，而立方体同调能捕捉全局拓扑特征。现有方法通常单独使用这两种技术，缺乏一个统一框架来同时利用形态学操作和拓扑分析的优势。

Method: 基于GUDHI包构建MMPersistence库，将数学形态学操作（如腐蚀、膨胀、开闭运算）与不同形状的结构元素结合，构建拓扑过滤来计算持久同调，从而同时编码图像的空间和形态特征。

Result: 提出的基于数学形态学的持久同调框架比传统的立方体同调提供了更丰富的局部几何信息，建立了整合拓扑洞察与形态学图像处理的统一分析基础。

Conclusion: MMPersistence库成功整合了数学形态学操作和持久同调计算，为数字图像分析提供了一个既能处理局部结构又能捕捉全局拓扑特征的综合框架，增强了图像分析的表达能力。

Abstract: Mathematical morphology (MM) is a powerful and widely used framework in image processing. Through set-theoretic and discrete geometric principles, MM operations such as erosion, dilation, opening, and closing effectively manipulate digital images by modifying local structures via structuring elements (SEs), while cubical homology captures global topological features such as connected components and loop structures within images. Building on the GUDHI package for persistent homology (PH) computation on cubical complexes, we propose the MMPersistence library, which integrates MM operations with diverse SEs and PH computation to extract multiscale persistence information. By employing SEs of different shapes to construct topological filtrations, the proposed MM-based PH framework encodes both spatial and morphological characteristics of digital images, providing richer local geometric information than conventional cubical homology alone and establishing a unified foundation for analyzing digital images that integrates topological insight with morphological image processing techniques.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [120] [Exploring Performance Tradeoffs in Age-Aware Remote Monitoring with Satellites](https://arxiv.org/abs/2602.15145)
*Sunjung Kang,Vishrant Tripathi,Christopher G. Brinton*

Main category: cs.NI

TL;DR: 研究多模态远程监控系统（地面IoT传感器、空中移动UAV、周期性卫星），使用信息年龄（AoI）评估信息新鲜度，分析是否应该使用卫星监控数据，提出随机调度策略和Lyapunov最大权重策略。


<details>
  <summary>Details</summary>
Motivation: 多模态监控系统（IoT传感器、UAV、卫星）各有优缺点：IoT覆盖小区域固定，UAV可移动覆盖较大区域，卫星覆盖全区但延迟高可靠性低。需要评估是否应该使用卫星监控更新，这是一个看似简单但实际复杂的问题。

Method: 将监控区域划分为单元格并建模为图，节点代表单元格，边代表UAV移动模式。采用信息年龄（AoI）作为信息新鲜度指标。提出：1）静态随机调度策略的闭式表达式和下界分析；2）Lyapunov风格的最大权重策略；3）详细仿真验证。

Result: 推导出加权和AoI的闭式表达式和下界，分析系统参数变化时的性能权衡。通过仿真为实际系统部署提供关键见解，特别是关于是否应该使用卫星监控更新的决策指导。

Conclusion: 多模态监控系统中是否使用卫星更新是一个复杂问题，需要根据具体系统参数权衡。提出的分析框架和调度策略为实际部署提供了理论指导和实用工具，帮助在IoT传感器、UAV和卫星之间做出最优监控决策。

Abstract: We investigate a remote monitoring framework with multiple sensing modalities including IoT sensors on the ground, mobile UAVs in the air, and a periodically available satellite constellation. While the IoT sensors cover small areas and remain fixed, the UAVs can move between locations and cover larger areas, and the satellites can observe the entire region but have high latency and low reliability. We divide the deployment region into cells and model it as a graph, with the nodes representing individual cells and edges representing possible UAV mobility patterns. To evaluate the freshness of collected information from this graph, we adopt the Age of Information (AoI) metric, measured separately for each cell. Under a given deployment of IoT nodes and UAV mobility patterns, our objective is to ascertain whether the system should actually utilize monitoring updates from satellites - a seemingly simple yet surprisingly elusive question. For stationary randomized scheduling policies, we develop closed-form expressions and lower bounds for the weighted-sum AoI and utilize this analysis to explore performance tradeoffs as system parameters vary. We also provide a Lyapunov style max-weight policy and detailed simulations that provide crucial insights for deploying such systems in practice.

</details>


### [121] [High-Fidelity Network Management for Federated AI-as-a-Service: Cross-Domain Orchestration](https://arxiv.org/abs/2602.15281)
*Merve Saimler,Mohaned Chraiti,Ozgur Ercetin*

Main category: cs.NI

TL;DR: 论文提出基于尾风险包络(TREs)的AIaaS保障管理平面，用于多域联合环境下确保AI服务的高保真度，通过确定性护栏与随机率-延迟-损伤模型结合，优化端到端延迟违规概率。


<details>
  <summary>Details</summary>
Motivation: 通信服务提供商(CSPs)正从纯连接提供商向AIaaS管理网络服务转型，需要解决多域联合环境下AIaaS服务的端到端保障问题，特别是通信损伤(延迟、丢包)和推理损伤(延迟、错误)的联合管理。

Method: 提出基于尾风险包络(TREs)的保障导向AIaaS管理平面，TREs是可组合的每域描述符，结合确定性护栏与随机率-延迟-损伤模型。使用随机网络演算推导串联域端到端延迟违规概率边界，获得优化就绪的风险预算分解。通过租户级预留防止突发流量在TRE合约下膨胀尾部延迟，审计层使用运行时遥测估计极端百分位性能。

Result: 包级蒙特卡洛模拟显示，通过准入控制和在相关突发性下的鲁棒租户隔离，在过载情况下改善了p99.9合规性。TRE框架能够量化不确定性并将尾部风险归因于各域以实现问责。

Conclusion: 基于TREs的AIaaS管理平面为多域联合环境提供了可操作的保障框架，通过可组合的域描述符、风险预算分解和运行时审计，实现了高保真AIaaS服务交付，特别是在过载和突发流量场景下。

Abstract: To support the emergence of AI-as-a-Service (AIaaS), communication service providers (CSPs) are on the verge of a radical transformation-from pure connectivity providers to AIaaS a managed network service (control-and-orchestration plane that exposes AI models). In this model, the CSP is responsible not only for transport/communications, but also for intent-to-model resolution and joint network-compute orchestration, i.e., reliable and timely end-to-end delivery. The resulting end-to-end AIaaS service thus becomes governed by communications impairments (delay, loss) and inference impairments (latency, error). A central open problem is an operational AIaaS control-and-orchestration framework that enforces high fidelity, particularly under multi-domain federation. This paper introduces an assurance-oriented AIaaS management plane based on Tail-Risk Envelopes (TREs): signed, composable per-domain descriptors that combine deterministic guardrails with stochastic rate-latency-impairment models. Using stochastic network calculus, we derive bounds on end-to-end delay violation probabilities across tandem domains and obtain an optimization-ready risk-budget decomposition. We show that tenant-level reservations prevent bursty traffic from inflating tail latency under TRE contracts. An auditing layer then uses runtime telemetry to estimate extreme-percentile performance, quantify uncertainty, and attribute tail-risk to each domain for accountability. Packet-level Monte-Carlo simulations demonstrate improved p99.9 compliance under overload via admission control and robust tenant isolation under correlated burstiness.

</details>


### [122] [AI-Paging: Lease-Based Execution Anchoring for Network-Exposed AI-as-a-Service](https://arxiv.org/abs/2602.15286)
*Merve Saimler,Mohaned Chraiti*

Main category: cs.NI

TL;DR: 提出AI-paging架构，让6G网络服务提供商根据用户意图自动匹配AI模型并选择执行端点，通过控制平面事务实现意图到AI服务身份的解析，确保在策略、信任和QoS约束下的AI服务连续性。


<details>
  <summary>Details</summary>
Motivation: 随着AIaaS在多提供商和多模型层级部署，终端用户难以在运行时选择合适的模型实例。需要6G服务提供商在用户仅提交意图的情况下，帮助完成意图到模型的匹配和执行放置，同时满足策略、信任和QoS约束。

Method: 提出AI-paging架构，作为控制平面事务，将用户意图解析为AI服务身份(AISI)、范围会话令牌(AIST)和过期准入租约(COMMIT)，授权用户平面转向选定的AI执行锚点(AEXF)。采用租约门控转向和先建后断锚定两个不变性。

Result: 原型使用现有控制平面和用户平面机制（基于服务的控制、QoS流和基于策略的转向），无需新包头，兼容现有3GPP架构。评估了事务延迟、重定位中断、租约过期时的执行正确性以及移动性和故障下的审计证据开销。

Conclusion: AI-paging架构使6G网络能够有效管理AIaaS服务的选择和执行，确保在动态网络条件下的服务连续性和可靠性，同时保持与现有3GPP架构的兼容性。

Abstract: With AI-as-a-Service (AIaaS) now deployed across multiple providers and model tiers, selecting the appropriate model instance at run time is increasingly outside the end user's knowledge and operational control. Accordingly, the 6G service providers are envisioned to play a crucial role in exposing AIaaS in a setting where users submit only an intent while the network helps in the intent-to-model matching (resolution) and execution placement under policy, trust, and Quality of Service (QoS) constraints. The network role becomes to discover candidate execution endpoints and selects a suitable model/anchor under policy and QoS constraints in a process referred here to as AI-paging (by analogy to cellular call paging). In the proposed architecture, AI-paging is a control-plane transaction that resolves an intent into an AI service identity (AISI), a scoped session token (AIST), and an expiring admission lease (COMMIT) that authorizes user-plane steering to a selected AI execution anchor (AEXF) under a QoS binding. AI-Paging enforces two invariants: (i) lease-gated steering (without COMMIT, no steering state is installed) and (ii) make-before-break anchoring to support continuity and reliability of AIaaS services under dynamic network conditions. We prototype AI-Paging using existing control- and user-plane mechanisms (service-based control, QoS flows, and policy-based steering) with no new packet headers, ensuring compatibility with existing 3GPP-based exposure and management architectures, and evaluate transaction latency, relocation interruption, enforcement correctness under lease expiry, and audit-evidence overhead under mobility and failures.

</details>


### [123] [AI Sessions for Network-Exposed AI-as-a-Service](https://arxiv.org/abs/2602.15288)
*Merve Saimler,Mohaned Chraiti*

Main category: cs.NI

TL;DR: 提出Network-Exposed AI-as-a-Service (NE-AIaaS)架构，通过AI Session (AIS)服务原语，将模型身份、执行位置、传输QoS等绑定为单一生命周期对象，实现可执行的尾延迟保证、计算感知准入控制和移动连续性。


<details>
  <summary>Details</summary>
Motivation: 当前云端AI推理服务通常作为应用选择的端点，网络仅提供尽力而为传输，这种解耦导致无法强制执行尾延迟保证、计算感知准入控制以及移动连续性，需要新的服务架构来解决这些问题。

Method: 提出AI Session (AIS)服务原语和AI Service Profile (ASP)契约，设计协议级流程：DISCOVER（模型/站点发现）、AI PAGING（上下文感知执行锚点选择）、两阶段PREPARE/COMMIT（原子化协同预留计算和QoS资源）、make-before-break MIGRATION（会话连续性）。

Result: 设计可映射到标准框架：CAPIF风格北向暴露、ETSI MEC执行基板、5G QoS流用于传输执行、NWDAF风格分析用于闭环分页/迁移触发。

Conclusion: NE-AIaaS通过AI Session原语和协议级流程，实现了可执行的AI服务保证，解决了当前AI-as-a-Service在延迟保证、准入控制和移动连续性方面的局限性。

Abstract: Cloud-based Artificial Intelligence (AI) inference is increasingly latency- and context-sensitive, yet today's AI-as-a-Service is typically consumed as an application-chosen endpoint, leaving the network to provide only best-effort transport. This decoupling prevents enforceable tail-latency guarantees, compute-aware admission control, and continuity under mobility. This paper proposes Network-Exposed AI-as-a-Service (NE-AIaaS) built around a new service primitive: the AI Session (AIS)-a contractual object that binds model identity, execution placement, transport Quality-of-Service (QoS), and consent/charging scope into a single lifecycle with explicit failure semantics. We introduce the AI Service Profile (ASP), a compact contract that expresses task modality and measurable service objectives (e.g., time-to-first-response/token, p99 latency, success probability) alongside privacy and mobility constraints. On this basis, we specify protocol-grade procedures for (i) DISCOVER (model/site discovery), (ii) AI PAGING (context-aware selection of execution anchor), (iii) two-phase PREPARE/COMMIT that atomically co-reserves compute and QoS resources, and (iv) make-before-break MIGRATION for session continuity. The design is standard-mappable to Common API Framework (CAPIF) style northbound exposure, ETSI Multi-access Edge Computing (MEC) execution substrates, 5G QoS flows for transport enforcement, and Network Data Analytics Function (NWDAF) style analytics for closed-loop paging/migration triggers.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [124] [The geometry of online conversations and the causal antecedents of conflictual discourse](https://arxiv.org/abs/2602.15600)
*Carlo Santagiustina,Caterina Cruciani*

Main category: cs.SI

TL;DR: 研究在线气候讨论中冲突性语言的前因及互动几何，发现回复延迟与尊重度正相关，与事实性负相关；对话环境存在强烈对齐效应，早期分支响应调节对齐动态


<details>
  <summary>Details</summary>
Motivation: 探究在线线程对话中冲突性语言的因果前因和互动几何结构，理解气候话题讨论中话语冲突如何受时间、对话和树状结构特征影响

Method: 使用LLM提示和平均推断三个注释维度（立场、语气、情感vs事实框架），分析在线论坛线程数据，检验这些维度如何响应讨论的时间、对话和树状结构特征

Result: 线程中连续帖子间延迟越长，回复越尊重；相对于父帖的延迟越长，分歧略少但更情感化（更少事实性）；存在强烈的局部对话环境对齐效应，父帖效应强于兄弟帖效应；早期分支响应调节对齐动态

Conclusion: 在线讨论的冲突动态受时间延迟、对话对齐和树状结构交互影响，不同冲突维度（文明相关vs情感框架）受不同机制调节，为理解在线话语冲突提供了多维度框架

Abstract: This article investigates the causal antecedents of conflictual language and the geometry of interaction in online threaded conversations related to climate change. We employ three annotation dimensions, inferred through LLM prompting and averaging, to capture complementary aspects of discursive conflict (such as stance: agreement vs disagreement; tone: attacking vs respectful; and emotional versus factual framing) and use data from a threaded online forum to examine how these dimensions respond to temporal, conversational, and arborescent structural features of discussions. We show that, as suggested by the literature, longer delays between successive posts in a thread are associated with replies that are, on average, more respectful, whereas longer delays relative to the parent post are associated with slightly less disagreement but more emotional (less factual) language. Second, we characterize alignment with the local conversational environment and find strong convergence both toward the average stance, tone and emotional framing of older sibling posts replying to the same parent and toward those of the parent post itself, with parent post effects generally stronger than sibling effects. We further show that early branch-level responses condition these alignment dynamics, such that parent-child stance alignment is amplified or attenuated depending on whether a branch is initiated in agreement or disagreement with the discussion's root message. These influences are largely additive for civility-related dimensions (attacking vs respectful, disagree vs agree), whereas for emotional versus factual framing there is a significant interaction: alignment with the parent's emotionality is amplified when older siblings are similarly aligned.

</details>


### [125] [SVD Incidence Centrality: A Unified Spectral Framework for Node and Edge Analysis in Directed Networks and Hypergraphs](https://arxiv.org/abs/2602.15736)
*Jorge Luiz Franco,Thomas Peron,Alcebiades Dal Col,Fabiano Petronetto,Filipe Alves Neto Verri,Eric K. Tokuda,Luiz Gustavo Nonato*

Main category: cs.SI

TL;DR: 提出基于奇异值分解的统一谱框架，用于有向网络的节点和边中心性分析，克服传统方法的方向信息丢失和稀疏排名问题。


<details>
  <summary>Details</summary>
Motivation: 现有有向网络中心性度量存在关键限制：要么通过对称化丢弃方向信息，要么产生稀疏、实现依赖的排名，模糊了结构重要性。

Method: 基于关联矩阵的奇异值分解，通过Hodge拉普拉斯算子的伪逆推导顶点和边中心性，形成密集且解析良好的排名。

Result: 该方法产生密集且解析良好的排名，克服了有向图中介中心性常见的稀疏性限制，并在真实世界网络中验证了有效性。

Conclusion: 提出的谱框架为有向网络中心性分析提供了统一方法，自然保留方向信息，支持有原则的枢纽/权威分析，并可扩展到超图。

Abstract: Identifying influential nodes and edges in directed networks remains a fundamental challenge across domains from social influence to biological regulation. Most existing centrality measures face a critical limitation: they either discard directional information through symmetrization or produce sparse, implementation-dependent rankings that obscure structural importance. We introduce a unified spectral framework for centrality analysis in directed networks grounded in the Singular value decomposition of the incidence matrix. The proposed approach derives both vertex and edge centralities via the pseudoinverse of Hodge Laplacians, yielding dense and well-resolved rankings that overcome the sparsity limitations commonly observed in betweenness centrality for directed graphs. Unlike traditional measures that require graph symmetrization, our framework naturally preserves directional information, enabling principled hub/authority analysis while maintaining mathematical consistency through spectral graph theory. The method extends naturally to hypergraphs through the same mathematical foundation. Experimental validation on real-world networks demonstrates the framework's effectiveness across diverse domains where traditional centrality measures encounter limitations due to implementation dependencies and sparse outputs.

</details>
